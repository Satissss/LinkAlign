[
    {
        "instance_id": "bq011",
        "question": "How many pseudo users were active in the last 7 days but inactive in the last 2 days as of January 7, 2021?",
        "external_knowledge": "ga4_obfuscated_sample_ecommerce.events.md",
        "question_toks": [
            "How",
            "many",
            "pseudo",
            "users",
            "were",
            "active",
            "in",
            "the",
            "last",
            "7",
            "days",
            "but",
            "inactive",
            "in",
            "the",
            "last",
            "2",
            "days",
            "as",
            "of",
            "January",
            "7,",
            "2021?"
        ],
        "query": "SELECT\n  COUNT(DISTINCT MDaysUsers.user_pseudo_id) AS n_day_inactive_users_count\nFROM\n  (\n    SELECT\n      user_pseudo_id\n    FROM\n      `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*` AS T\n    CROSS JOIN\n      UNNEST(T.event_params) AS event_params\n    WHERE\n      event_params.key = 'engagement_time_msec' AND event_params.value.int_value > 0\n      /* Has engaged in last M = 7 days */\n      AND event_timestamp > UNIX_MICROS(TIMESTAMP_SUB(TIMESTAMP('2021-01-07 23:59:59'), INTERVAL 7 DAY))\n      /* Include only relevant tables based on the fixed timestamp */\n      AND _TABLE_SUFFIX BETWEEN '20210101' AND '20210107'\n  ) AS MDaysUsers\nLEFT JOIN\n  (\n    SELECT\n      user_pseudo_id\n    FROM\n      `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*` AS T\n    CROSS JOIN\n      UNNEST(T.event_params) AS event_params\n    WHERE\n      event_params.key = 'engagement_time_msec' AND event_params.value.int_value > 0\n      /* Has engaged in last N = 2 days */\n      AND event_timestamp > UNIX_MICROS(TIMESTAMP_SUB(TIMESTAMP('2021-01-07 23:59:59'), INTERVAL 2 DAY))\n      /* Include only relevant tables based on the fixed timestamp */\n      AND _TABLE_SUFFIX BETWEEN '20210105' AND '20210107'\n  ) AS NDaysUsers\nON MDaysUsers.user_pseudo_id = NDaysUsers.user_pseudo_id\nWHERE\n  NDaysUsers.user_pseudo_id IS NULL;",
        "db_id": "ga4",
        "No. of candidate columns": 2116,
        "No. of gold tables": 20
    },
    {
        "instance_id": "bq010",
        "question": "Find the top-selling product among customers who bought 'Youtube Men’s Vintage Henley' in July 2017, excluding itself.",
        "external_knowledge": "google_analytics_sample.ga_sessions.md",
        "question_toks": [
            "Find",
            "the",
            "top-selling",
            "product",
            "among",
            "customers",
            "who",
            "bought",
            "'Youtube",
            "Men’s",
            "Vintage",
            "Henley'",
            "in",
            "July",
            "2017,",
            "excluding",
            "itself."
        ],
        "query": "WITH GET_CUS_ID AS (\n    SELECT \n        DISTINCT fullVisitorId as Henley_CUSTOMER_ID\n    FROM \n        `bigquery-public-data.google_analytics_sample.ga_sessions_201707*`,\n        UNNEST(hits) AS hits,\n        UNNEST(hits.product) as product\n    WHERE\n        product.v2ProductName = \"YouTube Men's Vintage Henley\"\n        AND product.productRevenue IS NOT NULL\n    )\n\nSELECT\n    product.v2ProductName AS other_purchased_products\nFROM\n    `bigquery-public-data.google_analytics_sample.ga_sessions_201707*` TAB_A \n    RIGHT JOIN GET_CUS_ID\n    ON GET_CUS_ID.Henley_CUSTOMER_ID=TAB_A.fullVisitorId,\n    UNNEST(hits) AS hits,\n    UNNEST(hits.product) as product\nWHERE\n    TAB_A.fullVisitorId IN (\n        SELECT * FROM GET_CUS_ID\n    )\n    AND product.v2ProductName <> \"YouTube Men's Vintage Henley\"\n    AND product.productRevenue IS NOT NULL\nGROUP BY\n    product.v2ProductName\nORDER BY\n    SUM(product.productQuantity) DESC\nLIMIT 1;",
        "db_id": "ga360",
        "No. of candidate columns": 5522,
        "No. of gold tables": 20
    },
    {
        "instance_id": "bq268",
        "question": "Identify the longest number of days between the first visit and the last recorded event (either the last visit or the first transaction) for a user, where the last recorded event is associated with a mobile device. The last recorded event could either be the last visit or the first transaction, and you should focus on users whose last recorded event occurred on a mobile device.",
        "external_knowledge": null,
        "question_toks": [
            "Identify",
            "the",
            "longest",
            "number",
            "of",
            "days",
            "between",
            "the",
            "first",
            "visit",
            "and",
            "the",
            "last",
            "recorded",
            "event",
            "(either",
            "the",
            "last",
            "visit",
            "or",
            "the",
            "first",
            "transaction)",
            "for",
            "a",
            "user,",
            "where",
            "the",
            "last",
            "recorded",
            "event",
            "is",
            "associated",
            "with",
            "a",
            "mobile",
            "device.",
            "The",
            "last",
            "recorded",
            "event",
            "could",
            "either",
            "be",
            "the",
            "last",
            "visit",
            "or",
            "the",
            "first",
            "transaction,",
            "and",
            "you",
            "should",
            "focus",
            "on",
            "users",
            "whose",
            "last",
            "recorded",
            "event",
            "occurred",
            "on",
            "a",
            "mobile",
            "device."
        ],
        "query": "",
        "db_id": "ga360",
        "No. of candidate columns": 5522,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq270",
        "question": "What were the monthly add-to-cart and purchase conversion rates, calculated as a percentage of pageviews on product details, from January to March 2017?",
        "external_knowledge": "ga360_hits.eCommerceAction.action_type.md",
        "question_toks": [
            "What",
            "were",
            "the",
            "monthly",
            "add-to-cart",
            "and",
            "purchase",
            "conversion",
            "rates,",
            "calculated",
            "as",
            "a",
            "percentage",
            "of",
            "pageviews",
            "on",
            "product",
            "details,",
            "from",
            "January",
            "to",
            "March",
            "2017?"
        ],
        "query": "WITH\n  cte1 AS\n    (SELECT\n      CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0',\n                EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n      COUNT(hits.eCommerceAction.action_type) AS num_product_view\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n      UNNEST(hits) AS hits\n    WHERE _table_suffix BETWEEN '0101' AND '0331'\n      AND hits.eCommerceAction.action_type = '2'\n    GROUP BY month),\n  cte2 AS\n    (SELECT\n      CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0',\n                EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n      COUNT(hits.eCommerceAction.action_type) AS num_addtocart\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n      UNNEST(hits) AS hits\n    WHERE _table_suffix BETWEEN '0101' AND '0331'\n      AND hits.eCommerceAction.action_type = '3'\n    GROUP BY month),\n  cte3 AS\n    (SELECT\n      CONCAT(EXTRACT(YEAR FROM (PARSE_DATE('%Y%m%d', date))),'0',\n                EXTRACT(MONTH FROM (PARSE_DATE('%Y%m%d', date)))) AS month,\n      COUNT(hits.eCommerceAction.action_type) AS num_purchase\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\n      UNNEST(hits) AS hits,\n      UNNEST(hits.product) AS product\n    WHERE _table_suffix BETWEEN '0101' AND '0331'\n      AND hits.eCommerceAction.action_type = '6'\n      AND product.productRevenue IS NOT NULL\n    GROUP BY month)\nSELECT \n  ROUND((num_addtocart/num_product_view * 100),2) AS add_to_cart_rate,\n  ROUND((num_purchase/num_product_view * 100),2) AS purchase_rate\nFROM cte1\n  LEFT JOIN cte2\n  USING(month) \n  LEFT JOIN cte3\n  USING(month)\nORDER BY month;",
        "db_id": "ga360",
        "No. of candidate columns": 5522,
        "No. of gold tables": 20
    },
    {
        "instance_id": "bq374",
        "question": "Calculates the percentage of new users who, between August 1, 2016, and April 30, 2017, both stayed on the site for more than 5 minutes during their initial visit and made a purchase on a subsequent visit at any later time, relative to the total number of new users in the same period.",
        "external_knowledge": null,
        "question_toks": [
            "Calculates",
            "the",
            "percentage",
            "of",
            "new",
            "users",
            "who,",
            "between",
            "August",
            "1,",
            "2016,",
            "and",
            "April",
            "30,",
            "2017,",
            "both",
            "stayed",
            "on",
            "the",
            "site",
            "for",
            "more",
            "than",
            "5",
            "minutes",
            "during",
            "their",
            "initial",
            "visit",
            "and",
            "made",
            "a",
            "purchase",
            "on",
            "a",
            "subsequent",
            "visit",
            "at",
            "any",
            "later",
            "time,",
            "relative",
            "to",
            "the",
            "total",
            "number",
            "of",
            "new",
            "users",
            "in",
            "the",
            "same",
            "period."
        ],
        "query": "",
        "db_id": "ga360",
        "No. of candidate columns": 5522,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq029",
        "question": "Get the number of patent publications and the average number of inventors per patent in CA every five years from 1960 to 2020, based on when the patents were filed. Focus only on patents with inventor details.",
        "external_knowledge": null,
        "question_toks": [
            "Get",
            "the",
            "number",
            "of",
            "patent",
            "publications",
            "and",
            "the",
            "average",
            "number",
            "of",
            "inventors",
            "per",
            "patent",
            "in",
            "CA",
            "every",
            "five",
            "years",
            "from",
            "1960",
            "to",
            "2020,",
            "based",
            "on",
            "when",
            "the",
            "patents",
            "were",
            "filed.",
            "Focus",
            "only",
            "on",
            "patents",
            "with",
            "inventor",
            "details."
        ],
        "query": "",
        "db_id": "PATENTS",
        "No. of candidate columns": 79,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq026",
        "question": "For the assignee who has been the most active in the patent category 'A61', I'd like to know the five patent jurisdictions code where they filed the most patents during their busiest year, separated by commas.",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "the",
            "assignee",
            "who",
            "has",
            "been",
            "the",
            "most",
            "active",
            "in",
            "the",
            "patent",
            "category",
            "'A61',",
            "I'd",
            "like",
            "to",
            "know",
            "the",
            "five",
            "patent",
            "jurisdictions",
            "code",
            "where",
            "they",
            "filed",
            "the",
            "most",
            "patents",
            "during",
            "their",
            "busiest",
            "year,",
            "separated",
            "by",
            "commas."
        ],
        "query": "",
        "db_id": "PATENTS",
        "No. of candidate columns": 79,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq091",
        "question": "In which year did the assignee with the most applications in the patent category 'A61' file the most?",
        "external_knowledge": null,
        "question_toks": [
            "In",
            "which",
            "year",
            "did",
            "the",
            "assignee",
            "with",
            "the",
            "most",
            "applications",
            "in",
            "the",
            "patent",
            "category",
            "'A61'",
            "file",
            "the",
            "most?"
        ],
        "query": "WITH AA AS (\n    SELECT \n        FIRST_VALUE(\"assignee_harmonized\") OVER (PARTITION BY \"application_number\" ORDER BY \"application_number\") AS assignee_harmonized,\n        FIRST_VALUE(\"filing_date\") OVER (PARTITION BY \"application_number\" ORDER BY \"application_number\") AS filing_date,\n        \"application_number\"\n    FROM \n        PATENTS.PATENTS.PUBLICATIONS AS pubs\n        , LATERAL FLATTEN(input => pubs.\"cpc\") AS c\n    WHERE \n        c.value:\"code\" LIKE 'A61%'\n),\n\nPatentApplications AS (\n    SELECT \n        ANY_VALUE(assignee_harmonized) as assignee_harmonized,\n        ANY_VALUE(filing_date) as filing_date\n    FROM AA\n    GROUP BY \"application_number\"\n),\n\nAssigneeApplications AS (\nSELECT \n    COUNT(*) AS total_applications,\n    a.value::STRING AS assignee_name,\n    CAST(FLOOR(filing_date / 10000) AS INT) AS filing_year\nFROM \n    PatentApplications\n    , LATERAL FLATTEN(input => assignee_harmonized) AS a\nGROUP BY \n    a.value::STRING, filing_year\n),\n\nTotalApplicationsPerAssignee AS (\n    SELECT\n        assignee_name,\n        SUM(total_applications) AS total_applications\n    FROM \n        AssigneeApplications\n    GROUP BY \n        assignee_name\n    ORDER BY \n        total_applications DESC\n    LIMIT 1\n),\n\nMaxYearForTopAssignee AS (\n    SELECT\n        aa.assignee_name,\n        aa.filing_year,\n        aa.total_applications\n    FROM \n        AssigneeApplications aa\n    INNER JOIN\n        TotalApplicationsPerAssignee tapa ON aa.assignee_name = tapa.assignee_name\n    ORDER BY \n        aa.total_applications DESC\n    LIMIT 1\n)\n\nSELECT filing_year\nFROM \n    MaxYearForTopAssignee",
        "db_id": "PATENTS",
        "No. of candidate columns": 79,
        "No. of gold tables": 1
    },
    {
        "instance_id": "sf_bq099",
        "question": "For patent class A01B3, I want to analyze the information of the top 3 assignees based on the total number of applications. Please provide the following five pieces of information: the name of this assignee,  total number of applications, the year with the most applications, the number of applications in that year, and the country code with the most applications during that year.",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "patent",
            "class",
            "A01B3,",
            "I",
            "want",
            "to",
            "analyze",
            "the",
            "information",
            "of",
            "the",
            "top",
            "3",
            "assignees",
            "based",
            "on",
            "the",
            "total",
            "number",
            "of",
            "applications.",
            "Please",
            "provide",
            "the",
            "following",
            "five",
            "pieces",
            "of",
            "information:",
            "the",
            "name",
            "of",
            "this",
            "assignee,",
            "",
            "total",
            "number",
            "of",
            "applications,",
            "the",
            "year",
            "with",
            "the",
            "most",
            "applications,",
            "the",
            "number",
            "of",
            "applications",
            "in",
            "that",
            "year,",
            "and",
            "the",
            "country",
            "code",
            "with",
            "the",
            "most",
            "applications",
            "during",
            "that",
            "year."
        ],
        "query": "WITH PatentApplications AS (\n   SELECT \n        \"assignee_harmonized\" AS assignee_harmonized,\n        \"filing_date\" AS filing_date,\n        \"country_code\" AS country_code,\n        \"application_number\" AS application_number\n    FROM \n        PATENTS.PATENTS.PUBLICATIONS AS pubs,\n        LATERAL FLATTEN(input => pubs.\"cpc\") AS c\n    WHERE c.value:\"code\" LIKE 'A01B3%'\n\n),\n\nAssigneeApplications AS (\n    SELECT \n        COUNT(*) AS year_country_cnt,\n        a.value:\"name\" AS assignee_name,\n        CAST(FLOOR(filing_date / 10000) AS INT) AS filing_year,\n        apps.country_code as country_code\n    FROM \n        PatentApplications as apps,\n        LATERAL FLATTEN(input => assignee_harmonized) AS a\n    GROUP BY \n        assignee_name, filing_year, country_code\n),\n\nRankedApplications AS (\n    SELECT\n        assignee_name,\n        filing_year,\n        country_code,\n        year_country_cnt,\n        SUM(year_country_cnt) OVER (PARTITION BY assignee_name, filing_year) AS total_cnt,\n        ROW_NUMBER() OVER (PARTITION BY assignee_name, filing_year ORDER BY year_country_cnt DESC) AS rn\n    FROM\n        AssigneeApplications\n),\n\nAggregatedData AS (\n    SELECT\n        total_cnt AS year_cnt,\n        assignee_name,\n        filing_year,\n        country_code\n    FROM\n        RankedApplications\n    WHERE\n        rn = 1\n)\n\n\nSELECT \n    total_count,\n    REPLACE(assignee_name, '\"', '') AS assignee_name,\n    year_cnt,\n    filing_year,\n    country_code\nFROM (\n    SELECT \n        year_cnt,\n        assignee_name,\n        filing_year,\n        country_code,\n        SUM(year_cnt) OVER (PARTITION BY assignee_name) AS total_count,\n        ROW_NUMBER() OVER (PARTITION BY assignee_name ORDER BY year_cnt DESC) AS rn\n    FROM\n        AggregatedData\n    ORDER BY assignee_name\n) sub\nWHERE rn = 1\nORDER BY total_count\nDESC\nLIMIT 3",
        "db_id": "PATENTS",
        "No. of candidate columns": 79,
        "No. of gold tables": 1
    },
    {
        "instance_id": "sf_bq033",
        "question": "How many U.S. publications related to IoT (where the abstract includes the phrase 'internet of things') were filed each month from 2008 to 2022, including months with no filings?",
        "external_knowledge": null,
        "question_toks": [
            "How",
            "many",
            "U.S.",
            "publications",
            "related",
            "to",
            "IoT",
            "(where",
            "the",
            "abstract",
            "includes",
            "the",
            "phrase",
            "'internet",
            "of",
            "things')",
            "were",
            "filed",
            "each",
            "month",
            "from",
            "2008",
            "to",
            "2022,",
            "including",
            "months",
            "with",
            "no",
            "filings?"
        ],
        "query": "WITH Patent_Matches AS (\n    SELECT\n      TO_DATE(CAST(ANY_VALUE(patentsdb.\"filing_date\") AS STRING), 'YYYYMMDD') AS Patent_Filing_Date,\n      patentsdb.\"application_number\" AS Patent_Application_Number,\n      MAX(abstract_info.value:\"text\") AS Patent_Title,\n      MAX(abstract_info.value:\"language\") AS Patent_Title_Language\n    FROM\n      PATENTS.PATENTS.PUBLICATIONS AS patentsdb,\n      LATERAL FLATTEN(input => patentsdb.\"abstract_localized\") AS abstract_info\n    WHERE\n      LOWER(abstract_info.value:\"text\") LIKE '%internet of things%'\n      AND patentsdb.\"country_code\" = 'US'\n    GROUP BY\n      Patent_Application_Number\n),\n\nDate_Series_Table AS (\n    SELECT\n        DATEADD(day, seq4(), DATE '2008-01-01') AS day,\n        0 AS Number_of_Patents\n    FROM\n        TABLE(\n            GENERATOR(\n                ROWCOUNT => 5479\n            )\n        )\n    ORDER BY\n        day\n)\n\nSELECT\n  TO_CHAR(Date_Series_Table.day, 'YYYY-MM') AS Patent_Date_YearMonth,\n  COUNT(Patent_Matches.Patent_Application_Number) AS Number_of_Patent_Applications\nFROM\n  Date_Series_Table\n  LEFT JOIN Patent_Matches\n    ON Date_Series_Table.day = Patent_Matches.Patent_Filing_Date\nWHERE\n    Date_Series_Table.day < DATE '2023-01-01'\nGROUP BY\n  TO_CHAR(Date_Series_Table.day, 'YYYY-MM')\nORDER BY\n  Patent_Date_YearMonth;",
        "db_id": "PATENTS",
        "No. of candidate columns": 79,
        "No. of gold tables": 1
    },
    {
        "instance_id": "sf_bq209",
        "question": "Can you find how many utility patents granted in 2010 have exactly one forward citation within the ten years following their application date?",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "find",
            "how",
            "many",
            "utility",
            "patents",
            "granted",
            "in",
            "2010",
            "have",
            "exactly",
            "one",
            "forward",
            "citation",
            "within",
            "the",
            "ten",
            "years",
            "following",
            "their",
            "application",
            "date?"
        ],
        "query": "WITH patents_sample AS (\n    SELECT\n        t1.\"publication_number\",\n        t1.\"application_number\"\n    FROM\n        PATENTS.PATENTS.PUBLICATIONS t1\n    WHERE\n        TO_DATE(\n            CASE\n                WHEN t1.\"grant_date\" != 0 THEN TO_CHAR(t1.\"grant_date\")\n                ELSE NULL\n            END, \n            'YYYYMMDD'\n        ) BETWEEN TO_DATE('20100101', 'YYYYMMDD') AND TO_DATE('20101231', 'YYYYMMDD')\n),\nforward_citation AS (\n    SELECT\n        patents_sample.\"publication_number\",\n        COUNT(DISTINCT t3.\"citing_application_number\") AS \"forward_citations\"\n    FROM\n        patents_sample\n        LEFT JOIN (\n            SELECT\n                x2.\"publication_number\",\n                TO_DATE(\n                    CASE\n                        WHEN x2.\"filing_date\" != 0 THEN TO_CHAR(x2.\"filing_date\")\n                        ELSE NULL\n                    END,\n                    'YYYYMMDD'\n                ) AS \"filing_date\"\n            FROM\n                PATENTS.PATENTS.PUBLICATIONS x2\n            WHERE\n                x2.\"filing_date\" != 0\n        ) t2\n            ON t2.\"publication_number\" = patents_sample.\"publication_number\"\n        LEFT JOIN (\n            SELECT\n                x3.\"publication_number\" AS \"citing_publication_number\",\n                x3.\"application_number\" AS \"citing_application_number\",\n                TO_DATE(\n                    CASE\n                        WHEN x3.\"filing_date\" != 0 THEN TO_CHAR(x3.\"filing_date\")\n                        ELSE NULL\n                    END,\n                    'YYYYMMDD'\n                ) AS \"joined_filing_date\",\n                cite.value:\"publication_number\"::STRING AS \"cited_publication_number\"\n            FROM\n                PATENTS.PATENTS.PUBLICATIONS x3,\n                LATERAL FLATTEN(INPUT => x3.\"citation\") cite\n            WHERE\n                x3.\"filing_date\" != 0\n        ) t3\n            ON patents_sample.\"publication_number\" = t3.\"cited_publication_number\"\n            AND t3.\"joined_filing_date\" BETWEEN t2.\"filing_date\" AND DATEADD(YEAR, 10, t2.\"filing_date\")\n    GROUP BY\n        patents_sample.\"publication_number\"\n)\n\nSELECT\n    COUNT(*)\nFROM\n    forward_citation\nWHERE\n    \"forward_citations\" = 1;",
        "db_id": "PATENTS",
        "No. of candidate columns": 79,
        "No. of gold tables": 3
    },
    {
        "instance_id": "sf_bq027",
        "question": "For patents granted between 2010 and 2018, provide the publication number of each patent and the number of backward citations it has received in the SEA category.",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "patents",
            "granted",
            "between",
            "2010",
            "and",
            "2018,",
            "provide",
            "the",
            "publication",
            "number",
            "of",
            "each",
            "patent",
            "and",
            "the",
            "number",
            "of",
            "backward",
            "citations",
            "it",
            "has",
            "received",
            "in",
            "the",
            "SEA",
            "category."
        ],
        "query": "",
        "db_id": "PATENTS",
        "No. of candidate columns": 79,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq211",
        "question": "Among patents granted between 2010 and 2023 in CN, how many of them belong to families that have a total of over one distinct applications?",
        "external_knowledge": null,
        "question_toks": [
            "Among",
            "patents",
            "granted",
            "between",
            "2010",
            "and",
            "2023",
            "in",
            "CN,",
            "how",
            "many",
            "of",
            "them",
            "belong",
            "to",
            "families",
            "that",
            "have",
            "a",
            "total",
            "of",
            "over",
            "one",
            "distinct",
            "applications?"
        ],
        "query": "",
        "db_id": "PATENTS",
        "No. of candidate columns": 79,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq212",
        "question": "For United States utility patents under the B2 classification granted between June and September of 2022, identify the most frequent 4-digit IPC code for each patent. Then, list the publication numbers and IPC4 codes of patents where this code appears 10 or more times.",
        "external_knowledge": "patents_info.md",
        "question_toks": [
            "For",
            "United",
            "States",
            "utility",
            "patents",
            "under",
            "the",
            "B2",
            "classification",
            "granted",
            "between",
            "June",
            "and",
            "September",
            "of",
            "2022,",
            "identify",
            "the",
            "most",
            "frequent",
            "4-digit",
            "IPC",
            "code",
            "for",
            "each",
            "patent.",
            "Then,",
            "list",
            "the",
            "publication",
            "numbers",
            "and",
            "IPC4",
            "codes",
            "of",
            "patents",
            "where",
            "this",
            "code",
            "appears",
            "10",
            "or",
            "more",
            "times."
        ],
        "query": "",
        "db_id": "PATENTS",
        "No. of candidate columns": 79,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq214",
        "question": "For United States utility patents under the B2 classification granted between 2010 and 2014, find the one with the most forward citations within a month of its filing date, and identify the most similar patent from the same filing year, regardless of its type.",
        "external_knowledge": "patents_info.md",
        "question_toks": [
            "For",
            "United",
            "States",
            "utility",
            "patents",
            "under",
            "the",
            "B2",
            "classification",
            "granted",
            "between",
            "2010",
            "and",
            "2014,",
            "find",
            "the",
            "one",
            "with",
            "the",
            "most",
            "forward",
            "citations",
            "within",
            "a",
            "month",
            "of",
            "its",
            "filing",
            "date,",
            "and",
            "identify",
            "the",
            "most",
            "similar",
            "patent",
            "from",
            "the",
            "same",
            "filing",
            "year,",
            "regardless",
            "of",
            "its",
            "type."
        ],
        "query": "",
        "db_id": "PATENTS_GOOGLE",
        "No. of candidate columns": 87,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq216",
        "question": "Identify the top five patents filed in the same year as `US-9741766-B2` that are most similar to it based on technological similarities. Please provide the publication numbers.",
        "external_knowledge": "patents_info.md",
        "question_toks": [
            "Identify",
            "the",
            "top",
            "five",
            "patents",
            "filed",
            "in",
            "the",
            "same",
            "year",
            "as",
            "`US-9741766-B2`",
            "that",
            "are",
            "most",
            "similar",
            "to",
            "it",
            "based",
            "on",
            "technological",
            "similarities.",
            "Please",
            "provide",
            "the",
            "publication",
            "numbers."
        ],
        "query": "WITH patents_sample AS (\n    SELECT \n        \"publication_number\", \n        \"application_number\"\n    FROM\n        PATENTS_GOOGLE.PATENTS_GOOGLE.PUBLICATIONS\n    WHERE\n        \"publication_number\" = 'US-9741766-B2'\n),\nflattened_t5 AS (\n    SELECT\n        t5.\"publication_number\",\n        f.value AS element_value,\n        f.index AS pos\n    FROM\n        PATENTS_GOOGLE.PATENTS_GOOGLE.ABS_AND_EMB t5,\n        LATERAL FLATTEN(input => t5.\"embedding_v1\") AS f\n),\nflattened_t6 AS (\n    SELECT\n        t6.\"publication_number\",\n        f.value AS element_value,\n        f.index AS pos\n    FROM\n        PATENTS_GOOGLE.PATENTS_GOOGLE.ABS_AND_EMB t6,\n        LATERAL FLATTEN(input => t6.\"embedding_v1\") AS f\n),\nsimilarities AS (\n    SELECT\n        t1.\"publication_number\" AS base_publication_number,\n        t4.\"publication_number\" AS similar_publication_number,\n        SUM(ft5.element_value * ft6.element_value) AS similarity\n    FROM\n        (SELECT * FROM patents_sample LIMIT 1) t1\n    LEFT JOIN (\n        SELECT \n            x3.\"publication_number\",\n            EXTRACT(YEAR, TO_DATE(CAST(x3.\"filing_date\" AS STRING), 'YYYYMMDD')) AS focal_filing_year\n        FROM \n            PATENTS_GOOGLE.PATENTS_GOOGLE.PUBLICATIONS x3\n        WHERE \n            x3.\"filing_date\" != 0\n    ) t3 ON t3.\"publication_number\" = t1.\"publication_number\"\n    LEFT JOIN (\n        SELECT \n            x4.\"publication_number\",\n            EXTRACT(YEAR, TO_DATE(CAST(x4.\"filing_date\" AS STRING), 'YYYYMMDD')) AS filing_year\n        FROM \n            PATENTS_GOOGLE.PATENTS_GOOGLE.PUBLICATIONS x4\n        WHERE \n            x4.\"filing_date\" != 0\n    ) t4 ON\n        t4.\"publication_number\" != t1.\"publication_number\"\n        AND t3.focal_filing_year = t4.filing_year\n    LEFT JOIN flattened_t5 AS ft5 ON ft5.\"publication_number\" = t1.\"publication_number\"\n    LEFT JOIN flattened_t6 AS ft6 ON ft6.\"publication_number\" = t4.\"publication_number\"\n    AND ft5.pos = ft6.pos  -- Align vector positions\n    GROUP BY\n        t1.\"publication_number\", t4.\"publication_number\"\n)\nSELECT\n    s.similar_publication_number,\n    s.similarity\nFROM (\n    SELECT\n        s.*,\n        ROW_NUMBER() OVER (PARTITION BY s.base_publication_number ORDER BY s.similarity DESC) AS seqnum\n    FROM\n        similarities s\n) s\nWHERE\n    seqnum <= 5;",
        "db_id": "PATENTS_GOOGLE",
        "No. of candidate columns": 87,
        "No. of gold tables": 5
    },
    {
        "instance_id": "sf_bq127",
        "question": "For each publication family whose earliest publication was first published in January 2015, please provide the earliest publication date, the distinct publication numbers, their country codes, the distinct CPC and IPC codes, distinct families (namely, the ids) that cite and are cited by this publication family. Please present all lists as comma-separated values, sorted alphabetically",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "each",
            "publication",
            "family",
            "whose",
            "earliest",
            "publication",
            "was",
            "first",
            "published",
            "in",
            "January",
            "2015,",
            "please",
            "provide",
            "the",
            "earliest",
            "publication",
            "date,",
            "the",
            "distinct",
            "publication",
            "numbers,",
            "their",
            "country",
            "codes,",
            "the",
            "distinct",
            "CPC",
            "and",
            "IPC",
            "codes,",
            "distinct",
            "families",
            "(namely,",
            "the",
            "ids)",
            "that",
            "cite",
            "and",
            "are",
            "cited",
            "by",
            "this",
            "publication",
            "family.",
            "Please",
            "present",
            "all",
            "lists",
            "as",
            "comma-separated",
            "values,",
            "sorted",
            "alphabetically"
        ],
        "query": "WITH fam AS (\n  SELECT DISTINCT\n    \"family_id\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"PUBLICATIONS\"\n),\n\ncrossover AS (\n  SELECT\n    \"publication_number\",\n    \"family_id\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"PUBLICATIONS\"\n),\n\npub AS (\n  SELECT\n    \"family_id\",\n    MIN(\"publication_date\") AS \"publication_date\",\n    LISTAGG(\"publication_number\", ',') WITHIN GROUP (ORDER BY \"publication_number\") AS \"publication_number\",\n    LISTAGG(\"country_code\", ',') WITHIN GROUP (ORDER BY \"country_code\") AS \"country_code\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"PUBLICATIONS\" AS p\n  GROUP BY\n    \"family_id\"\n),\n\ntech_class AS (\n  SELECT\n    p.\"family_id\",\n    LISTAGG(DISTINCT cpc.value:\"code\"::STRING, ',') WITHIN GROUP (ORDER BY cpc.value:\"code\"::STRING) AS \"cpc\",\n    LISTAGG(DISTINCT ipc.value:\"code\"::STRING, ',') WITHIN GROUP (ORDER BY ipc.value:\"code\"::STRING) AS \"ipc\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"PUBLICATIONS\" AS p\n    CROSS JOIN LATERAL FLATTEN(input => p.\"cpc\") AS cpc\n    CROSS JOIN LATERAL FLATTEN(input => p.\"ipc\") AS ipc\n  GROUP BY\n    p.\"family_id\"\n),\n\ncit AS (\n  SELECT\n    p.\"family_id\",\n    LISTAGG(crossover.\"family_id\", ',') WITHIN GROUP (ORDER BY crossover.\"family_id\" ASC) AS \"citation\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"PUBLICATIONS\" AS p\n    CROSS JOIN LATERAL FLATTEN(input => p.\"citation\") AS citation\n    LEFT JOIN\n      crossover\n    ON\n      citation.value:\"publication_number\"::STRING = crossover.\"publication_number\"\n  GROUP BY\n    p.\"family_id\"\n),\n\ntmp_gpr AS (\n  SELECT\n    \"family_id\",\n    LISTAGG(crossover.\"publication_number\", ',') AS \"cited_by_publication_number\"\n  FROM\n    \"PATENTS_GOOGLE\".\"PATENTS_GOOGLE\".\"ABS_AND_EMB\" AS p\n    CROSS JOIN LATERAL FLATTEN(input => p.\"cited_by\") AS cited_by\n    LEFT JOIN\n      crossover\n    ON\n      cited_by.value:\"publication_number\"::STRING = crossover.\"publication_number\"\n  GROUP BY\n    \"family_id\"\n),\n\ngpr AS (\n  SELECT\n    tmp_gpr.\"family_id\",\n    LISTAGG(crossover.\"family_id\", ',') WITHIN GROUP (ORDER BY crossover.\"family_id\" ASC) AS \"cited_by\"\n  FROM\n    tmp_gpr\n    CROSS JOIN LATERAL FLATTEN(input => SPLIT(tmp_gpr.\"cited_by_publication_number\", ',')) AS cited_by_publication_number\n    LEFT JOIN\n      crossover\n    ON\n      cited_by_publication_number.value::STRING = crossover.\"publication_number\"\n  GROUP BY\n    tmp_gpr.\"family_id\"\n)\n\nSELECT\n  fam.\"family_id\",\n  pub.\"publication_date\",\n  pub.\"publication_number\",\n  pub.\"country_code\",\n  tech_class.\"cpc\",\n  tech_class.\"ipc\",\n  cit.\"citation\",\n  gpr.\"cited_by\"\nFROM\n  fam\n  LEFT JOIN pub ON fam.\"family_id\" = pub.\"family_id\"\n  LEFT JOIN tech_class ON fam.\"family_id\" = tech_class.\"family_id\"\n  LEFT JOIN cit ON fam.\"family_id\" = cit.\"family_id\"\n  LEFT JOIN gpr ON fam.\"family_id\" = gpr.\"family_id\"\nWHERE\n  pub.\"publication_date\" BETWEEN 20150101 AND 20150131;",
        "db_id": "PATENTS_GOOGLE",
        "No. of candidate columns": 87,
        "No. of gold tables": 6
    },
    {
        "instance_id": "sf_bq222",
        "question": "Find the CPC technology areas in Germany that had the highest exponential moving average (smoothing factor 0.1) of patent filings per year, specifically for patents granted in December 2016. For each CPC group at level 4, show the full title, CPC group, and the year with the highest exponential moving average of patent filings.",
        "external_knowledge": "sliding_windows_calculation_cpc.md",
        "question_toks": [
            "Find",
            "the",
            "CPC",
            "technology",
            "areas",
            "in",
            "Germany",
            "that",
            "had",
            "the",
            "highest",
            "exponential",
            "moving",
            "average",
            "(smoothing",
            "factor",
            "0.1)",
            "of",
            "patent",
            "filings",
            "per",
            "year,",
            "specifically",
            "for",
            "patents",
            "granted",
            "in",
            "December",
            "2016.",
            "For",
            "each",
            "CPC",
            "group",
            "at",
            "level",
            "4,",
            "show",
            "the",
            "full",
            "title,",
            "CPC",
            "group,",
            "and",
            "the",
            "year",
            "with",
            "the",
            "highest",
            "exponential",
            "moving",
            "average",
            "of",
            "patent",
            "filings."
        ],
        "query": "WITH patent_cpcs AS (\n    SELECT\n        cd.\"parents\",\n        CAST(FLOOR(\"filing_date\" / 10000) AS INT) AS \"filing_year\"\n    FROM (\n        SELECT MAX(\"cpc\") AS \"cpc\", MAX(\"filing_date\") AS \"filing_date\"\n        FROM \"PATENTS\".\"PATENTS\".\"PUBLICATIONS\"\n        WHERE \"application_number\" != ''\n          AND \"country_code\" = 'DE'\n          AND \"grant_date\" >= 20161201\n          AND \"grant_date\" <= 20161231\n        GROUP BY \"application_number\"\n    ), LATERAL FLATTEN(INPUT => \"cpc\") AS cpcs\n    JOIN \"PATENTS\".\"PATENTS\".\"CPC_DEFINITION\" cd ON cd.\"symbol\" = cpcs.value:\"code\"\n    WHERE cpcs.value:\"first\" = TRUE\n      AND \"filing_date\" > 0\n),\nyearly_counts AS (\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        COUNT(*) AS \"cnt\"\n    FROM (\n        SELECT\n            cpc_parent.VALUE AS \"cpc_group\",  -- Corrected reference to flattened \"parents\"\n            \"filing_year\"\n        FROM patent_cpcs,\n             LATERAL FLATTEN(INPUT => \"parents\") AS cpc_parent  -- Corrected reference to flattened \"parents\"\n    )\n    GROUP BY \"cpc_group\", \"filing_year\"\n),\nmoving_avg AS (\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        \"cnt\",\n        AVG(\"cnt\") OVER (PARTITION BY \"cpc_group\" ORDER BY \"filing_year\" ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS \"moving_avg\"\n    FROM yearly_counts\n)\nSELECT \n    c.\"titleFull\",  -- Ensure correct column name (check case)\n    REPLACE(\"cpc_group\", '\"', '') AS \"cpc_group\",\n    MAX(\"filing_year\") AS \"best_filing_year\"\nFROM moving_avg\nJOIN \"PATENTS\".\"PATENTS\".\"CPC_DEFINITION\" c ON \"cpc_group\" = c.\"symbol\"\nWHERE c.\"level\" = 4\nGROUP BY c.\"titleFull\", \"cpc_group\"\nORDER BY c.\"titleFull\", \"cpc_group\" ASC;",
        "db_id": "PATENTS",
        "No. of candidate columns": 79,
        "No. of gold tables": 3
    },
    {
        "instance_id": "sf_bq420",
        "question": "Can you identify the top 5 patents that were initially rejected under section 101 with no allowed claims, based on the length of their granted claims? The patents should have been granted in the US between 2010 and 2023. Additionally, ensure to select the first office action date for each application. Please include their first publication numbers, along with their first publication dates, length of the filed claims and grant dates.",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "identify",
            "the",
            "top",
            "5",
            "patents",
            "that",
            "were",
            "initially",
            "rejected",
            "under",
            "section",
            "101",
            "with",
            "no",
            "allowed",
            "claims,",
            "based",
            "on",
            "the",
            "length",
            "of",
            "their",
            "granted",
            "claims?",
            "The",
            "patents",
            "should",
            "have",
            "been",
            "granted",
            "in",
            "the",
            "US",
            "between",
            "2010",
            "and",
            "2023.",
            "Additionally,",
            "ensure",
            "to",
            "select",
            "the",
            "first",
            "office",
            "action",
            "date",
            "for",
            "each",
            "application.",
            "Please",
            "include",
            "their",
            "first",
            "publication",
            "numbers,",
            "along",
            "with",
            "their",
            "first",
            "publication",
            "dates,",
            "length",
            "of",
            "the",
            "filed",
            "claims",
            "and",
            "grant",
            "dates."
        ],
        "query": "",
        "db_id": "PATENTS_USPTO",
        "No. of candidate columns": 419,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq128",
        "question": "Retrieve the following information for U.S. patents filed between January 1, 2014, and February 1, 2014. The patent title and abstract. The publication date of the patent. The number of backward citations for each patent (i.e., the number of patents cited by the current patent before its filing date). The number of forward citations for each patent within the first 5 years of its publication (i.e., the number of patents that cited the current patent within 5 years after its publication). For each patent, ensure the forward citations are counted only for citations within 5 years after the publication date, and backward citations are counted for citations before the filing date.",
        "external_knowledge": "forward_backward_citation.md",
        "question_toks": [
            "Retrieve",
            "the",
            "following",
            "information",
            "for",
            "U.S.",
            "patents",
            "filed",
            "between",
            "January",
            "1,",
            "2014,",
            "and",
            "February",
            "1,",
            "2014.",
            "The",
            "patent",
            "title",
            "and",
            "abstract.",
            "The",
            "publication",
            "date",
            "of",
            "the",
            "patent.",
            "The",
            "number",
            "of",
            "backward",
            "citations",
            "for",
            "each",
            "patent",
            "(i.e.,",
            "the",
            "number",
            "of",
            "patents",
            "cited",
            "by",
            "the",
            "current",
            "patent",
            "before",
            "its",
            "filing",
            "date).",
            "The",
            "number",
            "of",
            "forward",
            "citations",
            "for",
            "each",
            "patent",
            "within",
            "the",
            "first",
            "5",
            "years",
            "of",
            "its",
            "publication",
            "(i.e.,",
            "the",
            "number",
            "of",
            "patents",
            "that",
            "cited",
            "the",
            "current",
            "patent",
            "within",
            "5",
            "years",
            "after",
            "its",
            "publication).",
            "For",
            "each",
            "patent,",
            "ensure",
            "the",
            "forward",
            "citations",
            "are",
            "counted",
            "only",
            "for",
            "citations",
            "within",
            "5",
            "years",
            "after",
            "the",
            "publication",
            "date,",
            "and",
            "backward",
            "citations",
            "are",
            "counted",
            "for",
            "citations",
            "before",
            "the",
            "filing",
            "date."
        ],
        "query": "SELECT\n    patent.\"title\",\n    patent.\"abstract\",\n    app.\"date\" AS publication_date,\n    filterData.\"bkwdCitations\",\n    filterData.\"fwrdCitations_5\"\nFROM\n    \"PATENTSVIEW\".\"PATENTSVIEW\".\"PATENT\" AS patent\nJOIN\n    \"PATENTSVIEW\".\"PATENTSVIEW\".\"APPLICATION\" AS app\n    ON app.\"patent_id\" = patent.\"id\"\nJOIN (\n    SELECT\n        DISTINCT cpc.\"patent_id\",\n        IFNULL(citation_5.\"bkwdCitations\", 0) AS \"bkwdCitations\",\n        IFNULL(citation_5.\"fwrdCitations_5\", 0) AS \"fwrdCitations_5\"\n    FROM\n        \"PATENTSVIEW\".\"PATENTSVIEW\".\"CPC_CURRENT\" AS cpc\n    LEFT JOIN (\n        SELECT\n            b.\"patent_id\",\n            b.\"bkwdCitations\",\n            f.\"fwrdCitations_5\"\n        FROM (\n            SELECT \n                cited.\"citation_id\" AS \"patent_id\",\n                IFNULL(COUNT(*), 0) AS \"fwrdCitations_5\"\n            FROM \n                \"PATENTSVIEW\".\"PATENTSVIEW\".\"USPATENTCITATION\" AS cited\n            JOIN\n                \"PATENTSVIEW\".\"PATENTSVIEW\".\"APPLICATION\" AS apps\n                ON cited.\"citation_id\" = apps.\"patent_id\"\n            WHERE\n                apps.\"country\" = 'US'\n                AND cited.\"date\" >= apps.\"date\"\n                AND TRY_CAST(cited.\"date\" AS DATE) <= DATEADD(YEAR, 5, TRY_CAST(apps.\"date\" AS DATE)) -- 5-year citation window\n            GROUP BY \n                cited.\"citation_id\"\n        ) AS f\n        JOIN (\n            SELECT \n                cited.\"patent_id\",\n                IFNULL(COUNT(*), 0) AS \"bkwdCitations\"\n            FROM \n                \"PATENTSVIEW\".\"PATENTSVIEW\".\"USPATENTCITATION\" AS cited\n            JOIN\n                \"PATENTSVIEW\".\"PATENTSVIEW\".\"APPLICATION\" AS apps\n                ON cited.\"patent_id\" = apps.\"patent_id\"\n            WHERE\n                apps.\"country\" = 'US'\n                AND cited.\"date\" < apps.\"date\" -- backward citation count\n            GROUP BY \n                cited.\"patent_id\"\n        ) AS b\n        ON b.\"patent_id\" = f.\"patent_id\"\n        WHERE\n            b.\"bkwdCitations\" IS NOT NULL\n            AND f.\"fwrdCitations_5\" IS NOT NULL\n    ) AS citation_5 \n    ON cpc.\"patent_id\" = citation_5.\"patent_id\"\n    WHERE \n        cpc.\"subsection_id\" IN ('C05', 'C06', 'C07', 'C08', 'C09', 'C10', 'C11', 'C12', 'C13')\n        OR cpc.\"group_id\" IN ('A01G', 'A01H', 'A61K', 'A61P', 'A61Q', 'B01F', 'B01J', 'B81B', 'B82B', 'B82Y', 'G01N', 'G16H')\n) AS filterData\nON app.\"patent_id\" = filterData.\"patent_id\"\nWHERE\n    TRY_CAST(app.\"date\" AS DATE) < '2014-02-01' \n    AND TRY_CAST(app.\"date\" AS DATE) >= '2014-01-01';",
        "db_id": "PATENTSVIEW",
        "No. of candidate columns": 304,
        "No. of gold tables": 7
    },
    {
        "instance_id": "sf_bq246",
        "question": "Retrieve U.S. patents with the number of forward citations within the first 3 years after the patent application date (i.e., patents citing the current patent within 3 years). Only include patents with both backward citations within 1 year before the application date and forward citations within 1 year after the application date. The query should focus on specific CPC categories, sort results by backward citations in descending order, and return the patent with the most backward citations, limiting to one result.",
        "external_knowledge": null,
        "question_toks": [
            "Retrieve",
            "U.S.",
            "patents",
            "with",
            "the",
            "number",
            "of",
            "forward",
            "citations",
            "within",
            "the",
            "first",
            "3",
            "years",
            "after",
            "the",
            "patent",
            "application",
            "date",
            "(i.e.,",
            "patents",
            "citing",
            "the",
            "current",
            "patent",
            "within",
            "3",
            "years).",
            "Only",
            "include",
            "patents",
            "with",
            "both",
            "backward",
            "citations",
            "within",
            "1",
            "year",
            "before",
            "the",
            "application",
            "date",
            "and",
            "forward",
            "citations",
            "within",
            "1",
            "year",
            "after",
            "the",
            "application",
            "date.",
            "The",
            "query",
            "should",
            "focus",
            "on",
            "specific",
            "CPC",
            "categories,",
            "sort",
            "results",
            "by",
            "backward",
            "citations",
            "in",
            "descending",
            "order,",
            "and",
            "return",
            "the",
            "patent",
            "with",
            "the",
            "most",
            "backward",
            "citations,",
            "limiting",
            "to",
            "one",
            "result."
        ],
        "query": "SELECT filterData.\"fwrdCitations_3\"\nFROM\n  PATENTSVIEW.PATENTSVIEW.APPLICATION AS app\nJOIN (\n  SELECT DISTINCT \n    cpc.\"patent_id\", \n    IFNULL(citation_3.\"bkwdCitations_3\", 0) AS \"bkwdCitations_3\", \n    IFNULL(citation_3.\"fwrdCitations_3\", 0) AS \"fwrdCitations_3\"\n  FROM\n    PATENTSVIEW.PATENTSVIEW.CPC_CURRENT AS cpc\n  LEFT JOIN (\n    SELECT \n      b.\"patent_id\", \n      b.\"bkwdCitations_3\", \n      f.\"fwrdCitations_3\"\n    FROM \n      (SELECT \n         cited.\"patent_id\",\n         COUNT(*) AS \"fwrdCitations_3\"\n       FROM \n         PATENTSVIEW.PATENTSVIEW.USPATENTCITATION AS cited\n       JOIN\n         PATENTSVIEW.PATENTSVIEW.APPLICATION AS apps\n         ON cited.\"patent_id\" = apps.\"patent_id\"\n       WHERE\n         apps.\"country\" = 'US'\n         AND cited.\"date\" >= apps.\"date\"\n         AND TRY_CAST(cited.\"date\" AS DATE) <= DATEADD(YEAR, 1, TRY_CAST(apps.\"date\" AS DATE)) -- Citation within 1 year\n       GROUP BY \n         cited.\"patent_id\"\n      ) AS f\n    JOIN (\n      SELECT \n        cited.\"patent_id\",\n        COUNT(*) AS \"bkwdCitations_3\"\n      FROM \n        PATENTSVIEW.PATENTSVIEW.USPATENTCITATION AS cited\n      JOIN\n        PATENTSVIEW.PATENTSVIEW.APPLICATION AS apps\n        ON cited.\"patent_id\" = apps.\"patent_id\"\n      WHERE\n        apps.\"country\" = 'US'\n        AND cited.\"date\" < apps.\"date\"\n        AND TRY_CAST(cited.\"date\" AS DATE) >= DATEADD(YEAR, -1, TRY_CAST(apps.\"date\" AS DATE)) -- Citation within 1 year before\n      GROUP BY \n        cited.\"patent_id\"\n    ) AS b\n    ON b.\"patent_id\" = f.\"patent_id\"\n    WHERE \n      b.\"bkwdCitations_3\" IS NOT NULL\n      AND f.\"fwrdCitations_3\" IS NOT NULL\n  ) AS citation_3 \n  ON cpc.\"patent_id\" = citation_3.\"patent_id\"\n) AS filterData\nON app.\"patent_id\" = filterData.\"patent_id\"\nORDER BY filterData.\"bkwdCitations_3\" DESC\nLIMIT 1;",
        "db_id": "PATENTSVIEW",
        "No. of candidate columns": 304,
        "No. of gold tables": 6
    },
    {
        "instance_id": "sf_bq052",
        "question": "Retrieve the following information for U.S. patents: The patent ID, title, and application date. The number of backward citations within 1 month before the application date (i.e., patents that cited the current patent before its application). The number of forward citations within 1 month after the application date (i.e., patents that cited the current patent after its application). The abstract text of the patent. Only include patents that belong to specific CPC categories, such as subsection 'C05' or group 'A01G'. The query should filter patents to include only those that have at least one backward citation or one forward citation in the 1-month period specified. Sort the results by application date and return all matching records.",
        "external_knowledge": null,
        "question_toks": [
            "Retrieve",
            "the",
            "following",
            "information",
            "for",
            "U.S.",
            "patents:",
            "The",
            "patent",
            "ID,",
            "title,",
            "and",
            "application",
            "date.",
            "The",
            "number",
            "of",
            "backward",
            "citations",
            "within",
            "1",
            "month",
            "before",
            "the",
            "application",
            "date",
            "(i.e.,",
            "patents",
            "that",
            "cited",
            "the",
            "current",
            "patent",
            "before",
            "its",
            "application).",
            "The",
            "number",
            "of",
            "forward",
            "citations",
            "within",
            "1",
            "month",
            "after",
            "the",
            "application",
            "date",
            "(i.e.,",
            "patents",
            "that",
            "cited",
            "the",
            "current",
            "patent",
            "after",
            "its",
            "application).",
            "The",
            "abstract",
            "text",
            "of",
            "the",
            "patent.",
            "Only",
            "include",
            "patents",
            "that",
            "belong",
            "to",
            "specific",
            "CPC",
            "categories,",
            "such",
            "as",
            "subsection",
            "'C05'",
            "or",
            "group",
            "'A01G'.",
            "The",
            "query",
            "should",
            "filter",
            "patents",
            "to",
            "include",
            "only",
            "those",
            "that",
            "have",
            "at",
            "least",
            "one",
            "backward",
            "citation",
            "or",
            "one",
            "forward",
            "citation",
            "in",
            "the",
            "1-month",
            "period",
            "specified.",
            "Sort",
            "the",
            "results",
            "by",
            "application",
            "date",
            "and",
            "return",
            "all",
            "matching",
            "records."
        ],
        "query": "SELECT\n    app.\"patent_id\" AS \"patent_id\",\n    patent.\"title\",\n    app.\"date\" AS \"application_date\",\n    filterData.\"bkwdCitations_1\",\n    filterData.\"fwrdCitations_1\",\n    summary.\"text\" AS \"summary_text\"\nFROM\n    PATENTSVIEW.PATENTSVIEW.BRF_SUM_TEXT AS summary\nJOIN\n    PATENTSVIEW.PATENTSVIEW.PATENT AS patent\n    ON summary.\"patent_id\" = patent.\"id\"\nJOIN\n    PATENTSVIEW.PATENTSVIEW.APPLICATION AS app\n    ON app.\"patent_id\" = summary.\"patent_id\"\nJOIN (\n    SELECT DISTINCT\n        cpc.\"patent_id\",\n        IFNULL(citation_1.\"bkwdCitations_1\", 0) AS \"bkwdCitations_1\",\n        IFNULL(citation_1.\"fwrdCitations_1\", 0) AS \"fwrdCitations_1\"\n    FROM\n        PATENTSVIEW.PATENTSVIEW.CPC_CURRENT AS cpc\n    JOIN (\n        SELECT\n            b.\"patent_id\",\n            b.\"bkwdCitations_1\",\n            f.\"fwrdCitations_1\"\n        FROM (\n            SELECT\n                cited.\"patent_id\",\n                COUNT(*) AS \"fwrdCitations_1\"\n            FROM\n                PATENTSVIEW.PATENTSVIEW.USPATENTCITATION AS cited\n            JOIN\n                PATENTSVIEW.PATENTSVIEW.APPLICATION AS apps\n                ON cited.\"patent_id\" = apps.\"patent_id\"\n            WHERE\n                apps.\"country\" = 'US'\n                AND cited.\"date\" >= apps.\"date\"\n                AND TRY_CAST(cited.\"date\" AS DATE) <= DATEADD(MONTH, 1, TRY_CAST(apps.\"date\" AS DATE)) -- Citation within 1 month\n            GROUP BY\n                cited.\"patent_id\"\n        ) AS f\n        JOIN (\n            SELECT\n                cited.\"patent_id\",\n                COUNT(*) AS \"bkwdCitations_1\"\n            FROM\n                PATENTSVIEW.PATENTSVIEW.USPATENTCITATION AS cited\n            JOIN\n                PATENTSVIEW.PATENTSVIEW.APPLICATION AS apps\n                ON cited.\"patent_id\" = apps.\"patent_id\"\n            WHERE\n                apps.\"country\" = 'US'\n                AND cited.\"date\" < apps.\"date\"\n                AND TRY_CAST(cited.\"date\" AS DATE) >= DATEADD(MONTH, -1, TRY_CAST(apps.\"date\" AS DATE)) -- Citation within 1 month before\n            GROUP BY\n                cited.\"patent_id\"\n        ) AS b\n        ON b.\"patent_id\" = f.\"patent_id\"\n        WHERE\n            b.\"bkwdCitations_1\" IS NOT NULL\n            AND f.\"fwrdCitations_1\" IS NOT NULL\n            AND (b.\"bkwdCitations_1\" > 0 OR f.\"fwrdCitations_1\" > 0)\n    ) AS citation_1\n    ON cpc.\"patent_id\" = citation_1.\"patent_id\"\n    WHERE\n        cpc.\"subsection_id\" = 'C05'\n        OR cpc.\"group_id\" = 'A01G'\n) AS filterData\nON app.\"patent_id\" = filterData.\"patent_id\"\nORDER BY app.\"date\";",
        "db_id": "PATENTSVIEW",
        "No. of candidate columns": 304,
        "No. of gold tables": 8
    },
    {
        "instance_id": "sf_bq036",
        "question": "What was the average number of GitHub commits made per month in 2016 for repositories containing Python code?",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "was",
            "the",
            "average",
            "number",
            "of",
            "GitHub",
            "commits",
            "made",
            "per",
            "month",
            "in",
            "2016",
            "for",
            "repositories",
            "containing",
            "Python",
            "code?"
        ],
        "query": "",
        "db_id": "GITHUB_REPOS",
        "No. of candidate columns": 34,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq224",
        "question": "Which repository with an approved license in `licenses.md` had the highest combined total of forks, issues, and watches in April 2022?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "repository",
            "with",
            "an",
            "approved",
            "license",
            "in",
            "`licenses.md`",
            "had",
            "the",
            "highest",
            "combined",
            "total",
            "of",
            "forks,",
            "issues,",
            "and",
            "watches",
            "in",
            "April",
            "2022?"
        ],
        "query": "WITH allowed_repos AS (\n    SELECT \n        \"repo_name\",\n        \"license\"\n    FROM \n        GITHUB_REPOS_DATE.GITHUB_REPOS.LICENSES\n    WHERE \n        \"license\" IN (\n            'gpl-3.0', 'artistic-2.0', 'isc', 'cc0-1.0', 'epl-1.0', 'gpl-2.0',\n            'mpl-2.0', 'lgpl-2.1', 'bsd-2-clause', 'apache-2.0', 'mit', 'lgpl-3.0'\n        )\n),\nwatch_counts AS (\n    SELECT \n        TRY_PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\",\n        COUNT(DISTINCT TRY_PARSE_JSON(\"actor\"):\"login\"::STRING) AS \"watches\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._202204\n    WHERE \n        \"type\" = 'WatchEvent'\n    GROUP BY \n        TRY_PARSE_JSON(\"repo\"):\"name\"\n),\nissue_counts AS (\n    SELECT \n        TRY_PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\",\n        COUNT(*) AS \"issue_events\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._202204\n    WHERE \n        \"type\" = 'IssuesEvent'\n    GROUP BY \n        TRY_PARSE_JSON(\"repo\"):\"name\"\n),\nfork_counts AS (\n    SELECT \n        TRY_PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\",\n        COUNT(*) AS \"forks\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._202204\n    WHERE \n        \"type\" = 'ForkEvent'\n    GROUP BY \n        TRY_PARSE_JSON(\"repo\"):\"name\"\n)\nSELECT \n    ar.\"repo_name\"\nFROM \n    allowed_repos AS ar\nINNER JOIN \n    fork_counts AS fc ON ar.\"repo_name\" = fc.\"repo\"\nINNER JOIN \n    issue_counts AS ic ON ar.\"repo_name\" = ic.\"repo\"\nINNER JOIN \n    watch_counts AS wc ON ar.\"repo_name\" = wc.\"repo\"\nORDER BY \n    (fc.\"forks\" + ic.\"issue_events\" + wc.\"watches\") DESC\nLIMIT 1;",
        "db_id": "GITHUB_REPOS_DATE",
        "No. of candidate columns": 304,
        "No. of gold tables": 1
    },
    {
        "instance_id": "sf_bq192",
        "question": "Find the most active Python repository on GitHub based on watcher count, issues, and forks. The query should select repositories with specific open-source licenses (`artistic-2.0`, `isc`, `mit`, `apache-2.0`), count distinct watchers, issue events, and forks for each repository in April 2022, and include only those with `.py` files on the `master` branch. Join the license data with watch counts, issue events, and fork counts, then sort by a combined metric of forks, issues, and watches, returning the name and count of the most active repository.",
        "external_knowledge": null,
        "question_toks": [
            "Find",
            "the",
            "most",
            "active",
            "Python",
            "repository",
            "on",
            "GitHub",
            "based",
            "on",
            "watcher",
            "count,",
            "issues,",
            "and",
            "forks.",
            "The",
            "query",
            "should",
            "select",
            "repositories",
            "with",
            "specific",
            "open-source",
            "licenses",
            "(`artistic-2.0`,",
            "`isc`,",
            "`mit`,",
            "`apache-2.0`),",
            "count",
            "distinct",
            "watchers,",
            "issue",
            "events,",
            "and",
            "forks",
            "for",
            "each",
            "repository",
            "in",
            "April",
            "2022,",
            "and",
            "include",
            "only",
            "those",
            "with",
            "`.py`",
            "files",
            "on",
            "the",
            "`master`",
            "branch.",
            "Join",
            "the",
            "license",
            "data",
            "with",
            "watch",
            "counts,",
            "issue",
            "events,",
            "and",
            "fork",
            "counts,",
            "then",
            "sort",
            "by",
            "a",
            "combined",
            "metric",
            "of",
            "forks,",
            "issues,",
            "and",
            "watches,",
            "returning",
            "the",
            "name",
            "and",
            "count",
            "of",
            "the",
            "most",
            "active",
            "repository."
        ],
        "query": "",
        "db_id": "GITHUB_REPOS",
        "No. of candidate columns": 34,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq180",
        "question": "Get the top 5 most frequently used module names from Python (`.py`) and R (`.r`) scripts, counting occurrences of modules in `import` and `from` statements for Python, and `library()` calls for R. The query should consider only Python and R files, group by module name, and return the top 5 modules ordered by frequency.",
        "external_knowledge": null,
        "question_toks": [
            "Get",
            "the",
            "top",
            "5",
            "most",
            "frequently",
            "used",
            "module",
            "names",
            "from",
            "Python",
            "(`.py`)",
            "and",
            "R",
            "(`.r`)",
            "scripts,",
            "counting",
            "occurrences",
            "of",
            "modules",
            "in",
            "`import`",
            "and",
            "`from`",
            "statements",
            "for",
            "Python,",
            "and",
            "`library()`",
            "calls",
            "for",
            "R.",
            "The",
            "query",
            "should",
            "consider",
            "only",
            "Python",
            "and",
            "R",
            "files,",
            "group",
            "by",
            "module",
            "name,",
            "and",
            "return",
            "the",
            "top",
            "5",
            "modules",
            "ordered",
            "by",
            "frequency."
        ],
        "query": "",
        "db_id": "GITHUB_REPOS",
        "No. of candidate columns": 34,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq249",
        "question": "Please provide a report on the number of occurrences of specific line types across files from the GitHub repository. Categorize a line as 'trailing' if it ends with a blank character, as 'Space' if it starts with a space, and as 'Other' if it meets neither condition. The report should include the total number of occurrences for each category, considering all lines across all files.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "provide",
            "a",
            "report",
            "on",
            "the",
            "number",
            "of",
            "occurrences",
            "of",
            "specific",
            "line",
            "types",
            "across",
            "files",
            "from",
            "the",
            "GitHub",
            "repository.",
            "Categorize",
            "a",
            "line",
            "as",
            "'trailing'",
            "if",
            "it",
            "ends",
            "with",
            "a",
            "blank",
            "character,",
            "as",
            "'Space'",
            "if",
            "it",
            "starts",
            "with",
            "a",
            "space,",
            "and",
            "as",
            "'Other'",
            "if",
            "it",
            "meets",
            "neither",
            "condition.",
            "The",
            "report",
            "should",
            "include",
            "the",
            "total",
            "number",
            "of",
            "occurrences",
            "for",
            "each",
            "category,",
            "considering",
            "all",
            "lines",
            "across",
            "all",
            "files."
        ],
        "query": "",
        "db_id": "GITHUB_REPOS",
        "No. of candidate columns": 34,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq255",
        "question": "How many commit messages are there in repositories that use the 'Shell' programming language and 'apache-2.0' license, where the length of the commit message is more than 5 characters but less than 10,000 characters, and the messages do not start with the word 'merge', 'update' or 'test'?",
        "external_knowledge": null,
        "question_toks": [
            "How",
            "many",
            "commit",
            "messages",
            "are",
            "there",
            "in",
            "repositories",
            "that",
            "use",
            "the",
            "'Shell'",
            "programming",
            "language",
            "and",
            "'apache-2.0'",
            "license,",
            "where",
            "the",
            "length",
            "of",
            "the",
            "commit",
            "message",
            "is",
            "more",
            "than",
            "5",
            "characters",
            "but",
            "less",
            "than",
            "10,000",
            "characters,",
            "and",
            "the",
            "messages",
            "do",
            "not",
            "start",
            "with",
            "the",
            "word",
            "'merge',",
            "'update'",
            "or",
            "'test'?"
        ],
        "query": "SELECT\n  COUNT(commits_table.\"message\") AS \"num_messages\"\nFROM (\n  SELECT\n    L.\"repo_name\",\n    language_struct.value:\"name\"::STRING AS \"language_name\"\n  FROM\n    GITHUB_REPOS.GITHUB_REPOS.LANGUAGES AS L,\n    LATERAL FLATTEN(input => L.\"language\") AS language_struct\n) AS lang_table\nJOIN \n  GITHUB_REPOS.GITHUB_REPOS.LICENSES AS license_table\nON \n  license_table.\"repo_name\" = lang_table.\"repo_name\"\nJOIN (\n  SELECT\n    *\n  FROM\n    GITHUB_REPOS.GITHUB_REPOS.SAMPLE_COMMITS\n) AS commits_table\nON \n  commits_table.\"repo_name\" = lang_table.\"repo_name\"\nWHERE\n  license_table.\"license\" LIKE 'apache-2.0'\n  AND lang_table.\"language_name\" LIKE 'Shell'\n  AND LENGTH(commits_table.\"message\") > 5\n  AND LENGTH(commits_table.\"message\") < 10000\n  AND LOWER(commits_table.\"message\") NOT LIKE 'update%'\n  AND LOWER(commits_table.\"message\") NOT LIKE 'test%'\n  AND LOWER(commits_table.\"message\") NOT LIKE 'merge%';",
        "db_id": "GITHUB_REPOS",
        "No. of candidate columns": 34,
        "No. of gold tables": 3
    },
    {
        "instance_id": "sf_bq251",
        "question": "I want to know the GitHub project URLs for the top 3 most downloaded PyPI packages. First, extract the relevant information from PyPI package metadata, including the project URLs. Filter out only those URLs that link to GitHub. Use a regular expression to clean the GitHub URLs, removing unnecessary parts like `issues`, `pull`, `blob`, and `tree`, leaving only the main repository URL. Then, return the GitHub project URLs of the top 3 most downloaded packages, ensuring that only records with valid GitHub URLs are included. Do not put quotation marks around the final URL.",
        "external_knowledge": null,
        "question_toks": [
            "I",
            "want",
            "to",
            "know",
            "the",
            "GitHub",
            "project",
            "URLs",
            "for",
            "the",
            "top",
            "3",
            "most",
            "downloaded",
            "PyPI",
            "packages.",
            "First,",
            "extract",
            "the",
            "relevant",
            "information",
            "from",
            "PyPI",
            "package",
            "metadata,",
            "including",
            "the",
            "project",
            "URLs.",
            "Filter",
            "out",
            "only",
            "those",
            "URLs",
            "that",
            "link",
            "to",
            "GitHub.",
            "Use",
            "a",
            "regular",
            "expression",
            "to",
            "clean",
            "the",
            "GitHub",
            "URLs,",
            "removing",
            "unnecessary",
            "parts",
            "like",
            "`issues`,",
            "`pull`,",
            "`blob`,",
            "and",
            "`tree`,",
            "leaving",
            "only",
            "the",
            "main",
            "repository",
            "URL.",
            "Then,",
            "return",
            "the",
            "GitHub",
            "project",
            "URLs",
            "of",
            "the",
            "top",
            "3",
            "most",
            "downloaded",
            "packages,",
            "ensuring",
            "that",
            "only",
            "records",
            "with",
            "valid",
            "GitHub",
            "URLs",
            "are",
            "included.",
            "Do",
            "not",
            "put",
            "quotation",
            "marks",
            "around",
            "the",
            "final",
            "URL."
        ],
        "query": "",
        "db_id": "PYPI",
        "No. of candidate columns": 45,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq234",
        "question": "What is the most prescribed medication in each state in 2014?",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "is",
            "the",
            "most",
            "prescribed",
            "medication",
            "in",
            "each",
            "state",
            "in",
            "2014?"
        ],
        "query": "",
        "db_id": "cms_data",
        "No. of candidate columns": 865,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq355",
        "question": "Please tell me the percentage of participants not using quinapril and related medications(Quinapril RxCUI: 35208).",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "tell",
            "me",
            "the",
            "percentage",
            "of",
            "participants",
            "not",
            "using",
            "quinapril",
            "and",
            "related",
            "medications(Quinapril",
            "RxCUI:",
            "35208)."
        ],
        "query": "",
        "db_id": "cms_data",
        "No. of candidate columns": 865,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq032",
        "question": "Can you provide the latitude of the final coordinates for the hurricane that traveled the second longest distance in the North Atlantic during 2020?",
        "external_knowledge": "functions_st_distance.md",
        "question_toks": [
            "Can",
            "you",
            "provide",
            "the",
            "latitude",
            "of",
            "the",
            "final",
            "coordinates",
            "for",
            "the",
            "hurricane",
            "that",
            "traveled",
            "the",
            "second",
            "longest",
            "distance",
            "in",
            "the",
            "North",
            "Atlantic",
            "during",
            "2020?"
        ],
        "query": "WITH hurricane_geometry AS (\n  SELECT\n    * EXCEPT (longitude, latitude),\n    ST_GEOGPOINT(longitude, latitude) AS geom,\n    MAX(usa_wind) OVER (PARTITION BY sid) AS max_wnd_speed\n  FROM\n    `bigquery-public-data.noaa_hurricanes.hurricanes`\n  WHERE\n    season = '2020'\n    AND basin = 'NA'\n    AND name != 'NOT NAMED'\n),\ndist_between_points AS (\n  SELECT\n    sid,\n    name,\n    season,\n    iso_time,\n    max_wnd_speed,\n    geom,\n    ST_DISTANCE(geom, LAG(geom, 1) OVER (PARTITION BY sid ORDER BY iso_time ASC)) / 1000 AS dist\n  FROM\n    hurricane_geometry\n),\ntotal_distances AS (\n  SELECT\n    sid,\n    name,\n    season,\n    iso_time,\n    max_wnd_speed,\n    geom,\n    SUM(dist) OVER (PARTITION BY sid ORDER BY iso_time ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_distance,\n    SUM(dist) OVER (PARTITION BY sid) AS total_dist\n  FROM\n    dist_between_points\n),\nranked_hurricanes AS (\n  SELECT\n    *,\n    DENSE_RANK() OVER (ORDER BY total_dist DESC) AS dense_rank\n  FROM\n    total_distances\n)\n\nSELECT\n  ST_Y(geom)\nFROM\n  ranked_hurricanes\nWHERE\n  dense_rank = 2\nORDER BY\ncumulative_distance\nDESC\nLIMIT 1\n;",
        "db_id": "noaa_data",
        "No. of candidate columns": 7278,
        "No. of gold tables": 1
    },
    {
        "instance_id": "bq119",
        "question": "Please show information of the hurricane with the third longest total travel distance in the North Atlantic during 2020, including its travel coordinates, the cumulative travel distance at each point, and the maximum sustained wind speed at those times.",
        "external_knowledge": "functions_st_distance.md",
        "question_toks": [
            "Please",
            "show",
            "information",
            "of",
            "the",
            "hurricane",
            "with",
            "the",
            "third",
            "longest",
            "total",
            "travel",
            "distance",
            "in",
            "the",
            "North",
            "Atlantic",
            "during",
            "2020,",
            "including",
            "its",
            "travel",
            "coordinates,",
            "the",
            "cumulative",
            "travel",
            "distance",
            "at",
            "each",
            "point,",
            "and",
            "the",
            "maximum",
            "sustained",
            "wind",
            "speed",
            "at",
            "those",
            "times."
        ],
        "query": "WITH hurricane_geometry AS (\n  SELECT\n    * EXCEPT (longitude, latitude),\n    ST_GEOGPOINT(longitude, latitude) AS geom,\n  FROM\n    `bigquery-public-data.noaa_hurricanes.hurricanes`\n  WHERE\n    season = '2020'\n    AND basin = 'NA'\n    AND name != 'NOT NAMED'\n),\ndist_between_points AS (\n  SELECT\n    sid,\n    name,\n    season,\n    iso_time,\n    usa_wind,\n    geom,\n    ST_DISTANCE(geom, LAG(geom, 1) OVER (PARTITION BY sid ORDER BY iso_time ASC)) / 1000 AS dist\n  FROM\n    hurricane_geometry\n),\ntotal_distances AS (\n  SELECT\n    sid,\n    name,\n    season,\n    iso_time,\n    usa_wind,\n    geom,\n    SUM(dist) OVER (PARTITION BY sid ORDER BY iso_time ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_distance,\n    SUM(dist) OVER (PARTITION BY sid) AS total_dist\n  FROM\n    dist_between_points\n),\nranked_hurricanes AS (\n  SELECT\n    *,\n    DENSE_RANK() OVER (ORDER BY total_dist DESC) AS dense_rank\n  FROM\n    total_distances\n)\n\nSELECT\n  geom,cumulative_distance,usa_wind\nFROM\n  ranked_hurricanes\nWHERE\n  dense_rank = 3\nORDER BY\ncumulative_distance;",
        "db_id": "noaa_data",
        "No. of candidate columns": 7278,
        "No. of gold tables": 1
    },
    {
        "instance_id": "sf_bq117",
        "question": "What is the total number of severe storm events that occurred in the most affected month over the past 15 years according to NOAA records, considering only the top 100 storm events with the highest property damage?",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "is",
            "the",
            "total",
            "number",
            "of",
            "severe",
            "storm",
            "events",
            "that",
            "occurred",
            "in",
            "the",
            "most",
            "affected",
            "month",
            "over",
            "the",
            "past",
            "15",
            "years",
            "according",
            "to",
            "NOAA",
            "records,",
            "considering",
            "only",
            "the",
            "top",
            "100",
            "storm",
            "events",
            "with",
            "the",
            "highest",
            "property",
            "damage?"
        ],
        "query": "",
        "db_id": "NOAA_DATA",
        "No. of candidate columns": 7275,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq419",
        "question": "Which 5 states had the most storm events from 1980 to 1995, considering only the top 1000 states with the highest event counts each year? Please use state abbreviations.",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "5",
            "states",
            "had",
            "the",
            "most",
            "storm",
            "events",
            "from",
            "1980",
            "to",
            "1995,",
            "considering",
            "only",
            "the",
            "top",
            "1000",
            "states",
            "with",
            "the",
            "highest",
            "event",
            "counts",
            "each",
            "year?",
            "Please",
            "use",
            "state",
            "abbreviations."
        ],
        "query": "",
        "db_id": "noaa_data",
        "No. of candidate columns": 7278,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq071",
        "question": "Can you provide the count of hurricanes and a list of hurricane names (sorted alphabetically and separated by commas) for each city and its associated zip code, where the hurricanes fall within the boundaries of the zip codes? Please exclude any unnamed hurricanes, and sort the results by the count of hurricanes in descending order. The output should include the following columns: city, zip code, state, count of hurricanes, and the list of hurricanes.",
        "temporal": "Yes",
        "external_knowledge": "functions_st_within.md",
        "question_toks": [
            "Can",
            "you",
            "provide",
            "the",
            "count",
            "of",
            "hurricanes",
            "and",
            "a",
            "list",
            "of",
            "hurricane",
            "names",
            "(sorted",
            "alphabetically",
            "and",
            "separated",
            "by",
            "commas)",
            "for",
            "each",
            "city",
            "and",
            "its",
            "associated",
            "zip",
            "code,",
            "where",
            "the",
            "hurricanes",
            "fall",
            "within",
            "the",
            "boundaries",
            "of",
            "the",
            "zip",
            "codes?",
            "Please",
            "exclude",
            "any",
            "unnamed",
            "hurricanes,",
            "and",
            "sort",
            "the",
            "results",
            "by",
            "the",
            "count",
            "of",
            "hurricanes",
            "in",
            "descending",
            "order.",
            "The",
            "output",
            "should",
            "include",
            "the",
            "following",
            "columns:",
            "city,",
            "zip",
            "code,",
            "state,",
            "count",
            "of",
            "hurricanes,",
            "and",
            "the",
            "list",
            "of",
            "hurricanes."
        ],
        "query": "",
        "db_id": "NOAA_DATA_PLUS",
        "No. of candidate columns": 7450,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq236",
        "question": "What are the top 5 zip codes of the areas in the United States that have experienced the most hail storm events in the past 10 years? Don't use data from hail reports table.",
        "temporal": "Yes",
        "external_knowledge": "functions_st_within.md",
        "question_toks": [
            "What",
            "are",
            "the",
            "top",
            "5",
            "zip",
            "codes",
            "of",
            "the",
            "areas",
            "in",
            "the",
            "United",
            "States",
            "that",
            "have",
            "experienced",
            "the",
            "most",
            "hail",
            "storm",
            "events",
            "in",
            "the",
            "past",
            "10",
            "years?",
            "Don't",
            "use",
            "data",
            "from",
            "hail",
            "reports",
            "table."
        ],
        "query": "SELECT\n  CONCAT(\"city\", ', ', \"state_name\") AS \"city\",\n  \"zip_code\",\n  COUNT(\"event_id\") AS \"count_storms\"\nFROM (\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2014\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2015\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2016\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2017\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2018\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2019\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2020\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2021\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2022\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2023\n    UNION ALL\n    SELECT *\n    FROM NOAA_DATA_PLUS.NOAA_HISTORIC_SEVERE_STORMS.STORMS_2024\n) AS storms\nJOIN NOAA_DATA_PLUS.GEO_US_BOUNDARIES.ZIP_CODES\n  ON ST_WITHIN(ST_GEOGFROMWKB(storms.\"event_point\"), ST_GEOGFROMWKB(\"zip_code_geom\"))\nWHERE\n   LOWER(storms.\"event_type\") = 'hail'\nGROUP BY\n  \"zip_code\", \n  \"city\", \n  \"state_name\"\nORDER BY\n  \"count_storms\" DESC\nLIMIT 5;",
        "db_id": "NOAA_DATA_PLUS",
        "No. of candidate columns": 7450,
        "No. of gold tables": 12
    },
    {
        "instance_id": "bq394",
        "question": "What are the top 3 months between 2010 and 2014 with the smallest sum of absolute differences between the average air temperature, wet bulb temperature, dew point temperature, and sea surface temperature, including respective years and sum of differences? Please present the year and month in numerical format.",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "are",
            "the",
            "top",
            "3",
            "months",
            "between",
            "2010",
            "and",
            "2014",
            "with",
            "the",
            "smallest",
            "sum",
            "of",
            "absolute",
            "differences",
            "between",
            "the",
            "average",
            "air",
            "temperature,",
            "wet",
            "bulb",
            "temperature,",
            "dew",
            "point",
            "temperature,",
            "and",
            "sea",
            "surface",
            "temperature,",
            "including",
            "respective",
            "years",
            "and",
            "sum",
            "of",
            "differences?",
            "Please",
            "present",
            "the",
            "year",
            "and",
            "month",
            "in",
            "numerical",
            "format."
        ],
        "query": "",
        "db_id": "noaa_data",
        "No. of candidate columns": 7278,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq357",
        "question": "What are the latitude and longitude coordinates and dates between 2005 and 2015 with the top 5 highest daily average wind speeds, excluding records with missing wind speed values? Using data from tables start with prefix \"icoads_core\".",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "are",
            "the",
            "latitude",
            "and",
            "longitude",
            "coordinates",
            "and",
            "dates",
            "between",
            "2005",
            "and",
            "2015",
            "with",
            "the",
            "top",
            "5",
            "highest",
            "daily",
            "average",
            "wind",
            "speeds,",
            "excluding",
            "records",
            "with",
            "missing",
            "wind",
            "speed",
            "values?",
            "Using",
            "data",
            "from",
            "tables",
            "start",
            "with",
            "prefix",
            "\"icoads_core\"."
        ],
        "query": "",
        "db_id": "noaa_data",
        "No. of candidate columns": 7278,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq181",
        "question": "What percentage of weather stations recorded valid temperature data (with no missing or invalid values) for at least 90% of the days in 2022, where the temperature, maximum, and minimum values are neither NULL nor equal to 9999.9, and the station has a valid identifier (USAF code not equal to '999999'), out of all available stations in the NOAA GSOD database?",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "percentage",
            "of",
            "weather",
            "stations",
            "recorded",
            "valid",
            "temperature",
            "data",
            "(with",
            "no",
            "missing",
            "or",
            "invalid",
            "values)",
            "for",
            "at",
            "least",
            "90%",
            "of",
            "the",
            "days",
            "in",
            "2022,",
            "where",
            "the",
            "temperature,",
            "maximum,",
            "and",
            "minimum",
            "values",
            "are",
            "neither",
            "NULL",
            "nor",
            "equal",
            "to",
            "9999.9,",
            "and",
            "the",
            "station",
            "has",
            "a",
            "valid",
            "identifier",
            "(USAF",
            "code",
            "not",
            "equal",
            "to",
            "'999999'),",
            "out",
            "of",
            "all",
            "available",
            "stations",
            "in",
            "the",
            "NOAA",
            "GSOD",
            "database?"
        ],
        "query": "",
        "db_id": "noaa_data",
        "No. of candidate columns": 7278,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq358",
        "question": "Can you tell me which bike trip in New York City on July 15, 2015, started and ended in ZIP Code areas with the highest average temperature for that day, as recorded by the Central Park weather station '94728'? If there's more than one trip that meets these criteria, I'd like to know about the one that starts in the smallest ZIP Code and ends in the largest ZIP Code.",
        "temporal": "Yes",
        "external_knowledge": "functions_st_within.md",
        "question_toks": [
            "Can",
            "you",
            "tell",
            "me",
            "which",
            "bike",
            "trip",
            "in",
            "New",
            "York",
            "City",
            "on",
            "July",
            "15,",
            "2015,",
            "started",
            "and",
            "ended",
            "in",
            "ZIP",
            "Code",
            "areas",
            "with",
            "the",
            "highest",
            "average",
            "temperature",
            "for",
            "that",
            "day,",
            "as",
            "recorded",
            "by",
            "the",
            "Central",
            "Park",
            "weather",
            "station",
            "'94728'?",
            "If",
            "there's",
            "more",
            "than",
            "one",
            "trip",
            "that",
            "meets",
            "these",
            "criteria,",
            "I'd",
            "like",
            "to",
            "know",
            "about",
            "the",
            "one",
            "that",
            "starts",
            "in",
            "the",
            "smallest",
            "ZIP",
            "Code",
            "and",
            "ends",
            "in",
            "the",
            "largest",
            "ZIP",
            "Code."
        ],
        "query": "SELECT\n    \"ZIPSTART\".\"zip_code\" AS zip_code_start,\n    \"ZIPEND\".\"zip_code\" AS zip_code_end\nFROM  \n    \"NEW_YORK_CITIBIKE_1\".\"NEW_YORK_CITIBIKE\".\"CITIBIKE_TRIPS\" AS \"TRI\"\nINNER JOIN\n    \"NEW_YORK_CITIBIKE_1\".\"GEO_US_BOUNDARIES\".\"ZIP_CODES\" AS \"ZIPSTART\"\n    ON ST_WITHIN(\n        ST_POINT(\"TRI\".\"start_station_longitude\", \"TRI\".\"start_station_latitude\"),\n        ST_GEOGFROMWKB(\"ZIPSTART\".\"zip_code_geom\")\n    )\nINNER JOIN\n    \"NEW_YORK_CITIBIKE_1\".\"GEO_US_BOUNDARIES\".\"ZIP_CODES\" AS \"ZIPEND\"\n    ON ST_WITHIN(\n        ST_POINT(\"TRI\".\"end_station_longitude\", \"TRI\".\"end_station_latitude\"),\n        ST_GEOGFROMWKB(\"ZIPEND\".\"zip_code_geom\")\n    )\nINNER JOIN\n    \"NEW_YORK_CITIBIKE_1\".\"NOAA_GSOD\".\"GSOD2015\" AS \"WEA\"\n    ON TO_DATE(TO_CHAR(\"WEA\".\"year\") || LPAD(TO_CHAR(\"WEA\".\"mo\"), 2, '0') || LPAD(TO_CHAR(\"WEA\".\"da\"), 2, '0'), 'YYYYMMDD') = DATE_TRUNC('DAY', TO_TIMESTAMP_NTZ(TO_NUMBER(\"TRI\".\"starttime\") / 1000000))\nWHERE\n    \"WEA\".\"wban\" = '94728'\n    AND DATE_TRUNC('DAY', TO_TIMESTAMP_NTZ(TO_NUMBER(\"TRI\".\"starttime\") / 1000000)) = DATE '2015-07-15'\nORDER BY \n    \"WEA\".\"temp\" DESC, \"ZIPSTART\".\"zip_code\" ASC, \"ZIPEND\".\"zip_code\" DESC\nLIMIT 1;",
        "db_id": "NEW_YORK_CITIBIKE_1",
        "No. of candidate columns": 3303,
        "No. of gold tables": 4
    },
    {
        "instance_id": "bq290",
        "question": "Can you calculate the difference in maximum temperature, minimum temperature, and average temperature between US and UK weather stations for each day in October 2023, using the date field, and excluding records with missing or invalid temperature values?",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "calculate",
            "the",
            "difference",
            "in",
            "maximum",
            "temperature,",
            "minimum",
            "temperature,",
            "and",
            "average",
            "temperature",
            "between",
            "US",
            "and",
            "UK",
            "weather",
            "stations",
            "for",
            "each",
            "day",
            "in",
            "October",
            "2023,",
            "using",
            "the",
            "date",
            "field,",
            "and",
            "excluding",
            "records",
            "with",
            "missing",
            "or",
            "invalid",
            "temperature",
            "values?"
        ],
        "query": "",
        "db_id": "noaa_data",
        "No. of candidate columns": 7278,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq031",
        "question": "Provide the daily weather data for Rochester from January 1 to March 31, 2019, including temperature (in Celsius), precipitation (in centimeters), and wind speed (in meters per second). For each variable, calculate the 8-day moving average (including the current day and the previous 7 days). Also, calculate the difference between the moving average on each day and the moving averages for the previous 1 to 8 days (i.e., lag1 to lag8). The result should include: The daily values for temperature, precipitation, and wind speed.The 8-day moving averages for each variable. The differences between the moving averages for each of the previous 1 to 8 days (e.g., the difference between today's moving average and the moving average from 1 day ago, from 2 days ago, and so on). Round all values to one decimal place. The data should be ordered by date, starting from January 9, 2019.",
        "external_knowledge": null,
        "question_toks": [
            "Provide",
            "the",
            "daily",
            "weather",
            "data",
            "for",
            "Rochester",
            "from",
            "January",
            "1",
            "to",
            "March",
            "31,",
            "2019,",
            "including",
            "temperature",
            "(in",
            "Celsius),",
            "precipitation",
            "(in",
            "centimeters),",
            "and",
            "wind",
            "speed",
            "(in",
            "meters",
            "per",
            "second).",
            "For",
            "each",
            "variable,",
            "calculate",
            "the",
            "8-day",
            "moving",
            "average",
            "(including",
            "the",
            "current",
            "day",
            "and",
            "the",
            "previous",
            "7",
            "days).",
            "Also,",
            "calculate",
            "the",
            "difference",
            "between",
            "the",
            "moving",
            "average",
            "on",
            "each",
            "day",
            "and",
            "the",
            "moving",
            "averages",
            "for",
            "the",
            "previous",
            "1",
            "to",
            "8",
            "days",
            "(i.e.,",
            "lag1",
            "to",
            "lag8).",
            "The",
            "result",
            "should",
            "include:",
            "The",
            "daily",
            "values",
            "for",
            "temperature,",
            "precipitation,",
            "and",
            "wind",
            "speed.The",
            "8-day",
            "moving",
            "averages",
            "for",
            "each",
            "variable.",
            "The",
            "differences",
            "between",
            "the",
            "moving",
            "averages",
            "for",
            "each",
            "of",
            "the",
            "previous",
            "1",
            "to",
            "8",
            "days",
            "(e.g.,",
            "the",
            "difference",
            "between",
            "today's",
            "moving",
            "average",
            "and",
            "the",
            "moving",
            "average",
            "from",
            "1",
            "day",
            "ago,",
            "from",
            "2",
            "days",
            "ago,",
            "and",
            "so",
            "on).",
            "Round",
            "all",
            "values",
            "to",
            "one",
            "decimal",
            "place.",
            "The",
            "data",
            "should",
            "be",
            "ordered",
            "by",
            "date,",
            "starting",
            "from",
            "January",
            "9,",
            "2019."
        ],
        "query": "WITH transrate AS (\n    SELECT\n        DATE(CAST(year AS INT64), CAST(mo AS INT64), CAST(da AS INT64)) AS observation_date\n        , ROUND((temp - 32.0) / 1.8, 1) AS temp_mean_c -- using Celsius instead of Fahrenheit\n        , ROUND(prcp * 2.54, 1) AS prcp_cm -- from inches to centimeters\n        , ROUND(CAST(wdsp AS FLOAT64) * 1.852 / 3.6, 1) AS wdsp_ms -- from knots to meters per second\n    FROM `bigquery-public-data.noaa_gsod.gsod*`\n    WHERE _TABLE_SUFFIX = \"2019\"\n        AND CAST(mo AS INT64) <= 3\n        AND stn in (SELECT usaf FROM `bigquery-public-data.noaa_gsod.stations` WHERE name = \"ROCHESTER\")\n),\n\nmoving_avg AS (\n    SELECT\n        observation_date\n        , temp_mean_c\n        , prcp_cm\n        , wdsp_ms\n        , AVG(temp_mean_c) OVER (ORDER BY observation_date ROWS 7 PRECEDING) AS temp_moving_avg\n        , AVG(prcp_cm) OVER (ORDER BY observation_date ROWS 7 PRECEDING) AS prcp_moving_avg\n        , AVG(wdsp_ms) OVER (ORDER BY observation_date ROWS 7 PRECEDING) AS wdsp_moving_avg\n    FROM transrate\n),\n\nlag_moving_avg AS (\n    SELECT\n        observation_date\n        , temp_mean_c\n        , prcp_cm\n        , wdsp_ms\n        , LAG(temp_moving_avg, 1) OVER (ORDER BY observation_date) AS lag1_temp_moving_avg\n        , LAG(prcp_moving_avg, 1) OVER (ORDER BY observation_date) AS lag1_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 1) OVER (ORDER BY observation_date) AS lag1_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 2) OVER (ORDER BY observation_date) AS lag2_temp_moving_avg\n        , LAG(prcp_moving_avg, 2) OVER (ORDER BY observation_date) AS lag2_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 2) OVER (ORDER BY observation_date) AS lag2_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 3) OVER (ORDER BY observation_date) AS lag3_temp_moving_avg\n        , LAG(prcp_moving_avg, 3) OVER (ORDER BY observation_date) AS lag3_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 3) OVER (ORDER BY observation_date) AS lag3_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 4) OVER (ORDER BY observation_date) AS lag4_temp_moving_avg\n        , LAG(prcp_moving_avg, 4) OVER (ORDER BY observation_date) AS lag4_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 4) OVER (ORDER BY observation_date) AS lag4_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 5) OVER (ORDER BY observation_date) AS lag5_temp_moving_avg\n        , LAG(prcp_moving_avg, 5) OVER (ORDER BY observation_date) AS lag5_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 5) OVER (ORDER BY observation_date) AS lag5_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 6) OVER (ORDER BY observation_date) AS lag6_temp_moving_avg\n        , LAG(prcp_moving_avg, 6) OVER (ORDER BY observation_date) AS lag6_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 6) OVER (ORDER BY observation_date) AS lag6_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 7) OVER (ORDER BY observation_date) AS lag7_temp_moving_avg\n        , LAG(prcp_moving_avg, 7) OVER (ORDER BY observation_date) AS lag7_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 7) OVER (ORDER BY observation_date) AS lag7_wdsp_moving_avg\n\n        , LAG(temp_moving_avg, 8) OVER (ORDER BY observation_date) AS lag8_temp_moving_avg\n        , LAG(prcp_moving_avg, 8) OVER (ORDER BY observation_date) AS lag8_prcp_moving_avg\n        , LAG(wdsp_moving_avg, 8) OVER (ORDER BY observation_date) AS lag8_wdsp_moving_avg\n    FROM moving_avg\n)\n\nSELECT\n    observation_date\n    , temp_mean_c\n    , prcp_cm\n    , wdsp_ms\n\n    , ROUND(lag1_temp_moving_avg, 1) AS lag1_temp_moving_avg\n    , ROUND(lag1_prcp_moving_avg, 1) AS lag1_prcp_moving_avg\n    , ROUND(lag1_wdsp_moving_avg, 1) AS lag1_wdsp_moving_avg\n    \n    , ROUND(lag1_temp_moving_avg - lag2_temp_moving_avg, 1) AS diff2_temp_moving_avg\n    , ROUND(lag1_prcp_moving_avg - lag2_prcp_moving_avg, 1) AS diff2_prcp_moving_avg\n    , ROUND(lag1_wdsp_moving_avg - lag2_wdsp_moving_avg, 1) AS diff2_wdsp_moving_avg\n    , ROUND(lag2_temp_moving_avg, 1) AS lag2_temp_moving_avg\n    , ROUND(lag2_prcp_moving_avg, 1) AS lag2_prcp_moving_avg\n    , ROUND(lag2_wdsp_moving_avg, 1) AS lag2_wdsp_moving_avg\n    \n    , ROUND(lag2_temp_moving_avg - lag3_temp_moving_avg, 1) AS diff3_temp_moving_avg\n    , ROUND(lag2_prcp_moving_avg - lag3_prcp_moving_avg, 1) AS diff3_prcp_moving_avg\n    , ROUND(lag2_wdsp_moving_avg - lag3_wdsp_moving_avg, 1) AS diff3_wdsp_moving_avg\n    , ROUND(lag3_temp_moving_avg, 1) AS lag3_temp_moving_avg\n    , ROUND(lag3_prcp_moving_avg, 1) AS lag3_prcp_moving_avg\n    , ROUND(lag3_wdsp_moving_avg, 1) AS lag3_wdsp_moving_avg\n    \n    , ROUND(lag3_temp_moving_avg - lag4_temp_moving_avg, 1) AS diff4_temp_moving_avg\n    , ROUND(lag3_prcp_moving_avg - lag4_prcp_moving_avg, 1) AS diff4_prcp_moving_avg\n    , ROUND(lag3_wdsp_moving_avg - lag4_wdsp_moving_avg, 1) AS diff4_wdsp_moving_avg\n    , ROUND(lag4_temp_moving_avg, 1) AS lag4_temp_moving_avg\n    , ROUND(lag4_prcp_moving_avg, 1) AS lag4_prcp_moving_avg\n    , ROUND(lag4_wdsp_moving_avg, 1) AS lag4_wdsp_moving_avg\n    \n    , ROUND(lag4_temp_moving_avg - lag5_temp_moving_avg, 1) AS diff5_temp_moving_avg\n    , ROUND(lag4_prcp_moving_avg - lag5_prcp_moving_avg, 1) AS diff5_prcp_moving_avg\n    , ROUND(lag4_wdsp_moving_avg - lag5_wdsp_moving_avg, 1) AS diff5_wdsp_moving_avg\n    , ROUND(lag5_temp_moving_avg, 1) AS lag5_temp_moving_avg\n    , ROUND(lag5_prcp_moving_avg, 1) AS lag5_prcp_moving_avg\n    , ROUND(lag5_wdsp_moving_avg, 1) AS lag5_wdsp_moving_avg\n    \n    , ROUND(lag5_temp_moving_avg - lag6_temp_moving_avg, 1) AS diff6_temp_moving_avg\n    , ROUND(lag5_prcp_moving_avg - lag6_prcp_moving_avg, 1) AS diff6_prcp_moving_avg\n    , ROUND(lag5_wdsp_moving_avg - lag6_wdsp_moving_avg, 1) AS diff6_wdsp_moving_avg\n    , ROUND(lag6_temp_moving_avg, 1) AS lag6_temp_moving_avg\n    , ROUND(lag6_prcp_moving_avg, 1) AS lag6_prcp_moving_avg\n    , ROUND(lag6_wdsp_moving_avg, 1) AS lag6_wdsp_moving_avg\n    \n    , ROUND(lag6_temp_moving_avg - lag7_temp_moving_avg, 1) AS diff7_temp_moving_avg\n    , ROUND(lag6_prcp_moving_avg - lag7_prcp_moving_avg, 1) AS diff7_prcp_moving_avg\n    , ROUND(lag6_wdsp_moving_avg - lag7_wdsp_moving_avg, 1) AS diff7_wdsp_moving_avg\n    , ROUND(lag7_temp_moving_avg, 1) AS lag7_temp_moving_avg\n    , ROUND(lag7_prcp_moving_avg, 1) AS lag7_prcp_moving_avg\n    , ROUND(lag7_wdsp_moving_avg, 1) AS lag7_wdsp_moving_avg\n    \n    , ROUND(lag7_temp_moving_avg - lag8_temp_moving_avg, 1) AS diff8_temp_moving_avg\n    , ROUND(lag7_prcp_moving_avg - lag8_prcp_moving_avg, 1) AS diff8_prcp_moving_avg\n    , ROUND(lag7_wdsp_moving_avg - lag8_wdsp_moving_avg, 1) AS diff8_wdsp_moving_avg\n    , ROUND(lag8_temp_moving_avg, 1) AS lag8_temp_moving_avg\n    , ROUND(lag8_prcp_moving_avg, 1) AS lag8_prcp_moving_avg\n    , ROUND(lag8_wdsp_moving_avg, 1) AS lag8_wdsp_moving_avg\nFROM lag_moving_avg\nWHERE\n  lag8_temp_moving_avg IS NOT NULL\nORDER BY observation_date;\n-- all result rounded to 1 decimal place",
        "db_id": "noaa_data",
        "No. of candidate columns": 7278,
        "No. of gold tables": 1
    },
    {
        "instance_id": "sf_bq050",
        "question": "I want to analyze bike trips in New York City for 2014 by linking trip data with weather information to understand how weather conditions (temperature, wind speed, and precipitation) affect bike trips between neighborhoods. For each combination of starting and ending neighborhoods, I need the following: 1. Total number of bike trips between the neighborhoods. 2. Average trip duration in minutes (rounded to 1 decimal). 3. Average temperature at the start of the trip (rounded to 1 decimal). 4. Average wind speed at the start (in meters per second, rounded to 1 decimal). 5. Average precipitation at the start (in centimeters, rounded to 1 decimal). 6. The month with the most trips (e.g., `4` for April). The data should be grouped by the starting and ending neighborhoods, with:`zip_codes` in `geo_us_boundaries` used to map the bike trip locations based on latitude and longitude. `zip_codes` in `cyclistic` used to obtain the borough and neighborhood names. Using weather data from the Central Park station for the trip date, covering all trips in 2014.",
        "external_knowledge": "functions_st_within.md",
        "question_toks": [
            "I",
            "want",
            "to",
            "analyze",
            "bike",
            "trips",
            "in",
            "New",
            "York",
            "City",
            "for",
            "2014",
            "by",
            "linking",
            "trip",
            "data",
            "with",
            "weather",
            "information",
            "to",
            "understand",
            "how",
            "weather",
            "conditions",
            "(temperature,",
            "wind",
            "speed,",
            "and",
            "precipitation)",
            "affect",
            "bike",
            "trips",
            "between",
            "neighborhoods.",
            "For",
            "each",
            "combination",
            "of",
            "starting",
            "and",
            "ending",
            "neighborhoods,",
            "I",
            "need",
            "the",
            "following:",
            "1.",
            "Total",
            "number",
            "of",
            "bike",
            "trips",
            "between",
            "the",
            "neighborhoods.",
            "2.",
            "Average",
            "trip",
            "duration",
            "in",
            "minutes",
            "(rounded",
            "to",
            "1",
            "decimal).",
            "3.",
            "Average",
            "temperature",
            "at",
            "the",
            "start",
            "of",
            "the",
            "trip",
            "(rounded",
            "to",
            "1",
            "decimal).",
            "4.",
            "Average",
            "wind",
            "speed",
            "at",
            "the",
            "start",
            "(in",
            "meters",
            "per",
            "second,",
            "rounded",
            "to",
            "1",
            "decimal).",
            "5.",
            "Average",
            "precipitation",
            "at",
            "the",
            "start",
            "(in",
            "centimeters,",
            "rounded",
            "to",
            "1",
            "decimal).",
            "6.",
            "The",
            "month",
            "with",
            "the",
            "most",
            "trips",
            "(e.g.,",
            "`4`",
            "for",
            "April).",
            "The",
            "data",
            "should",
            "be",
            "grouped",
            "by",
            "the",
            "starting",
            "and",
            "ending",
            "neighborhoods,",
            "with:`zip_codes`",
            "in",
            "`geo_us_boundaries`",
            "used",
            "to",
            "map",
            "the",
            "bike",
            "trip",
            "locations",
            "based",
            "on",
            "latitude",
            "and",
            "longitude.",
            "`zip_codes`",
            "in",
            "`cyclistic`",
            "used",
            "to",
            "obtain",
            "the",
            "borough",
            "and",
            "neighborhood",
            "names.",
            "Using",
            "weather",
            "data",
            "from",
            "the",
            "Central",
            "Park",
            "station",
            "for",
            "the",
            "trip",
            "date,",
            "covering",
            "all",
            "trips",
            "in",
            "2014."
        ],
        "query": "WITH data AS (\n    SELECT\n        \"ZIPSTARTNAME\".\"borough\" AS \"borough_start\",\n        \"ZIPSTARTNAME\".\"neighborhood\" AS \"neighborhood_start\",\n        \"ZIPENDNAME\".\"borough\" AS \"borough_end\",\n        \"ZIPENDNAME\".\"neighborhood\" AS \"neighborhood_end\",\n        CAST(\"TRI\".\"tripduration\" / 60 AS NUMERIC) AS \"trip_minutes\",\n        \"WEA\".\"temp\" AS \"temperature\",\n        CAST(\"WEA\".\"wdsp\" AS NUMERIC) AS \"wind_speed\",\n        \"WEA\".\"prcp\" AS \"precipitation\",\n        EXTRACT(MONTH FROM DATE(\"TRI\".\"starttime\")) AS \"start_month\"\n    FROM\n        \"NEW_YORK_CITIBIKE_1\".\"NEW_YORK_CITIBIKE\".\"CITIBIKE_TRIPS\" AS \"TRI\"\n    INNER JOIN\n        \"NEW_YORK_CITIBIKE_1\".\"GEO_US_BOUNDARIES\".\"ZIP_CODES\" AS \"ZIPSTART\"\n        ON ST_WITHIN(\n            ST_POINT(\"TRI\".\"start_station_longitude\", \"TRI\".\"start_station_latitude\"),\n            ST_GEOGFROMWKB(\"ZIPSTART\".\"zip_code_geom\")\n        )\n    INNER JOIN\n        \"NEW_YORK_CITIBIKE_1\".\"GEO_US_BOUNDARIES\".\"ZIP_CODES\" AS \"ZIPEND\"\n        ON ST_WITHIN(\n            ST_POINT(\"TRI\".\"end_station_longitude\", \"TRI\".\"end_station_latitude\"),\n            ST_GEOGFROMWKB(\"ZIPEND\".\"zip_code_geom\")\n        )\n    INNER JOIN\n        \"NEW_YORK_CITIBIKE_1\".\"NOAA_GSOD\".\"GSOD2014\" AS \"WEA\"\n        ON TO_DATE(CONCAT(\"WEA\".\"year\", LPAD(\"WEA\".\"mo\", 2, '0'), LPAD(\"WEA\".\"da\", 2, '0')), 'YYYYMMDD') = DATE(\"TRI\".\"starttime\")\n    INNER JOIN\n        \"NEW_YORK_CITIBIKE_1\".\"CYCLISTIC\".\"ZIP_CODES\" AS \"ZIPSTARTNAME\"\n        ON \"ZIPSTART\".\"zip_code\" = CAST(\"ZIPSTARTNAME\".\"zip\" AS STRING)\n    INNER JOIN\n        \"NEW_YORK_CITIBIKE_1\".\"CYCLISTIC\".\"ZIP_CODES\" AS \"ZIPENDNAME\"\n        ON \"ZIPEND\".\"zip_code\" = CAST(\"ZIPENDNAME\".\"zip\" AS STRING)\n    WHERE\n        \"WEA\".\"wban\" = (\n            SELECT \"wban\" \n            FROM \"NEW_YORK_CITIBIKE_1\".\"NOAA_GSOD\".\"STATIONS\"\n            WHERE\n                \"state\" = 'NY'\n                AND LOWER(\"name\") LIKE LOWER('%New York Central Park%')\n            LIMIT 1\n        )\n        AND EXTRACT(YEAR FROM DATE(\"TRI\".\"starttime\")) = 2014\n),\nagg_data AS (\n    SELECT\n        \"borough_start\",\n        \"neighborhood_start\",\n        \"borough_end\",\n        \"neighborhood_end\",\n        COUNT(*) AS \"num_trips\",\n        ROUND(AVG(\"trip_minutes\"), 1) AS \"avg_trip_minutes\",\n        ROUND(AVG(\"temperature\"), 1) AS \"avg_temperature\",\n        ROUND(AVG(\"wind_speed\"), 1) AS \"avg_wind_speed\",\n        ROUND(AVG(\"precipitation\"), 1) AS \"avg_precipitation\"\n    FROM data\n    GROUP BY\n        \"borough_start\",\n        \"neighborhood_start\",\n        \"borough_end\",\n        \"neighborhood_end\"\n),\nmost_common_months AS (\n    SELECT\n        \"borough_start\",\n        \"neighborhood_start\",\n        \"borough_end\",\n        \"neighborhood_end\",\n        \"start_month\",\n        ROW_NUMBER() OVER (\n            PARTITION BY \"borough_start\", \"neighborhood_start\", \"borough_end\", \"neighborhood_end\" \n            ORDER BY COUNT(*) DESC\n        ) AS \"row_num\"\n    FROM data\n    GROUP BY\n        \"borough_start\",\n        \"neighborhood_start\",\n        \"borough_end\",\n        \"neighborhood_end\",\n        \"start_month\"\n)\n\nSELECT\n    a.*,\n    m.\"start_month\" AS \"most_common_month\"\nFROM\n    agg_data a\nJOIN\n    most_common_months m\n    ON a.\"borough_start\" = m.\"borough_start\" \n    AND a.\"neighborhood_start\" = m.\"neighborhood_start\" \n    AND a.\"borough_end\" = m.\"borough_end\" \n    AND a.\"neighborhood_end\" = m.\"neighborhood_end\" \n    AND m.\"row_num\" = 1\nORDER BY \n    a.\"neighborhood_start\", \n    a.\"neighborhood_end\";",
        "db_id": "NEW_YORK_CITIBIKE_1",
        "No. of candidate columns": 3303,
        "No. of gold tables": 7
    },
    {
        "instance_id": "sf_bq426",
        "question": "What user type recorded the highest average temperature for trips starting and ending in New York City's zip code 10019 during 2018? Include average precipitation, wind speed, and temperature for that user type based on weather data from the New York Central Park station.",
        "external_knowledge": "functions_st_within.md",
        "question_toks": [
            "What",
            "user",
            "type",
            "recorded",
            "the",
            "highest",
            "average",
            "temperature",
            "for",
            "trips",
            "starting",
            "and",
            "ending",
            "in",
            "New",
            "York",
            "City's",
            "zip",
            "code",
            "10019",
            "during",
            "2018?",
            "Include",
            "average",
            "precipitation,",
            "wind",
            "speed,",
            "and",
            "temperature",
            "for",
            "that",
            "user",
            "type",
            "based",
            "on",
            "weather",
            "data",
            "from",
            "the",
            "New",
            "York",
            "Central",
            "Park",
            "station."
        ],
        "query": "",
        "db_id": "NEW_YORK_CITIBIKE_1",
        "No. of candidate columns": 3303,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq291",
        "question": "Can you provide a daily weather summary for July 2019 within a 5 km radius of latitude 26.75 and longitude 51.5? I need the maximum, minimum, and average temperatures; total precipitation; average cloud cover between 10 AM and 5 PM; total snowfall (when average temperature is below 32°F); and total rainfall (when average temperature is 32°F or above) for each forecast date. The data should correspond to forecasts created in July 2019 for the following day.",
        "external_knowledge": "functions_st_within.md",
        "question_toks": [
            "Can",
            "you",
            "provide",
            "a",
            "daily",
            "weather",
            "summary",
            "for",
            "July",
            "2019",
            "within",
            "a",
            "5",
            "km",
            "radius",
            "of",
            "latitude",
            "26.75",
            "and",
            "longitude",
            "51.5?",
            "I",
            "need",
            "the",
            "maximum,",
            "minimum,",
            "and",
            "average",
            "temperatures;",
            "total",
            "precipitation;",
            "average",
            "cloud",
            "cover",
            "between",
            "10",
            "AM",
            "and",
            "5",
            "PM;",
            "total",
            "snowfall",
            "(when",
            "average",
            "temperature",
            "is",
            "below",
            "32°F);",
            "and",
            "total",
            "rainfall",
            "(when",
            "average",
            "temperature",
            "is",
            "32°F",
            "or",
            "above)",
            "for",
            "each",
            "forecast",
            "date.",
            "The",
            "data",
            "should",
            "correspond",
            "to",
            "forecasts",
            "created",
            "in",
            "July",
            "2019",
            "for",
            "the",
            "following",
            "day."
        ],
        "query": "WITH daily_forecasts AS (\n    SELECT\n        \"TRI\".\"creation_time\",\n\n        CAST(DATEADD(hour, 1, TO_TIMESTAMP_NTZ(TO_NUMBER(\"forecast\".value:\"time\") / 1000000)) AS DATE) AS \"local_forecast_date\",\n        MAX(\n            CASE \n                WHEN \"forecast\".value:\"temperature_2m_above_ground\" IS NOT NULL \n                THEN \"forecast\".value:\"temperature_2m_above_ground\" \n                ELSE NULL \n            END\n        ) AS \"max_temp\",\n        MIN(\n            CASE \n                WHEN \"forecast\".value:\"temperature_2m_above_ground\" IS NOT NULL \n                THEN \"forecast\".value:\"temperature_2m_above_ground\" \n                ELSE NULL \n            END\n        ) AS \"min_temp\",\n        AVG(\n            CASE \n                WHEN \"forecast\".value:\"temperature_2m_above_ground\" IS NOT NULL \n                THEN \"forecast\".value:\"temperature_2m_above_ground\" \n                ELSE NULL \n            END\n        ) AS \"avg_temp\",\n        SUM(\n            CASE \n                WHEN \"forecast\".value:\"total_precipitation_surface\" IS NOT NULL \n                THEN \"forecast\".value:\"total_precipitation_surface\" \n                ELSE 0 \n            END\n        ) AS \"total_precipitation\",\n        AVG(\n            CASE \n                WHEN CAST(DATEADD(hour, 1, TO_TIMESTAMP_NTZ(TO_NUMBER(\"forecast\".value:\"time\") / 1000000)    ) AS TIME) BETWEEN '10:00:00' AND '17:00:00'\n                     AND \"forecast\".value:\"total_cloud_cover_entire_atmosphere\" IS NOT NULL \n                THEN \"forecast\".value:\"total_cloud_cover_entire_atmosphere\" \n                ELSE NULL \n            END\n        ) AS \"avg_cloud_cover\",\n        CASE\n            WHEN AVG(\"forecast\".value:\"temperature_2m_above_ground\") < 32 THEN \n                SUM(\n                    CASE \n                        WHEN \"forecast\".value:\"total_precipitation_surface\" IS NOT NULL \n                        THEN \"forecast\".value:\"total_precipitation_surface\" \n                        ELSE 0 \n                    END\n                )\n            ELSE 0\n        END AS \"total_snow\",\n        CASE\n            WHEN AVG(\"forecast\".value:\"temperature_2m_above_ground\") >= 32 THEN \n                SUM(\n                    CASE \n                        WHEN \"forecast\".value:\"total_precipitation_surface\" IS NOT NULL \n                        THEN \"forecast\".value:\"total_precipitation_surface\" \n                        ELSE 0 \n                    END\n                )\n            ELSE 0\n        END AS \"total_rain\"\n    FROM\n        \"NOAA_GLOBAL_FORECAST_SYSTEM\".\"NOAA_GLOBAL_FORECAST_SYSTEM\".\"NOAA_GFS0P25\" AS \"TRI\"\n    CROSS JOIN LATERAL FLATTEN(input => \"TRI\".\"forecast\") AS \"forecast\"\n    WHERE\n        TO_TIMESTAMP_NTZ(TO_NUMBER(\"TRI\".\"creation_time\") / 1000000) BETWEEN '2019-07-01' AND '2021-07-31'  \n        AND ST_DWITHIN(\n            ST_GEOGFROMWKB(\"TRI\".\"geography\"),\n            ST_POINT(26.75, 51.5),\n            5000\n        )\n        AND CAST(TO_TIMESTAMP_NTZ(TO_NUMBER(\"forecast\".value:\"time\") / 1000000) AS DATE) = DATEADD(day, 1, CAST( TO_TIMESTAMP_NTZ(TO_NUMBER(\"TRI\".\"creation_time\") / 1000000) AS DATE))\n    GROUP BY\n        \"TRI\".\"creation_time\",\n        \"local_forecast_date\"\n)\n\nSELECT\n    TO_TIMESTAMP_NTZ(TO_NUMBER(\"creation_time\") / 1000000),\n    \"local_forecast_date\" AS \"forecast_date\",\n    \"max_temp\",\n    \"min_temp\",\n    \"avg_temp\",\n    \"total_precipitation\",\n    \"avg_cloud_cover\",\n    \"total_snow\",\n    \"total_rain\"\nFROM\n    daily_forecasts\nORDER BY\n    \"creation_time\",\n    \"forecast_date\";",
        "db_id": "NOAA_GLOBAL_FORECAST_SYSTEM",
        "No. of candidate columns": 90,
        "No. of gold tables": 1
    },
    {
        "instance_id": "bq208",
        "question": "Can you provide weather stations within a 20-mile radius of Chappaqua, New York (Latitude: 41.197, Longitude: -73.764), and tell me the number of valid temperature observations they have recorded from 2011 to 2020, excluding any invalid or missing temperature data?",
        "external_knowledge": "functions_st_dwithin.md",
        "question_toks": [
            "Can",
            "you",
            "provide",
            "weather",
            "stations",
            "within",
            "a",
            "20-mile",
            "radius",
            "of",
            "Chappaqua,",
            "New",
            "York",
            "(Latitude:",
            "41.197,",
            "Longitude:",
            "-73.764),",
            "and",
            "tell",
            "me",
            "the",
            "number",
            "of",
            "valid",
            "temperature",
            "observations",
            "they",
            "have",
            "recorded",
            "from",
            "2011",
            "to",
            "2020,",
            "excluding",
            "any",
            "invalid",
            "or",
            "missing",
            "temperature",
            "data?"
        ],
        "query": "",
        "db_id": "new_york_noaa",
        "No. of candidate columns": 3571,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq293",
        "question": "I want to analyze yellow taxi trip data in New York City for January 2015, focusing on the number of trips by ZIP code and hour of the day. The query should (1) calculate the total number of taxi trips for each ZIP code per hour, (2) join the taxi trip data with ZIP code boundaries to ensure each trip is correctly mapped to its respective neighborhood based on latitude and longitude, and (3) compute several time-based metrics, including the number of trips from 1 hour ago (lag 1h), 1 day ago (lag 1d), 7 days ago (lag 7d), and 14 days ago (lag 14d). Additionally, the query should calculate the 14-day and 21-day moving averages and standard deviations of trip counts, excluding the current hour. The final results should include the following values: the total number of trips, the lag counts (1h, 1d, 7d, and 14d), the moving averages for 14 and 21 days and the standard deviations for 14 and 21 days. The data should be sorted by the highest trip counts, showing the top 15 groups with the most trips.",
        "external_knowledge": "functions_st_contains.md",
        "question_toks": [
            "I",
            "want",
            "to",
            "analyze",
            "yellow",
            "taxi",
            "trip",
            "data",
            "in",
            "New",
            "York",
            "City",
            "for",
            "January",
            "2015,",
            "focusing",
            "on",
            "the",
            "number",
            "of",
            "trips",
            "by",
            "ZIP",
            "code",
            "and",
            "hour",
            "of",
            "the",
            "day.",
            "The",
            "query",
            "should",
            "(1)",
            "calculate",
            "the",
            "total",
            "number",
            "of",
            "taxi",
            "trips",
            "for",
            "each",
            "ZIP",
            "code",
            "per",
            "hour,",
            "(2)",
            "join",
            "the",
            "taxi",
            "trip",
            "data",
            "with",
            "ZIP",
            "code",
            "boundaries",
            "to",
            "ensure",
            "each",
            "trip",
            "is",
            "correctly",
            "mapped",
            "to",
            "its",
            "respective",
            "neighborhood",
            "based",
            "on",
            "latitude",
            "and",
            "longitude,",
            "and",
            "(3)",
            "compute",
            "several",
            "time-based",
            "metrics,",
            "including",
            "the",
            "number",
            "of",
            "trips",
            "from",
            "1",
            "hour",
            "ago",
            "(lag",
            "1h),",
            "1",
            "day",
            "ago",
            "(lag",
            "1d),",
            "7",
            "days",
            "ago",
            "(lag",
            "7d),",
            "and",
            "14",
            "days",
            "ago",
            "(lag",
            "14d).",
            "Additionally,",
            "the",
            "query",
            "should",
            "calculate",
            "the",
            "14-day",
            "and",
            "21-day",
            "moving",
            "averages",
            "and",
            "standard",
            "deviations",
            "of",
            "trip",
            "counts,",
            "excluding",
            "the",
            "current",
            "hour.",
            "The",
            "final",
            "results",
            "should",
            "include",
            "the",
            "following",
            "values:",
            "the",
            "total",
            "number",
            "of",
            "trips,",
            "the",
            "lag",
            "counts",
            "(1h,",
            "1d,",
            "7d,",
            "and",
            "14d),",
            "the",
            "moving",
            "averages",
            "for",
            "14",
            "and",
            "21",
            "days",
            "and",
            "the",
            "standard",
            "deviations",
            "for",
            "14",
            "and",
            "21",
            "days.",
            "The",
            "data",
            "should",
            "be",
            "sorted",
            "by",
            "the",
            "highest",
            "trip",
            "counts,",
            "showing",
            "the",
            "top",
            "15",
            "groups",
            "with",
            "the",
            "most",
            "trips."
        ],
        "query": "",
        "db_id": "new_york_geo",
        "No. of candidate columns": 670,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq017",
        "question": "What are the five longest types of highways within the multipolygon boundary of Denmark (as defined by Wikidata ID 'Q35') by total length, analyzed through planet features?",
        "external_knowledge": "functions_st_dwithin.md",
        "question_toks": [
            "What",
            "are",
            "the",
            "five",
            "longest",
            "types",
            "of",
            "highways",
            "within",
            "the",
            "multipolygon",
            "boundary",
            "of",
            "Denmark",
            "(as",
            "defined",
            "by",
            "Wikidata",
            "ID",
            "'Q35')",
            "by",
            "total",
            "length,",
            "analyzed",
            "through",
            "planet",
            "features?"
        ],
        "query": "WITH bounding_area AS (\n    SELECT \"geometry\" AS geometry\n    FROM GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_FEATURES,\n    LATERAL FLATTEN(INPUT => planet_features.\"all_tags\") AS \"tag\"\n    WHERE \"feature_type\" = 'multipolygons'\n      AND \"tag\".value:\"key\" = 'wikidata'\n      AND \"tag\".value:\"value\" = 'Q35'\n),\n\nhighway_info AS (\n    SELECT \n        SUM(ST_LENGTH(\n                ST_GEOGRAPHYFROMWKB(planet_features.\"geometry\")\n            )\n        ) AS highway_length,\n        \"tag\".value:\"value\" AS highway_type\n    FROM \n        GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_FEATURES AS planet_features,\n        bounding_area\n    CROSS JOIN LATERAL FLATTEN(INPUT => planet_features.\"all_tags\") AS \"tag\"\n    WHERE \"tag\".value:\"key\" = 'highway'\n    AND \"feature_type\" = 'lines'\n    AND ST_DWITHIN(\n        ST_GEOGFROMWKB(planet_features.\"geometry\"), \n        ST_GEOGFROMWKB(bounding_area.geometry),\n        0.0\n    ) \n    GROUP BY highway_type\n)\n\nSELECT \n  REPLACE(highway_type, '\"', '') AS highway_type\nFROM\n  highway_info\nORDER BY \n  highway_length DESC\nLIMIT 5;",
        "db_id": "GEO_OPENSTREETMAP",
        "No. of candidate columns": 86,
        "No. of gold tables": 2
    },
    {
        "instance_id": "sf_bq349",
        "question": "Which OpenStreetMap ID from the planet features table corresponds to an administrative boundary, represented as multipolygons, whose total number of 'amenity'-tagged Points of Interest (POIs), as derived from the planet nodes table, is closest to the median count among all such boundaries?",
        "external_knowledge": "functions_st_dwithin.md",
        "question_toks": [
            "Which",
            "OpenStreetMap",
            "ID",
            "from",
            "the",
            "planet",
            "features",
            "table",
            "corresponds",
            "to",
            "an",
            "administrative",
            "boundary,",
            "represented",
            "as",
            "multipolygons,",
            "whose",
            "total",
            "number",
            "of",
            "'amenity'-tagged",
            "Points",
            "of",
            "Interest",
            "(POIs),",
            "as",
            "derived",
            "from",
            "the",
            "planet",
            "nodes",
            "table,",
            "is",
            "closest",
            "to",
            "the",
            "median",
            "count",
            "among",
            "all",
            "such",
            "boundaries?"
        ],
        "query": "WITH bounding_area AS (\n    SELECT \n        \"osm_id\",\n        \"geometry\" AS geometry,\n        ST_AREA(ST_GEOGRAPHYFROMWKB(\"geometry\")) AS area\n    FROM GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_FEATURES,\n    LATERAL FLATTEN(INPUT => PLANET_FEATURES.\"all_tags\") AS \"tag\"\n    WHERE \n        \"feature_type\" = 'multipolygons'\n        AND \"tag\".value:\"key\" = 'boundary'\n        AND \"tag\".value:\"value\" = 'administrative'\n),\n\npoi AS (\n    SELECT \n        nodes.\"id\" AS poi_id,\n        nodes.\"geometry\" AS poi_geometry,\n        tags.value:\"value\" AS poitype\n    FROM GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_NODES AS nodes,\n    LATERAL FLATTEN(INPUT => nodes.\"all_tags\") AS tags\n    WHERE tags.value:\"key\" = 'amenity'\n),\n\npoi_counts AS (\n    SELECT\n        ba.\"osm_id\",\n        COUNT(poi.poi_id) AS total_pois\n    FROM bounding_area ba\n    JOIN poi\n    ON ST_DWITHIN(\n        ST_GEOGRAPHYFROMWKB(ba.geometry), \n        ST_GEOGRAPHYFROMWKB(poi.poi_geometry), \n        0.0\n    )\n    GROUP BY ba.\"osm_id\"\n),\n\nmedian_value AS (\n    SELECT \n        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY total_pois) AS median_pois\n    FROM poi_counts\n),\n\nclosest_to_median AS (\n    SELECT\n        \"osm_id\",\n        total_pois,\n        ABS(total_pois - (SELECT median_pois FROM median_value)) AS diff_from_median\n    FROM poi_counts\n)\n\nSELECT\n    \"osm_id\"\nFROM closest_to_median\nORDER BY diff_from_median\nLIMIT 1;",
        "db_id": "GEO_OPENSTREETMAP",
        "No. of candidate columns": 86,
        "No. of gold tables": 2
    },
    {
        "instance_id": "sf_bq007",
        "question": "Identify the top 10 U.S. states with the highest vulnerable population, calculated based on a weighted sum of employment sectors using 2017 ACS 5-Year data, and determine their average median income change from 2015 to 2018 using zip code data. ",
        "external_knowledge": "total_vulnerable_weights.md",
        "question_toks": [
            "Identify",
            "the",
            "top",
            "10",
            "U.S.",
            "states",
            "with",
            "the",
            "highest",
            "vulnerable",
            "population,",
            "calculated",
            "based",
            "on",
            "a",
            "weighted",
            "sum",
            "of",
            "employment",
            "sectors",
            "using",
            "2017",
            "ACS",
            "5-Year",
            "data,",
            "and",
            "determine",
            "their",
            "average",
            "median",
            "income",
            "change",
            "from",
            "2015",
            "to",
            "2018",
            "using",
            "zip",
            "code",
            "data.",
            ""
        ],
        "query": "",
        "db_id": "CENSUS_BUREAU_ACS_2",
        "No. of candidate columns": 68434,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq410",
        "question": "Show the top 3 states with the smallest adjusted non-labor force population, calculated as the sum of the unemployed population, not in labor force population, and group quarters population (with negative results clamped to zero). For these states, provide the total median income change between 2015 and 2018, the adjusted non-labor force count from 2017 ACS data, and the population-adjusted proportion (calculated as the ratio of adjusted non-labor force to total population). Use 2017 ACS tract-level data, match tracts to states via FIPS code prefixes, and exclude tracts with null income differences. The states should be ordered by the smallest adjusted non-labor force count, and results should include state abbreviations with aggregated values.",
        "external_knowledge": null,
        "question_toks": [
            "Show",
            "the",
            "top",
            "3",
            "states",
            "with",
            "the",
            "smallest",
            "adjusted",
            "non-labor",
            "force",
            "population,",
            "calculated",
            "as",
            "the",
            "sum",
            "of",
            "the",
            "unemployed",
            "population,",
            "not",
            "in",
            "labor",
            "force",
            "population,",
            "and",
            "group",
            "quarters",
            "population",
            "(with",
            "negative",
            "results",
            "clamped",
            "to",
            "zero).",
            "For",
            "these",
            "states,",
            "provide",
            "the",
            "total",
            "median",
            "income",
            "change",
            "between",
            "2015",
            "and",
            "2018,",
            "the",
            "adjusted",
            "non-labor",
            "force",
            "count",
            "from",
            "2017",
            "ACS",
            "data,",
            "and",
            "the",
            "population-adjusted",
            "proportion",
            "(calculated",
            "as",
            "the",
            "ratio",
            "of",
            "adjusted",
            "non-labor",
            "force",
            "to",
            "total",
            "population).",
            "Use",
            "2017",
            "ACS",
            "tract-level",
            "data,",
            "match",
            "tracts",
            "to",
            "states",
            "via",
            "FIPS",
            "code",
            "prefixes,",
            "and",
            "exclude",
            "tracts",
            "with",
            "null",
            "income",
            "differences.",
            "The",
            "states",
            "should",
            "be",
            "ordered",
            "by",
            "the",
            "smallest",
            "adjusted",
            "non-labor",
            "force",
            "count,",
            "and",
            "results",
            "should",
            "include",
            "state",
            "abbreviations",
            "with",
            "aggregated",
            "values."
        ],
        "query": "",
        "db_id": "CENSUS_BUREAU_ACS_2",
        "No. of candidate columns": 68434,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq253",
        "question": "Find the name of the OpenStreetMap relation that encompasses the most features within the same geographic area as the multipolygon tagged with the Wikidata item 'Q1095'. The relation should have a specified name and no 'wikidata' tag, and at least one of its included features must have a 'wikidata' tag. The analysis should be conducted using the planet_features table. Return the name of this relation.",
        "external_knowledge": "functions_st_dwithin.md",
        "question_toks": [
            "Find",
            "the",
            "name",
            "of",
            "the",
            "OpenStreetMap",
            "relation",
            "that",
            "encompasses",
            "the",
            "most",
            "features",
            "within",
            "the",
            "same",
            "geographic",
            "area",
            "as",
            "the",
            "multipolygon",
            "tagged",
            "with",
            "the",
            "Wikidata",
            "item",
            "'Q1095'.",
            "The",
            "relation",
            "should",
            "have",
            "a",
            "specified",
            "name",
            "and",
            "no",
            "'wikidata'",
            "tag,",
            "and",
            "at",
            "least",
            "one",
            "of",
            "its",
            "included",
            "features",
            "must",
            "have",
            "a",
            "'wikidata'",
            "tag.",
            "The",
            "analysis",
            "should",
            "be",
            "conducted",
            "using",
            "the",
            "planet_features",
            "table.",
            "Return",
            "the",
            "name",
            "of",
            "this",
            "relation."
        ],
        "query": "",
        "db_id": "GEO_OPENSTREETMAP",
        "No. of candidate columns": 86,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq056",
        "question": "How many different pairs of roads classified as motorway, trunk, primary, secondary, or residential in California overlap each other without sharing nodes and do not have a bridge tag, where these roads are tagged with 'highway', analyzed through planet ways",
        "external_knowledge": "functions_st_intersects.md",
        "question_toks": [
            "How",
            "many",
            "different",
            "pairs",
            "of",
            "roads",
            "classified",
            "as",
            "motorway,",
            "trunk,",
            "primary,",
            "secondary,",
            "or",
            "residential",
            "in",
            "California",
            "overlap",
            "each",
            "other",
            "without",
            "sharing",
            "nodes",
            "and",
            "do",
            "not",
            "have",
            "a",
            "bridge",
            "tag,",
            "where",
            "these",
            "roads",
            "are",
            "tagged",
            "with",
            "'highway',",
            "analyzed",
            "through",
            "planet",
            "ways"
        ],
        "query": "",
        "db_id": "GEO_OPENSTREETMAP_BOUNDARIES",
        "No. of candidate columns": 261,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq289",
        "question": "Can you find the shortest distance between any two amenities (either a library, place of worship, or community center) located within Philadelphia, analyzed through pennsylvania table and planet features points?",
        "external_knowledge": "functions_st_contains.md",
        "question_toks": [
            "Can",
            "you",
            "find",
            "the",
            "shortest",
            "distance",
            "between",
            "any",
            "two",
            "amenities",
            "(either",
            "a",
            "library,",
            "place",
            "of",
            "worship,",
            "or",
            "community",
            "center)",
            "located",
            "within",
            "Philadelphia,",
            "analyzed",
            "through",
            "pennsylvania",
            "table",
            "and",
            "planet",
            "features",
            "points?"
        ],
        "query": "WITH philadelphia AS (\n    SELECT \n        * \n    FROM \n        GEO_OPENSTREETMAP_CENSUS_PLACES.GEO_US_CENSUS_PLACES.PLACES_PENNSYLVANIA\n    WHERE \n        \"place_name\" = 'Philadelphia'\n),\namenities AS (\n    SELECT \n        features.*, \n        tags.value:\"value\" AS amenity\n    FROM \n        GEO_OPENSTREETMAP_CENSUS_PLACES.GEO_OPENSTREETMAP.PLANET_FEATURES_POINTS AS features\n    CROSS JOIN philadelphia\n    -- Use FLATTEN on \"all_tags\" to get the tags and filter by \"key\"\n    , LATERAL FLATTEN(input => features.\"all_tags\") AS tags\n    WHERE \n        ST_CONTAINS(ST_GEOGFROMWKB(philadelphia.\"place_geom\"), ST_GEOGFROMWKB(features.\"geometry\"))\n    AND \n        tags.value:\"key\" = 'amenity' \n    AND \n        tags.value:\"value\" IN ('library', 'place_of_worship', 'community_centre')\n),\njoiin AS (\n    SELECT \n        a1.*, \n        a2.\"osm_id\" AS nearest_osm_id, \n        ST_DISTANCE(ST_GEOGFROMWKB(a1.\"geometry\"), ST_GEOGFROMWKB(a2.\"geometry\")) AS distance, \n        ROW_NUMBER() OVER (PARTITION BY a1.\"osm_id\" ORDER BY ST_DISTANCE(ST_GEOGFROMWKB(a1.\"geometry\"), ST_GEOGFROMWKB(a2.\"geometry\"))) AS row_num\n    FROM amenities a1\n    CROSS JOIN amenities a2\n    WHERE a1.\"osm_id\" < a2.\"osm_id\"\n    ORDER BY a1.\"osm_id\", distance\n) \nSELECT distance\nFROM joiin  \nWHERE row_num = 1\nORDER BY distance ASC\nLIMIT 1;",
        "db_id": "GEO_OPENSTREETMAP_CENSUS_PLACES",
        "No. of candidate columns": 1056,
        "No. of gold tables": 2
    },
    {
        "instance_id": "sf_bq195",
        "question": "What are the top 10 Ethereum addresses by balance, considering both value transactions and gas fees, before September 1, 2021? Only keep successful transactions with no call type or where the call type is 'call'.",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "are",
            "the",
            "top",
            "10",
            "Ethereum",
            "addresses",
            "by",
            "balance,",
            "considering",
            "both",
            "value",
            "transactions",
            "and",
            "gas",
            "fees,",
            "before",
            "September",
            "1,",
            "2021?",
            "Only",
            "keep",
            "successful",
            "transactions",
            "with",
            "no",
            "call",
            "type",
            "or",
            "where",
            "the",
            "call",
            "type",
            "is",
            "'call'."
        ],
        "query": "",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq080",
        "question": "Using only the Ethereum traces table, can you provide a daily cumulative count of smart contracts created by external users (where trace_address is null) versus contracts created by other contracts (where trace_address is not null) between August 30, 2018, and September 30, 2018? Ensure results include every date in this range, even if no new contracts were created, and show strictly increasing cumulative totals.",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "only",
            "the",
            "Ethereum",
            "traces",
            "table,",
            "can",
            "you",
            "provide",
            "a",
            "daily",
            "cumulative",
            "count",
            "of",
            "smart",
            "contracts",
            "created",
            "by",
            "external",
            "users",
            "(where",
            "trace_address",
            "is",
            "null)",
            "versus",
            "contracts",
            "created",
            "by",
            "other",
            "contracts",
            "(where",
            "trace_address",
            "is",
            "not",
            "null)",
            "between",
            "August",
            "30,",
            "2018,",
            "and",
            "September",
            "30,",
            "2018?",
            "Ensure",
            "results",
            "include",
            "every",
            "date",
            "in",
            "this",
            "range,",
            "even",
            "if",
            "no",
            "new",
            "contracts",
            "were",
            "created,",
            "and",
            "show",
            "strictly",
            "increasing",
            "cumulative",
            "totals."
        ],
        "query": "",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq341",
        "question": "Which Ethereum address has the top 3 smallest positive balance from transactions involving the token at address \"0xa92a861fc11b99b24296af880011b47f9cafb5ab\"?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "Ethereum",
            "address",
            "has",
            "the",
            "top",
            "3",
            "smallest",
            "positive",
            "balance",
            "from",
            "transactions",
            "involving",
            "the",
            "token",
            "at",
            "address",
            "\"0xa92a861fc11b99b24296af880011b47f9cafb5ab\"?"
        ],
        "query": "WITH transaction_addresses AS (\n    SELECT \n        \"from_address\", \n        \"to_address\", \n        CAST(\"value\" AS NUMERIC) / 1000000 AS \"value\"\n    FROM \n        \"CRYPTO\".\"CRYPTO_ETHEREUM\".\"TOKEN_TRANSFERS\"\n    WHERE \n        \"token_address\" = '0xa92a861fc11b99b24296af880011b47f9cafb5ab'\n),\n\nout_addresses AS (\n    SELECT \n        \"from_address\", \n        SUM(-1 * \"value\") AS \"total_value\"\n    FROM \n        transaction_addresses\n    GROUP BY \n        \"from_address\"\n),\n\nin_addresses AS (\n    SELECT \n        \"to_address\", \n        SUM(\"value\") AS \"total_value\"\n    FROM \n        transaction_addresses\n    GROUP BY \n        \"to_address\"\n),\n\nall_addresses AS (\n    SELECT \n        \"from_address\" AS \"address\", \n        \"total_value\"\n    FROM \n        out_addresses\n\n    UNION ALL\n\n    SELECT \n        \"to_address\" AS \"address\", \n        \"total_value\"\n    FROM \n        in_addresses\n)\n\nSELECT \n    \"address\"\nFROM \n    all_addresses\nGROUP BY \n    \"address\"\nHAVING \n    SUM(\"total_value\") > 0\nORDER BY \n    SUM(\"total_value\") ASC\nLIMIT 3;",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 1
    },
    {
        "instance_id": "sf_bq444",
        "question": "Can you pull the blockchain timestamp, block number, and transaction hash for the first five mint and burn events from Ethereum logs for the address '0x8ad599c3a0ff1de082011efddc58f1908eb6e6d8'? Please include mint events identified by the topic '0x7a53080ba414158be7ec69b987b5fb7d07dee101fe85488f0853ae16239d0bde' and burn events by '0x0c396cd989a39f4459b5fa1aed6a9a8dcdbc45908acfd67e028cd568da98982c', and order them by block timestamp from the oldest to the newest.",
        "external_knowledge": "ethereum_logs_and_events_overview.md",
        "question_toks": [
            "Can",
            "you",
            "pull",
            "the",
            "blockchain",
            "timestamp,",
            "block",
            "number,",
            "and",
            "transaction",
            "hash",
            "for",
            "the",
            "first",
            "five",
            "mint",
            "and",
            "burn",
            "events",
            "from",
            "Ethereum",
            "logs",
            "for",
            "the",
            "address",
            "'0x8ad599c3a0ff1de082011efddc58f1908eb6e6d8'?",
            "Please",
            "include",
            "mint",
            "events",
            "identified",
            "by",
            "the",
            "topic",
            "'0x7a53080ba414158be7ec69b987b5fb7d07dee101fe85488f0853ae16239d0bde'",
            "and",
            "burn",
            "events",
            "by",
            "'0x0c396cd989a39f4459b5fa1aed6a9a8dcdbc45908acfd67e028cd568da98982c',",
            "and",
            "order",
            "them",
            "by",
            "block",
            "timestamp",
            "from",
            "the",
            "oldest",
            "to",
            "the",
            "newest."
        ],
        "query": "WITH parsed_burn_logs AS (\n  SELECT\n    logs.\"block_timestamp\" AS block_timestamp,\n    logs.\"block_number\" AS block_number,\n    logs.\"transaction_hash\" AS transaction_hash,\n    logs.\"log_index\" AS log_index,\n    PARSE_JSON(logs.\"data\") AS data,\n    logs.\"topics\"\n  FROM CRYPTO.CRYPTO_ETHEREUM.LOGS AS logs\n  WHERE logs.\"address\" = '0x8ad599c3a0ff1de082011efddc58f1908eb6e6d8'\n    AND logs.\"topics\"[0] = '0x0c396cd989a39f4459b5fa1aed6a9a8dcdbc45908acfd67e028cd568da98982c'\n),\nparsed_mint_logs AS (\n  SELECT\n    logs.\"block_timestamp\" AS block_timestamp,\n    logs.\"block_number\" AS block_number,\n    logs.\"transaction_hash\" AS transaction_hash,\n    logs.\"log_index\" AS log_index,\n    PARSE_JSON(logs.\"data\") AS data,\n    logs.\"topics\"\n  FROM CRYPTO.CRYPTO_ETHEREUM.LOGS AS logs\n  WHERE logs.\"address\" = '0x8ad599c3a0ff1de082011efddc58f1908eb6e6d8'\n    AND logs.\"topics\"[0] = '0x7a53080ba414158be7ec69b987b5fb7d07dee101fe85488f0853ae16239d0bde'\n)\n\nSELECT\n    block_timestamp,\n    block_number,\n    transaction_hash\nFROM parsed_mint_logs\n\nUNION ALL\n\nSELECT\n    block_timestamp,\n    block_number,\n    transaction_hash\nFROM parsed_burn_logs\n\nORDER BY block_timestamp\nLIMIT 5;",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 2
    },
    {
        "instance_id": "sf_bq340",
        "question": "Which six Ethereum addresses, excluding '0x0000000000000000000000000000000000000000', have the largest absolute differences between their previous and current balances from the tokens at addresses '0x0d8775f648430679a709e98d2b0cb6250d2887ef0' and '0x1e15c05cbad367f044cbfbafda3d9a1510db5513'?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "six",
            "Ethereum",
            "addresses,",
            "excluding",
            "'0x0000000000000000000000000000000000000000',",
            "have",
            "the",
            "largest",
            "absolute",
            "differences",
            "between",
            "their",
            "previous",
            "and",
            "current",
            "balances",
            "from",
            "the",
            "tokens",
            "at",
            "addresses",
            "'0x0d8775f648430679a709e98d2b0cb6250d2887ef0'",
            "and",
            "'0x1e15c05cbad367f044cbfbafda3d9a1510db5513'?"
        ],
        "query": "",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq005",
        "question": "Calculate the daily average Bitcoin block interval (in seconds) for 2023 by joining consecutive blocks via row-numbered self-joins (including cross-day intervals), excluding the genesis block, and list the first 10 dates with their unadjusted averages.",
        "external_knowledge": null,
        "question_toks": [
            "Calculate",
            "the",
            "daily",
            "average",
            "Bitcoin",
            "block",
            "interval",
            "(in",
            "seconds)",
            "for",
            "2023",
            "by",
            "joining",
            "consecutive",
            "blocks",
            "via",
            "row-numbered",
            "self-joins",
            "(including",
            "cross-day",
            "intervals),",
            "excluding",
            "the",
            "genesis",
            "block,",
            "and",
            "list",
            "the",
            "first",
            "10",
            "dates",
            "with",
            "their",
            "unadjusted",
            "averages."
        ],
        "query": "",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq334",
        "question": "Calculate the annual differences in Bitcoin output value averages between two methods: Merged input/output records: Combine the inputs and outputs tables, filter to only output records, and calculate yearly averages. Transactions table: Directly use the output_value field from the transactions table for yearly averages. Show the difference (merged outputs average minus transactions average) only for years with data in both methods.",
        "external_knowledge": null,
        "question_toks": [
            "Calculate",
            "the",
            "annual",
            "differences",
            "in",
            "Bitcoin",
            "output",
            "value",
            "averages",
            "between",
            "two",
            "methods:",
            "Merged",
            "input/output",
            "records:",
            "Combine",
            "the",
            "inputs",
            "and",
            "outputs",
            "tables,",
            "filter",
            "to",
            "only",
            "output",
            "records,",
            "and",
            "calculate",
            "yearly",
            "averages.",
            "Transactions",
            "table:",
            "Directly",
            "use",
            "the",
            "output_value",
            "field",
            "from",
            "the",
            "transactions",
            "table",
            "for",
            "yearly",
            "averages.",
            "Show",
            "the",
            "difference",
            "(merged",
            "outputs",
            "average",
            "minus",
            "transactions",
            "average)",
            "only",
            "for",
            "years",
            "with",
            "data",
            "in",
            "both",
            "methods."
        ],
        "query": "WITH all_transactions AS (\n    SELECT \n        TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000) AS \"timestamp\",  -- 将时间戳转换为日期时间格式\n        \"value\",\n        'input' AS \"type\"\n    FROM \n        \"CRYPTO\".\"CRYPTO_BITCOIN\".\"INPUTS\"\n    UNION ALL\n    SELECT \n        TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000) AS \"timestamp\",  -- 将时间戳转换为日期时间格式\n        \"value\",\n        'output' AS \"type\"\n    FROM \n        \"CRYPTO\".\"CRYPTO_BITCOIN\".\"OUTPUTS\"\n),\nfiltered_transactions AS (\n    SELECT\n        EXTRACT(YEAR FROM \"timestamp\") AS \"year\",\n        \"value\"\n    FROM \n        all_transactions\n    WHERE \"type\" = 'output'\n),\naverage_output_values AS (\n    SELECT\n        \"year\",\n        AVG(\"value\") AS \"avg_value\"\n    FROM \n        filtered_transactions\n    GROUP BY \"year\"\n),\naverage_transaction_values AS (\n    SELECT \n        EXTRACT(YEAR FROM TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000)) AS \"year\",  -- 同样转换时间戳\n        AVG(\"output_value\") AS \"avg_transaction_value\" \n    FROM \n        \"CRYPTO\".\"CRYPTO_BITCOIN\".\"TRANSACTIONS\" \n    GROUP BY \"year\" \n    ORDER BY \"year\"\n),\ncommon_years AS (\n    SELECT\n        ao.\"year\",\n        ao.\"avg_value\" AS \"avg_output_value\",\n        atv.\"avg_transaction_value\"\n    FROM\n        average_output_values ao\n    JOIN\n        average_transaction_values atv \n        ON ao.\"year\" = atv.\"year\"\n)\n\nSELECT\n    \"year\",\n    \"avg_transaction_value\" - \"avg_output_value\" AS \"difference\"\nFROM\n    common_years\nORDER BY\n    \"year\";",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 3
    },
    {
        "instance_id": "sf_bq057",
        "question": "Which month (e.g., 3) in 2021 witnessed the highest percent of Bitcoin volume that took place in CoinJoin transactions? Also give me the percentage of CoinJoins transactions, the average input and output UTXOs ratio, and the proportion of CoinJoin transaction volume for that month (all 1 decimal).",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "month",
            "(e.g.,",
            "3)",
            "in",
            "2021",
            "witnessed",
            "the",
            "highest",
            "percent",
            "of",
            "Bitcoin",
            "volume",
            "that",
            "took",
            "place",
            "in",
            "CoinJoin",
            "transactions?",
            "Also",
            "give",
            "me",
            "the",
            "percentage",
            "of",
            "CoinJoins",
            "transactions,",
            "the",
            "average",
            "input",
            "and",
            "output",
            "UTXOs",
            "ratio,",
            "and",
            "the",
            "proportion",
            "of",
            "CoinJoin",
            "transaction",
            "volume",
            "for",
            "that",
            "month",
            "(all",
            "1",
            "decimal)."
        ],
        "query": "WITH totals AS (\n    -- Aggregate monthly totals for Bitcoin txs, input/output UTXOs,\n    -- and input/output values (UTXO stands for Unspent Transaction Output)\n    SELECT\n        \"txs_tot\".\"block_timestamp_month\" AS tx_month,\n        COUNT(\"txs_tot\".\"hash\") AS tx_count,\n        SUM(\"txs_tot\".\"input_count\") AS tx_inputs,\n        SUM(\"txs_tot\".\"output_count\") AS tx_outputs,\n        SUM(\"txs_tot\".\"input_value\") / 100000000 AS tx_input_val,\n        SUM(\"txs_tot\".\"output_value\") / 100000000 AS tx_output_val\n    FROM CRYPTO.CRYPTO_BITCOIN.TRANSACTIONS AS \"txs_tot\"\n    WHERE \"txs_tot\".\"block_timestamp_month\" BETWEEN CAST('2021-01-01' AS DATE) AND CAST('2021-12-31' AS DATE)\n    GROUP BY \"txs_tot\".\"block_timestamp_month\"\n    ORDER BY \"txs_tot\".\"block_timestamp_month\" DESC\n),\ncoinjoinOuts AS (\n    -- Builds a table where each row represents an output of a \n    -- potential CoinJoin tx, defined as a tx that had more \n    -- than two outputs and had a total output value less than its\n    -- input value, per Adam Fiscor's description in this article: \n    SELECT \n        \"txs\".\"hash\",\n        \"txs\".\"block_number\",\n        \"txs\".\"block_timestamp_month\",\n        \"txs\".\"input_count\",\n        \"txs\".\"output_count\",\n        \"txs\".\"input_value\",\n        \"txs\".\"output_value\",\n        \"o\".value:\"value\" AS \"outputs_val\"\n    FROM CRYPTO.CRYPTO_BITCOIN.TRANSACTIONS AS \"txs\", \n         LATERAL FLATTEN(INPUT => \"txs\".\"outputs\") AS \"o\"\n    WHERE \"txs\".\"output_count\" > 2 \n      AND \"txs\".\"output_value\" <= \"txs\".\"input_value\"\n      AND \"txs\".\"block_timestamp_month\" BETWEEN CAST('2021-01-01' AS DATE) AND CAST('2021-12-31' AS DATE)\n    ORDER BY \"txs\".\"block_number\", \"txs\".\"hash\" DESC\n),\ncoinjoinTxs AS (\n    -- Builds a table of just the distinct CoinJoin tx hashes\n    -- which had more than one equal-value output.\n    SELECT \n        \"coinjoinouts\".\"hash\" AS \"cjhash\",\n        \"coinjoinouts\".\"outputs_val\" AS outputVal,\n        COUNT(*) AS cjOuts\n    FROM coinjoinOuts AS \"coinjoinouts\"\n    GROUP BY \"coinjoinouts\".\"hash\", \"coinjoinouts\".\"outputs_val\"\n    HAVING COUNT(*) > 1\n),\ncoinjoinsD AS (\n    -- Filter out all potential CoinJoin txs that did not have\n    -- more than one equal-value output. Do not list the\n    -- outputs themselves, only the distinct tx hashes and\n    -- their input/output counts and values.\n    SELECT DISTINCT \n        \"coinjoinouts\".\"hash\", \n        \"coinjoinouts\".\"block_number\", \n        \"coinjoinouts\".\"block_timestamp_month\",\n        \"coinjoinouts\".\"input_count\",\n        \"coinjoinouts\".\"output_count\",\n        \"coinjoinouts\".\"input_value\",\n        \"coinjoinouts\".\"output_value\"\n    FROM coinjoinOuts AS \"coinjoinouts\"\n    INNER JOIN coinjoinTxs AS \"coinjointxs\" \n        ON \"coinjoinouts\".\"hash\" = \"coinjointxs\".\"cjhash\"\n),\ncoinjoins AS (\n    -- Aggregate monthly totals for CoinJoin txs, input/output UTXOs,\n    -- and input/output values\n    SELECT \n        \"cjs\".\"block_timestamp_month\" AS cjs_month,\n        COUNT(\"cjs\".\"hash\") AS cjs_count,\n        SUM(\"cjs\".\"input_count\") AS cjs_inputs,\n        SUM(\"cjs\".\"output_count\") AS cjs_outputs,\n        SUM(\"cjs\".\"input_value\") / 100000000 AS cjs_input_val,\n        SUM(\"cjs\".\"output_value\") / 100000000 AS cjs_output_val\n    FROM coinjoinsD AS \"cjs\"\n    GROUP BY \"cjs\".\"block_timestamp_month\"\n    ORDER BY \"cjs\".\"block_timestamp_month\" DESC\n)\nSELECT EXTRACT(MONTH FROM tx_month) AS month,\n    -- Calculate resulting CoinJoin percentages:\n    -- tx_percent = percent of monthly Bitcoin txs that were CoinJoins\n    ROUND(coinjoins.cjs_count / totals.tx_count * 100, 1) AS tx_percent,\n    \n    -- utxos_percent = percent of monthly Bitcoin utxos that were CoinJoins\n    ROUND((coinjoins.cjs_inputs / totals.tx_inputs + coinjoins.cjs_outputs / totals.tx_outputs) / 2 * 100, 1) AS utxos_percent,\n    \n    -- value_percent = percent of monthly Bitcoin volume that took place\n    -- in CoinJoined transactions\n    ROUND(coinjoins.cjs_input_val / totals.tx_input_val * 100, 1) AS value_percent\nFROM totals\nINNER JOIN coinjoins\n    ON totals.tx_month = coinjoins.cjs_month\nORDER BY value_percent DESC\nLIMIT 1;",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 2
    },
    {
        "instance_id": "sf_bq093",
        "question": "Tell me the maximum and minimum net changes in balances for Ethereum Classic addresses on October 14, 2016, calculated by summing debits (values sent to addresses, excluding internal calls), credits (values sent from addresses, excluding internal calls), and gas fees (total gas used multiplied by the gas price for both miners and senders), while only considering successful transactions",
        "external_knowledge": null,
        "question_toks": [
            "Tell",
            "me",
            "the",
            "maximum",
            "and",
            "minimum",
            "net",
            "changes",
            "in",
            "balances",
            "for",
            "Ethereum",
            "Classic",
            "addresses",
            "on",
            "October",
            "14,",
            "2016,",
            "calculated",
            "by",
            "summing",
            "debits",
            "(values",
            "sent",
            "to",
            "addresses,",
            "excluding",
            "internal",
            "calls),",
            "credits",
            "(values",
            "sent",
            "from",
            "addresses,",
            "excluding",
            "internal",
            "calls),",
            "and",
            "gas",
            "fees",
            "(total",
            "gas",
            "used",
            "multiplied",
            "by",
            "the",
            "gas",
            "price",
            "for",
            "both",
            "miners",
            "and",
            "senders),",
            "while",
            "only",
            "considering",
            "successful",
            "transactions"
        ],
        "query": "WITH double_entry_book AS (\n    -- Debits\n    SELECT \n        \"to_address\" AS \"address\", \n        \"value\" AS \"value\"\n    FROM \n        CRYPTO.CRYPTO_ETHEREUM_CLASSIC.TRACES\n    WHERE \n        \"to_address\" IS NOT NULL\n        AND \"status\" = 1\n        AND (\"call_type\" NOT IN ('delegatecall', 'callcode', 'staticcall') OR \"call_type\" IS NULL)\n        AND TO_DATE(TO_TIMESTAMP(\"block_timestamp\" / 1000000)) = '2016-10-14'\n\n    UNION ALL\n    \n    -- Credits\n    SELECT \n        \"from_address\" AS \"address\", \n        - \"value\" AS \"value\"\n    FROM \n        CRYPTO.CRYPTO_ETHEREUM_CLASSIC.TRACES\n    WHERE \n        \"from_address\" IS NOT NULL\n        AND \"status\" = 1\n        AND (\"call_type\" NOT IN ('delegatecall', 'callcode', 'staticcall') OR \"call_type\" IS NULL)\n        AND TO_DATE(TO_TIMESTAMP(\"block_timestamp\" / 1000000)) = '2016-10-14'\n\n    UNION ALL\n\n    -- Transaction Fees Debits\n    SELECT \n        \"miner\" AS \"address\", \n        SUM(CAST(\"receipt_gas_used\" AS NUMERIC) * CAST(\"gas_price\" AS NUMERIC)) AS \"value\"\n    FROM \n        CRYPTO.CRYPTO_ETHEREUM_CLASSIC.TRANSACTIONS AS \"transactions\"\n    JOIN \n        CRYPTO.CRYPTO_ETHEREUM_CLASSIC.BLOCKS AS \"blocks\" \n        ON \"blocks\".\"number\" = \"transactions\".\"block_number\"\n    WHERE \n        TO_DATE(TO_TIMESTAMP(\"block_timestamp\" / 1000000)) = '2016-10-14'\n    GROUP BY \n        \"blocks\".\"miner\"\n\n    UNION ALL\n    \n    -- Transaction Fees Credits\n    SELECT \n        \"from_address\" AS \"address\", \n        -(CAST(\"receipt_gas_used\" AS NUMERIC) * CAST(\"gas_price\" AS NUMERIC)) AS \"value\"\n    FROM \n        CRYPTO.CRYPTO_ETHEREUM_CLASSIC.TRANSACTIONS\n    WHERE \n        TO_DATE(TO_TIMESTAMP(\"block_timestamp\" / 1000000)) = '2016-10-14'\n),\nnet_changes AS (\n    SELECT \n        \"address\",\n        SUM(\"value\") AS \"net_change\"\n    FROM \n        double_entry_book\n    GROUP BY \n        \"address\"\n)\nSELECT \n    MAX(\"net_change\") AS \"max_net_change\",\n    MIN(\"net_change\") AS \"min_net_change\"\nFROM\n    net_changes;",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 5
    },
    {
        "instance_id": "sf_bq292",
        "question": "Analyze Bitcoin transactions since July 2023 to determine monthly percentages of: (1)Transactions classified as CoinJoins (defined by >2 outputs, output value ≤ input value, and multiple identical-value outputs), (2) UTXOs involved in CoinJoins (calculated as the average of CoinJoin input/output ratios against total network UTXOs), (3) Transaction volume (based on input value) attributed to CoinJoins. Provide results in a table with monthly metrics for transactions, UTXOs, and volume.",
        "external_knowledge": null,
        "question_toks": [
            "Analyze",
            "Bitcoin",
            "transactions",
            "since",
            "July",
            "2023",
            "to",
            "determine",
            "monthly",
            "percentages",
            "of:",
            "(1)Transactions",
            "classified",
            "as",
            "CoinJoins",
            "(defined",
            "by",
            ">2",
            "outputs,",
            "output",
            "value",
            "≤",
            "input",
            "value,",
            "and",
            "multiple",
            "identical-value",
            "outputs),",
            "(2)",
            "UTXOs",
            "involved",
            "in",
            "CoinJoins",
            "(calculated",
            "as",
            "the",
            "average",
            "of",
            "CoinJoin",
            "input/output",
            "ratios",
            "against",
            "total",
            "network",
            "UTXOs),",
            "(3)",
            "Transaction",
            "volume",
            "(based",
            "on",
            "input",
            "value)",
            "attributed",
            "to",
            "CoinJoins.",
            "Provide",
            "results",
            "in",
            "a",
            "table",
            "with",
            "monthly",
            "metrics",
            "for",
            "transactions,",
            "UTXOs,",
            "and",
            "volume."
        ],
        "query": "",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq136",
        "question": "Find all 2-hop transaction paths on Zilliqa between addresses `zil1jrpjd8pjuv50cfkfr7eu6yrm3rn5u8rulqhqpz` (source) and `zil19nmxkh020jnequql9kvqkf3pkwm0j0spqtd26e` (destination) since the first transaction date. Exclude paths where intermediate addresses have >50 outgoing transactions (to filter exchanges/high-activity wallets). Ensure paths:  (1) Follow chronological order (earlier transaction timestamps first), (2) Use the format: `<from> --(tx ABCDE..)--> <intermediate> --(tx FGHIJ..)--> <to>`,  (3) Only show paths where both transactions are on-chain confirmed.",
        "external_knowledge": null,
        "question_toks": [
            "Find",
            "all",
            "2-hop",
            "transaction",
            "paths",
            "on",
            "Zilliqa",
            "between",
            "addresses",
            "`zil1jrpjd8pjuv50cfkfr7eu6yrm3rn5u8rulqhqpz`",
            "(source)",
            "and",
            "`zil19nmxkh020jnequql9kvqkf3pkwm0j0spqtd26e`",
            "(destination)",
            "since",
            "the",
            "first",
            "transaction",
            "date.",
            "Exclude",
            "paths",
            "where",
            "intermediate",
            "addresses",
            "have",
            ">50",
            "outgoing",
            "transactions",
            "(to",
            "filter",
            "exchanges/high-activity",
            "wallets).",
            "Ensure",
            "paths:",
            "",
            "(1)",
            "Follow",
            "chronological",
            "order",
            "(earlier",
            "transaction",
            "timestamps",
            "first),",
            "(2)",
            "Use",
            "the",
            "format:",
            "`<from>",
            "--(tx",
            "ABCDE..)-->",
            "<intermediate>",
            "--(tx",
            "FGHIJ..)-->",
            "<to>`,",
            "",
            "(3)",
            "Only",
            "show",
            "paths",
            "where",
            "both",
            "transactions",
            "are",
            "on-chain",
            "confirmed."
        ],
        "query": "",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq065",
        "question": "Retrieve the 10 most recent oracle requests with script ID 3, and for each request: Extract all symbol-rate pairs from the decoded result, adjust each rate by dividing it by the request’s multiplier, return the block timestamp, request ID, symbol, and adjusted rate. Prioritize chronological order (newest first).",
        "external_knowledge": null,
        "question_toks": [
            "Retrieve",
            "the",
            "10",
            "most",
            "recent",
            "oracle",
            "requests",
            "with",
            "script",
            "ID",
            "3,",
            "and",
            "for",
            "each",
            "request:",
            "Extract",
            "all",
            "symbol-rate",
            "pairs",
            "from",
            "the",
            "decoded",
            "result,",
            "adjust",
            "each",
            "rate",
            "by",
            "dividing",
            "it",
            "by",
            "the",
            "request’s",
            "multiplier,",
            "return",
            "the",
            "block",
            "timestamp,",
            "request",
            "ID,",
            "symbol,",
            "and",
            "adjusted",
            "rate.",
            "Prioritize",
            "chronological",
            "order",
            "(newest",
            "first)."
        ],
        "query": "",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq037",
        "question": "About the refined human genetic variations collected in phase 3 on 2015-02-20, I want to know the minimum and maximum start positions as well as the proportions of these two respectively for reference bases 'AT' and 'TA'.",
        "external_knowledge": null,
        "question_toks": [
            "About",
            "the",
            "refined",
            "human",
            "genetic",
            "variations",
            "collected",
            "in",
            "phase",
            "3",
            "on",
            "2015-02-20,",
            "I",
            "want",
            "to",
            "know",
            "the",
            "minimum",
            "and",
            "maximum",
            "start",
            "positions",
            "as",
            "well",
            "as",
            "the",
            "proportions",
            "of",
            "these",
            "two",
            "respectively",
            "for",
            "reference",
            "bases",
            "'AT'",
            "and",
            "'TA'."
        ],
        "query": "WITH A AS (\n    SELECT\n        \"reference_bases\",\n        \"start_position\"\n    FROM\n        \"HUMAN_GENOME_VARIANTS\".\"HUMAN_GENOME_VARIANTS\".\"_1000_GENOMES_PHASE_3_OPTIMIZED_SCHEMA_VARIANTS_20150220\"\n    WHERE\n        \"reference_bases\" IN ('AT', 'TA')\n),\nB AS (\n    SELECT\n        \"reference_bases\",\n        MIN(\"start_position\") AS \"min_start_position\",\n        MAX(\"start_position\") AS \"max_start_position\",\n        COUNT(1) AS \"total_count\"\n    FROM\n        A\n    GROUP BY\n        \"reference_bases\"\n),\nmin_counts AS (\n    SELECT\n        A.\"reference_bases\",  -- Explicitly referencing the column from table A\n        A.\"start_position\" AS \"min_start_position\",\n        COUNT(1) AS \"min_count\"\n    FROM\n        A\n    INNER JOIN B \n        ON A.\"reference_bases\" = B.\"reference_bases\"\n    WHERE\n        A.\"start_position\" = B.\"min_start_position\"\n    GROUP BY\n        A.\"reference_bases\", A.\"start_position\"\n),\nmax_counts AS (\n    SELECT\n        A.\"reference_bases\",  -- Explicitly referencing the column from table A\n        A.\"start_position\" AS \"max_start_position\",\n        COUNT(1) AS \"max_count\"\n    FROM\n        A\n    INNER JOIN B\n        ON A.\"reference_bases\" = B.\"reference_bases\"\n    WHERE\n        A.\"start_position\" = B.\"max_start_position\"\n    GROUP BY\n        A.\"reference_bases\", A.\"start_position\"\n)\nSELECT\n    B.\"reference_bases\",  -- Explicitly referencing the column from table B\n    B.\"min_start_position\",\n    CAST(min_counts.\"min_count\" AS FLOAT) / B.\"total_count\" AS \"min_position_ratio\",\n    B.\"max_start_position\",\n    CAST(max_counts.\"max_count\" AS FLOAT) / B.\"total_count\" AS \"max_position_ratio\"\nFROM\n    B\nLEFT JOIN\n    min_counts ON B.\"reference_bases\" = min_counts.\"reference_bases\" AND B.\"min_start_position\" = min_counts.\"min_start_position\"\nLEFT JOIN\n    max_counts ON B.\"reference_bases\" = max_counts.\"reference_bases\" AND B.\"max_start_position\" = max_counts.\"max_start_position\"\nORDER BY\n    B.\"reference_bases\";",
        "db_id": "HUMAN_GENOME_VARIANTS",
        "No. of candidate columns": 202,
        "No. of gold tables": 1
    },
    {
        "instance_id": "sf_bq012",
        "question": "Calculate the average balance (in quadrillions, 10^15) of the top 10 Ethereum addresses by net balance, including incoming and outgoing transfers from traces (only successful transactions and excluding call types like delegatecall, callcode, and staticcall), miner rewards (sum of gas fees per block), and sender gas fee deductions. Exclude null addresses and round the result to two decimal places.",
        "external_knowledge": null,
        "question_toks": [
            "Calculate",
            "the",
            "average",
            "balance",
            "(in",
            "quadrillions,",
            "10^15)",
            "of",
            "the",
            "top",
            "10",
            "Ethereum",
            "addresses",
            "by",
            "net",
            "balance,",
            "including",
            "incoming",
            "and",
            "outgoing",
            "transfers",
            "from",
            "traces",
            "(only",
            "successful",
            "transactions",
            "and",
            "excluding",
            "call",
            "types",
            "like",
            "delegatecall,",
            "callcode,",
            "and",
            "staticcall),",
            "miner",
            "rewards",
            "(sum",
            "of",
            "gas",
            "fees",
            "per",
            "block),",
            "and",
            "sender",
            "gas",
            "fee",
            "deductions.",
            "Exclude",
            "null",
            "addresses",
            "and",
            "round",
            "the",
            "result",
            "to",
            "two",
            "decimal",
            "places."
        ],
        "query": "WITH double_entry_book AS (\n  -- Debits\n  SELECT \n    \"to_address\" AS \"address\",\n    \"value\" AS \"value\"\n  FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TRACES\"\n  WHERE \"to_address\" IS NOT NULL\n    AND \"status\" = 1\n    AND (\"call_type\" NOT IN ('delegatecall', 'callcode', 'staticcall') OR \"call_type\" IS NULL)\n  \n  UNION ALL\n  \n  -- Credits\n  SELECT \n    \"from_address\" AS \"address\",\n    - \"value\" AS \"value\"\n  FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TRACES\"\n  WHERE \"from_address\" IS NOT NULL\n    AND \"status\" = 1\n    AND (\"call_type\" NOT IN ('delegatecall', 'callcode', 'staticcall') OR \"call_type\" IS NULL)\n  \n  UNION ALL\n  \n  -- Transaction fees debits\n  SELECT \n    \"miner\" AS \"address\",\n    SUM(CAST(\"receipt_gas_used\" AS NUMBER) * CAST(\"gas_price\" AS NUMBER)) AS \"value\"\n  FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TRANSACTIONS\" AS \"transactions\"\n  JOIN \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"BLOCKS\" AS \"blocks\"\n    ON \"blocks\".\"number\" = \"transactions\".\"block_number\"\n  GROUP BY \"blocks\".\"miner\"\n  \n  UNION ALL\n  \n  -- Transaction fees credits\n  SELECT \n    \"from_address\" AS \"address\",\n    -(CAST(\"receipt_gas_used\" AS NUMBER) * CAST(\"gas_price\" AS NUMBER)) AS \"value\"\n  FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TRANSACTIONS\"\n),\ntop_10_balances AS (\n  SELECT\n    \"address\",\n    SUM(\"value\") AS \"balance\"\n  FROM double_entry_book\n  GROUP BY \"address\"\n  ORDER BY \"balance\" DESC\n  LIMIT 10\n)\nSELECT \n    ROUND(AVG(\"balance\") / 1e15, 2) AS \"average_balance_trillion\"\nFROM top_10_balances;",
        "db_id": "ETHEREUM_BLOCKCHAIN",
        "No. of candidate columns": 88,
        "No. of gold tables": 5
    },
    {
        "instance_id": "sf_bq187",
        "question": "Calculate the total circulating supply of 'BNB' tokens (in units divided by 10^18) by summing balances of all non-zero addresses, where each address’s balance equals its total received BNB minus sent BNB. Exclude transactions involving the zero address (0x000...) for both senders and receivers.",
        "external_knowledge": null,
        "question_toks": [
            "Calculate",
            "the",
            "total",
            "circulating",
            "supply",
            "of",
            "'BNB'",
            "tokens",
            "(in",
            "units",
            "divided",
            "by",
            "10^18)",
            "by",
            "summing",
            "balances",
            "of",
            "all",
            "non-zero",
            "addresses,",
            "where",
            "each",
            "address’s",
            "balance",
            "equals",
            "its",
            "total",
            "received",
            "BNB",
            "minus",
            "sent",
            "BNB.",
            "Exclude",
            "transactions",
            "involving",
            "the",
            "zero",
            "address",
            "(0x000...)",
            "for",
            "both",
            "senders",
            "and",
            "receivers."
        ],
        "query": "WITH tokenInfo AS (\n    SELECT \"address\"\n    FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TOKENS\"\n    WHERE \"name\" = 'BNB'\n),\n\nreceivedTx AS (\n    SELECT \"tx\".\"to_address\" AS \"addr\", \n           \"tokens\".\"name\" AS \"name\", \n           SUM(CAST(\"tx\".\"value\" AS FLOAT) / POWER(10, 18)) AS \"amount_received\"\n    FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TOKEN_TRANSFERS\" AS \"tx\"\n    JOIN tokenInfo ON \"tx\".\"token_address\" = tokenInfo.\"address\"\n    JOIN \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TOKENS\" AS \"tokens\"\n      ON \"tx\".\"token_address\" = \"tokens\".\"address\"\n    WHERE \"tx\".\"to_address\" <> '0x0000000000000000000000000000000000000000'\n    GROUP BY \"tx\".\"to_address\", \"tokens\".\"name\"\n),\n\nsentTx AS (\n    SELECT \"tx\".\"from_address\" AS \"addr\", \n           \"tokens\".\"name\" AS \"name\", \n           SUM(CAST(\"tx\".\"value\" AS FLOAT) / POWER(10, 18)) AS \"amount_sent\"\n    FROM \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TOKEN_TRANSFERS\" AS \"tx\"\n    JOIN tokenInfo ON \"tx\".\"token_address\" = tokenInfo.\"address\"\n    JOIN \"ETHEREUM_BLOCKCHAIN\".\"ETHEREUM_BLOCKCHAIN\".\"TOKENS\" AS \"tokens\"\n      ON \"tx\".\"token_address\" = \"tokens\".\"address\"\n    WHERE \"tx\".\"from_address\" <> '0x0000000000000000000000000000000000000000'\n    GROUP BY \"tx\".\"from_address\", \"tokens\".\"name\"\n),\n\nwalletBalances AS (\n    SELECT r.\"addr\",\n           COALESCE(SUM(r.\"amount_received\"), 0) - COALESCE(SUM(s.\"amount_sent\"), 0) AS \"balance\"\n    FROM receivedTx AS r\n    LEFT JOIN sentTx AS s\n      ON r.\"addr\" = s.\"addr\"\n    GROUP BY r.\"addr\"\n)\n\nSELECT \n    SUM(\"balance\") AS \"circulating_supply\"\nFROM walletBalances;",
        "db_id": "ETHEREUM_BLOCKCHAIN",
        "No. of candidate columns": 88,
        "No. of gold tables": 5
    },
    {
        "instance_id": "sf_bq450",
        "question": "Generate a comprehensive report of all Ethereum addresses active before January 1, 2017, calculating their net balances (adjusted for transaction fees and excluding delegatecall/callcode/staticcall transactions), hourly activity patterns, active days, incoming/outgoing transaction metrics (counts, unique counterparties, average ETH transfers), ERC20 token interactions (in/out counts, unique tokens, counterparties), mining rewards, contract creation frequency, failed transaction counts, and contract bytecode sizes, with all ETH values converted to standard units (divided by 10^18) and excluding addresses with no transaction history.",
        "external_knowledge": "ethereum_data_transformation.md",
        "question_toks": [
            "Generate",
            "a",
            "comprehensive",
            "report",
            "of",
            "all",
            "Ethereum",
            "addresses",
            "active",
            "before",
            "January",
            "1,",
            "2017,",
            "calculating",
            "their",
            "net",
            "balances",
            "(adjusted",
            "for",
            "transaction",
            "fees",
            "and",
            "excluding",
            "delegatecall/callcode/staticcall",
            "transactions),",
            "hourly",
            "activity",
            "patterns,",
            "active",
            "days,",
            "incoming/outgoing",
            "transaction",
            "metrics",
            "(counts,",
            "unique",
            "counterparties,",
            "average",
            "ETH",
            "transfers),",
            "ERC20",
            "token",
            "interactions",
            "(in/out",
            "counts,",
            "unique",
            "tokens,",
            "counterparties),",
            "mining",
            "rewards,",
            "contract",
            "creation",
            "frequency,",
            "failed",
            "transaction",
            "counts,",
            "and",
            "contract",
            "bytecode",
            "sizes,",
            "with",
            "all",
            "ETH",
            "values",
            "converted",
            "to",
            "standard",
            "units",
            "(divided",
            "by",
            "10^18)",
            "and",
            "excluding",
            "addresses",
            "with",
            "no",
            "transaction",
            "history."
        ],
        "query": "",
        "db_id": "ETHEREUM_BLOCKCHAIN",
        "No. of candidate columns": 88,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq034",
        "question": "I want to know the IDs, names of weather stations within a 50 km straight-line distance from the center of Chicago (41.8319°N, 87.6847°W)",
        "external_knowledge": null,
        "question_toks": [
            "I",
            "want",
            "to",
            "know",
            "the",
            "IDs,",
            "names",
            "of",
            "weather",
            "stations",
            "within",
            "a",
            "50",
            "km",
            "straight-line",
            "distance",
            "from",
            "the",
            "center",
            "of",
            "Chicago",
            "(41.8319°N,",
            "87.6847°W)"
        ],
        "query": "",
        "db_id": "ghcn_d",
        "No. of candidate columns": 2141,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq383",
        "question": "Could you provide the highest recorded precipitation, minimum temperature, and maximum temperature from the last 15 days of each year from 2013 to 2016 at weather station USW00094846? Ensure each value represents the peak measurement for that period, with precipitation in millimeters and temperatures in degrees Celsius, using only validated data (non-null values and no quality flags)",
        "external_knowledge": null,
        "question_toks": [
            "Could",
            "you",
            "provide",
            "the",
            "highest",
            "recorded",
            "precipitation,",
            "minimum",
            "temperature,",
            "and",
            "maximum",
            "temperature",
            "from",
            "the",
            "last",
            "15",
            "days",
            "of",
            "each",
            "year",
            "from",
            "2013",
            "to",
            "2016",
            "at",
            "weather",
            "station",
            "USW00094846?",
            "Ensure",
            "each",
            "value",
            "represents",
            "the",
            "peak",
            "measurement",
            "for",
            "that",
            "period,",
            "with",
            "precipitation",
            "in",
            "millimeters",
            "and",
            "temperatures",
            "in",
            "degrees",
            "Celsius,",
            "using",
            "only",
            "validated",
            "data",
            "(non-null",
            "values",
            "and",
            "no",
            "quality",
            "flags)"
        ],
        "query": "WITH data AS (\n  SELECT\n    EXTRACT(YEAR FROM wx.date) AS year,\n    MAX(IF(wx.element = 'PRCP', wx.value/10, NULL)) AS max_prcp,\n    MAX(IF(wx.element = 'TMIN', wx.value/10, NULL)) AS max_tmin,\n    MAX(IF(wx.element = 'TMAX', wx.value/10, NULL)) AS max_tmax\n  FROM\n    `bigquery-public-data.ghcn_d.ghcnd_2013` AS wx\n  WHERE\n    wx.id = 'USW00094846' AND\n    wx.qflag IS NULL AND\n    wx.value IS NOT NULL AND\n    DATE_DIFF(DATE('2013-12-31'), wx.date, DAY) < 15\n  GROUP BY\n    year\n\n  UNION ALL\n\n  SELECT\n    EXTRACT(YEAR FROM wx.date) AS year,\n    MAX(IF(wx.element = 'PRCP', wx.value/10, NULL)) AS max_prcp,\n    MAX(IF(wx.element = 'TMIN', wx.value/10, NULL)) AS max_tmin,\n    MAX(IF(wx.element = 'TMAX', wx.value/10, NULL)) AS max_tmax\n  FROM\n    `bigquery-public-data.ghcn_d.ghcnd_2014` AS wx\n  WHERE\n    wx.id = 'USW00094846' AND\n    wx.qflag IS NULL AND\n    wx.value IS NOT NULL AND\n    DATE_DIFF(DATE('2014-12-31'), wx.date, DAY) < 15\n  GROUP BY\n    year\n\n  UNION ALL\n\n  SELECT\n    EXTRACT(YEAR FROM wx.date) AS year,\n    MAX(IF(wx.element = 'PRCP', wx.value/10, NULL)) AS max_prcp,\n    MAX(IF(wx.element = 'TMIN', wx.value/10, NULL)) AS max_tmin,\n    MAX(IF(wx.element = 'TMAX', wx.value/10, NULL)) AS max_tmax\n  FROM\n    `bigquery-public-data.ghcn_d.ghcnd_2015` AS wx\n  WHERE\n    wx.id = 'USW00094846' AND\n    wx.qflag IS NULL AND\n    wx.value IS NOT NULL AND\n    DATE_DIFF(DATE('2015-12-31'), wx.date, DAY) < 15\n  GROUP BY\n    year\n\n  UNION ALL\n\n  SELECT\n    EXTRACT(YEAR FROM wx.date) AS year,\n    MAX(IF(wx.element = 'PRCP', wx.value/10, NULL)) AS max_prcp,\n    MAX(IF(wx.element = 'TMIN', wx.value/10, NULL)) AS max_tmin,\n    MAX(IF(wx.element = 'TMAX', wx.value/10, NULL)) AS max_tmax\n  FROM\n    `bigquery-public-data.ghcn_d.ghcnd_2016` AS wx\n  WHERE\n    wx.id = 'USW00094846' AND\n    wx.qflag IS NULL AND\n    wx.value IS NOT NULL AND\n    DATE_DIFF(DATE('2016-12-31'), wx.date, DAY) < 15\n  GROUP BY\n    year\n)\n\nSELECT\n  year,\n  MAX(max_prcp) AS annual_max_prcp,\n  MAX(max_tmin) AS annual_max_tmin,\n  MAX(max_tmax) AS annual_max_tmax\nFROM data\nGROUP BY year\nORDER BY year ASC;",
        "db_id": "ghcn_d",
        "No. of candidate columns": 2141,
        "No. of gold tables": 4
    },
    {
        "instance_id": "bq038",
        "question": "Identify the top 10 Citibike stations by highest proportion of group rides, defined as trips starting and ending at the same station where multiple riders departed/arrived within the same 2-minute time window",
        "external_knowledge": null,
        "question_toks": [
            "Identify",
            "the",
            "top",
            "10",
            "Citibike",
            "stations",
            "by",
            "highest",
            "proportion",
            "of",
            "group",
            "rides,",
            "defined",
            "as",
            "trips",
            "starting",
            "and",
            "ending",
            "at",
            "the",
            "same",
            "station",
            "where",
            "multiple",
            "riders",
            "departed/arrived",
            "within",
            "the",
            "same",
            "2-minute",
            "time",
            "window"
        ],
        "query": "",
        "db_id": "new_york",
        "No. of candidate columns": 483,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq098",
        "question": "For NYC yellow taxi trips where both the pickup and dropoff occurred between January 1 and 7, 2016, inclusive, calculate the percentage of trips with no tip in each pickup borough, ensuring that only trips where the dropoff occurs after the pickup are included, the passenger count is greater than zero, and the trip distance, tip amount, tolls amount, MTA tax, fare amount, and total amount are non-negative; define \"no tip\" trips as those where the tip rate is zero, with the tip rate calculated as (tip_amount × 100) divided by total_amount (and considered zero when total_amount is zero).",
        "external_knowledge": "taxi_tip_rate.md",
        "question_toks": [
            "For",
            "NYC",
            "yellow",
            "taxi",
            "trips",
            "where",
            "both",
            "the",
            "pickup",
            "and",
            "dropoff",
            "occurred",
            "between",
            "January",
            "1",
            "and",
            "7,",
            "2016,",
            "inclusive,",
            "calculate",
            "the",
            "percentage",
            "of",
            "trips",
            "with",
            "no",
            "tip",
            "in",
            "each",
            "pickup",
            "borough,",
            "ensuring",
            "that",
            "only",
            "trips",
            "where",
            "the",
            "dropoff",
            "occurs",
            "after",
            "the",
            "pickup",
            "are",
            "included,",
            "the",
            "passenger",
            "count",
            "is",
            "greater",
            "than",
            "zero,",
            "and",
            "the",
            "trip",
            "distance,",
            "tip",
            "amount,",
            "tolls",
            "amount,",
            "MTA",
            "tax,",
            "fare",
            "amount,",
            "and",
            "total",
            "amount",
            "are",
            "non-negative;",
            "define",
            "\"no",
            "tip\"",
            "trips",
            "as",
            "those",
            "where",
            "the",
            "tip",
            "rate",
            "is",
            "zero,",
            "with",
            "the",
            "tip",
            "rate",
            "calculated",
            "as",
            "(tip_amount",
            "×",
            "100)",
            "divided",
            "by",
            "total_amount",
            "(and",
            "considered",
            "zero",
            "when",
            "total_amount",
            "is",
            "zero)."
        ],
        "query": "",
        "db_id": "new_york_plus",
        "No. of candidate columns": 853,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq081",
        "question": "Find the latest ride data for each region between 2014 and 2017. I want to know the name of each region, the trip ID of this ride, the ride duration, the start time, the starting station, and the gender of the rider.",
        "external_knowledge": null,
        "question_toks": [
            "Find",
            "the",
            "latest",
            "ride",
            "data",
            "for",
            "each",
            "region",
            "between",
            "2014",
            "and",
            "2017.",
            "I",
            "want",
            "to",
            "know",
            "the",
            "name",
            "of",
            "each",
            "region,",
            "the",
            "trip",
            "ID",
            "of",
            "this",
            "ride,",
            "the",
            "ride",
            "duration,",
            "the",
            "start",
            "time,",
            "the",
            "starting",
            "station,",
            "and",
            "the",
            "gender",
            "of",
            "the",
            "rider."
        ],
        "query": "",
        "db_id": "san_francisco_plus",
        "No. of candidate columns": 278,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq339",
        "question": "Which month in 2017 had the largest absolute difference between cumulative bike usage minutes for customers and subscribers?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "month",
            "in",
            "2017",
            "had",
            "the",
            "largest",
            "absolute",
            "difference",
            "between",
            "cumulative",
            "bike",
            "usage",
            "minutes",
            "for",
            "customers",
            "and",
            "subscribers?"
        ],
        "query": "WITH monthly_totals AS (\n  SELECT\n    SUM(CASE WHEN subscriber_type = 'Customer' THEN duration_sec / 60 ELSE NULL END) AS customer_minutes_sum,\n    SUM(CASE WHEN subscriber_type = 'Subscriber' THEN duration_sec / 60 ELSE NULL END) AS subscriber_minutes_sum,\n    EXTRACT(MONTH FROM end_date) AS end_month\n  FROM\n    `bigquery-public-data.san_francisco_bikeshare.bikeshare_trips`\n  WHERE\n    EXTRACT(YEAR FROM end_date) = 2017\n  GROUP BY\n    end_month\n),\n\ncumulative_totals AS (\n  SELECT\n    end_month,\n    SUM(customer_minutes_sum) OVER (ORDER BY end_month ROWS UNBOUNDED PRECEDING) / 1000 AS cumulative_minutes_cust,\n    SUM(subscriber_minutes_sum) OVER (ORDER BY end_month ROWS UNBOUNDED PRECEDING) / 1000 AS cumulative_minutes_sub\n  FROM\n    monthly_totals\n),\n\ndifferences AS (\n  SELECT\n    end_month,\n    ABS(cumulative_minutes_cust - cumulative_minutes_sub) AS abs_diff\n  FROM\n    cumulative_totals\n)\n\nSELECT\n  end_month\nFROM\n  differences\nORDER BY\n  abs_diff DESC\nLIMIT 1;",
        "db_id": "san_francisco_plus",
        "No. of candidate columns": 278,
        "No. of gold tables": 1
    },
    {
        "instance_id": "sf_bq014",
        "question": "Can you help me figure out the revenue for the product category that has the highest number of customers making a purchase in their first non-cancelled and non-returned order?",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "help",
            "me",
            "figure",
            "out",
            "the",
            "revenue",
            "for",
            "the",
            "product",
            "category",
            "that",
            "has",
            "the",
            "highest",
            "number",
            "of",
            "customers",
            "making",
            "a",
            "purchase",
            "in",
            "their",
            "first",
            "non-cancelled",
            "and",
            "non-returned",
            "order?"
        ],
        "query": "",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq259",
        "question": "Using data up to the end of 2022 and organized by the month of each user's first purchase, can you provide the percentage of users who made a purchase in each of the first, second, third, and fourth months since their initial purchase, where the \"first month\" refers to the month of their initial purchase?",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "data",
            "up",
            "to",
            "the",
            "end",
            "of",
            "2022",
            "and",
            "organized",
            "by",
            "the",
            "month",
            "of",
            "each",
            "user's",
            "first",
            "purchase,",
            "can",
            "you",
            "provide",
            "the",
            "percentage",
            "of",
            "users",
            "who",
            "made",
            "a",
            "purchase",
            "in",
            "each",
            "of",
            "the",
            "first,",
            "second,",
            "third,",
            "and",
            "fourth",
            "months",
            "since",
            "their",
            "initial",
            "purchase,",
            "where",
            "the",
            "\"first",
            "month\"",
            "refers",
            "to",
            "the",
            "month",
            "of",
            "their",
            "initial",
            "purchase?"
        ],
        "query": "",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq189",
        "question": "Based solely on completed orders, calculate the average monthly percentage growth rate in the number of unique orders (counting distinct order IDs) for each product category by comparing each month's count to the previous month within the same category. Identify the product category with the highest average of these monthly order growth rates. Then, for that specific product category, compute the average monthly revenue growth rate by calculating the percentage change in total revenue (sum of sale prices) from month to month and averaging these values over the entire period.",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Based",
            "solely",
            "on",
            "completed",
            "orders,",
            "calculate",
            "the",
            "average",
            "monthly",
            "percentage",
            "growth",
            "rate",
            "in",
            "the",
            "number",
            "of",
            "unique",
            "orders",
            "(counting",
            "distinct",
            "order",
            "IDs)",
            "for",
            "each",
            "product",
            "category",
            "by",
            "comparing",
            "each",
            "month's",
            "count",
            "to",
            "the",
            "previous",
            "month",
            "within",
            "the",
            "same",
            "category.",
            "Identify",
            "the",
            "product",
            "category",
            "with",
            "the",
            "highest",
            "average",
            "of",
            "these",
            "monthly",
            "order",
            "growth",
            "rates.",
            "Then,",
            "for",
            "that",
            "specific",
            "product",
            "category,",
            "compute",
            "the",
            "average",
            "monthly",
            "revenue",
            "growth",
            "rate",
            "by",
            "calculating",
            "the",
            "percentage",
            "change",
            "in",
            "total",
            "revenue",
            "(sum",
            "of",
            "sale",
            "prices)",
            "from",
            "month",
            "to",
            "month",
            "and",
            "averaging",
            "these",
            "values",
            "over",
            "the",
            "entire",
            "period."
        ],
        "query": "",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq264",
        "question": "Identify the difference in the number of the oldest and youngest users registered between January 1, 2019, and April 30, 2022, from our e-commerce platform data.",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Identify",
            "the",
            "difference",
            "in",
            "the",
            "number",
            "of",
            "the",
            "oldest",
            "and",
            "youngest",
            "users",
            "registered",
            "between",
            "January",
            "1,",
            "2019,",
            "and",
            "April",
            "30,",
            "2022,",
            "from",
            "our",
            "e-commerce",
            "platform",
            "data."
        ],
        "query": "WITH youngest AS (\n    SELECT\n        \"gender\", \n        \"id\", \n        \"first_name\", \n        \"last_name\", \n        \"age\", \n        'youngest' AS \"tag\"\n    FROM \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\"\n    WHERE \n        \"age\" = (SELECT MIN(\"age\") FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\")\n        AND TO_TIMESTAMP(\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2019-01-01') AND TO_TIMESTAMP('2022-04-30')\n    GROUP BY \n        \"gender\", \"id\", \"first_name\", \"last_name\", \"age\"\n    ORDER BY \n        \"gender\"\n),\n\noldest AS (\n    SELECT\n        \"gender\", \n        \"id\", \n        \"first_name\", \n        \"last_name\", \n        \"age\", \n        'oldest' AS \"tag\"\n    FROM \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\"\n    WHERE \n        \"age\" = (SELECT MAX(\"age\") FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\")\n        AND TO_TIMESTAMP(\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2019-01-01') AND TO_TIMESTAMP('2022-04-30')\n    GROUP BY \n        \"gender\", \"id\", \"first_name\", \"last_name\", \"age\"\n    ORDER BY \n        \"gender\"\n),\n\nTEMP_record AS (\n    SELECT * FROM youngest\n    UNION ALL\n    SELECT * FROM oldest\n)\n\nSELECT \n    SUM(CASE WHEN \"age\" = (SELECT MAX(\"age\") FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\") THEN 1 END) - \n    SUM(CASE WHEN \"age\" = (SELECT MIN(\"age\") FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\") THEN 1 END) AS \"diff\"\nFROM \n    TEMP_record;",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 6
    },
    {
        "instance_id": "sf_bq197",
        "question": "Considering only orders with a status of 'Complete' and products with a non-null brand, identify for each month prior to July 2024 the product that achieved the highest sales volume and revenue, including in the results the product's name, brand, category, total sales, total revenue, month, and order status.",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Considering",
            "only",
            "orders",
            "with",
            "a",
            "status",
            "of",
            "'Complete'",
            "and",
            "products",
            "with",
            "a",
            "non-null",
            "brand,",
            "identify",
            "for",
            "each",
            "month",
            "prior",
            "to",
            "July",
            "2024",
            "the",
            "product",
            "that",
            "achieved",
            "the",
            "highest",
            "sales",
            "volume",
            "and",
            "revenue,",
            "including",
            "in",
            "the",
            "results",
            "the",
            "product's",
            "name,",
            "brand,",
            "category,",
            "total",
            "sales,",
            "total",
            "revenue,",
            "month,",
            "and",
            "order",
            "status."
        ],
        "query": "",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq266",
        "question": "Please provide the names of the products that had sales in each month of 2020 and had the lowest profit, calculated as the difference between their retail price and cost from the products data. Exclude any months where this data isn't available. Please list the products in chronological order based on the month.",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "provide",
            "the",
            "names",
            "of",
            "the",
            "products",
            "that",
            "had",
            "sales",
            "in",
            "each",
            "month",
            "of",
            "2020",
            "and",
            "had",
            "the",
            "lowest",
            "profit,",
            "calculated",
            "as",
            "the",
            "difference",
            "between",
            "their",
            "retail",
            "price",
            "and",
            "cost",
            "from",
            "the",
            "products",
            "data.",
            "Exclude",
            "any",
            "months",
            "where",
            "this",
            "data",
            "isn't",
            "available.",
            "Please",
            "list",
            "the",
            "products",
            "in",
            "chronological",
            "order",
            "based",
            "on",
            "the",
            "month."
        ],
        "query": "",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq361",
        "question": "For the user cohort with a first purchase date in January 2020, what proportion of users returned in the subsequent months of 2020?",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "the",
            "user",
            "cohort",
            "with",
            "a",
            "first",
            "purchase",
            "date",
            "in",
            "January",
            "2020,",
            "what",
            "proportion",
            "of",
            "users",
            "returned",
            "in",
            "the",
            "subsequent",
            "months",
            "of",
            "2020?"
        ],
        "query": "",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq271",
        "question": "Please generate a report that, for each month in 2021, provides the number of orders, the number of unique purchasers, and the profit (calculated as the sum of product retail prices minus the sum of product costs), where the orders were placed during 2021 by users who registered in 2021 for inventory items created in 2021, and group the results by the users' country, product department, and product category.",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "generate",
            "a",
            "report",
            "that,",
            "for",
            "each",
            "month",
            "in",
            "2021,",
            "provides",
            "the",
            "number",
            "of",
            "orders,",
            "the",
            "number",
            "of",
            "unique",
            "purchasers,",
            "and",
            "the",
            "profit",
            "(calculated",
            "as",
            "the",
            "sum",
            "of",
            "product",
            "retail",
            "prices",
            "minus",
            "the",
            "sum",
            "of",
            "product",
            "costs),",
            "where",
            "the",
            "orders",
            "were",
            "placed",
            "during",
            "2021",
            "by",
            "users",
            "who",
            "registered",
            "in",
            "2021",
            "for",
            "inventory",
            "items",
            "created",
            "in",
            "2021,",
            "and",
            "group",
            "the",
            "results",
            "by",
            "the",
            "users'",
            "country,",
            "product",
            "department,",
            "and",
            "product",
            "category."
        ],
        "query": "WITH\norders_x_order_items AS (\n  SELECT orders.*,\n         order_items.\"inventory_item_id\",\n         order_items.\"sale_price\"\n  FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDERS\" AS orders\n  LEFT JOIN \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDER_ITEMS\" AS order_items\n  ON orders.\"order_id\" = order_items.\"order_id\"\n  WHERE TO_TIMESTAMP_NTZ(orders.\"created_at\" / 1000000) BETWEEN TO_TIMESTAMP_NTZ('2021-01-01') AND TO_TIMESTAMP_NTZ('2021-12-31')\n),\n\norders_x_inventory AS (\n  SELECT orders_x_order_items.*,\n         inventory_items.\"product_category\",\n         inventory_items.\"product_department\",\n         inventory_items.\"product_retail_price\",\n         inventory_items.\"product_distribution_center_id\",\n         inventory_items.\"cost\",\n         distribution_centers.\"name\"\n  FROM orders_x_order_items\n  LEFT JOIN \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"INVENTORY_ITEMS\" AS inventory_items\n  ON orders_x_order_items.\"inventory_item_id\" = inventory_items.\"id\"\n  LEFT JOIN \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"DISTRIBUTION_CENTERS\" AS distribution_centers\n  ON inventory_items.\"product_distribution_center_id\" = distribution_centers.\"id\"\n  WHERE TO_TIMESTAMP_NTZ(inventory_items.\"created_at\" / 1000000) BETWEEN TO_TIMESTAMP_NTZ('2021-01-01') AND TO_TIMESTAMP_NTZ('2021-12-31')\n),\n\norders_x_users AS (\n  SELECT orders_x_inventory.*,\n         users.\"country\" AS \"users_country\"\n  FROM orders_x_inventory\n  LEFT JOIN \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\" AS users\n  ON orders_x_inventory.\"user_id\" = users.\"id\"\n  WHERE TO_TIMESTAMP_NTZ(users.\"created_at\" / 1000000) BETWEEN TO_TIMESTAMP_NTZ('2021-01-01') AND TO_TIMESTAMP_NTZ('2021-12-31')\n)\n\nSELECT \n  DATE_TRUNC('MONTH', TO_DATE(TO_TIMESTAMP_NTZ(orders_x_users.\"created_at\" / 1000000))) AS \"reporting_month\",\n  orders_x_users.\"users_country\",\n  orders_x_users.\"product_department\",\n  orders_x_users.\"product_category\",\n  COUNT(DISTINCT orders_x_users.\"order_id\") AS \"n_order\",\n  COUNT(DISTINCT orders_x_users.\"user_id\") AS \"n_purchasers\",\n  SUM(orders_x_users.\"product_retail_price\") - SUM(orders_x_users.\"cost\") AS \"profit\"\nFROM orders_x_users\nGROUP BY 1, 2, 3, 4\nORDER BY \"reporting_month\";",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 5
    },
    {
        "instance_id": "sf_bq273",
        "question": "Can you list the top 5 months from August 2022 to November 2023 where the profit from Facebook-sourced completed orders showed the largest month-over-month increase? Calculate profit as sales minus costs.",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "list",
            "the",
            "top",
            "5",
            "months",
            "from",
            "August",
            "2022",
            "to",
            "November",
            "2023",
            "where",
            "the",
            "profit",
            "from",
            "Facebook-sourced",
            "completed",
            "orders",
            "showed",
            "the",
            "largest",
            "month-over-month",
            "increase?",
            "Calculate",
            "profit",
            "as",
            "sales",
            "minus",
            "costs."
        ],
        "query": "WITH \norders AS (\n  SELECT\n    \"order_id\", \n    \"user_id\", \n    \"created_at\",\n    DATE_TRUNC('MONTH', TO_TIMESTAMP_NTZ(\"delivered_at\" / 1000000)) AS \"delivery_month\",  -- Converting to timestamp\n    \"status\" \n  FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDERS\"\n),\n\norder_items AS (\n  SELECT \n    \"order_id\", \n    \"product_id\", \n    \"sale_price\" \n  FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDER_ITEMS\"\n),\n\nproducts AS (\n  SELECT \n    \"id\", \n    \"cost\"\n  FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"PRODUCTS\"\n),\n\nusers AS (\n  SELECT\n    \"id\", \n    \"traffic_source\" \n  FROM \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\"\n),\n\nfilter_join AS (\n  SELECT \n    orders.\"order_id\",\n    orders.\"user_id\",\n    order_items.\"product_id\",\n    orders.\"delivery_month\",\n    orders.\"status\",\n    order_items.\"sale_price\",\n    products.\"cost\",\n    users.\"traffic_source\"\n  FROM orders\n  JOIN order_items ON orders.\"order_id\" = order_items.\"order_id\"\n  JOIN products ON order_items.\"product_id\" = products.\"id\"\n  JOIN users ON orders.\"user_id\" = users.\"id\"\n  WHERE orders.\"status\" = 'Complete' \n    AND users.\"traffic_source\" = 'Facebook'\n    AND TO_TIMESTAMP_NTZ(orders.\"created_at\" / 1000000) BETWEEN TO_TIMESTAMP_NTZ('2022-07-01') AND TO_TIMESTAMP_NTZ('2023-11-30')  -- Include July for calculation\n),\n\nmonthly_sales AS (\n  SELECT \n    \"delivery_month\",\n    \"traffic_source\",\n    SUM(\"sale_price\") AS \"total_revenue\",\n    SUM(\"sale_price\") - SUM(\"cost\") AS \"total_profit\",\n    COUNT(DISTINCT \"product_id\") AS \"product_quantity\",\n    COUNT(DISTINCT \"order_id\") AS \"orders_quantity\",\n    COUNT(DISTINCT \"user_id\") AS \"users_quantity\"\n  FROM filter_join\n  GROUP BY \"delivery_month\", \"traffic_source\"\n)\n\n-- Filter to show only 8th month and onwards, but calculate using July\nSELECT \n  current_month.\"delivery_month\",\n  COALESCE(\n    current_month.\"total_profit\" - previous_month.\"total_profit\", \n    0  -- If there is no previous month (i.e. for 8月), return 0\n  ) AS \"profit_vs_prior_month\"\nFROM monthly_sales AS current_month\nLEFT JOIN monthly_sales AS previous_month\n  ON current_month.\"traffic_source\" = previous_month.\"traffic_source\"\n  AND current_month.\"delivery_month\" = DATEADD(MONTH, -1, previous_month.\"delivery_month\")  -- Correctly join to previous month\nWHERE current_month.\"delivery_month\" >= '2022-08-01'  -- Only show August and later data, but use July for calculation\nORDER BY \"profit_vs_prior_month\" DESC\nLIMIT 5;",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 4
    },
    {
        "instance_id": "bq018",
        "question": "Which day in March and April had the highest COVID-19 confirmed case growth rate in the United States? The format is MM-DD.",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "day",
            "in",
            "March",
            "and",
            "April",
            "had",
            "the",
            "highest",
            "COVID-19",
            "confirmed",
            "case",
            "growth",
            "rate",
            "in",
            "the",
            "United",
            "States?",
            "The",
            "format",
            "is",
            "MM-DD."
        ],
        "query": "",
        "db_id": "covid19_open_data",
        "No. of candidate columns": 701,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq085",
        "question": "Could you provide, for the United States, France, China, Italy, Spain, Germany, and Iran, the total number of confirmed COVID-19 cases as of April 20, 2020, along with the number of cases per 100,000 people based on their total 2020 populations calculated by summing all relevant population entries from the World Bank data",
        "external_knowledge": null,
        "question_toks": [
            "Could",
            "you",
            "provide,",
            "for",
            "the",
            "United",
            "States,",
            "France,",
            "China,",
            "Italy,",
            "Spain,",
            "Germany,",
            "and",
            "Iran,",
            "the",
            "total",
            "number",
            "of",
            "confirmed",
            "COVID-19",
            "cases",
            "as",
            "of",
            "April",
            "20,",
            "2020,",
            "along",
            "with",
            "the",
            "number",
            "of",
            "cases",
            "per",
            "100,000",
            "people",
            "based",
            "on",
            "their",
            "total",
            "2020",
            "populations",
            "calculated",
            "by",
            "summing",
            "all",
            "relevant",
            "population",
            "entries",
            "from",
            "the",
            "World",
            "Bank",
            "data"
        ],
        "query": "",
        "db_id": "covid19_jhu_world_bank",
        "No. of candidate columns": 3771,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq088",
        "question": "Please calculate the average levels of anxiety and depression symptoms from the weekly country data for the United States during the periods from January 1, 2019, to January 1, 2020, and from January 1, 2020, to January 1, 2021. Then, compute the percentage increase in these average symptom levels from the 2019 period to the 2020 period.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "calculate",
            "the",
            "average",
            "levels",
            "of",
            "anxiety",
            "and",
            "depression",
            "symptoms",
            "from",
            "the",
            "weekly",
            "country",
            "data",
            "for",
            "the",
            "United",
            "States",
            "during",
            "the",
            "periods",
            "from",
            "January",
            "1,",
            "2019,",
            "to",
            "January",
            "1,",
            "2020,",
            "and",
            "from",
            "January",
            "1,",
            "2020,",
            "to",
            "January",
            "1,",
            "2021.",
            "Then,",
            "compute",
            "the",
            "percentage",
            "increase",
            "in",
            "these",
            "average",
            "symptom",
            "levels",
            "from",
            "the",
            "2019",
            "period",
            "to",
            "the",
            "2020",
            "period."
        ],
        "query": "",
        "db_id": "covid19_symptom_search",
        "No. of candidate columns": 2580,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq089",
        "question": "Given the latest population estimates from the 2018 five-year American Community Survey, what is the number of vaccine sites per 1000 people for counties in California?",
        "external_knowledge": null,
        "question_toks": [
            "Given",
            "the",
            "latest",
            "population",
            "estimates",
            "from",
            "the",
            "2018",
            "five-year",
            "American",
            "Community",
            "Survey,",
            "what",
            "is",
            "the",
            "number",
            "of",
            "vaccine",
            "sites",
            "per",
            "1000",
            "people",
            "for",
            "counties",
            "in",
            "California?"
        ],
        "query": "",
        "db_id": "covid19_usa",
        "No. of candidate columns": 70861,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq407",
        "question": "Find the top three counties with populations over 50,000, using the 2020 5-year census data, that had the highest COVID-19 case fatality rates on August 27, 2020. For these counties, provide the name, state, median age, total population, number of confirmed COVID-19 cases per 100,000 people, number of deaths per 100,000 people, and the case fatality rate as a percentage",
        "external_knowledge": null,
        "question_toks": [
            "Find",
            "the",
            "top",
            "three",
            "counties",
            "with",
            "populations",
            "over",
            "50,000,",
            "using",
            "the",
            "2020",
            "5-year",
            "census",
            "data,",
            "that",
            "had",
            "the",
            "highest",
            "COVID-19",
            "case",
            "fatality",
            "rates",
            "on",
            "August",
            "27,",
            "2020.",
            "For",
            "these",
            "counties,",
            "provide",
            "the",
            "name,",
            "state,",
            "median",
            "age,",
            "total",
            "population,",
            "number",
            "of",
            "confirmed",
            "COVID-19",
            "cases",
            "per",
            "100,000",
            "people,",
            "number",
            "of",
            "deaths",
            "per",
            "100,000",
            "people,",
            "and",
            "the",
            "case",
            "fatality",
            "rate",
            "as",
            "a",
            "percentage"
        ],
        "query": "",
        "db_id": "covid19_usa",
        "No. of candidate columns": 70861,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq461",
        "question": "Please provide a chronological summary of all scoring plays from the 2014 season game where the Wildcats were the home team and the Fighting Irish were the away team. Include for each scoring event the game clock, cumulative scores for both teams (Wildcats and Fighting Irish), the team that scored, and a description of the event.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "provide",
            "a",
            "chronological",
            "summary",
            "of",
            "all",
            "scoring",
            "plays",
            "from",
            "the",
            "2014",
            "season",
            "game",
            "where",
            "the",
            "Wildcats",
            "were",
            "the",
            "home",
            "team",
            "and",
            "the",
            "Fighting",
            "Irish",
            "were",
            "the",
            "away",
            "team.",
            "Include",
            "for",
            "each",
            "scoring",
            "event",
            "the",
            "game",
            "clock,",
            "cumulative",
            "scores",
            "for",
            "both",
            "teams",
            "(Wildcats",
            "and",
            "Fighting",
            "Irish),",
            "the",
            "team",
            "that",
            "scored,",
            "and",
            "a",
            "description",
            "of",
            "the",
            "event."
        ],
        "query": "",
        "db_id": "ncaa_basketball",
        "No. of candidate columns": 505,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq198",
        "question": "List the top 5 universities with the most seasons where they achieved the maximum wins in their respective NCAA basketball seasons between 1900-2000, showing each team's total number of such peak-performance seasons, while excluding entries with missing team names.",
        "external_knowledge": null,
        "question_toks": [
            "List",
            "the",
            "top",
            "5",
            "universities",
            "with",
            "the",
            "most",
            "seasons",
            "where",
            "they",
            "achieved",
            "the",
            "maximum",
            "wins",
            "in",
            "their",
            "respective",
            "NCAA",
            "basketball",
            "seasons",
            "between",
            "1900-2000,",
            "showing",
            "each",
            "team's",
            "total",
            "number",
            "of",
            "such",
            "peak-performance",
            "seasons,",
            "while",
            "excluding",
            "entries",
            "with",
            "missing",
            "team",
            "names."
        ],
        "query": "",
        "db_id": "ncaa_basketball",
        "No. of candidate columns": 505,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq462",
        "question": "Please generate a table that lists the top five NCAA basketball records in each of the following four categories: (1) the largest venues by seating capacity (include all venues with Date as 'N/A'), (2) the National Championship games since the 2016 season with the biggest point margin victories, (3) the games since the 2011 season with the highest total points scored by both teams combined, and (4) the games since the 2011 season with the highest total three-pointers made by both teams combined. Organize the results into a table with columns for Category, Date, Matchup or Venue, and Key Metric.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "generate",
            "a",
            "table",
            "that",
            "lists",
            "the",
            "top",
            "five",
            "NCAA",
            "basketball",
            "records",
            "in",
            "each",
            "of",
            "the",
            "following",
            "four",
            "categories:",
            "(1)",
            "the",
            "largest",
            "venues",
            "by",
            "seating",
            "capacity",
            "(include",
            "all",
            "venues",
            "with",
            "Date",
            "as",
            "'N/A'),",
            "(2)",
            "the",
            "National",
            "Championship",
            "games",
            "since",
            "the",
            "2016",
            "season",
            "with",
            "the",
            "biggest",
            "point",
            "margin",
            "victories,",
            "(3)",
            "the",
            "games",
            "since",
            "the",
            "2011",
            "season",
            "with",
            "the",
            "highest",
            "total",
            "points",
            "scored",
            "by",
            "both",
            "teams",
            "combined,",
            "and",
            "(4)",
            "the",
            "games",
            "since",
            "the",
            "2011",
            "season",
            "with",
            "the",
            "highest",
            "total",
            "three-pointers",
            "made",
            "by",
            "both",
            "teams",
            "combined.",
            "Organize",
            "the",
            "results",
            "into",
            "a",
            "table",
            "with",
            "columns",
            "for",
            "Category,",
            "Date,",
            "Matchup",
            "or",
            "Venue,",
            "and",
            "Key",
            "Metric."
        ],
        "query": "",
        "db_id": "ncaa_basketball",
        "No. of candidate columns": 505,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq428",
        "question": "For the top five team markets with the highest number of distinct players who scored at least 15 points during the second period of games between 2010 and 2018, provide details of each game they played in NCAA basketball historical tournament matches during the same period, as specified in the data model document.",
        "external_knowledge": "ncaa_data_model.md",
        "question_toks": [
            "For",
            "the",
            "top",
            "five",
            "team",
            "markets",
            "with",
            "the",
            "highest",
            "number",
            "of",
            "distinct",
            "players",
            "who",
            "scored",
            "at",
            "least",
            "15",
            "points",
            "during",
            "the",
            "second",
            "period",
            "of",
            "games",
            "between",
            "2010",
            "and",
            "2018,",
            "provide",
            "details",
            "of",
            "each",
            "game",
            "they",
            "played",
            "in",
            "NCAA",
            "basketball",
            "historical",
            "tournament",
            "matches",
            "during",
            "the",
            "same",
            "period,",
            "as",
            "specified",
            "in",
            "the",
            "data",
            "model",
            "document."
        ],
        "query": "",
        "db_id": "ncaa_basketball",
        "No. of candidate columns": 505,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq144",
        "question": "Create a dataset by combining NCAA men's basketball tournament game outcomes from the 2014 season onwards, including both the historical tournament games and the 2018 tournament results, with the corresponding pace and efficiency performance metrics for each team and their opponents from the feature_engineering data. The dataset should include the season, game outcome labels (win or loss), team and opponent seeds, school names, pace and efficiency rankings, statistical values, and the differences between the team's and the opponent's metrics to enable a comprehensive analysis of team and opponent dynamics.",
        "external_knowledge": "NCAA_Basketball_Tournament_SQL_Query_Variable_Guide.md",
        "question_toks": [
            "Create",
            "a",
            "dataset",
            "by",
            "combining",
            "NCAA",
            "men's",
            "basketball",
            "tournament",
            "game",
            "outcomes",
            "from",
            "the",
            "2014",
            "season",
            "onwards,",
            "including",
            "both",
            "the",
            "historical",
            "tournament",
            "games",
            "and",
            "the",
            "2018",
            "tournament",
            "results,",
            "with",
            "the",
            "corresponding",
            "pace",
            "and",
            "efficiency",
            "performance",
            "metrics",
            "for",
            "each",
            "team",
            "and",
            "their",
            "opponents",
            "from",
            "the",
            "feature_engineering",
            "data.",
            "The",
            "dataset",
            "should",
            "include",
            "the",
            "season,",
            "game",
            "outcome",
            "labels",
            "(win",
            "or",
            "loss),",
            "team",
            "and",
            "opponent",
            "seeds,",
            "school",
            "names,",
            "pace",
            "and",
            "efficiency",
            "rankings,",
            "statistical",
            "values,",
            "and",
            "the",
            "differences",
            "between",
            "the",
            "team's",
            "and",
            "the",
            "opponent's",
            "metrics",
            "to",
            "enable",
            "a",
            "comprehensive",
            "analysis",
            "of",
            "team",
            "and",
            "opponent",
            "dynamics."
        ],
        "query": "",
        "db_id": "ncaa_insights",
        "No. of candidate columns": 552,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq113",
        "question": "Which county in Utah experienced the greatest percentage increase in construction employment from 2000 to 2018, calculated by averaging the employment levels during the third month of each quarter in those years? What is the corresponding percentage increase?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "county",
            "in",
            "Utah",
            "experienced",
            "the",
            "greatest",
            "percentage",
            "increase",
            "in",
            "construction",
            "employment",
            "from",
            "2000",
            "to",
            "2018,",
            "calculated",
            "by",
            "averaging",
            "the",
            "employment",
            "levels",
            "during",
            "the",
            "third",
            "month",
            "of",
            "each",
            "quarter",
            "in",
            "those",
            "years?",
            "What",
            "is",
            "the",
            "corresponding",
            "percentage",
            "increase?"
        ],
        "query": "",
        "db_id": "bls",
        "No. of candidate columns": 23205,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq406",
        "question": "Please calculate the growth rates for Asians, Black people, Latinx people, Native Americans, White people, US women, US men, global women, and global men from 2014 to 2024 concerning the overall workforce.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "calculate",
            "the",
            "growth",
            "rates",
            "for",
            "Asians,",
            "Black",
            "people,",
            "Latinx",
            "people,",
            "Native",
            "Americans,",
            "White",
            "people,",
            "US",
            "women,",
            "US",
            "men,",
            "global",
            "women,",
            "and",
            "global",
            "men",
            "from",
            "2014",
            "to",
            "2024",
            "concerning",
            "the",
            "overall",
            "workforce."
        ],
        "query": "",
        "db_id": "google_dei",
        "No. of candidate columns": 23134,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq058",
        "question": "Retrieve all finalized deposits into Optimism at block 29815485 using the Optimism Standard Bridge, including transaction hash, an Etherscan link (the complete URL), L1 and L2 token addresses, sender and receiver addresses (with leading zeroes stripped), and the deposited amount (converted from hex to decimal). Ensure data is properly formatted and parsed according to Optimism's address and token standards, and remove the prefix '0x' except transaction hash. Note that, the keccak-256 hash of the Ethereum event signature for DepositFinalized is \"0x3303facd24627943a92e9dc87cfbb34b15c49b726eec3ad3487c16be9ab8efe8\".",
        "external_knowledge": "optimism_standard_bridge_contract.md",
        "question_toks": [
            "Retrieve",
            "all",
            "finalized",
            "deposits",
            "into",
            "Optimism",
            "at",
            "block",
            "29815485",
            "using",
            "the",
            "Optimism",
            "Standard",
            "Bridge,",
            "including",
            "transaction",
            "hash,",
            "an",
            "Etherscan",
            "link",
            "(the",
            "complete",
            "URL),",
            "L1",
            "and",
            "L2",
            "token",
            "addresses,",
            "sender",
            "and",
            "receiver",
            "addresses",
            "(with",
            "leading",
            "zeroes",
            "stripped),",
            "and",
            "the",
            "deposited",
            "amount",
            "(converted",
            "from",
            "hex",
            "to",
            "decimal).",
            "Ensure",
            "data",
            "is",
            "properly",
            "formatted",
            "and",
            "parsed",
            "according",
            "to",
            "Optimism's",
            "address",
            "and",
            "token",
            "standards,",
            "and",
            "remove",
            "the",
            "prefix",
            "'0x'",
            "except",
            "transaction",
            "hash.",
            "Note",
            "that,",
            "the",
            "keccak-256",
            "hash",
            "of",
            "the",
            "Ethereum",
            "event",
            "signature",
            "for",
            "DepositFinalized",
            "is",
            "\"0x3303facd24627943a92e9dc87cfbb34b15c49b726eec3ad3487c16be9ab8efe8\"."
        ],
        "query": "",
        "db_id": "GOOG_BLOCKCHAIN",
        "No. of candidate columns": 22,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq062",
        "question": "What is the most frequently used license by packages in each system?",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "is",
            "the",
            "most",
            "frequently",
            "used",
            "license",
            "by",
            "packages",
            "in",
            "each",
            "system?"
        ],
        "query": "",
        "db_id": "DEPS_DEV_V1",
        "No. of candidate columns": 78,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq063",
        "question": "Find the GitHub URL (with link label 'SOURCE_REPO') of the latest released version of the NPM package that has the highest number of dependencies in its latest released version, excluding packages whose names contain the character '@' and only considering URLs where the link label is 'SOURCE_REPO' and the URL contains 'github.com'.",
        "external_knowledge": null,
        "question_toks": [
            "Find",
            "the",
            "GitHub",
            "URL",
            "(with",
            "link",
            "label",
            "'SOURCE_REPO')",
            "of",
            "the",
            "latest",
            "released",
            "version",
            "of",
            "the",
            "NPM",
            "package",
            "that",
            "has",
            "the",
            "highest",
            "number",
            "of",
            "dependencies",
            "in",
            "its",
            "latest",
            "released",
            "version,",
            "excluding",
            "packages",
            "whose",
            "names",
            "contain",
            "the",
            "character",
            "'@'",
            "and",
            "only",
            "considering",
            "URLs",
            "where",
            "the",
            "link",
            "label",
            "is",
            "'SOURCE_REPO'",
            "and",
            "the",
            "URL",
            "contains",
            "'github.com'."
        ],
        "query": "",
        "db_id": "DEPS_DEV_V1",
        "No. of candidate columns": 78,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq363",
        "question": "Calculate the total number of trips and average fare (formatted to two decimal places) for ten equal quantile groups of taxi trips based on rounded minute durations between 1-50 minutes, displaying each group's formatted time range (XXm to XXm) sorted chronologically, where quantile groups are created from ordered trip durations and time ranges represent the minimum/maximum values within each quantile partition",
        "external_knowledge": null,
        "question_toks": [
            "Calculate",
            "the",
            "total",
            "number",
            "of",
            "trips",
            "and",
            "average",
            "fare",
            "(formatted",
            "to",
            "two",
            "decimal",
            "places)",
            "for",
            "ten",
            "equal",
            "quantile",
            "groups",
            "of",
            "taxi",
            "trips",
            "based",
            "on",
            "rounded",
            "minute",
            "durations",
            "between",
            "1-50",
            "minutes,",
            "displaying",
            "each",
            "group's",
            "formatted",
            "time",
            "range",
            "(XXm",
            "to",
            "XXm)",
            "sorted",
            "chronologically,",
            "where",
            "quantile",
            "groups",
            "are",
            "created",
            "from",
            "ordered",
            "trip",
            "durations",
            "and",
            "time",
            "ranges",
            "represent",
            "the",
            "minimum/maximum",
            "values",
            "within",
            "each",
            "quantile",
            "partition"
        ],
        "query": "SELECT\n  FORMAT('%02.0fm to %02.0fm', min_minutes, max_minutes) AS minutes_range,\n  SUM(trips) AS total_trips,\n  FORMAT('%3.2f', SUM(total_fare) / SUM(trips)) AS average_fare\nFROM (\n  SELECT\n    MIN(duration_in_minutes) OVER (quantiles) AS min_minutes,\n    MAX(duration_in_minutes) OVER (quantiles) AS max_minutes,\n    SUM(trips) AS trips,\n    SUM(total_fare) AS total_fare\n  FROM (\n    SELECT\n      ROUND(trip_seconds / 60) AS duration_in_minutes,\n      NTILE(10) OVER (ORDER BY trip_seconds / 60) AS quantile,\n      COUNT(1) AS trips,\n      SUM(fare) AS total_fare\n    FROM\n      `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n    WHERE\n      ROUND(trip_seconds / 60) BETWEEN 1 AND 50\n    GROUP BY\n      trip_seconds,\n      duration_in_minutes )\n  GROUP BY\n    duration_in_minutes,\n    quantile\n  WINDOW quantiles AS (PARTITION BY quantile)\n  )\nGROUP BY\n  minutes_range\nORDER BY\n  Minutes_range",
        "db_id": "chicago",
        "No. of candidate columns": 45,
        "No. of gold tables": 1
    },
    {
        "instance_id": "bq077",
        "question": "For each year from 2010 to 2016, what is the highest number of motor thefts in one month?",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "each",
            "year",
            "from",
            "2010",
            "to",
            "2016,",
            "what",
            "is",
            "the",
            "highest",
            "number",
            "of",
            "motor",
            "thefts",
            "in",
            "one",
            "month?"
        ],
        "query": "",
        "db_id": "chicago",
        "No. of candidate columns": 45,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq350",
        "question": "For the detailed molecule data, Please display the drug id, drug type and withdrawal status for approved drugs with a black box warning and known drug type among 'Keytruda', 'Vioxx', 'Premarin', and 'Humira'",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "the",
            "detailed",
            "molecule",
            "data,",
            "Please",
            "display",
            "the",
            "drug",
            "id,",
            "drug",
            "type",
            "and",
            "withdrawal",
            "status",
            "for",
            "approved",
            "drugs",
            "with",
            "a",
            "black",
            "box",
            "warning",
            "and",
            "known",
            "drug",
            "type",
            "among",
            "'Keytruda',",
            "'Vioxx',",
            "'Premarin',",
            "and",
            "'Humira'"
        ],
        "query": "",
        "db_id": "open_targets_platform_1",
        "No. of candidate columns": 332,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq379",
        "question": "Which target approved symbol has the overall association score closest to the mean score for psoriasis?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "target",
            "approved",
            "symbol",
            "has",
            "the",
            "overall",
            "association",
            "score",
            "closest",
            "to",
            "the",
            "mean",
            "score",
            "for",
            "psoriasis?"
        ],
        "query": "WITH AvgScore AS (\n  SELECT\n    AVG(associations.score) AS avg_score\n  FROM\n    `open-targets-prod.platform.associationByOverallDirect` AS associations\n  JOIN\n    `open-targets-prod.platform.diseases` AS diseases\n  ON\n    associations.diseaseId = diseases.id\n  WHERE\n    diseases.name = 'psoriasis'\n)\nSELECT\n  targets.approvedSymbol AS target_approved_symbol\nFROM\n  `open-targets-prod.platform.associationByOverallDirect` AS associations\nJOIN\n  `open-targets-prod.platform.diseases` AS diseases\nON\n  associations.diseaseId = diseases.id\nJOIN\n  `open-targets-prod.platform.targets` AS targets\nON\n  associations.targetId = targets.id\nCROSS JOIN\n  AvgScore\nWHERE\n  diseases.name = 'psoriasis'\nORDER BY\n  ABS(associations.score - AvgScore.avg_score) ASC\nLIMIT 1",
        "db_id": "open_targets_platform_1",
        "No. of candidate columns": 332,
        "No. of gold tables": 13
    },
    {
        "instance_id": "bq078",
        "question": "Retrieve the approved symbol of target genes with the highest overall score that are associated with the disease 'EFO_0000676' from the data source 'IMPC'.",
        "external_knowledge": null,
        "question_toks": [
            "Retrieve",
            "the",
            "approved",
            "symbol",
            "of",
            "target",
            "genes",
            "with",
            "the",
            "highest",
            "overall",
            "score",
            "that",
            "are",
            "associated",
            "with",
            "the",
            "disease",
            "'EFO_0000676'",
            "from",
            "the",
            "data",
            "source",
            "'IMPC'."
        ],
        "query": "SELECT\n  T1.targetId AS target_id,\n  T1.datasourceId,\n  targets.approvedSymbol AS approved_symbol,\n  overall_associations.score AS overall_score\nFROM\n  `bigquery-public-data.open_targets_platform.associationByDatasourceDirect` as T1\nJOIN\n  `bigquery-public-data.open_targets_platform.targets` AS targets\nON\n  targetId = targets.id\nJOIN\n  `bigquery-public-data.open_targets_platform.associationByOverallDirect` AS overall_associations\nON\n  T1.targetId = overall_associations.targetId\nWHERE\n  overall_associations.diseaseId = 'EFO_0000676' AND datasourceId = 'impc'\nORDER BY\n  overall_associations.score DESC\nLIMIT\n  1;",
        "db_id": "open_targets_platform_2",
        "No. of candidate columns": 351,
        "No. of gold tables": 4
    },
    {
        "instance_id": "bq095",
        "question": "Generate a list of drugs from the table containing molecular details that have completed clinical trials for pancreatic endocrine carcinoma, disease ID EFO_0007416. Please include each drug's name, the target approved symbol, and links to the relevant clinical trials.",
        "external_knowledge": null,
        "question_toks": [
            "Generate",
            "a",
            "list",
            "of",
            "drugs",
            "from",
            "the",
            "table",
            "containing",
            "molecular",
            "details",
            "that",
            "have",
            "completed",
            "clinical",
            "trials",
            "for",
            "pancreatic",
            "endocrine",
            "carcinoma,",
            "disease",
            "ID",
            "EFO_0007416.",
            "Please",
            "include",
            "each",
            "drug's",
            "name,",
            "the",
            "target",
            "approved",
            "symbol,",
            "and",
            "links",
            "to",
            "the",
            "relevant",
            "clinical",
            "trials."
        ],
        "query": "",
        "db_id": "open_targets_platform_1",
        "No. of candidate columns": 332,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq109",
        "question": "Find the average, variance, max-min difference, and the QTL source(right study) of the maximum log2(h4/h3) for data where right gene id is \"ENSG00000169174\", h4 > 0.8, h3 < 0.02, reported trait includes \"lesterol levels\", right biological feature is \"IPSC\", and the variant is '1_55029009_C_T'.",
        "external_knowledge": null,
        "question_toks": [
            "Find",
            "the",
            "average,",
            "variance,",
            "max-min",
            "difference,",
            "and",
            "the",
            "QTL",
            "source(right",
            "study)",
            "of",
            "the",
            "maximum",
            "log2(h4/h3)",
            "for",
            "data",
            "where",
            "right",
            "gene",
            "id",
            "is",
            "\"ENSG00000169174\",",
            "h4",
            ">",
            "0.8,",
            "h3",
            "<",
            "0.02,",
            "reported",
            "trait",
            "includes",
            "\"lesterol",
            "levels\",",
            "right",
            "biological",
            "feature",
            "is",
            "\"IPSC\",",
            "and",
            "the",
            "variant",
            "is",
            "'1_55029009_C_T'."
        ],
        "query": "",
        "db_id": "open_targets_genetics_1",
        "No. of candidate columns": 293,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq090",
        "question": "How much higher the average intrinsic value is for trades using the feeling-lucky strategy compared to those using the momentum strategy under long-side trades?",
        "external_knowledge": null,
        "question_toks": [
            "How",
            "much",
            "higher",
            "the",
            "average",
            "intrinsic",
            "value",
            "is",
            "for",
            "trades",
            "using",
            "the",
            "feeling-lucky",
            "strategy",
            "compared",
            "to",
            "those",
            "using",
            "the",
            "momentum",
            "strategy",
            "under",
            "long-side",
            "trades?"
        ],
        "query": "",
        "db_id": "CYMBAL_INVESTMENTS",
        "No. of candidate columns": 14,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq442",
        "question": "Please collect the information of the top 6 trade report with the highest closing prices. Refer to the document for all the information I want.",
        "external_knowledge": "Trade_Capture_Report_Data_List.md",
        "question_toks": [
            "Please",
            "collect",
            "the",
            "information",
            "of",
            "the",
            "top",
            "6",
            "trade",
            "report",
            "with",
            "the",
            "highest",
            "closing",
            "prices.",
            "Refer",
            "to",
            "the",
            "document",
            "for",
            "all",
            "the",
            "information",
            "I",
            "want."
        ],
        "query": "",
        "db_id": "CYMBAL_INVESTMENTS",
        "No. of candidate columns": 14,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq079",
        "question": "Considering only the latest evaluation group per state for the 'EXPCURR' evaluation type, determine which state has the highest total acreage of timberland and which has the highest total acreage of forestland. For timberland, include plots where the condition status code is 1, the reserved status code is 0, and the site productivity class code is between 1 and 6. For forestland, include plots where the condition status code is 1. Calculate the total acres by summing the adjusted expansion factors for macroplots and subplots, using their respective proportion bases ('MACR' for macroplots and 'SUBP' for subplots) and adjustment factors when greater than zero. For each category (timberland and forestland), provide the state code, evaluation group, state name, and the total acres for the state with the highest total acreage, considering only the latest evaluation group per state.",
        "external_knowledge": null,
        "question_toks": [
            "Considering",
            "only",
            "the",
            "latest",
            "evaluation",
            "group",
            "per",
            "state",
            "for",
            "the",
            "'EXPCURR'",
            "evaluation",
            "type,",
            "determine",
            "which",
            "state",
            "has",
            "the",
            "highest",
            "total",
            "acreage",
            "of",
            "timberland",
            "and",
            "which",
            "has",
            "the",
            "highest",
            "total",
            "acreage",
            "of",
            "forestland.",
            "For",
            "timberland,",
            "include",
            "plots",
            "where",
            "the",
            "condition",
            "status",
            "code",
            "is",
            "1,",
            "the",
            "reserved",
            "status",
            "code",
            "is",
            "0,",
            "and",
            "the",
            "site",
            "productivity",
            "class",
            "code",
            "is",
            "between",
            "1",
            "and",
            "6.",
            "For",
            "forestland,",
            "include",
            "plots",
            "where",
            "the",
            "condition",
            "status",
            "code",
            "is",
            "1.",
            "Calculate",
            "the",
            "total",
            "acres",
            "by",
            "summing",
            "the",
            "adjusted",
            "expansion",
            "factors",
            "for",
            "macroplots",
            "and",
            "subplots,",
            "using",
            "their",
            "respective",
            "proportion",
            "bases",
            "('MACR'",
            "for",
            "macroplots",
            "and",
            "'SUBP'",
            "for",
            "subplots)",
            "and",
            "adjustment",
            "factors",
            "when",
            "greater",
            "than",
            "zero.",
            "For",
            "each",
            "category",
            "(timberland",
            "and",
            "forestland),",
            "provide",
            "the",
            "state",
            "code,",
            "evaluation",
            "group,",
            "state",
            "name,",
            "and",
            "the",
            "total",
            "acres",
            "for",
            "the",
            "state",
            "with",
            "the",
            "highest",
            "total",
            "acreage,",
            "considering",
            "only",
            "the",
            "latest",
            "evaluation",
            "group",
            "per",
            "state."
        ],
        "query": "",
        "db_id": "usfs_fia",
        "No. of candidate columns": 1050,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq024",
        "question": "For the year 2012, which top 10 evaluation groups have the largest subplot acres when considering only the condition with the largest subplot acres within each group? Please include the evaluation group, evaluation type, condition status code, evaluation description, state code, macroplot acres, and subplot acres.",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "the",
            "year",
            "2012,",
            "which",
            "top",
            "10",
            "evaluation",
            "groups",
            "have",
            "the",
            "largest",
            "subplot",
            "acres",
            "when",
            "considering",
            "only",
            "the",
            "condition",
            "with",
            "the",
            "largest",
            "subplot",
            "acres",
            "within",
            "each",
            "group?",
            "Please",
            "include",
            "the",
            "evaluation",
            "group,",
            "evaluation",
            "type,",
            "condition",
            "status",
            "code,",
            "evaluation",
            "description,",
            "state",
            "code,",
            "macroplot",
            "acres,",
            "and",
            "subplot",
            "acres."
        ],
        "query": "",
        "db_id": "usfs_fia",
        "No. of candidate columns": 1050,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq096",
        "question": "Determine which year had the earliest date after January on which more than 10 sightings of Sterna paradisaea were recorded north of 40 degrees latitude. For each year, find the first day after January with over 10 sightings of this species in that region, and identify the year whose earliest such date is the earliest among all years.",
        "external_knowledge": null,
        "question_toks": [
            "Determine",
            "which",
            "year",
            "had",
            "the",
            "earliest",
            "date",
            "after",
            "January",
            "on",
            "which",
            "more",
            "than",
            "10",
            "sightings",
            "of",
            "Sterna",
            "paradisaea",
            "were",
            "recorded",
            "north",
            "of",
            "40",
            "degrees",
            "latitude.",
            "For",
            "each",
            "year,",
            "find",
            "the",
            "first",
            "day",
            "after",
            "January",
            "with",
            "over",
            "10",
            "sightings",
            "of",
            "this",
            "species",
            "in",
            "that",
            "region,",
            "and",
            "identify",
            "the",
            "year",
            "whose",
            "earliest",
            "such",
            "date",
            "is",
            "the",
            "earliest",
            "among",
            "all",
            "years."
        ],
        "query": "",
        "db_id": "gbif",
        "No. of candidate columns": 50,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq278",
        "question": "Please provide a detailed comparison of the solar potential for each state, distinguishing between postal code and census tract levels. For each state, include the total number of buildings available for solar installations, the average percentage of Google Maps area covered by Project Sunroof, the average percentage of that coverage which is suitable for solar, the total potential panel count, the total kilowatt capacity, the energy generation potential, the carbon dioxide offset, the current number of buildings with solar panels, and the gap in potential installations calculated by adjusting the total qualified buildings with the coverage and suitability percentages and subtracting the current installations.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "provide",
            "a",
            "detailed",
            "comparison",
            "of",
            "the",
            "solar",
            "potential",
            "for",
            "each",
            "state,",
            "distinguishing",
            "between",
            "postal",
            "code",
            "and",
            "census",
            "tract",
            "levels.",
            "For",
            "each",
            "state,",
            "include",
            "the",
            "total",
            "number",
            "of",
            "buildings",
            "available",
            "for",
            "solar",
            "installations,",
            "the",
            "average",
            "percentage",
            "of",
            "Google",
            "Maps",
            "area",
            "covered",
            "by",
            "Project",
            "Sunroof,",
            "the",
            "average",
            "percentage",
            "of",
            "that",
            "coverage",
            "which",
            "is",
            "suitable",
            "for",
            "solar,",
            "the",
            "total",
            "potential",
            "panel",
            "count,",
            "the",
            "total",
            "kilowatt",
            "capacity,",
            "the",
            "energy",
            "generation",
            "potential,",
            "the",
            "carbon",
            "dioxide",
            "offset,",
            "the",
            "current",
            "number",
            "of",
            "buildings",
            "with",
            "solar",
            "panels,",
            "and",
            "the",
            "gap",
            "in",
            "potential",
            "installations",
            "calculated",
            "by",
            "adjusting",
            "the",
            "total",
            "qualified",
            "buildings",
            "with",
            "the",
            "coverage",
            "and",
            "suitability",
            "percentages",
            "and",
            "subtracting",
            "the",
            "current",
            "installations."
        ],
        "query": "",
        "db_id": "sunroof_solar",
        "No. of candidate columns": 64,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq102",
        "question": "Identify which start positions are associated with missense variants in the BRCA1 gene on chromosome 17, where the reference base is 'C' and the alternate base is 'T'. Using data from the gnomAD v2.1.1 version.",
        "external_knowledge": null,
        "question_toks": [
            "Identify",
            "which",
            "start",
            "positions",
            "are",
            "associated",
            "with",
            "missense",
            "variants",
            "in",
            "the",
            "BRCA1",
            "gene",
            "on",
            "chromosome",
            "17,",
            "where",
            "the",
            "reference",
            "base",
            "is",
            "'C'",
            "and",
            "the",
            "alternate",
            "base",
            "is",
            "'T'.",
            "Using",
            "data",
            "from",
            "the",
            "gnomAD",
            "v2.1.1",
            "version."
        ],
        "query": "",
        "db_id": "gnomAD",
        "No. of candidate columns": 10264,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq103",
        "question": "Generate summary statistics on genetic variants in the region between positions 55039447 and 55064852 on chromosome 1. This includes the number of variants, the total allele count, the total number of alleles, and distinct gene symbols (using Variant Effect Predictor, VEP, for gene annotation). Additionally, compute the density of mutations by dividing the length of the region by the number of variants.  Using data from the gnomAD v3 version.",
        "external_knowledge": null,
        "question_toks": [
            "Generate",
            "summary",
            "statistics",
            "on",
            "genetic",
            "variants",
            "in",
            "the",
            "region",
            "between",
            "positions",
            "55039447",
            "and",
            "55064852",
            "on",
            "chromosome",
            "1.",
            "This",
            "includes",
            "the",
            "number",
            "of",
            "variants,",
            "the",
            "total",
            "allele",
            "count,",
            "the",
            "total",
            "number",
            "of",
            "alleles,",
            "and",
            "distinct",
            "gene",
            "symbols",
            "(using",
            "Variant",
            "Effect",
            "Predictor,",
            "VEP,",
            "for",
            "gene",
            "annotation).",
            "Additionally,",
            "compute",
            "the",
            "density",
            "of",
            "mutations",
            "by",
            "dividing",
            "the",
            "length",
            "of",
            "the",
            "region",
            "by",
            "the",
            "number",
            "of",
            "variants.",
            "",
            "Using",
            "data",
            "from",
            "the",
            "gnomAD",
            "v3",
            "version."
        ],
        "query": "",
        "db_id": "gnomAD",
        "No. of candidate columns": 10264,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq441",
        "question": "Please help me compile the critical details on traffic accidents in 2015, as listed in the info document.",
        "external_knowledge": "Traffic_Fatalities_Info_List_2015.md",
        "question_toks": [
            "Please",
            "help",
            "me",
            "compile",
            "the",
            "critical",
            "details",
            "on",
            "traffic",
            "accidents",
            "in",
            "2015,",
            "as",
            "listed",
            "in",
            "the",
            "info",
            "document."
        ],
        "query": "",
        "db_id": "nhtsa_traffic_fatalities",
        "No. of candidate columns": 366,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq097",
        "question": "What is the increasing amount of the average earnings per job between the years 2012 and 2017 for each geographic region in Massachusetts (indicated by \"MA\" at the end of GeoName)?",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "is",
            "the",
            "increasing",
            "amount",
            "of",
            "the",
            "average",
            "earnings",
            "per",
            "job",
            "between",
            "the",
            "years",
            "2012",
            "and",
            "2017",
            "for",
            "each",
            "geographic",
            "region",
            "in",
            "Massachusetts",
            "(indicated",
            "by",
            "\"MA\"",
            "at",
            "the",
            "end",
            "of",
            "GeoName)?"
        ],
        "query": "",
        "db_id": "sdoh",
        "No. of candidate columns": 68863,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq120",
        "question": "Identify the top 10 regions (counties) with the highest total number of SNAP-participating households, using the 2017 5-year ACS county-level data and SNAP enrollment data from January 1, 2017, excluding regions where the total SNAP participation is zero. For each of these regions, calculate the ratio of households earning under $20,000 to the total number of SNAP-participating households.",
        "external_knowledge": null,
        "question_toks": [
            "Identify",
            "the",
            "top",
            "10",
            "regions",
            "(counties)",
            "with",
            "the",
            "highest",
            "total",
            "number",
            "of",
            "SNAP-participating",
            "households,",
            "using",
            "the",
            "2017",
            "5-year",
            "ACS",
            "county-level",
            "data",
            "and",
            "SNAP",
            "enrollment",
            "data",
            "from",
            "January",
            "1,",
            "2017,",
            "excluding",
            "regions",
            "where",
            "the",
            "total",
            "SNAP",
            "participation",
            "is",
            "zero.",
            "For",
            "each",
            "of",
            "these",
            "regions,",
            "calculate",
            "the",
            "ratio",
            "of",
            "households",
            "earning",
            "under",
            "$20,000",
            "to",
            "the",
            "total",
            "number",
            "of",
            "SNAP-participating",
            "households."
        ],
        "query": "",
        "db_id": "sdoh",
        "No. of candidate columns": 68863,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq110",
        "question": "What is the change in the number of homeless veterans between 2012 and 2018 for each CoC region in New York that has data available in both years?",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "is",
            "the",
            "change",
            "in",
            "the",
            "number",
            "of",
            "homeless",
            "veterans",
            "between",
            "2012",
            "and",
            "2018",
            "for",
            "each",
            "CoC",
            "region",
            "in",
            "New",
            "York",
            "that",
            "has",
            "data",
            "available",
            "in",
            "both",
            "years?"
        ],
        "query": "",
        "db_id": "sdoh",
        "No. of candidate columns": 68863,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq395",
        "question": "Calculate the percentage change in the total number of unsheltered homeless people from 2015 to 2018 for each state by summing the counts over all Continuums of Care (CoCs) within each state. Then, determine the national average of these state percentage changes. Identify the five states whose percentage change is closest to this national average percentage change. Please provide the state abbreviations.",
        "external_knowledge": null,
        "question_toks": [
            "Calculate",
            "the",
            "percentage",
            "change",
            "in",
            "the",
            "total",
            "number",
            "of",
            "unsheltered",
            "homeless",
            "people",
            "from",
            "2015",
            "to",
            "2018",
            "for",
            "each",
            "state",
            "by",
            "summing",
            "the",
            "counts",
            "over",
            "all",
            "Continuums",
            "of",
            "Care",
            "(CoCs)",
            "within",
            "each",
            "state.",
            "Then,",
            "determine",
            "the",
            "national",
            "average",
            "of",
            "these",
            "state",
            "percentage",
            "changes.",
            "Identify",
            "the",
            "five",
            "states",
            "whose",
            "percentage",
            "change",
            "is",
            "closest",
            "to",
            "this",
            "national",
            "average",
            "percentage",
            "change.",
            "Please",
            "provide",
            "the",
            "state",
            "abbreviations."
        ],
        "query": "",
        "db_id": "sdoh",
        "No. of candidate columns": 68863,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq352",
        "question": "Please list the average number of prenatal weeks in 2018 for counties in Wisconsin where more than 5% of the employed population had commutes of 45-59 minutes in 2017.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "list",
            "the",
            "average",
            "number",
            "of",
            "prenatal",
            "weeks",
            "in",
            "2018",
            "for",
            "counties",
            "in",
            "Wisconsin",
            "where",
            "more",
            "than",
            "5%",
            "of",
            "the",
            "employed",
            "population",
            "had",
            "commutes",
            "of",
            "45-59",
            "minutes",
            "in",
            "2017."
        ],
        "query": "",
        "db_id": "sdoh",
        "No. of candidate columns": 68863,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq074",
        "question": "Count the number of counties that experienced an increase in unemployment from 2015 to 2018, using 5-year ACS data, and a decrease in dual-eligible enrollee counts between December 1, 2015, and December 1, 2018.",
        "external_knowledge": null,
        "question_toks": [
            "Count",
            "the",
            "number",
            "of",
            "counties",
            "that",
            "experienced",
            "an",
            "increase",
            "in",
            "unemployment",
            "from",
            "2015",
            "to",
            "2018,",
            "using",
            "5-year",
            "ACS",
            "data,",
            "and",
            "a",
            "decrease",
            "in",
            "dual-eligible",
            "enrollee",
            "counts",
            "between",
            "December",
            "1,",
            "2015,",
            "and",
            "December",
            "1,",
            "2018."
        ],
        "query": "",
        "db_id": "sdoh",
        "No. of candidate columns": 68863,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq041",
        "question": "Compute the monthly statistics for new StackOverflow users created in 2021. For each month, report the total number of new users, the percentage of these new users who asked at least one question within 30 days of signing up, and among those who asked a question within 30 days, the percentage who then answered at least one question after their first question and within 30 days following their first question.",
        "external_knowledge": null,
        "question_toks": [
            "Compute",
            "the",
            "monthly",
            "statistics",
            "for",
            "new",
            "StackOverflow",
            "users",
            "created",
            "in",
            "2021.",
            "For",
            "each",
            "month,",
            "report",
            "the",
            "total",
            "number",
            "of",
            "new",
            "users,",
            "the",
            "percentage",
            "of",
            "these",
            "new",
            "users",
            "who",
            "asked",
            "at",
            "least",
            "one",
            "question",
            "within",
            "30",
            "days",
            "of",
            "signing",
            "up,",
            "and",
            "among",
            "those",
            "who",
            "asked",
            "a",
            "question",
            "within",
            "30",
            "days,",
            "the",
            "percentage",
            "who",
            "then",
            "answered",
            "at",
            "least",
            "one",
            "question",
            "after",
            "their",
            "first",
            "question",
            "and",
            "within",
            "30",
            "days",
            "following",
            "their",
            "first",
            "question."
        ],
        "query": "",
        "db_id": "stackoverflow",
        "No. of candidate columns": 228,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq121",
        "question": "How do the average reputation and number of badges vary among Stack Overflow users based on the number of complete years they have been members, considering only those who joined on or before October 1, 2021?",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "How",
            "do",
            "the",
            "average",
            "reputation",
            "and",
            "number",
            "of",
            "badges",
            "vary",
            "among",
            "Stack",
            "Overflow",
            "users",
            "based",
            "on",
            "the",
            "number",
            "of",
            "complete",
            "years",
            "they",
            "have",
            "been",
            "members,",
            "considering",
            "only",
            "those",
            "who",
            "joined",
            "on",
            "or",
            "before",
            "October",
            "1,",
            "2021?"
        ],
        "query": "WITH sub AS (\n  SELECT \n    \"users\".\"id\",\n    CAST(TO_TIMESTAMP(MAX(\"users\".\"creation_date\") / 1000000.0) AS DATE) AS \"user_creation_date\",  -- 使用 MAX 聚合 creation_date 并转换为 DATE\n    MAX(\"users\".\"reputation\") AS \"reputation\",  \n    SUM(CASE WHEN badges.\"user_id\" IS NULL THEN 0 ELSE 1 END) AS \"num_badges\"\n  FROM \"STACKOVERFLOW\".\"STACKOVERFLOW\".\"USERS\" \"users\"\n  LEFT JOIN \"STACKOVERFLOW\".\"STACKOVERFLOW\".\"BADGES\" badges\n    ON \"users\".\"id\" = badges.\"user_id\"\n  WHERE CAST(TO_TIMESTAMP(\"users\".\"creation_date\" / 1000000.0) AS DATE) <= DATE '2021-10-01'\n  GROUP BY \"users\".\"id\"\n)\n\nSELECT \n  DATEDIFF(YEAR, \"user_creation_date\", DATE '2021-10-01') AS \"user_tenure\",\n  COUNT(1) AS \"Num_Users\",\n  AVG(\"reputation\") AS \"Avg_Reputation\",\n  AVG(\"num_badges\") AS \"Avg_Num_Badges\"\nFROM sub\nGROUP BY \"user_tenure\"\nORDER BY \"user_tenure\";",
        "db_id": "STACKOVERFLOW",
        "No. of candidate columns": 228,
        "No. of gold tables": 2
    },
    {
        "instance_id": "bq300",
        "question": "What is the highest number of answers received for a single Python 2 specific question on Stack Overflow, excluding any discussions that involve Python 3?",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "is",
            "the",
            "highest",
            "number",
            "of",
            "answers",
            "received",
            "for",
            "a",
            "single",
            "Python",
            "2",
            "specific",
            "question",
            "on",
            "Stack",
            "Overflow,",
            "excluding",
            "any",
            "discussions",
            "that",
            "involve",
            "Python",
            "3?"
        ],
        "query": "WITH\n  python2_questions AS (\n    SELECT\n      q.id AS question_id,\n      q.title,\n      q.body AS question_body,\n      q.tags\n    FROM\n      `bigquery-public-data.stackoverflow.posts_questions` q\n    WHERE\n      (LOWER(q.tags) LIKE '%python-2%'\n      OR LOWER(q.tags) LIKE '%python-2.x%'\n      OR (\n        LOWER(q.title) LIKE '%python 2%'\n        OR LOWER(q.body) LIKE '%python 2%'\n        OR LOWER(q.title) LIKE '%python2%'\n        OR LOWER(q.body) LIKE '%python2%'\n      ))\n      AND (\n        LOWER(q.title) NOT LIKE '%python 3%'\n        AND LOWER(q.body) NOT LIKE '%python 3%'\n        AND LOWER(q.title) NOT LIKE '%python3%'\n        AND LOWER(q.body) NOT LIKE '%python3%'\n      )\n  )\n\nSELECT\n  COUNT(*) AS count_number\nFROM\n  python2_questions q\nLEFT JOIN\n  `bigquery-public-data.stackoverflow.posts_answers` a\nON\n  q.question_id = a.parent_id\nGROUP BY q.question_id\nORDER BY count_number DESC\nLIMIT 1",
        "db_id": "stackoverflow",
        "No. of candidate columns": 228,
        "No. of gold tables": 5
    },
    {
        "instance_id": "bq301",
        "question": "Retrieve details of accepted answers to Stack Overflow questions posted in January 2016 that have tags including \"javascript\" and at least one of \"xss\", \"cross-site\", \"exploit\", or \"cybersecurity\"; the answers themselves must also have been posted in January 2016. For each accepted answer, include the answer's ID, the answerer's reputation, score, and comment count, along with the associated question's tags, score, answer count, the asker's reputation, view count, and comment count.",
        "external_knowledge": null,
        "question_toks": [
            "Retrieve",
            "details",
            "of",
            "accepted",
            "answers",
            "to",
            "Stack",
            "Overflow",
            "questions",
            "posted",
            "in",
            "January",
            "2016",
            "that",
            "have",
            "tags",
            "including",
            "\"javascript\"",
            "and",
            "at",
            "least",
            "one",
            "of",
            "\"xss\",",
            "\"cross-site\",",
            "\"exploit\",",
            "or",
            "\"cybersecurity\";",
            "the",
            "answers",
            "themselves",
            "must",
            "also",
            "have",
            "been",
            "posted",
            "in",
            "January",
            "2016.",
            "For",
            "each",
            "accepted",
            "answer,",
            "include",
            "the",
            "answer's",
            "ID,",
            "the",
            "answerer's",
            "reputation,",
            "score,",
            "and",
            "comment",
            "count,",
            "along",
            "with",
            "the",
            "associated",
            "question's",
            "tags,",
            "score,",
            "answer",
            "count,",
            "the",
            "asker's",
            "reputation,",
            "view",
            "count,",
            "and",
            "comment",
            "count."
        ],
        "query": "SELECT\n    answer.id AS a_id,\n    (SELECT users.reputation FROM `bigquery-public-data.stackoverflow.users` users\n        WHERE users.id = answer.owner_user_id) AS a_user_reputation,\n    answer.score AS a_score,\n    answer.comment_count AS answer_comment_count,\n    questions.tags as q_tags,\n    questions.score AS q_score,  \n    questions.answer_count AS answer_count, \n    (SELECT users.reputation FROM `bigquery-public-data.stackoverflow.users` users\n        WHERE users.id = questions.owner_user_id) AS q_user_reputation,\n    questions.view_count AS q_view_count,\n    questions.comment_count AS q_comment_count\nFROM\n   `bigquery-public-data.stackoverflow.posts_answers` AS answer \nLEFT JOIN\n   `bigquery-public-data.stackoverflow.posts_questions` AS questions\n      ON answer.parent_id = questions.id\nWHERE\n    answer.id = questions.accepted_answer_id\n    AND \n    (\n        questions.tags LIKE '%javascript%' AND\n        (questions.tags LIKE '%xss%' OR\n        questions.tags LIKE '%cross-site%' OR\n        questions.tags LIKE '%exploit%' OR\n        questions.tags LIKE '%cybersecurity%')\n    )\n    AND DATE(questions.creation_date) BETWEEN '2016-01-01' AND '2016-01-31'\n    AND DATE(answer.creation_date) BETWEEN '2016-01-01' AND '2016-01-31'",
        "db_id": "stackoverflow",
        "No. of candidate columns": 228,
        "No. of gold tables": 12
    },
    {
        "instance_id": "bq302",
        "question": "What is the monthly proportion of Stack Overflow questions tagged with 'python' in the year 2022?",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "is",
            "the",
            "monthly",
            "proportion",
            "of",
            "Stack",
            "Overflow",
            "questions",
            "tagged",
            "with",
            "'python'",
            "in",
            "the",
            "year",
            "2022?"
        ],
        "query": "",
        "db_id": "stackoverflow",
        "No. of candidate columns": 228,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq304",
        "question": "Retrieve the top 50 most viewed questions for each of the following Android-related tags on StackOverflow: 'android-layout', 'android-activity', 'android-intent', 'android-edittext', 'android-fragments', 'android-recyclerview', 'listview', 'android-actionbar', 'google-maps', and 'android-asynctask'. Each question must contain the word 'how' in either its title or body and must not contain any of the following troubleshooting terms in either its title or body: 'fail', 'problem', 'error', 'wrong', 'fix', 'bug', 'issue', 'solve', or 'trouble'. Only include tags that have at least 50 questions meeting these criteria, and for each such tag, select the top 50 questions ranked by view count.",
        "external_knowledge": null,
        "question_toks": [
            "Retrieve",
            "the",
            "top",
            "50",
            "most",
            "viewed",
            "questions",
            "for",
            "each",
            "of",
            "the",
            "following",
            "Android-related",
            "tags",
            "on",
            "StackOverflow:",
            "'android-layout',",
            "'android-activity',",
            "'android-intent',",
            "'android-edittext',",
            "'android-fragments',",
            "'android-recyclerview',",
            "'listview',",
            "'android-actionbar',",
            "'google-maps',",
            "and",
            "'android-asynctask'.",
            "Each",
            "question",
            "must",
            "contain",
            "the",
            "word",
            "'how'",
            "in",
            "either",
            "its",
            "title",
            "or",
            "body",
            "and",
            "must",
            "not",
            "contain",
            "any",
            "of",
            "the",
            "following",
            "troubleshooting",
            "terms",
            "in",
            "either",
            "its",
            "title",
            "or",
            "body:",
            "'fail',",
            "'problem',",
            "'error',",
            "'wrong',",
            "'fix',",
            "'bug',",
            "'issue',",
            "'solve',",
            "or",
            "'trouble'.",
            "Only",
            "include",
            "tags",
            "that",
            "have",
            "at",
            "least",
            "50",
            "questions",
            "meeting",
            "these",
            "criteria,",
            "and",
            "for",
            "each",
            "such",
            "tag,",
            "select",
            "the",
            "top",
            "50",
            "questions",
            "ranked",
            "by",
            "view",
            "count."
        ],
        "query": "",
        "db_id": "stackoverflow",
        "No. of candidate columns": 228,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq310",
        "question": "What is the title of the most viewed \"how\" question related to Android development on StackOverflow, across specified tags such as 'android-layout', 'android-activity', 'android-intent', and others",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "is",
            "the",
            "title",
            "of",
            "the",
            "most",
            "viewed",
            "\"how\"",
            "question",
            "related",
            "to",
            "Android",
            "development",
            "on",
            "StackOverflow,",
            "across",
            "specified",
            "tags",
            "such",
            "as",
            "'android-layout',",
            "'android-activity',",
            "'android-intent',",
            "and",
            "others"
        ],
        "query": "",
        "db_id": "stackoverflow",
        "No. of candidate columns": 228,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq307",
        "question": "Find the top 10 gold badges that users most commonly earn as their first gold badge on Stack Overflow. For each of these badges, display the badge name, the number of users who earned it as their first gold badge, and the average number of days from the user's account creation date to the date they earned the badge, calculated in days without any adjustments for date formats.",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Find",
            "the",
            "top",
            "10",
            "gold",
            "badges",
            "that",
            "users",
            "most",
            "commonly",
            "earn",
            "as",
            "their",
            "first",
            "gold",
            "badge",
            "on",
            "Stack",
            "Overflow.",
            "For",
            "each",
            "of",
            "these",
            "badges,",
            "display",
            "the",
            "badge",
            "name,",
            "the",
            "number",
            "of",
            "users",
            "who",
            "earned",
            "it",
            "as",
            "their",
            "first",
            "gold",
            "badge,",
            "and",
            "the",
            "average",
            "number",
            "of",
            "days",
            "from",
            "the",
            "user's",
            "account",
            "creation",
            "date",
            "to",
            "the",
            "date",
            "they",
            "earned",
            "the",
            "badge,",
            "calculated",
            "in",
            "days",
            "without",
            "any",
            "adjustments",
            "for",
            "date",
            "formats."
        ],
        "query": "",
        "db_id": "STACKOVERFLOW",
        "No. of candidate columns": 228,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq308",
        "question": "Show the number of Stack Overflow questions asked each day of the week in 2021, and find out how many and what percentage of those were answered within one hour.",
        "external_knowledge": null,
        "question_toks": [
            "Show",
            "the",
            "number",
            "of",
            "Stack",
            "Overflow",
            "questions",
            "asked",
            "each",
            "day",
            "of",
            "the",
            "week",
            "in",
            "2021,",
            "and",
            "find",
            "out",
            "how",
            "many",
            "and",
            "what",
            "percentage",
            "of",
            "those",
            "were",
            "answered",
            "within",
            "one",
            "hour."
        ],
        "query": "",
        "db_id": "stackoverflow",
        "No. of candidate columns": 228,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq366",
        "question": "What are the top three most frequently associated labels with artworks from each historical period in The Met's collection, only considering labels linked to 500 or more artworks? Provide me with the period, label, and the associated count.",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "are",
            "the",
            "top",
            "three",
            "most",
            "frequently",
            "associated",
            "labels",
            "with",
            "artworks",
            "from",
            "each",
            "historical",
            "period",
            "in",
            "The",
            "Met's",
            "collection,",
            "only",
            "considering",
            "labels",
            "linked",
            "to",
            "500",
            "or",
            "more",
            "artworks?",
            "Provide",
            "me",
            "with",
            "the",
            "period,",
            "label,",
            "and",
            "the",
            "associated",
            "count."
        ],
        "query": "",
        "db_id": "the_met",
        "No. of candidate columns": 61,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq458",
        "question": "Tokenize the body text of each article into words, excluding stop words, and obtain the corresponding word vectors for these words from the glove vector. For each word, weight its word vector by dividing each component by the 0.4th power of the word's frequency from the word frequencies. Then, for each article, aggregate these weighted word vectors by summing their components to form an article vector. Normalize each article vector to unit length by dividing by its magnitude. Finally, retrieve the ID, date, title, and the normalized article vector for each article.",
        "external_knowledge": null,
        "question_toks": [
            "Tokenize",
            "the",
            "body",
            "text",
            "of",
            "each",
            "article",
            "into",
            "words,",
            "excluding",
            "stop",
            "words,",
            "and",
            "obtain",
            "the",
            "corresponding",
            "word",
            "vectors",
            "for",
            "these",
            "words",
            "from",
            "the",
            "glove",
            "vector.",
            "For",
            "each",
            "word,",
            "weight",
            "its",
            "word",
            "vector",
            "by",
            "dividing",
            "each",
            "component",
            "by",
            "the",
            "0.4th",
            "power",
            "of",
            "the",
            "word's",
            "frequency",
            "from",
            "the",
            "word",
            "frequencies.",
            "Then,",
            "for",
            "each",
            "article,",
            "aggregate",
            "these",
            "weighted",
            "word",
            "vectors",
            "by",
            "summing",
            "their",
            "components",
            "to",
            "form",
            "an",
            "article",
            "vector.",
            "Normalize",
            "each",
            "article",
            "vector",
            "to",
            "unit",
            "length",
            "by",
            "dividing",
            "by",
            "its",
            "magnitude.",
            "Finally,",
            "retrieve",
            "the",
            "ID,",
            "date,",
            "title,",
            "and",
            "the",
            "normalized",
            "article",
            "vector",
            "for",
            "each",
            "article."
        ],
        "query": "",
        "db_id": "WORD_VECTORS_US",
        "No. of candidate columns": 19,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq345",
        "question": "How large are the DICOM image files with SEG or RTSTRUCT modalities and the SOP Class UID \"1.2.840.10008.5.1.4.1.1.66.4\", when grouped by collection, study, and series IDs, if they have no references to other series, images, or sources? Can you also provide a viewer URL formatted as \"https://viewer.imaging.datacommons.cancer.gov/viewer/\" followed by the study ID, and list these sizes in kilobytes, sorted from largest to smallest?",
        "external_knowledge": null,
        "question_toks": [
            "How",
            "large",
            "are",
            "the",
            "DICOM",
            "image",
            "files",
            "with",
            "SEG",
            "or",
            "RTSTRUCT",
            "modalities",
            "and",
            "the",
            "SOP",
            "Class",
            "UID",
            "\"1.2.840.10008.5.1.4.1.1.66.4\",",
            "when",
            "grouped",
            "by",
            "collection,",
            "study,",
            "and",
            "series",
            "IDs,",
            "if",
            "they",
            "have",
            "no",
            "references",
            "to",
            "other",
            "series,",
            "images,",
            "or",
            "sources?",
            "Can",
            "you",
            "also",
            "provide",
            "a",
            "viewer",
            "URL",
            "formatted",
            "as",
            "\"https://viewer.imaging.datacommons.cancer.gov/viewer/\"",
            "followed",
            "by",
            "the",
            "study",
            "ID,",
            "and",
            "list",
            "these",
            "sizes",
            "in",
            "kilobytes,",
            "sorted",
            "from",
            "largest",
            "to",
            "smallest?"
        ],
        "query": "WITH seg_rtstruct AS (\n  SELECT\n    \"collection_id\",\n    \"StudyInstanceUID\",\n    \"SeriesInstanceUID\",\n    CONCAT('https://viewer.imaging.datacommons.cancer.gov/viewer/', \"StudyInstanceUID\") AS \"viewer_url\",\n    \"instance_size\"\n  FROM\n    \"IDC\".\"IDC_V17\".\"DICOM_ALL\"\n  WHERE\n    \"Modality\" IN ('SEG', 'RTSTRUCT')\n    AND \"SOPClassUID\" = '1.2.840.10008.5.1.4.1.1.66.4'\n    AND ARRAY_SIZE(\"ReferencedSeriesSequence\") = 0\n    AND ARRAY_SIZE(\"ReferencedImageSequence\") = 0\n    AND ARRAY_SIZE(\"SourceImageSequence\") = 0\n)\n\nSELECT\n  seg_rtstruct.\"collection_id\",\n  seg_rtstruct.\"SeriesInstanceUID\",\n  seg_rtstruct.\"StudyInstanceUID\",\n  seg_rtstruct.\"viewer_url\",\n  SUM(seg_rtstruct.\"instance_size\") / 1024 AS \"collection_size_KB\"\nFROM\n  seg_rtstruct\nGROUP BY\n  seg_rtstruct.\"collection_id\",\n  seg_rtstruct.\"SeriesInstanceUID\",\n  seg_rtstruct.\"StudyInstanceUID\",\n  seg_rtstruct.\"viewer_url\"\nORDER BY\n  \"collection_size_KB\" DESC;",
        "db_id": "IDC",
        "No. of candidate columns": 2100,
        "No. of gold tables": 1
    },
    {
        "instance_id": "sf_bq422",
        "question": "Considering only CT images from the 'nlst' collection, what are the average series sizes in MiB for the top 3 patients with the highest slice interval difference tolerance (calculated as the difference between the maximum and minimum unique slice intervals within their series) and the top 3 patients with the highest maximum exposure difference (calculated as the difference between the maximum and minimum unique exposure values within their series), where the series size is determined by summing the instance sizes of all images in a series and converting it to MiB?",
        "external_knowledge": null,
        "question_toks": [
            "Considering",
            "only",
            "CT",
            "images",
            "from",
            "the",
            "'nlst'",
            "collection,",
            "what",
            "are",
            "the",
            "average",
            "series",
            "sizes",
            "in",
            "MiB",
            "for",
            "the",
            "top",
            "3",
            "patients",
            "with",
            "the",
            "highest",
            "slice",
            "interval",
            "difference",
            "tolerance",
            "(calculated",
            "as",
            "the",
            "difference",
            "between",
            "the",
            "maximum",
            "and",
            "minimum",
            "unique",
            "slice",
            "intervals",
            "within",
            "their",
            "series)",
            "and",
            "the",
            "top",
            "3",
            "patients",
            "with",
            "the",
            "highest",
            "maximum",
            "exposure",
            "difference",
            "(calculated",
            "as",
            "the",
            "difference",
            "between",
            "the",
            "maximum",
            "and",
            "minimum",
            "unique",
            "exposure",
            "values",
            "within",
            "their",
            "series),",
            "where",
            "the",
            "series",
            "size",
            "is",
            "determined",
            "by",
            "summing",
            "the",
            "instance",
            "sizes",
            "of",
            "all",
            "images",
            "in",
            "a",
            "series",
            "and",
            "converting",
            "it",
            "to",
            "MiB?"
        ],
        "query": "WITH\n  nonLocalizerRawData AS (\n    SELECT\n      \"SeriesInstanceUID\",\n      \"StudyInstanceUID\",\n      \"PatientID\",\n      TRY_CAST(\"Exposure\"::STRING AS FLOAT) AS \"Exposure\",  -- 直接从 bid 获取 Exposure\n      TRY_CAST(axes.VALUE::STRING AS FLOAT) AS \"zImagePosition\",\n      LEAD(TRY_CAST(axes.VALUE::STRING AS FLOAT)) OVER (\n        PARTITION BY \"SeriesInstanceUID\" \n        ORDER BY TRY_CAST(axes.VALUE::STRING AS FLOAT)\n      ) - TRY_CAST(axes.VALUE::STRING AS FLOAT) AS \"slice_interval\",\n      \"instance_size\" AS \"instanceSize\"\n    FROM\n      \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"bid\",\n      LATERAL FLATTEN(input => \"bid\".\"ImagePositionPatient\") AS axes  -- 使用 LATERAL FLATTEN 展开数组\n    WHERE\n      \"collection_id\" = 'nlst' \n      AND \"Modality\" = 'CT' \n  ),\n  geometryChecks AS (\n    SELECT\n      \"SeriesInstanceUID\",\n      \"StudyInstanceUID\",\n      \"PatientID\",\n      ARRAY_AGG(DISTINCT \"slice_interval\") AS \"sliceIntervalDifferences\",\n      ARRAY_AGG(DISTINCT \"Exposure\") AS \"distinctExposures\",\n      SUM(\"instanceSize\") / 1024 / 1024 AS \"seriesSizeInMB\"\n    FROM\n      nonLocalizerRawData\n    GROUP BY\n      \"SeriesInstanceUID\", \n      \"StudyInstanceUID\",\n      \"PatientID\"\n  ),\n  patientMetrics AS (\n    SELECT\n      \"PatientID\",\n      MAX(TRY_CAST(sid.VALUE::STRING AS FLOAT)) AS \"maxSliceIntervalDifference\",\n      MIN(TRY_CAST(sid.VALUE::STRING AS FLOAT)) AS \"minSliceIntervalDifference\",\n      MAX(TRY_CAST(sid.VALUE::STRING AS FLOAT)) - MIN(TRY_CAST(sid.VALUE::STRING AS FLOAT)) AS \"sliceIntervalDifferenceTolerance\",\n      MAX(TRY_CAST(de.VALUE::STRING AS FLOAT)) AS \"maxExposure\",\n      MIN(TRY_CAST(de.VALUE::STRING AS FLOAT)) AS \"minExposure\",\n      MAX(TRY_CAST(de.VALUE::STRING AS FLOAT)) - MIN(TRY_CAST(de.VALUE::STRING AS FLOAT)) AS \"maxExposureDifference\",\n      \"seriesSizeInMB\"\n    FROM\n      geometryChecks,\n      LATERAL FLATTEN(input => \"sliceIntervalDifferences\") AS sid,  -- 展开 sliceIntervalDifferences\n      LATERAL FLATTEN(input => \"distinctExposures\") AS de  -- 展开 distinctExposures\n    WHERE\n      sid.VALUE IS NOT NULL\n      AND de.VALUE IS NOT NULL\n    GROUP BY\n      \"PatientID\",\n      \"seriesSizeInMB\"\n  ),\n  top3BySliceInterval AS (\n    SELECT\n      \"PatientID\",\n      \"seriesSizeInMB\"\n    FROM\n      patientMetrics\n    ORDER BY\n      \"sliceIntervalDifferenceTolerance\" DESC\n    LIMIT 3\n  ),\n  top3ByMaxExposure AS (\n    SELECT\n      \"PatientID\",\n      \"seriesSizeInMB\"\n    FROM\n      patientMetrics\n    ORDER BY\n      \"maxExposureDifference\" DESC\n    LIMIT 3\n  )\nSELECT\n  'Top 3 by Slice Interval' AS \"MetricGroup\",\n  AVG(\"seriesSizeInMB\") AS \"AverageSeriesSizeInMB\"\nFROM\n  top3BySliceInterval\nUNION ALL\nSELECT\n  'Top 3 by Max Exposure' AS \"MetricGroup\",\n  AVG(\"seriesSizeInMB\") AS \"AverageSeriesSizeInMB\"\nFROM\n  top3ByMaxExposure;",
        "db_id": "IDC",
        "No. of candidate columns": 2100,
        "No. of gold tables": 1
    },
    {
        "instance_id": "bq218",
        "question": "What are the top 5 items with the highest year-over-year growth percentage in total sales revenue for the year 2023?",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "are",
            "the",
            "top",
            "5",
            "items",
            "with",
            "the",
            "highest",
            "year-over-year",
            "growth",
            "percentage",
            "in",
            "total",
            "sales",
            "revenue",
            "for",
            "the",
            "year",
            "2023?"
        ],
        "query": "",
        "db_id": "iowa_liquor_sales",
        "No. of candidate columns": 24,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq044",
        "question": "For bladder cancer patients who have mutations in the CDKN2A (cyclin-dependent kinase inhibitor 2A) gene, using clinical data from the Genomic Data Commons Release 39, what types of mutations are they, what is their gender, vital status, and days to death - and for four downstream genes (MDM2 (MDM2 proto-oncogene), TP53 (tumor protein p53), CDKN1A (cyclin-dependent kinase inhibitor 1A), and CCNE1 (Cyclin E1)), what are the gene expression levels for each patient?",
        "external_knowledge": "TCGA_Study_Abbreviations.md",
        "question_toks": [
            "For",
            "bladder",
            "cancer",
            "patients",
            "who",
            "have",
            "mutations",
            "in",
            "the",
            "CDKN2A",
            "(cyclin-dependent",
            "kinase",
            "inhibitor",
            "2A)",
            "gene,",
            "using",
            "clinical",
            "data",
            "from",
            "the",
            "Genomic",
            "Data",
            "Commons",
            "Release",
            "39,",
            "what",
            "types",
            "of",
            "mutations",
            "are",
            "they,",
            "what",
            "is",
            "their",
            "gender,",
            "vital",
            "status,",
            "and",
            "days",
            "to",
            "death",
            "-",
            "and",
            "for",
            "four",
            "downstream",
            "genes",
            "(MDM2",
            "(MDM2",
            "proto-oncogene),",
            "TP53",
            "(tumor",
            "protein",
            "p53),",
            "CDKN1A",
            "(cyclin-dependent",
            "kinase",
            "inhibitor",
            "1A),",
            "and",
            "CCNE1",
            "(Cyclin",
            "E1)),",
            "what",
            "are",
            "the",
            "gene",
            "expression",
            "levels",
            "for",
            "each",
            "patient?"
        ],
        "query": "",
        "db_id": "TCGA",
        "No. of candidate columns": 4107,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq043",
        "question": "What are the RNA expression levels of the genes MDM2, TP53, CDKN1A, and CCNE1, along with associated clinical information, in bladder cancer patients with CDKN2A mutations in the 'TCGA-BLCA' project?  Use clinical data from the Genomic Data Commons Release 39, data about somatic mutations derived from the hg19 human genome reference in Feb 2017.",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "are",
            "the",
            "RNA",
            "expression",
            "levels",
            "of",
            "the",
            "genes",
            "MDM2,",
            "TP53,",
            "CDKN1A,",
            "and",
            "CCNE1,",
            "along",
            "with",
            "associated",
            "clinical",
            "information,",
            "in",
            "bladder",
            "cancer",
            "patients",
            "with",
            "CDKN2A",
            "mutations",
            "in",
            "the",
            "'TCGA-BLCA'",
            "project?",
            "",
            "Use",
            "clinical",
            "data",
            "from",
            "the",
            "Genomic",
            "Data",
            "Commons",
            "Release",
            "39,",
            "data",
            "about",
            "somatic",
            "mutations",
            "derived",
            "from",
            "the",
            "hg19",
            "human",
            "genome",
            "reference",
            "in",
            "Feb",
            "2017."
        ],
        "query": "SELECT\n  genex.\"case_barcode\" AS \"case_barcode\",\n  genex.\"sample_barcode\" AS \"sample_barcode\",\n  genex.\"aliquot_barcode\" AS \"aliquot_barcode\",\n  genex.\"HGNC_gene_symbol\" AS \"HGNC_gene_symbol\",\n  clinical_info.\"Variant_Type\" AS \"Variant_Type\",\n  genex.\"gene_id\" AS \"gene_id\",\n  genex.\"normalized_count\" AS \"normalized_count\",\n  genex.\"project_short_name\" AS \"project_short_name\",\n  clinical_info.\"demo__gender\" AS \"gender\",\n  clinical_info.\"demo__vital_status\" AS \"vital_status\",\n  clinical_info.\"demo__days_to_death\" AS \"days_to_death\"\nFROM ( \n  SELECT\n    case_list.\"Variant_Type\" AS \"Variant_Type\",\n    case_list.\"case_barcode\" AS \"case_barcode\",\n    clinical.\"demo__gender\",\n    clinical.\"demo__vital_status\",\n    clinical.\"demo__days_to_death\"\n  FROM\n    (SELECT\n      mutation.\"case_barcode\",\n      mutation.\"Variant_Type\"\n    FROM\n      \"TCGA\".\"TCGA_VERSIONED\".\"SOMATIC_MUTATION_HG19_DCC_2017_02\" AS mutation\n    WHERE\n      mutation.\"Hugo_Symbol\" = 'CDKN2A'\n      AND mutation.\"project_short_name\" = 'TCGA-BLCA'\n    GROUP BY\n      mutation.\"case_barcode\",\n      mutation.\"Variant_Type\"\n    ORDER BY\n      mutation.\"case_barcode\"\n    ) AS case_list /* end case_list */\n  INNER JOIN\n    \"TCGA\".\"TCGA_VERSIONED\".\"CLINICAL_GDC_R39\" AS clinical\n  ON\n    case_list.\"case_barcode\" = clinical.\"submitter_id\" /* end clinical annotation */ ) AS clinical_info\nINNER JOIN\n  \"TCGA\".\"TCGA_VERSIONED\".\"RNASEQ_HG19_GDC_2017_02\" AS genex\nON\n  genex.\"case_barcode\" = clinical_info.\"case_barcode\"\nWHERE\n  genex.\"HGNC_gene_symbol\" IN ('MDM2', 'TP53', 'CDKN1A','CCNE1')\nORDER BY\n  \"case_barcode\",\n  \"HGNC_gene_symbol\";",
        "db_id": "TCGA",
        "No. of candidate columns": 4107,
        "No. of gold tables": 3
    },
    {
        "instance_id": "bq143",
        "question": "Use CPTAC proteomics and RNAseq data for Clear Cell Renal Cell Carcinoma to select 'Primary Tumor' and 'Solid Tissue Normal' samples. Join the datasets on sample submitter IDs and gene symbols. Calculate the correlation between protein abundance (log2 ratio) and gene expression levels (log-transformed+1 FPKM) for each gene and sample type. Filter out correlations with an absolute value greater than 0.5, and compute the average correlation for each sample type.",
        "external_knowledge": null,
        "question_toks": [
            "Use",
            "CPTAC",
            "proteomics",
            "and",
            "RNAseq",
            "data",
            "for",
            "Clear",
            "Cell",
            "Renal",
            "Cell",
            "Carcinoma",
            "to",
            "select",
            "'Primary",
            "Tumor'",
            "and",
            "'Solid",
            "Tissue",
            "Normal'",
            "samples.",
            "Join",
            "the",
            "datasets",
            "on",
            "sample",
            "submitter",
            "IDs",
            "and",
            "gene",
            "symbols.",
            "Calculate",
            "the",
            "correlation",
            "between",
            "protein",
            "abundance",
            "(log2",
            "ratio)",
            "and",
            "gene",
            "expression",
            "levels",
            "(log-transformed+1",
            "FPKM)",
            "for",
            "each",
            "gene",
            "and",
            "sample",
            "type.",
            "Filter",
            "out",
            "correlations",
            "with",
            "an",
            "absolute",
            "value",
            "greater",
            "than",
            "0.5,",
            "and",
            "compute",
            "the",
            "average",
            "correlation",
            "for",
            "each",
            "sample",
            "type."
        ],
        "query": "",
        "db_id": "CPTAC_PDC",
        "No. of candidate columns": 1451,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq147",
        "question": "Can you identify the TCGA breast cancer cases from the RNA sequencing hg38 r35` where the protein_coding gene and the project TCGA-BRCA, and which have RNA sequencing samples of multiple tissue types—including \"Solid Tissue Normal\"—within the same case?",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "identify",
            "the",
            "TCGA",
            "breast",
            "cancer",
            "cases",
            "from",
            "the",
            "RNA",
            "sequencing",
            "hg38",
            "r35`",
            "where",
            "the",
            "protein_coding",
            "gene",
            "and",
            "the",
            "project",
            "TCGA-BRCA,",
            "and",
            "which",
            "have",
            "RNA",
            "sequencing",
            "samples",
            "of",
            "multiple",
            "tissue",
            "types—including",
            "\"Solid",
            "Tissue",
            "Normal\"—within",
            "the",
            "same",
            "case?"
        ],
        "query": "",
        "db_id": "TCGA",
        "No. of candidate columns": 4107,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq148",
        "question": "Could you list the top five protein-coding genes with the highest variance in expression levels, measured as `fpkm_uq_unstranded`, specifically in 'Solid Tissue Normal' samples from TCGA-BRCA cases that include 'Solid Tissue Normal' among their sample types?",
        "external_knowledge": null,
        "question_toks": [
            "Could",
            "you",
            "list",
            "the",
            "top",
            "five",
            "protein-coding",
            "genes",
            "with",
            "the",
            "highest",
            "variance",
            "in",
            "expression",
            "levels,",
            "measured",
            "as",
            "`fpkm_uq_unstranded`,",
            "specifically",
            "in",
            "'Solid",
            "Tissue",
            "Normal'",
            "samples",
            "from",
            "TCGA-BRCA",
            "cases",
            "that",
            "include",
            "'Solid",
            "Tissue",
            "Normal'",
            "among",
            "their",
            "sample",
            "types?"
        ],
        "query": "",
        "db_id": "TCGA",
        "No. of candidate columns": 4107,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq175",
        "question": "Identify cytoband names on chromosome 1 in the TCGA-KIRC segment allelic dataset where the frequency of amplifications, gains, and heterozygous deletions each rank within the top 11. Calculate these rankings based on the maximum copy number observed across various genomic studies of kidney cancer, reflecting the severity of genetic alterations.",
        "external_knowledge": "Comprehensive_Guide_to_Copy_Number_Variations_in_Cancer_Genomics.md",
        "question_toks": [
            "Identify",
            "cytoband",
            "names",
            "on",
            "chromosome",
            "1",
            "in",
            "the",
            "TCGA-KIRC",
            "segment",
            "allelic",
            "dataset",
            "where",
            "the",
            "frequency",
            "of",
            "amplifications,",
            "gains,",
            "and",
            "heterozygous",
            "deletions",
            "each",
            "rank",
            "within",
            "the",
            "top",
            "11.",
            "Calculate",
            "these",
            "rankings",
            "based",
            "on",
            "the",
            "maximum",
            "copy",
            "number",
            "observed",
            "across",
            "various",
            "genomic",
            "studies",
            "of",
            "kidney",
            "cancer,",
            "reflecting",
            "the",
            "severity",
            "of",
            "genetic",
            "alterations."
        ],
        "query": "",
        "db_id": "TCGA_MITELMAN",
        "No. of candidate columns": 4272,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq176",
        "question": "Identify the case barcodes from the TCGA-LAML study with the highest weighted average copy number in cytoband 15q11 on chromosome 15, using segment data and cytoband overlaps from TCGA's genomic and Mitelman databases.",
        "external_knowledge": null,
        "question_toks": [
            "Identify",
            "the",
            "case",
            "barcodes",
            "from",
            "the",
            "TCGA-LAML",
            "study",
            "with",
            "the",
            "highest",
            "weighted",
            "average",
            "copy",
            "number",
            "in",
            "cytoband",
            "15q11",
            "on",
            "chromosome",
            "15,",
            "using",
            "segment",
            "data",
            "and",
            "cytoband",
            "overlaps",
            "from",
            "TCGA's",
            "genomic",
            "and",
            "Mitelman",
            "databases."
        ],
        "query": "WITH copy AS (\n  SELECT \n    \"case_barcode\", \n    \"chromosome\", \n    \"start_pos\", \n    \"end_pos\", \n    MAX(\"copy_number\") AS \"copy_number\"\n  FROM \n    \"TCGA_MITELMAN\".\"TCGA_VERSIONED\".\"COPY_NUMBER_SEGMENT_ALLELIC_HG38_GDC_R23\"\n  WHERE \n    \"project_short_name\" = 'TCGA-LAML'\n  GROUP BY \n    \"case_barcode\", \n    \"chromosome\", \n    \"start_pos\", \n    \"end_pos\"\n),\ntotal_cases AS (\n  SELECT COUNT(DISTINCT \"case_barcode\") AS \"total\"\n  FROM copy\n),\ncytob AS (\n  SELECT \n    \"chromosome\", \n    \"cytoband_name\", \n    \"hg38_start\", \n    \"hg38_stop\"\n  FROM \n    \"TCGA_MITELMAN\".\"PROD\".\"CYTOBANDS_HG38\"\n),\njoined AS (\n  SELECT \n    cytob.\"chromosome\", \n    cytob.\"cytoband_name\", \n    cytob.\"hg38_start\", \n    cytob.\"hg38_stop\", \n    copy.\"case_barcode\",\n    (ABS(cytob.\"hg38_stop\" - cytob.\"hg38_start\") + ABS(copy.\"end_pos\" - copy.\"start_pos\") \n      - ABS(cytob.\"hg38_stop\" - copy.\"end_pos\") - ABS(cytob.\"hg38_start\" - copy.\"start_pos\")) / 2.0 AS \"overlap\", \n    copy.\"copy_number\"\n  FROM \n    copy\n  LEFT JOIN \n    cytob\n  ON \n    cytob.\"chromosome\" = copy.\"chromosome\"\n  WHERE \n    (cytob.\"hg38_start\" >= copy.\"start_pos\" AND copy.\"end_pos\" >= cytob.\"hg38_start\")\n    OR (copy.\"start_pos\" >= cytob.\"hg38_start\" AND copy.\"start_pos\" <= cytob.\"hg38_stop\")\n),\nINFO AS (\n  SELECT \n    \"chromosome\", \n    \"cytoband_name\", \n    \"hg38_start\", \n    \"hg38_stop\", \n    \"case_barcode\",\n    ROUND(SUM(\"overlap\" * \"copy_number\") / SUM(\"overlap\")) AS \"copy_number\"\n  FROM \n    joined\n  GROUP BY \n    \"chromosome\", \"cytoband_name\", \"hg38_start\", \"hg38_stop\", \"case_barcode\"\n)\n\nSELECT \n  \"case_barcode\"\nFROM \n  INFO\nWHERE \n  \"chromosome\" = 'chr15' \n  AND \"cytoband_name\" = '15q11'\nORDER BY \n  \"copy_number\" DESC\nLIMIT 1;",
        "db_id": "TCGA_MITELMAN",
        "No. of candidate columns": 4272,
        "No. of gold tables": 2
    },
    {
        "instance_id": "sf_bq170",
        "question": "For breast cancer cases (TCGA-BRCA) from Release 23 of the active GDC archive, identify and categorize copy number variations (CNVs) across all cytobands on every chromosome. For each cytoband and each case, determine the overlap between the cytoband region and the case's copy number segments, and compute the overlap-weighted average copy number for that cytoband in the case, rounding to the nearest whole number. Classify the rounded copy number into CNV types as follows: homozygous deletions (0), heterozygous deletions (1), normal diploid state (2), gains (3), and amplifications (greater than 3). For each cytoband, provide its name and start/end positions, and calculate the frequency of each CNV type across all cases as a percentage of the total number of cases, rounded to two decimal places.",
        "external_knowledge": "copy_number_variations.md",
        "question_toks": [
            "For",
            "breast",
            "cancer",
            "cases",
            "(TCGA-BRCA)",
            "from",
            "Release",
            "23",
            "of",
            "the",
            "active",
            "GDC",
            "archive,",
            "identify",
            "and",
            "categorize",
            "copy",
            "number",
            "variations",
            "(CNVs)",
            "across",
            "all",
            "cytobands",
            "on",
            "every",
            "chromosome.",
            "For",
            "each",
            "cytoband",
            "and",
            "each",
            "case,",
            "determine",
            "the",
            "overlap",
            "between",
            "the",
            "cytoband",
            "region",
            "and",
            "the",
            "case's",
            "copy",
            "number",
            "segments,",
            "and",
            "compute",
            "the",
            "overlap-weighted",
            "average",
            "copy",
            "number",
            "for",
            "that",
            "cytoband",
            "in",
            "the",
            "case,",
            "rounding",
            "to",
            "the",
            "nearest",
            "whole",
            "number.",
            "Classify",
            "the",
            "rounded",
            "copy",
            "number",
            "into",
            "CNV",
            "types",
            "as",
            "follows:",
            "homozygous",
            "deletions",
            "(0),",
            "heterozygous",
            "deletions",
            "(1),",
            "normal",
            "diploid",
            "state",
            "(2),",
            "gains",
            "(3),",
            "and",
            "amplifications",
            "(greater",
            "than",
            "3).",
            "For",
            "each",
            "cytoband,",
            "provide",
            "its",
            "name",
            "and",
            "start/end",
            "positions,",
            "and",
            "calculate",
            "the",
            "frequency",
            "of",
            "each",
            "CNV",
            "type",
            "across",
            "all",
            "cases",
            "as",
            "a",
            "percentage",
            "of",
            "the",
            "total",
            "number",
            "of",
            "cases,",
            "rounded",
            "to",
            "two",
            "decimal",
            "places."
        ],
        "query": "",
        "db_id": "TCGA_MITELMAN",
        "No. of candidate columns": 4272,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq150",
        "question": "Assess whether different genetic variants affect the log10-transformed TP53 expression levels in TCGA-BRCA samples using sequencing and mutation data. Provide the total number of samples, the number of mutation types, the mean square between groups, the mean square within groups, and the F-statistic.",
        "external_knowledge": "TCGA_F_Score.md",
        "question_toks": [
            "Assess",
            "whether",
            "different",
            "genetic",
            "variants",
            "affect",
            "the",
            "log10-transformed",
            "TP53",
            "expression",
            "levels",
            "in",
            "TCGA-BRCA",
            "samples",
            "using",
            "sequencing",
            "and",
            "mutation",
            "data.",
            "Provide",
            "the",
            "total",
            "number",
            "of",
            "samples,",
            "the",
            "number",
            "of",
            "mutation",
            "types,",
            "the",
            "mean",
            "square",
            "between",
            "groups,",
            "the",
            "mean",
            "square",
            "within",
            "groups,",
            "and",
            "the",
            "F-statistic."
        ],
        "query": "WITH\ncohortExpr AS (\n  SELECT\n    \"sample_barcode\",\n    LOG(10, \"normalized_count\") AS \"expr\"\n  FROM\n    \"TCGA_HG19_DATA_V0\".\"TCGA_HG19_DATA_V0\".\"RNASEQ_GENE_EXPRESSION_UNC_RSEM\"\n  WHERE\n    \"project_short_name\" = 'TCGA-BRCA'\n    AND \"HGNC_gene_symbol\" = 'TP53'\n    AND \"normalized_count\" IS NOT NULL\n    AND \"normalized_count\" > 0\n),\ncohortVar AS (\n  SELECT\n    \"Variant_Type\",\n    \"sample_barcode_tumor\" AS \"sample_barcode\"\n  FROM\n    \"TCGA_HG19_DATA_V0\".\"TCGA_HG19_DATA_V0\".\"SOMATIC_MUTATION_MC3\"\n  WHERE\n    \"SYMBOL\" = 'TP53'\n),\ncohort AS (\n  SELECT\n    e.\"sample_barcode\" AS \"sample_barcode\",\n    v.\"Variant_Type\" AS \"group_name\",\n    e.\"expr\"\n  FROM\n    cohortExpr e\n  JOIN\n    cohortVar v\n  ON\n    e.\"sample_barcode\" = v.\"sample_barcode\"\n),\ngrandMeanTable AS (\n  SELECT\n    AVG(\"expr\") AS \"grand_mean\"\n  FROM\n    cohort\n),\ngroupMeansTable AS (\n  SELECT\n    AVG(\"expr\") AS \"group_mean\",\n    \"group_name\",\n    COUNT(\"sample_barcode\") AS \"n\"\n  FROM\n    cohort\n  GROUP BY\n    \"group_name\"\n),\nssBetween AS (\n  SELECT\n    g.\"group_name\",\n    g.\"group_mean\",\n    gm.\"grand_mean\",\n    g.\"n\",\n    g.\"n\" * POW(g.\"group_mean\" - gm.\"grand_mean\", 2) AS \"n_diff_sq\"\n  FROM\n    groupMeansTable g\n  CROSS JOIN\n    grandMeanTable gm\n),\nssWithin AS (\n  SELECT\n    c.\"group_name\" AS \"group_name\",\n    c.\"expr\",\n    b.\"group_mean\",\n    b.\"n\" AS \"n\",\n    POW(c.\"expr\" - b.\"group_mean\", 2) AS \"s2\"\n  FROM\n    cohort c\n  JOIN\n    ssBetween b\n  ON\n    c.\"group_name\" = b.\"group_name\"\n),\nnumerator AS (\n  SELECT\n    SUM(\"n_diff_sq\") / (COUNT(\"group_name\") - 1) AS \"mean_sq_between\"\n  FROM\n    ssBetween\n),\ndenominator AS (\n  SELECT\n    COUNT(DISTINCT \"group_name\") AS \"k\",\n    COUNT(\"group_name\") AS \"n\",\n    SUM(\"s2\") / (COUNT(\"group_name\") - COUNT(DISTINCT \"group_name\")) AS \"mean_sq_within\"\n  FROM\n    ssWithin\n)\n\nSELECT\n  \"n\",\n  \"k\",\n  \"mean_sq_between\",\n  \"mean_sq_within\",\n  \"mean_sq_between\" / \"mean_sq_within\" AS \"F\"\nFROM\n  numerator,\n  denominator;",
        "db_id": "TCGA_HG19_DATA_V0",
        "No. of candidate columns": 401,
        "No. of gold tables": 2
    },
    {
        "instance_id": "sf_bq152",
        "question": "For breast cancer cases (TCGA-BRCA) from Release 23 of the active GDC archive, identify and categorize copy number variations (CNVs) across all cytobands on every chromosome. For each cytoband and each case, determine the overlap between the cytoband region and the case's copy number segments, and compute the overlap-weighted average copy number for that cytoband in the case, rounding to the nearest whole number. Classify the rounded copy number into CNV types as follows: homozygous deletions (0), heterozygous deletions (1), normal diploid state (2), gains (3), and amplifications (greater than 3). For each cytoband, provide its name and start/end positions, and calculate the frequency of each CNV type across all cases as a percentage of the total number of cases, rounded to two decimal places.",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "breast",
            "cancer",
            "cases",
            "(TCGA-BRCA)",
            "from",
            "Release",
            "23",
            "of",
            "the",
            "active",
            "GDC",
            "archive,",
            "identify",
            "and",
            "categorize",
            "copy",
            "number",
            "variations",
            "(CNVs)",
            "across",
            "all",
            "cytobands",
            "on",
            "every",
            "chromosome.",
            "For",
            "each",
            "cytoband",
            "and",
            "each",
            "case,",
            "determine",
            "the",
            "overlap",
            "between",
            "the",
            "cytoband",
            "region",
            "and",
            "the",
            "case's",
            "copy",
            "number",
            "segments,",
            "and",
            "compute",
            "the",
            "overlap-weighted",
            "average",
            "copy",
            "number",
            "for",
            "that",
            "cytoband",
            "in",
            "the",
            "case,",
            "rounding",
            "to",
            "the",
            "nearest",
            "whole",
            "number.",
            "Classify",
            "the",
            "rounded",
            "copy",
            "number",
            "into",
            "CNV",
            "types",
            "as",
            "follows:",
            "homozygous",
            "deletions",
            "(0),",
            "heterozygous",
            "deletions",
            "(1),",
            "normal",
            "diploid",
            "state",
            "(2),",
            "gains",
            "(3),",
            "and",
            "amplifications",
            "(greater",
            "than",
            "3).",
            "For",
            "each",
            "cytoband,",
            "provide",
            "its",
            "name",
            "and",
            "start/end",
            "positions,",
            "and",
            "calculate",
            "the",
            "frequency",
            "of",
            "each",
            "CNV",
            "type",
            "across",
            "all",
            "cases",
            "as",
            "a",
            "percentage",
            "of",
            "the",
            "total",
            "number",
            "of",
            "cases,",
            "rounded",
            "to",
            "two",
            "decimal",
            "places."
        ],
        "query": "",
        "db_id": "TCGA_HG38_DATA_V0",
        "No. of candidate columns": 1145,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq046",
        "question": "Find case barcodes and their corresponding GDC file URLs for female patients aged 30 or younger diagnosed with breast cancer, whose clinical history includes problematic prior treatments for other cancers or redacted annotations. Only consider relevant clinical and annotation data from TCGA with GDC archive release 14.",
        "external_knowledge": null,
        "question_toks": [
            "Find",
            "case",
            "barcodes",
            "and",
            "their",
            "corresponding",
            "GDC",
            "file",
            "URLs",
            "for",
            "female",
            "patients",
            "aged",
            "30",
            "or",
            "younger",
            "diagnosed",
            "with",
            "breast",
            "cancer,",
            "whose",
            "clinical",
            "history",
            "includes",
            "problematic",
            "prior",
            "treatments",
            "for",
            "other",
            "cancers",
            "or",
            "redacted",
            "annotations.",
            "Only",
            "consider",
            "relevant",
            "clinical",
            "and",
            "annotation",
            "data",
            "from",
            "TCGA",
            "with",
            "GDC",
            "archive",
            "release",
            "14."
        ],
        "query": "",
        "db_id": "TCGA_bioclin_v0",
        "No. of candidate columns": 1829,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq153",
        "question": "Calculate, for each histology type specified in the 'icd_o_3_histology' field (excluding those enclosed in square brackets), the average of the per-patient average log10(normalized_count + 1) expression levels of the IGF2 gene among LGG patients with valid IGF2 expression data. Match gene expression and clinical data using the ParticipantBarcode field.",
        "external_knowledge": null,
        "question_toks": [
            "Calculate,",
            "for",
            "each",
            "histology",
            "type",
            "specified",
            "in",
            "the",
            "'icd_o_3_histology'",
            "field",
            "(excluding",
            "those",
            "enclosed",
            "in",
            "square",
            "brackets),",
            "the",
            "average",
            "of",
            "the",
            "per-patient",
            "average",
            "log10(normalized_count",
            "+",
            "1)",
            "expression",
            "levels",
            "of",
            "the",
            "IGF2",
            "gene",
            "among",
            "LGG",
            "patients",
            "with",
            "valid",
            "IGF2",
            "expression",
            "data.",
            "Match",
            "gene",
            "expression",
            "and",
            "clinical",
            "data",
            "using",
            "the",
            "ParticipantBarcode",
            "field."
        ],
        "query": "WITH\n    table1 AS (\n        SELECT \n            \"Symbol\" AS \"symbol\", \n            AVG(LOG(10, \"normalized_count\" + 1)) AS \"data\", \n            \"ParticipantBarcode\"\n        FROM \n            PANCANCER_ATLAS_1.PANCANCER_ATLAS_FILTERED.EBPP_ADJUSTPANCAN_ILLUMINAHISEQ_RNASEQV2_GENEXP_FILTERED\n        WHERE \n            \"Study\" = 'LGG' \n            AND \"Symbol\" = 'IGF2' \n            AND \"normalized_count\" IS NOT NULL\n        GROUP BY \n            \"ParticipantBarcode\", \"symbol\"\n    ),\n    table2 AS (\n        SELECT\n            \"symbol\",\n            \"avgdata\" AS \"data\",\n            \"ParticipantBarcode\"\n        FROM (\n            SELECT\n                'icd_o_3_histology' AS \"symbol\", \n                \"icd_o_3_histology\" AS \"avgdata\",\n                \"bcr_patient_barcode\" AS \"ParticipantBarcode\"\n            FROM \n                PANCANCER_ATLAS_1.PANCANCER_ATLAS_FILTERED.CLINICAL_PANCAN_PATIENT_WITH_FOLLOWUP_FILTERED\n            WHERE \n                \"acronym\" = 'LGG' \n                AND \"icd_o_3_histology\" IS NOT NULL  \n                AND NOT REGEXP_LIKE(\"icd_o_3_histology\", '^(\\\\[.*\\\\]$)')\n        )\n    ),\n    table_data AS (\n        SELECT \n            n1.\"data\" AS \"data1\",\n            n2.\"data\" AS \"data2\",\n            n1.\"ParticipantBarcode\"\n        FROM \n            table1 AS n1\n        INNER JOIN \n            table2 AS n2\n        ON \n            n1.\"ParticipantBarcode\" = n2.\"ParticipantBarcode\"\n    ) \n\nSELECT \n    \"data2\" AS \"Histology_Type\", \n    AVG(\"data1\") AS \"Average_Log_Expression\"\nFROM \n    table_data\nGROUP BY \n    \"data2\";",
        "db_id": "PANCANCER_ATLAS_1",
        "No. of candidate columns": 833,
        "No. of gold tables": 2
    },
    {
        "instance_id": "sf_bq156",
        "question": "Compute the t-score (rounded to 2 decimals) to compare the difference in mean expression levels of the gene DRG2 between two groups (TP53 mutated vs. non-mutated) in the Lower Grade Glioma (LGG) study, where the expression levels are calculated as the average of log10(normalized_count + 1) for each participant, only considering samples with TP53 mutations that have a 'FILTER' status of 'PASS' in the mutation data, and ignoring any groups with fewer than 10 samples or with zero variance; refer to `t_score.md` for the method of computing the t-score.",
        "external_knowledge": "t_score.md",
        "question_toks": [
            "Compute",
            "the",
            "t-score",
            "(rounded",
            "to",
            "2",
            "decimals)",
            "to",
            "compare",
            "the",
            "difference",
            "in",
            "mean",
            "expression",
            "levels",
            "of",
            "the",
            "gene",
            "DRG2",
            "between",
            "two",
            "groups",
            "(TP53",
            "mutated",
            "vs.",
            "non-mutated)",
            "in",
            "the",
            "Lower",
            "Grade",
            "Glioma",
            "(LGG)",
            "study,",
            "where",
            "the",
            "expression",
            "levels",
            "are",
            "calculated",
            "as",
            "the",
            "average",
            "of",
            "log10(normalized_count",
            "+",
            "1)",
            "for",
            "each",
            "participant,",
            "only",
            "considering",
            "samples",
            "with",
            "TP53",
            "mutations",
            "that",
            "have",
            "a",
            "'FILTER'",
            "status",
            "of",
            "'PASS'",
            "in",
            "the",
            "mutation",
            "data,",
            "and",
            "ignoring",
            "any",
            "groups",
            "with",
            "fewer",
            "than",
            "10",
            "samples",
            "or",
            "with",
            "zero",
            "variance;",
            "refer",
            "to",
            "`t_score.md`",
            "for",
            "the",
            "method",
            "of",
            "computing",
            "the",
            "t-score."
        ],
        "query": "",
        "db_id": "PANCANCER_ATLAS_1",
        "No. of candidate columns": 833,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq157",
        "question": "Please compute the T-score to determine the statistical difference in the expression of the DRG2 gene between LGG patients with and without TP53 mutation: for each patient, calculate the average of log10(normalized_count + 1) of DRG2 expression across all their samples, using only samples present in the `MC3_MAF_V5_one_per_tumor_sample` table for the LGG study; identify patients with TP53 mutations from this table where `Hugo_Symbol` is 'TP53' and `FILTER` is 'PASS'; then perform a T-test comparing the mean averaged log-transformed DRG2 expression between patients with and without TP53 mutation.",
        "external_knowledge": "Regulome_Explorer_T_test_for_numerical_and_binary_data.md",
        "question_toks": [
            "Please",
            "compute",
            "the",
            "T-score",
            "to",
            "determine",
            "the",
            "statistical",
            "difference",
            "in",
            "the",
            "expression",
            "of",
            "the",
            "DRG2",
            "gene",
            "between",
            "LGG",
            "patients",
            "with",
            "and",
            "without",
            "TP53",
            "mutation:",
            "for",
            "each",
            "patient,",
            "calculate",
            "the",
            "average",
            "of",
            "log10(normalized_count + 1)",
            "of",
            "DRG2",
            "expression",
            "across",
            "all",
            "their",
            "samples,",
            "using",
            "only",
            "samples",
            "present",
            "in",
            "the",
            "`MC3_MAF_V5_one_per_tumor_sample`",
            "table",
            "for",
            "the",
            "LGG",
            "study;",
            "identify",
            "patients",
            "with",
            "TP53",
            "mutations",
            "from",
            "this",
            "table",
            "where",
            "`Hugo_Symbol`",
            "is",
            "'TP53'",
            "and",
            "`FILTER`",
            "is",
            "'PASS';",
            "then",
            "perform",
            "a",
            "T-test",
            "comparing",
            "the",
            "mean",
            "averaged",
            "log-transformed",
            "DRG2",
            "expression",
            "between",
            "patients",
            "with",
            "and",
            "without",
            "TP53",
            "mutation."
        ],
        "query": "",
        "db_id": "PANCANCER_ATLAS_1",
        "No. of candidate columns": 833,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq158",
        "question": "Which top five histological types of breast cancer (BRCA) in the PanCancer Atlas exhibit the highest percentage of CDH1 gene mutations?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "top",
            "five",
            "histological",
            "types",
            "of",
            "breast",
            "cancer",
            "(BRCA)",
            "in",
            "the",
            "PanCancer",
            "Atlas",
            "exhibit",
            "the",
            "highest",
            "percentage",
            "of",
            "CDH1",
            "gene",
            "mutations?"
        ],
        "query": "WITH\n    table1 AS (\n        SELECT\n            \"histological_type\" AS \"data1\",\n            \"bcr_patient_barcode\" AS \"ParticipantBarcode\"\n        FROM \n            \"PANCANCER_ATLAS_1\".\"PANCANCER_ATLAS_FILTERED\".\"CLINICAL_PANCAN_PATIENT_WITH_FOLLOWUP_FILTERED\"\n        WHERE \n            \"acronym\" = 'BRCA' \n            AND \"histological_type\" IS NOT NULL      \n    ),\n    table2 AS (\n        SELECT\n            \"Hugo_Symbol\" AS \"symbol\", \n            \"ParticipantBarcode\"\n        FROM \n            \"PANCANCER_ATLAS_1\".\"PANCANCER_ATLAS_FILTERED\".\"MC3_MAF_V5_ONE_PER_TUMOR_SAMPLE\"\n        WHERE \n            \"Study\" = 'BRCA' \n            AND \"Hugo_Symbol\" = 'CDH1'\n            AND \"FILTER\" = 'PASS'  \n        GROUP BY\n            \"ParticipantBarcode\", \"symbol\"\n    ),\n    summ_table AS (\n        SELECT \n            n1.\"data1\",\n            CASE \n                WHEN n2.\"ParticipantBarcode\" IS NULL THEN 'NO' \n                ELSE 'YES' \n            END AS \"data2\",\n            COUNT(*) AS \"Nij\"\n        FROM\n            table1 AS n1\n        LEFT JOIN\n            table2 AS n2 \n            ON n1.\"ParticipantBarcode\" = n2.\"ParticipantBarcode\"\n        GROUP BY\n            n1.\"data1\", \"data2\"\n    ),\n    percentages AS (\n        SELECT\n            \"data1\",\n            SUM(CASE WHEN \"data2\" = 'YES' THEN \"Nij\" ELSE 0 END) AS \"mutation_count\",\n            SUM(\"Nij\") AS \"total\",\n            SUM(CASE WHEN \"data2\" = 'YES' THEN \"Nij\" ELSE 0 END) / SUM(\"Nij\") AS \"mutation_percentage\"\n        FROM \n            summ_table\n        GROUP BY \n            \"data1\"\n    )\nSELECT \n    \"data1\" AS \"Histological_Type\"\nFROM \n    percentages\nORDER BY \n    \"mutation_percentage\" DESC\nLIMIT 5;",
        "db_id": "PANCANCER_ATLAS_1",
        "No. of candidate columns": 833,
        "No. of gold tables": 2
    },
    {
        "instance_id": "sf_bq159",
        "question": "Calculate the chi-square value to assess the association between histological types and the presence of CDH1 gene mutations in BRCA patients using data from the PanCancer Atlas. Focus on patients with known histological types and consider only reliable mutation entries.  Exclude any histological types or mutation statuses with marginal totals less than or equal to 10. Match clinical and mutation data using ParticipantBarcode",
        "external_knowledge": null,
        "question_toks": [
            "Calculate",
            "the",
            "chi-square",
            "value",
            "to",
            "assess",
            "the",
            "association",
            "between",
            "histological",
            "types",
            "and",
            "the",
            "presence",
            "of",
            "CDH1",
            "gene",
            "mutations",
            "in",
            "BRCA",
            "patients",
            "using",
            "data",
            "from",
            "the",
            "PanCancer",
            "Atlas.",
            "Focus",
            "on",
            "patients",
            "with",
            "known",
            "histological",
            "types",
            "and",
            "consider",
            "only",
            "reliable",
            "mutation",
            "entries.",
            "",
            "Exclude",
            "any",
            "histological",
            "types",
            "or",
            "mutation",
            "statuses",
            "with",
            "marginal",
            "totals",
            "less",
            "than",
            "or",
            "equal",
            "to",
            "10.",
            "Match",
            "clinical",
            "and",
            "mutation",
            "data",
            "using",
            "ParticipantBarcode"
        ],
        "query": "WITH\n    table1 AS (\n        SELECT\n            \"symbol\",\n            \"avgdata\" AS \"data\",\n            \"ParticipantBarcode\"\n        FROM (\n            SELECT\n                'histological_type' AS \"symbol\", \n                \"histological_type\" AS \"avgdata\",\n                \"bcr_patient_barcode\" AS \"ParticipantBarcode\"\n            FROM \n                \"PANCANCER_ATLAS_1\".\"PANCANCER_ATLAS_FILTERED\".\"CLINICAL_PANCAN_PATIENT_WITH_FOLLOWUP_FILTERED\"\n            WHERE \n                \"acronym\" = 'BRCA' \n                AND \"histological_type\" IS NOT NULL      \n        )\n    ),\n    table2 AS (\n        SELECT\n            \"symbol\",\n            \"ParticipantBarcode\"\n        FROM (\n            SELECT\n                \"Hugo_Symbol\" AS \"symbol\", \n                \"ParticipantBarcode\" AS \"ParticipantBarcode\"\n            FROM \n                \"PANCANCER_ATLAS_1\".\"PANCANCER_ATLAS_FILTERED\".\"MC3_MAF_V5_ONE_PER_TUMOR_SAMPLE\"\n            WHERE \n                \"Study\" = 'BRCA' \n                AND \"Hugo_Symbol\" = 'CDH1'\n                AND \"FILTER\" = 'PASS'  \n            GROUP BY\n                \"ParticipantBarcode\", \"symbol\"\n        )\n    ),\n    summ_table AS (\n        SELECT \n            n1.\"data\" AS \"data1\",\n            CASE \n                WHEN n2.\"ParticipantBarcode\" IS NULL THEN 'NO' \n                ELSE 'YES' \n            END AS \"data2\",\n            COUNT(*) AS \"Nij\"\n        FROM\n            table1 AS n1\n        LEFT JOIN\n            table2 AS n2 \n            ON n1.\"ParticipantBarcode\" = n2.\"ParticipantBarcode\"\n        GROUP BY\n            n1.\"data\", \"data2\"\n    ),\n    expected_table AS (\n        SELECT \n            \"data1\", \n            \"data2\"\n        FROM (     \n            SELECT \n                \"data1\", \n                SUM(\"Nij\") AS \"Ni\"   \n            FROM \n                summ_table\n            GROUP BY \n                \"data1\"\n        ) AS Ni_table\n        CROSS JOIN ( \n            SELECT \n                \"data2\", \n                SUM(\"Nij\") AS \"Nj\"\n            FROM \n                summ_table\n            GROUP BY \n                \"data2\"\n        ) AS Nj_table\n        WHERE \n            Ni_table.\"Ni\" > 10 \n            AND Nj_table.\"Nj\" > 10\n    ),\n    contingency_table AS (\n        SELECT\n            T1.\"data1\",\n            T1.\"data2\",\n            COALESCE(T2.\"Nij\", 0) AS \"Nij\",\n            (SUM(T2.\"Nij\") OVER (PARTITION BY T1.\"data1\")) * \n            (SUM(T2.\"Nij\") OVER (PARTITION BY T1.\"data2\")) / \n            SUM(T2.\"Nij\") OVER () AS \"E_nij\"\n        FROM\n            expected_table AS T1\n        LEFT JOIN\n            summ_table AS T2\n        ON \n            T1.\"data1\" = T2.\"data1\" \n            AND T1.\"data2\" = T2.\"data2\"\n    )\nSELECT\n    SUM( ( \"Nij\" - \"E_nij\" ) * ( \"Nij\" - \"E_nij\" ) / \"E_nij\" ) AS \"Chi2\"\nFROM \n    contingency_table;",
        "db_id": "PANCANCER_ATLAS_1",
        "No. of candidate columns": 833,
        "No. of gold tables": 2
    },
    {
        "instance_id": "bq161",
        "question": "Calculate the net difference between the number of pancreatic adenocarcinoma (PAAD) patients in TCGA's dataset who are confirmed to have mutations in both KRAS and TP53 genes, and those without mutations in either gene. Utilize patient clinical and follow-up data alongside genomic mutation details from TCGA’s cancer genomics database, focusing specifically on PAAD studies where the mutations have passed quality filters.",
        "external_knowledge": null,
        "question_toks": [
            "Calculate",
            "the",
            "net",
            "difference",
            "between",
            "the",
            "number",
            "of",
            "pancreatic",
            "adenocarcinoma",
            "(PAAD)",
            "patients",
            "in",
            "TCGA's",
            "dataset",
            "who",
            "are",
            "confirmed",
            "to",
            "have",
            "mutations",
            "in",
            "both",
            "KRAS",
            "and",
            "TP53",
            "genes,",
            "and",
            "those",
            "without",
            "mutations",
            "in",
            "either",
            "gene.",
            "Utilize",
            "patient",
            "clinical",
            "and",
            "follow-up",
            "data",
            "alongside",
            "genomic",
            "mutation",
            "details",
            "from",
            "TCGA’s",
            "cancer",
            "genomics",
            "database,",
            "focusing",
            "specifically",
            "on",
            "PAAD",
            "studies",
            "where",
            "the",
            "mutations",
            "have",
            "passed",
            "quality",
            "filters."
        ],
        "query": "WITH\nbarcodes AS (\n   SELECT bcr_patient_barcode AS ParticipantBarcode\n   FROM `isb-cgc-bq.pancancer_atlas.Filtered_clinical_PANCAN_patient_with_followup`\n   WHERE acronym = 'PAAD'\n)\n,table1 AS (\nSELECT\n   t1.ParticipantBarcode,\n   IF( t2.ParticipantBarcode is null, 'NO', 'YES') as data\nFROM\n   barcodes AS t1\nLEFT JOIN\n   (\n   SELECT\n      ParticipantBarcode AS ParticipantBarcode\n   FROM `isb-cgc-bq.pancancer_atlas.Filtered_MC3_MAF_V5_one_per_tumor_sample`\n   WHERE Study = 'PAAD' AND Hugo_Symbol = 'KRAS'\n         AND FILTER = 'PASS'\n   GROUP BY ParticipantBarcode\n   ) AS t2\nON t1.ParticipantBarcode = t2.ParticipantBarcode\n)\n,table2 AS (\nSELECT\n   t1.ParticipantBarcode,\n   IF( t2.ParticipantBarcode is null, 'NO', 'YES') as data\nFROM\n   barcodes AS t1\nLEFT JOIN\n   (\n   SELECT\n      ParticipantBarcode AS ParticipantBarcode\n   FROM `isb-cgc-bq.pancancer_atlas.Filtered_MC3_MAF_V5_one_per_tumor_sample`\n   WHERE Study = 'PAAD' AND Hugo_Symbol = 'TP53'\n         AND FILTER = 'PASS'\n   GROUP BY ParticipantBarcode\n   ) AS t2\nON t1.ParticipantBarcode = t2.ParticipantBarcode\n),\n\nINFO AS (\nSELECT\n   n1.data as data1,\n   n2.data as data2,\n   COUNT(*) as Nij\nFROM\n   table1 AS n1\nINNER JOIN\n   table2 AS n2\nON\n   n1.ParticipantBarcode = n2.ParticipantBarcode\nGROUP BY\n  data1, data2\n)\n\nSELECT \n(SELECT Nij FROM INFO WHERE data1=\"YES\" AND data2=\"YES\")\n-\n(SELECT Nij FROM INFO WHERE data1=\"NO\" AND data2=\"NO\")",
        "db_id": "pancancer_atlas_2",
        "No. of candidate columns": 1634,
        "No. of gold tables": 3
    },
    {
        "instance_id": "bq151",
        "question": "Using TCGA dataset, calculate the chi-squared statistic to evaluate the association between KRAS and TP53 gene mutations in patients diagnosed with pancreatic adenocarcinoma (PAAD). Incorporate clinical follow-up data and high-quality mutation annotations to accurately determine the frequency of patients with co-occurring KRAS and TP53 mutations compared to those with each mutation occurring independently. Ensure that patient records are meticulously matched based on unique identifiers to maintain data integrity. This analysis aims to identify and quantify potential correlations between KRAS and TP53 genetic alterations within the PAAD patient population.",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "TCGA",
            "dataset,",
            "calculate",
            "the",
            "chi-squared",
            "statistic",
            "to",
            "evaluate",
            "the",
            "association",
            "between",
            "KRAS",
            "and",
            "TP53",
            "gene",
            "mutations",
            "in",
            "patients",
            "diagnosed",
            "with",
            "pancreatic",
            "adenocarcinoma",
            "(PAAD).",
            "Incorporate",
            "clinical",
            "follow-up",
            "data",
            "and",
            "high-quality",
            "mutation",
            "annotations",
            "to",
            "accurately",
            "determine",
            "the",
            "frequency",
            "of",
            "patients",
            "with",
            "co-occurring",
            "KRAS",
            "and",
            "TP53",
            "mutations",
            "compared",
            "to",
            "those",
            "with",
            "each",
            "mutation",
            "occurring",
            "independently.",
            "Ensure",
            "that",
            "patient",
            "records",
            "are",
            "meticulously",
            "matched",
            "based",
            "on",
            "unique",
            "identifiers",
            "to",
            "maintain",
            "data",
            "integrity.",
            "This",
            "analysis",
            "aims",
            "to",
            "identify",
            "and",
            "quantify",
            "potential",
            "correlations",
            "between",
            "KRAS",
            "and",
            "TP53",
            "genetic",
            "alterations",
            "within",
            "the",
            "PAAD",
            "patient",
            "population."
        ],
        "query": "",
        "db_id": "pancancer_atlas_2",
        "No. of candidate columns": 1634,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq162",
        "question": "Based on the 5th revision (r5) of the HTAN data, list the imaging assay types available at the HTAN WUSTL center that have Level2 data and any associated higher-level data (Level3, Level4) derived from them through 'entityId' relationships in the 'id_provenance_r5' table; exclude any records where the 'Component' is NULL or contains 'Auxiliary' or 'OtherAssay'; for each imaging assay type, provide the available data levels (Level2, Level3, Level4), and do not include Level1 data or Electron Microscopy assay types.",
        "external_knowledge": null,
        "question_toks": [
            "Based",
            "on",
            "the",
            "5th",
            "revision",
            "(r5)",
            "of",
            "the",
            "HTAN",
            "data,",
            "list",
            "the",
            "imaging",
            "assay",
            "types",
            "available",
            "at",
            "the",
            "HTAN",
            "WUSTL",
            "center",
            "that",
            "have",
            "Level2",
            "data",
            "and",
            "any",
            "associated",
            "higher-level",
            "data",
            "(Level3,",
            "Level4)",
            "derived",
            "from",
            "them",
            "through",
            "'entityId'",
            "relationships",
            "in",
            "the",
            "'id_provenance_r5'",
            "table;",
            "exclude",
            "any",
            "records",
            "where",
            "the",
            "'Component'",
            "is",
            "NULL",
            "or",
            "contains",
            "'Auxiliary'",
            "or",
            "'OtherAssay';",
            "for",
            "each",
            "imaging",
            "assay",
            "type,",
            "provide",
            "the",
            "available",
            "data",
            "levels",
            "(Level2,",
            "Level3,",
            "Level4),",
            "and",
            "do",
            "not",
            "include",
            "Level1",
            "data",
            "or",
            "Electron",
            "Microscopy",
            "assay",
            "types."
        ],
        "query": "",
        "db_id": "HTAN_1",
        "No. of candidate columns": 7030,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq164",
        "question": "Consolidate metadata from spatial transcriptomics and scRNAseq datasets—including levels 1 through 4 and auxiliary files—for the run ID 'HT264P1-S1H2Fc2U1Z1Bs1-H2Bs2-Test'. Include Filename, HTAN Parent Biospecimen ID, Component, File Format, Entity ID, and Run ID.",
        "external_knowledge": null,
        "question_toks": [
            "Consolidate",
            "metadata",
            "from",
            "spatial",
            "transcriptomics",
            "and",
            "scRNAseq",
            "datasets—including",
            "levels",
            "1",
            "through",
            "4",
            "and",
            "auxiliary",
            "files—for",
            "the",
            "run",
            "ID",
            "'HT264P1-S1H2Fc2U1Z1Bs1-H2Bs2-Test'.",
            "Include",
            "Filename,",
            "HTAN",
            "Parent",
            "Biospecimen",
            "ID,",
            "Component,",
            "File",
            "Format,",
            "Entity",
            "ID,",
            "and",
            "Run",
            "ID."
        ],
        "query": "",
        "db_id": "HTAN_2",
        "No. of candidate columns": 3428,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq165",
        "question": "Can you use CytoConverter genomic coordinates to calculate the frequency of chromosomal gains and losses across a cohort of breast cancer (morphology='3111') and adenocarcinoma (topology='0401') samples? Concretely, please include the number and frequency (2 decimals in percentage) of amplifications (gains of more than 1 copy), gains (1 extra copy), losses (1 copy) and homozygous deletions (loss of 2 copies) for each chromosomal band. And sort the result by the ordinal of each chromosome and the starting-ending base-pair position of each band in ascending order.",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "use",
            "CytoConverter",
            "genomic",
            "coordinates",
            "to",
            "calculate",
            "the",
            "frequency",
            "of",
            "chromosomal",
            "gains",
            "and",
            "losses",
            "across",
            "a",
            "cohort",
            "of",
            "breast",
            "cancer",
            "(morphology='3111')",
            "and",
            "adenocarcinoma",
            "(topology='0401')",
            "samples?",
            "Concretely,",
            "please",
            "include",
            "the",
            "number",
            "and",
            "frequency",
            "(2",
            "decimals",
            "in",
            "percentage)",
            "of",
            "amplifications",
            "(gains",
            "of",
            "more",
            "than",
            "1",
            "copy),",
            "gains",
            "(1",
            "extra",
            "copy),",
            "losses",
            "(1",
            "copy)",
            "and",
            "homozygous",
            "deletions",
            "(loss",
            "of",
            "2",
            "copies)",
            "for",
            "each",
            "chromosomal",
            "band.",
            "And",
            "sort",
            "the",
            "result",
            "by",
            "the",
            "ordinal",
            "of",
            "each",
            "chromosome",
            "and",
            "the",
            "starting-ending",
            "base-pair",
            "position",
            "of",
            "each",
            "band",
            "in",
            "ascending",
            "order."
        ],
        "query": "",
        "db_id": "mitelman",
        "No. of candidate columns": 165,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq169",
        "question": "Retrieve distinct case and clone information for which, within the same clone, there is simultaneously a loss of genetic material on chromosome 13 between positions 48,303,751 and 48,481,890, a loss on chromosome 17 between positions 7,668,421 and 7,687,490, and a gain on chromosome 11 between positions 108,223,067 and 108,369,102. For each such clone, also return the chromosomal details for each of these regions (including chromosome number, start and end positions) and the corresponding karyotype information.",
        "external_knowledge": null,
        "question_toks": [
            "Retrieve",
            "distinct",
            "case",
            "and",
            "clone",
            "information",
            "for",
            "which,",
            "within",
            "the",
            "same",
            "clone,",
            "there",
            "is",
            "simultaneously",
            "a",
            "loss",
            "of",
            "genetic",
            "material",
            "on",
            "chromosome",
            "13",
            "between",
            "positions",
            "48,303,751",
            "and",
            "48,481,890,",
            "a",
            "loss",
            "on",
            "chromosome",
            "17",
            "between",
            "positions",
            "7,668,421",
            "and",
            "7,687,490,",
            "and",
            "a",
            "gain",
            "on",
            "chromosome",
            "11",
            "between",
            "positions",
            "108,223,067",
            "and",
            "108,369,102.",
            "For",
            "each",
            "such",
            "clone,",
            "also",
            "return",
            "the",
            "chromosomal",
            "details",
            "for",
            "each",
            "of",
            "these",
            "regions",
            "(including",
            "chromosome",
            "number,",
            "start",
            "and",
            "end",
            "positions)",
            "and",
            "the",
            "corresponding",
            "karyotype",
            "information."
        ],
        "query": "",
        "db_id": "mitelman",
        "No. of candidate columns": 165,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq451",
        "question": "Extract genotype data for single nucleotide polymorphisms (SNPs) on chromosome X, excluding positions where the `start` value is between 59999 and 2699519 or between 154931042 and 155260559. For each sample, identify genotype calls where the genotype array has at least one allele. Classify each genotype call into one of the following categories: homozygous reference alleles (both alleles are 0), homozygous alternate alleles (both alleles are the same and greater than 0), or heterozygous alleles (alleles are different, or any allele is null, and at least one allele is greater than 0). Compute the total number of callable sites (the sum of all three genotype categories), the number of homozygous reference, homozygous alternate, and heterozygous genotype calls, the total number of single nucleotide variants (SNVs) as the sum of homozygous alternate and heterozygous genotype calls, the percentage of heterozygous genotype calls among all SNVs, and the percentage of homozygous alternate genotype calls among all SNVs. Output the sample ID along with these computed counts and percentages, and order the results by the percentage of heterozygous genotype calls among SNVs in descending order, then by sample ID.",
        "external_knowledge": "1000_genomes_alleles_type.md",
        "question_toks": [
            "Extract",
            "genotype",
            "data",
            "for",
            "single",
            "nucleotide",
            "polymorphisms",
            "(SNPs)",
            "on",
            "chromosome",
            "X,",
            "excluding",
            "positions",
            "where",
            "the",
            "`start`",
            "value",
            "is",
            "between",
            "59999",
            "and",
            "2699519",
            "or",
            "between",
            "154931042",
            "and",
            "155260559.",
            "For",
            "each",
            "sample,",
            "identify",
            "genotype",
            "calls",
            "where",
            "the",
            "genotype",
            "array",
            "has",
            "at",
            "least",
            "one",
            "allele.",
            "Classify",
            "each",
            "genotype",
            "call",
            "into",
            "one",
            "of",
            "the",
            "following",
            "categories:",
            "homozygous",
            "reference",
            "alleles",
            "(both",
            "alleles",
            "are",
            "0),",
            "homozygous",
            "alternate",
            "alleles",
            "(both",
            "alleles",
            "are",
            "the",
            "same",
            "and",
            "greater",
            "than",
            "0),",
            "or",
            "heterozygous",
            "alleles",
            "(alleles",
            "are",
            "different,",
            "or",
            "any",
            "allele",
            "is",
            "null,",
            "and",
            "at",
            "least",
            "one",
            "allele",
            "is",
            "greater",
            "than",
            "0).",
            "Compute",
            "the",
            "total",
            "number",
            "of",
            "callable",
            "sites",
            "(the",
            "sum",
            "of",
            "all",
            "three",
            "genotype",
            "categories),",
            "the",
            "number",
            "of",
            "homozygous",
            "reference,",
            "homozygous",
            "alternate,",
            "and",
            "heterozygous",
            "genotype",
            "calls,",
            "the",
            "total",
            "number",
            "of",
            "single",
            "nucleotide",
            "variants",
            "(SNVs)",
            "as",
            "the",
            "sum",
            "of",
            "homozygous",
            "alternate",
            "and",
            "heterozygous",
            "genotype",
            "calls,",
            "the",
            "percentage",
            "of",
            "heterozygous",
            "genotype",
            "calls",
            "among",
            "all",
            "SNVs,",
            "and",
            "the",
            "percentage",
            "of",
            "homozygous",
            "alternate",
            "genotype",
            "calls",
            "among",
            "all",
            "SNVs.",
            "Output",
            "the",
            "sample",
            "ID",
            "along",
            "with",
            "these",
            "computed",
            "counts",
            "and",
            "percentages,",
            "and",
            "order",
            "the",
            "results",
            "by",
            "the",
            "percentage",
            "of",
            "heterozygous",
            "genotype",
            "calls",
            "among",
            "SNVs",
            "in",
            "descending",
            "order,",
            "then",
            "by",
            "sample",
            "ID."
        ],
        "query": "",
        "db_id": "_1000_genomes",
        "No. of candidate columns": 114,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq452",
        "question": "Identify variants on chromosome 12 and, for each variant, calculate the chi-squared score using allele counts in cases and controls, where cases are individuals from the 'EAS' super population and controls are individuals from all other super populations. Apply Yates's correction for continuity in the chi-squared calculation, ensuring that the expected counts for each allele in both groups are at least 5. Return the start position, end position, and chi-squared score of the top variants where the chi-squared score is no less than 29.71679.",
        "external_knowledge": null,
        "question_toks": [
            "Identify",
            "variants",
            "on",
            "chromosome",
            "12",
            "and,",
            "for",
            "each",
            "variant,",
            "calculate",
            "the",
            "chi-squared",
            "score",
            "using",
            "allele",
            "counts",
            "in",
            "cases",
            "and",
            "controls,",
            "where",
            "cases",
            "are",
            "individuals",
            "from",
            "the",
            "'EAS'",
            "super",
            "population",
            "and",
            "controls",
            "are",
            "individuals",
            "from",
            "all",
            "other",
            "super",
            "populations.",
            "Apply",
            "Yates's",
            "correction",
            "for",
            "continuity",
            "in",
            "the",
            "chi-squared",
            "calculation,",
            "ensuring",
            "that",
            "the",
            "expected",
            "counts",
            "for",
            "each",
            "allele",
            "in",
            "both",
            "groups",
            "are",
            "at",
            "least",
            "5.",
            "Return",
            "the",
            "start",
            "position,",
            "end",
            "position,",
            "and",
            "chi-squared",
            "score",
            "of",
            "the",
            "top",
            "variants",
            "where",
            "the",
            "chi-squared",
            "score",
            "is",
            "no",
            "less",
            "than",
            "29.71679."
        ],
        "query": "SELECT *\nFROM (\n  SELECT\n    `start`,\n    `end`,\n    ROUND(\n      POW(ABS(case_ref_count - (ref_count / allele_count) * case_count) - 0.5, 2) / ((ref_count / allele_count) * case_count) +\n      POW(ABS(control_ref_count - (ref_count / allele_count) * control_count) - 0.5, 2) / ((ref_count / allele_count) * control_count) +\n      POW(ABS(case_alt_count - (alt_count / allele_count) * case_count) - 0.5, 2) / ((alt_count / allele_count) * case_count) +\n      POW(ABS(control_alt_count - (alt_count / allele_count) * control_count) - 0.5, 2) / ((alt_count / allele_count) * control_count),\n      3\n    ) AS chi_squared_score\n  FROM (\n    SELECT\n      reference_name,\n      `start`,\n      `end`,\n      reference_bases,\n      alternate_bases,\n      vt,\n      SUM(ref_count + alt_count) AS allele_count,\n      SUM(ref_count) AS ref_count,\n      SUM(alt_count) AS alt_count,\n      SUM(IF(is_case, CAST(ref_count + alt_count AS INT64), 0)) AS case_count,\n      SUM(IF(NOT is_case, CAST(ref_count + alt_count AS INT64), 0)) AS control_count,\n      SUM(IF(is_case, ref_count, 0)) AS case_ref_count,\n      SUM(IF(is_case, alt_count, 0)) AS case_alt_count,\n      SUM(IF(NOT is_case, ref_count, 0)) AS control_ref_count,\n      SUM(IF(NOT is_case, alt_count, 0)) AS control_alt_count\n    FROM (\n      SELECT\n        v.reference_name,\n        v.`start`,\n        v.`end`,\n        v.reference_bases,\n        v.alternate_bases,\n        v.vt,\n        ('EAS' = p.super_population) AS is_case,\n        IF(call.genotype[SAFE_OFFSET(0)] = 0, 1, 0) AS ref_count,\n        IF(call.genotype[SAFE_OFFSET(0)] = 1, 1, 0) AS alt_count\n      FROM\n        `spider2-public-data.1000_genomes.variants` AS v,\n        UNNEST(v.call) AS call\n      JOIN\n        `spider2-public-data.1000_genomes.sample_info` AS p\n      ON\n        call.call_set_name = p.sample\n      WHERE\n        v.reference_name = '12'\n    )\n    GROUP BY\n      reference_name,\n      `start`,\n      `end`,\n      reference_bases,\n      alternate_bases,\n      vt\n  )\n  WHERE\n    (ref_count / allele_count) * case_count >= 5.0\n    AND (ref_count / allele_count) * control_count >= 5.0\n    AND (alt_count / allele_count) * case_count >= 5.0\n    AND (alt_count / allele_count) * control_count >= 5.0\n)\nWHERE\n  chi_squared_score >= 29.71679\nORDER BY\n  chi_squared_score DESC",
        "db_id": "_1000_genomes",
        "No. of candidate columns": 114,
        "No. of gold tables": 2
    },
    {
        "instance_id": "bq454",
        "question": "Determine, for each super population, the number of common autosomal variants (with an allele frequency of at least 0.05) grouped by the number of samples within that super population that possess the variant. Include the total population size for each super population, the variant types, and the sample counts in your analysis. Exclude sex chromosomes (X, Y, MT) from the analysis.",
        "external_knowledge": null,
        "question_toks": [
            "Determine,",
            "for",
            "each",
            "super",
            "population,",
            "the",
            "number",
            "of",
            "common",
            "autosomal",
            "variants",
            "(with",
            "an",
            "allele",
            "frequency",
            "of",
            "at",
            "least",
            "0.05)",
            "grouped",
            "by",
            "the",
            "number",
            "of",
            "samples",
            "within",
            "that",
            "super",
            "population",
            "that",
            "possess",
            "the",
            "variant.",
            "Include",
            "the",
            "total",
            "population",
            "size",
            "for",
            "each",
            "super",
            "population,",
            "the",
            "variant",
            "types,",
            "and",
            "the",
            "sample",
            "counts",
            "in",
            "your",
            "analysis.",
            "Exclude",
            "sex",
            "chromosomes",
            "(X,",
            "Y,",
            "MT)",
            "from",
            "the",
            "analysis."
        ],
        "query": "",
        "db_id": "_1000_genomes",
        "No. of candidate columns": 114,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq415",
        "question": "List the top 10 samples in the genome data that have the highest number of positions where there is exactly one alternate allele and the sample's genotype is homozygous for the reference allele (both alleles are 0). Order the results in descending order of these counts.",
        "external_knowledge": "Homozygous_Reference_Genotype.md",
        "question_toks": [
            "List",
            "the",
            "top",
            "10",
            "samples",
            "in",
            "the",
            "genome",
            "data",
            "that",
            "have",
            "the",
            "highest",
            "number",
            "of",
            "positions",
            "where",
            "there",
            "is",
            "exactly",
            "one",
            "alternate",
            "allele",
            "and",
            "the",
            "sample's",
            "genotype",
            "is",
            "homozygous",
            "for",
            "the",
            "reference",
            "allele",
            "(both",
            "alleles",
            "are",
            "0).",
            "Order",
            "the",
            "results",
            "in",
            "descending",
            "order",
            "of",
            "these",
            "counts."
        ],
        "query": "",
        "db_id": "HUMAN_GENOME_VARIANTS",
        "No. of candidate columns": 202,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq279",
        "question": "Can you provide the number of distinct active and closed bike share stations for each year 2013 and 2014?",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "provide",
            "the",
            "number",
            "of",
            "distinct",
            "active",
            "and",
            "closed",
            "bike",
            "share",
            "stations",
            "for",
            "each",
            "year",
            "2013",
            "and",
            "2014?"
        ],
        "query": "SELECT\n    t.year,\n    CASE \n        WHEN t.year = 2013 THEN (\n                                  SELECT \n                                    COUNT(DISTINCT station_id)\n                                  FROM \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_trips` t\n                                  INNER JOIN \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_stations` s\n                                  ON \n                                    t.start_station_id = s.station_id\n                                  WHERE \n                                    s.status = 'active' AND EXTRACT(YEAR FROM start_time) = 2013\n                                 ) \n        WHEN t.year = 2014 THEN (\n                                  SELECT \n                                    COUNT(DISTINCT station_id)\n                                  FROM \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_trips` t\n                                  INNER JOIN \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_stations` s\n                                  ON \n                                    t.start_station_id = s.station_id\n                                  WHERE \n                                    s.status = 'active' AND EXTRACT(YEAR FROM start_time) = 2014\n                                 )\n    END\n    AS number_status_active,\n    CASE \n        WHEN t.year = 2013 THEN (\n                                  SELECT \n                                   COUNT(DISTINCT station_id)\n                                  FROM \n                                  `bigquery-public-data.austin_bikeshare.bikeshare_trips` t\n                                  INNER JOIN \n                                  `bigquery-public-data.austin_bikeshare.bikeshare_stations` s\n                                  ON \n                                   t.start_station_id = s.station_id\n                                  WHERE \n                                   s.status = 'closed' AND EXTRACT(YEAR FROM start_time) = 2013\n                                 ) \n        WHEN t.year = 2014 THEN (\n                                  SELECT \n                                  COUNT(DISTINCT station_id)\n                                  FROM \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_trips` t\n                                  INNER JOIN \n                                    `bigquery-public-data.austin_bikeshare.bikeshare_stations` s\n                                  ON \n                                    t.start_station_id = s.station_id\n                                  WHERE \n                                    s.status = 'closed' AND EXTRACT(YEAR FROM start_time) = 2014\n                                 )\n    END\n    AS number_status_closed\nFROM\n    (\n      SELECT \n         EXTRACT(YEAR FROM start_time) AS year,\n         start_station_id\n      FROM\n         `bigquery-public-data.austin_bikeshare.bikeshare_trips`\n    ) \n    AS t\nINNER JOIN\n    `bigquery-public-data.austin_bikeshare.bikeshare_stations` s\nON\n    t.start_station_id = s.station_id\nWHERE\n    t.year BETWEEN 2013 AND 2014\nGROUP BY\n    t.year\nORDER BY\n    t.year",
        "db_id": "austin",
        "No. of candidate columns": 117,
        "No. of gold tables": 10
    },
    {
        "instance_id": "bq413",
        "question": "Retrieve the venue titles of publications that have a `date_inserted` from the year 2021 onwards and are associated with a grid whose address city is 'Qianjiang'. For each publication, prioritize the venue title by selecting the journal title first if it exists; if not, then the proceedings title; if that's also unavailable, then the book title; and finally, if none of those are available, the book series title.",
        "external_knowledge": null,
        "question_toks": [
            "Retrieve",
            "the",
            "venue",
            "titles",
            "of",
            "publications",
            "that",
            "have",
            "a",
            "`date_inserted`",
            "from",
            "the",
            "year",
            "2021",
            "onwards",
            "and",
            "are",
            "associated",
            "with",
            "a",
            "grid",
            "whose",
            "address",
            "city",
            "is",
            "'Qianjiang'.",
            "For",
            "each",
            "publication,",
            "prioritize",
            "the",
            "venue",
            "title",
            "by",
            "selecting",
            "the",
            "journal",
            "title",
            "first",
            "if",
            "it",
            "exists;",
            "if",
            "not,",
            "then",
            "the",
            "proceedings",
            "title;",
            "if",
            "that's",
            "also",
            "unavailable,",
            "then",
            "the",
            "book",
            "title;",
            "and",
            "finally,",
            "if",
            "none",
            "of",
            "those",
            "are",
            "available,",
            "the",
            "book",
            "series",
            "title."
        ],
        "query": "",
        "db_id": "dimensions_ai_covid19",
        "No. of candidate columns": 282,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq430",
        "question": "Find pairs of different molecules tested in the same assay and standard type, where both have 10–15 heavy atoms, fewer than 5 activities in that assay, fewer than 2 duplicate activities, non-null standard values, and pChEMBL values over 10. For each pair, report the maximum heavy atom count, the latest publication date (calculated based on the document's rank within the same journal and year, and map it to a synthetic month and day), the highest document ID, classify the change in standard values as 'increase', 'decrease', or 'no-change' based on their values and relations, and generate UUIDs from their activity IDs and canonical SMILES.",
        "external_knowledge": "chembl.md",
        "question_toks": [
            "Find",
            "pairs",
            "of",
            "different",
            "molecules",
            "tested",
            "in",
            "the",
            "same",
            "assay",
            "and",
            "standard",
            "type,",
            "where",
            "both",
            "have",
            "10–15",
            "heavy",
            "atoms,",
            "fewer",
            "than",
            "5",
            "activities",
            "in",
            "that",
            "assay,",
            "fewer",
            "than",
            "2",
            "duplicate",
            "activities,",
            "non-null",
            "standard",
            "values,",
            "and",
            "pChEMBL",
            "values",
            "over",
            "10.",
            "For",
            "each",
            "pair,",
            "report",
            "the",
            "maximum",
            "heavy",
            "atom",
            "count,",
            "the",
            "latest",
            "publication",
            "date",
            "(calculated",
            "based",
            "on",
            "the",
            "document's",
            "rank",
            "within",
            "the",
            "same",
            "journal",
            "and",
            "year,",
            "and",
            "map",
            "it",
            "to",
            "a",
            "synthetic",
            "month",
            "and",
            "day),",
            "the",
            "highest",
            "document",
            "ID,",
            "classify",
            "the",
            "change",
            "in",
            "standard",
            "values",
            "as",
            "'increase',",
            "'decrease',",
            "or",
            "'no-change'",
            "based",
            "on",
            "their",
            "values",
            "and",
            "relations,",
            "and",
            "generate",
            "UUIDs",
            "from",
            "their",
            "activity",
            "IDs",
            "and",
            "canonical",
            "SMILES."
        ],
        "query": "select \n  -- *, \n  greatest(heavy_atoms_1, heavy_atoms_2) as heavy_atoms_greatest,\n  greatest(publication_date_1, publication_date_2) as publication_date_greatest,\n  greatest(doc_id_1, doc_id_2) as doc_id_greatest,\n  case \n    when \n      standard_value_1 > standard_value_2 and \n      standard_relation_1 not in ('<', '<<') and \n      standard_relation_2 not in ('>', '>>')\n    then 'decrease'\n    when\n      standard_value_1 < standard_value_2 and \n      standard_relation_1 not in ('>', '>>') and \n      standard_relation_2 not in ('<', '<<') \n    then 'increase'\n    when\n      standard_value_1 = standard_value_2 and \n      standard_relation_1 in ('=', '~') and \n      standard_relation_2 in ('=', '~') \n    then 'no-change'\n    else null\n  end as standard_change,\n  to_hex(md5(to_json_string(struct(activity_id_1, activity_id_2)))) as mmp_delta_uuid,\n  to_hex(md5(to_json_string(struct(canonical_smiles_1, canonical_smiles_2, 5)))) as mmp_search_uuid\nfrom (\n  select \n    act.assay_id,\n    act.standard_type,\n    act.activity_id as activity_id_1,\n    cast(act.standard_value as numeric) as standard_value_1,\n    act.standard_relation as standard_relation_1,\n    cast(act.pchembl_value as numeric) as pchembl_value_1,\n    count(*) over (partition by act.assay_id) as count_activities_1,\n    count(*) over (partition by act.assay_id, act.molregno) as duplicate_activities_1,\n    act.molregno as molregno_1,\n    com.canonical_smiles as canonical_smiles_1,\n    cast(cmp.heavy_atoms as int64) as heavy_atoms_1,\n    cast(d.doc_id as int64) as doc_id_1,\n    date(\n      coalesce(cast(d.year as int64), 1970), \n      coalesce(cast(floor(percent_rank() over (\n        partition by d.journal, d.year order by SAFE_CAST(d.first_page as int64)) * 11) as int64) + 1, 1),\n      coalesce(mod(cast(floor(percent_rank() over (\n        partition by d.journal, d.year order by SAFE_CAST(d.first_page as int64)) * 308) as int64), 28) + 1, 1)) as publication_date_1\n  FROM `bigquery-public-data.ebi_chembl.activities_29` act\n  join `bigquery-public-data.ebi_chembl.compound_structures_29` com using (molregno)\n  join `bigquery-public-data.ebi_chembl.compound_properties_29` cmp using (molregno)\n  left join `bigquery-public-data.ebi_chembl.docs_29` d using (doc_id)\n  where standard_type in (select distinct standard_type from`bigquery-public-data.ebi_chembl.activities_29` where pchembl_value is not null)\n  ) a1\njoin (\n  select \n    act.assay_id,\n    act.standard_type,\n    act.activity_id as activity_id_2,\n    cast(act.standard_value as numeric) as standard_value_2,\n    act.standard_relation as standard_relation_2,\n    cast(act.pchembl_value as numeric) as pchembl_value_2,\n    count(*) over (partition by act.assay_id) as count_activities_2,\n    count(*) over (partition by act.assay_id, act.molregno) as duplicate_activities_2, \n    act.molregno as molregno_2,\n    com.canonical_smiles as canonical_smiles_2, \n    cast(cmp.heavy_atoms as int64) as heavy_atoms_2,\n    cast(d.doc_id as int64) as doc_id_2,\n    date(\n      coalesce(cast(d.year as int64), 1970), \n      coalesce(cast(floor(percent_rank() over (\n        partition by d.journal, d.year order by SAFE_CAST(d.first_page as int64)) * 11) as int64) + 1, 1),\n      coalesce(mod(cast(floor(percent_rank() over (\n        partition by d.journal, d.year order by SAFE_CAST(d.first_page as int64)) * 308) as int64), 28) + 1, 1)) as publication_date_2\n  FROM `bigquery-public-data.ebi_chembl.activities_29` act\n  join `bigquery-public-data.ebi_chembl.compound_structures_29` com using (molregno)\n  join `bigquery-public-data.ebi_chembl.compound_properties_29` cmp using (molregno)\n  left join `bigquery-public-data.ebi_chembl.docs_29` d using (doc_id)\n  where standard_type in (select distinct standard_type from`bigquery-public-data.ebi_chembl.activities_29` where pchembl_value is not null)\n  ) a2 using (assay_id, standard_type)\nwhere \n  a1.molregno_1 != a2.molregno_2 and\n  a1.count_activities_1 < 5 and \n  a2.count_activities_2 < 5 and \n  a1.heavy_atoms_1 between 10 and 15 and\n  a2.heavy_atoms_2 between 10 and 15 and\n  a1.standard_value_1 is not null and \n  a2.standard_value_2 is not null and\n  a1.duplicate_activities_1 < 2 and\n  a2.duplicate_activities_2 < 2 and\n  a1.pchembl_value_1 > 10 and\n  a2.pchembl_value_2 > 10",
        "db_id": "ebi_chembl",
        "No. of candidate columns": 5337,
        "No. of gold tables": 10
    },
    {
        "instance_id": "bq432",
        "question": "Please provide the food events data where both \"date_created\" and \"date_started\" are between January 1 and January 31, 2015, applying all data cleansing steps as specified in the cleansing documentation. This includes splitting the \"reactions\" and \"outcomes\" fields into arrays by commas, handling special numeric patterns in the \"products_brand_name\" field by appropriately splitting and replacing \", \" with \" -- \", replacing \", \" with \" -- \" in the \"products_industry_code\", \"products_role\", and \"products_industry_name\" fields, and calculating \"industry_code_length\" and \"brand_name_length\" as the lengths of the resulting arrays after splitting.",
        "external_knowledge": "Food_Event_Cleansing_Logic.md",
        "question_toks": [
            "Please",
            "provide",
            "the",
            "food",
            "events",
            "data",
            "where",
            "both",
            "\"date_created\"",
            "and",
            "\"date_started\"",
            "are",
            "between",
            "January",
            "1",
            "and",
            "January",
            "31,",
            "2015,",
            "applying",
            "all",
            "data",
            "cleansing",
            "steps",
            "as",
            "specified",
            "in",
            "the",
            "cleansing",
            "documentation.",
            "This",
            "includes",
            "splitting",
            "the",
            "\"reactions\"",
            "and",
            "\"outcomes\"",
            "fields",
            "into",
            "arrays",
            "by",
            "commas,",
            "handling",
            "special",
            "numeric",
            "patterns",
            "in",
            "the",
            "\"products_brand_name\"",
            "field",
            "by",
            "appropriately",
            "splitting",
            "and",
            "replacing",
            "\",",
            "\"",
            "with",
            "\"",
            "--",
            "\",",
            "replacing",
            "\",",
            "\"",
            "with",
            "\"",
            "--",
            "\"",
            "in",
            "the",
            "\"products_industry_code\",",
            "\"products_role\",",
            "and",
            "\"products_industry_name\"",
            "fields,",
            "and",
            "calculating",
            "\"industry_code_length\"",
            "and",
            "\"brand_name_length\"",
            "as",
            "the",
            "lengths",
            "of",
            "the",
            "resulting",
            "arrays",
            "after",
            "splitting."
        ],
        "query": "",
        "db_id": "fda",
        "No. of candidate columns": 1202,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq288",
        "question": "What is the total number of all banking institutions in the state that has the highest sum of assets from banks established between January 1, 1900, and December 31, 2000, with institution names starting with 'Bank'?",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "is",
            "the",
            "total",
            "number",
            "of",
            "all",
            "banking",
            "institutions",
            "in",
            "the",
            "state",
            "that",
            "has",
            "the",
            "highest",
            "sum",
            "of",
            "assets",
            "from",
            "banks",
            "established",
            "between",
            "January",
            "1,",
            "1900,",
            "and",
            "December",
            "31,",
            "2000,",
            "with",
            "institution",
            "names",
            "starting",
            "with",
            "'Bank'?"
        ],
        "query": "",
        "db_id": "fda",
        "No. of candidate columns": 1202,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq323",
        "question": "Within the 'prostatex' collection, for MRI sequences where the Modality is 'MR', assign the label 't2w_prostateX' to sequences whose SeriesDescription contains 't2_tse_tra' and 'adc_prostateX' to sequences whose SeriesDescription contains 'ADC'. For all sequences labeled as 't2w_prostateX' or 'adc_prostateX', calculate the average Repetition Time, the average Echo Time, and the average Slice Thickness, and then compute the sum of these averages to obtain the combined overall average.",
        "external_knowledge": null,
        "question_toks": [
            "Within",
            "the",
            "'prostatex'",
            "collection,",
            "for",
            "MRI",
            "sequences",
            "where",
            "the",
            "Modality",
            "is",
            "'MR',",
            "assign",
            "the",
            "label",
            "'t2w_prostateX'",
            "to",
            "sequences",
            "whose",
            "SeriesDescription",
            "contains",
            "'t2_tse_tra'",
            "and",
            "'adc_prostateX'",
            "to",
            "sequences",
            "whose",
            "SeriesDescription",
            "contains",
            "'ADC'.",
            "For",
            "all",
            "sequences",
            "labeled",
            "as",
            "'t2w_prostateX'",
            "or",
            "'adc_prostateX',",
            "calculate",
            "the",
            "average",
            "Repetition",
            "Time,",
            "the",
            "average",
            "Echo",
            "Time,",
            "and",
            "the",
            "average",
            "Slice",
            "Thickness,",
            "and",
            "then",
            "compute",
            "the",
            "sum",
            "of",
            "these",
            "averages",
            "to",
            "obtain",
            "the",
            "combined",
            "overall",
            "average."
        ],
        "query": "",
        "db_id": "IDC",
        "No. of candidate columns": 2100,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq455",
        "question": "Identify the top five CT scan series by size (in MiB), including their SeriesInstanceUID, series number, patient ID, and series size. These series must be from the CT modality and not part of the 'nlst' collection. Exclude any series where the ImageType is classified as 'LOCALIZER' or where the TransferSyntaxUID is either '1.2.840.10008.1.2.4.70' or '1.2.840.10008.1.2.4.51' (i.e., JPEG compressed). The selected series must have consistent slice intervals, exposure levels, image orientation (with only one unique ImageOrientationPatient value), pixel spacing, image positions (both z-axis and xy positions), and pixel dimensions (rows and columns). Ensure that the number of images matches the number of unique z-axis positions, indicating no duplicate slices. Additionally, the z-axis component of the cross product of the x and y direction cosines from ImageOrientationPatient must have an absolute value between 0.99 and 1.01, ensuring alignment with the expected imaging plane. Finally, order the results by series size in descending order and limit the output to the top five series satisfying these conditions.",
        "external_knowledge": null,
        "question_toks": [
            "Identify",
            "the",
            "top",
            "five",
            "CT",
            "scan",
            "series",
            "by",
            "size",
            "(in",
            "MiB),",
            "including",
            "their",
            "SeriesInstanceUID,",
            "series",
            "number,",
            "patient",
            "ID,",
            "and",
            "series",
            "size.",
            "These",
            "series",
            "must",
            "be",
            "from",
            "the",
            "CT",
            "modality",
            "and",
            "not",
            "part",
            "of",
            "the",
            "'nlst'",
            "collection.",
            "Exclude",
            "any",
            "series",
            "where",
            "the",
            "ImageType",
            "is",
            "classified",
            "as",
            "'LOCALIZER'",
            "or",
            "where",
            "the",
            "TransferSyntaxUID",
            "is",
            "either",
            "'1.2.840.10008.1.2.4.70'",
            "or",
            "'1.2.840.10008.1.2.4.51'",
            "(i.e.,",
            "JPEG",
            "compressed).",
            "The",
            "selected",
            "series",
            "must",
            "have",
            "consistent",
            "slice",
            "intervals,",
            "exposure",
            "levels,",
            "image",
            "orientation",
            "(with",
            "only",
            "one",
            "unique",
            "ImageOrientationPatient",
            "value),",
            "pixel",
            "spacing,",
            "image",
            "positions",
            "(both",
            "z-axis",
            "and",
            "xy",
            "positions),",
            "and",
            "pixel",
            "dimensions",
            "(rows",
            "and",
            "columns).",
            "Ensure",
            "that",
            "the",
            "number",
            "of",
            "images",
            "matches",
            "the",
            "number",
            "of",
            "unique",
            "z-axis",
            "positions,",
            "indicating",
            "no",
            "duplicate",
            "slices.",
            "Additionally,",
            "the",
            "z-axis",
            "component",
            "of",
            "the",
            "cross",
            "product",
            "of",
            "the",
            "x",
            "and",
            "y",
            "direction",
            "cosines",
            "from",
            "ImageOrientationPatient",
            "must",
            "have",
            "an",
            "absolute",
            "value",
            "between",
            "0.99",
            "and",
            "1.01,",
            "ensuring",
            "alignment",
            "with",
            "the",
            "expected",
            "imaging",
            "plane.",
            "Finally,",
            "order",
            "the",
            "results",
            "by",
            "series",
            "size",
            "in",
            "descending",
            "order",
            "and",
            "limit",
            "the",
            "output",
            "to",
            "the",
            "top",
            "five",
            "series",
            "satisfying",
            "these",
            "conditions."
        ],
        "query": "WITH\n  -- Create a common table expression (CTE) named localizerAndJpegCompressedSeries\n  localizerAndJpegCompressedSeries AS (\n    SELECT \n      \"SeriesInstanceUID\"\n    FROM \n      IDC.IDC_V17.\"DICOM_ALL\" AS bid\n    WHERE \n      \"ImageType\" = 'LOCALIZER' OR\n      \"TransferSyntaxUID\" IN ('1.2.840.10008.1.2.4.70', '1.2.840.10008.1.2.4.51')\n  ),\n  \n  -- Create a common table expression (CTE) for x_vector calculation (first three elements)\n  imageOrientation AS (\n    SELECT\n      \"SeriesInstanceUID\",\n      ARRAY_AGG(CAST(part.value AS FLOAT)) AS \"x_vector\"\n    FROM \n      IDC.IDC_V17.\"DICOM_ALL\" AS bid,\n      LATERAL FLATTEN(input => bid.\"ImageOrientationPatient\") AS part\n    WHERE\n      part.index BETWEEN 0 AND 2\n    GROUP BY \"SeriesInstanceUID\"\n  ),\n  \n  -- Create a common table expression (CTE) for y_vector calculation (next three elements)\n  imageOrientationY AS (\n    SELECT\n      \"SeriesInstanceUID\",\n      ARRAY_AGG(CAST(part.value AS FLOAT)) AS \"y_vector\"\n    FROM \n      IDC.IDC_V17.\"DICOM_ALL\" AS bid,\n      LATERAL FLATTEN(input => bid.\"ImageOrientationPatient\") AS part\n    WHERE\n      part.index BETWEEN 3 AND 5\n    GROUP BY \"SeriesInstanceUID\"\n  ),\n  \n  -- Create a common table expression (CTE) named nonLocalizerRawData\n  nonLocalizerRawData AS (\n    SELECT\n      bid.\"SeriesInstanceUID\",  -- Added table alias bid\n      bid.\"StudyInstanceUID\",\n      bid.\"PatientID\",\n      bid.\"SOPInstanceUID\",\n      bid.\"SliceThickness\",\n      bid.\"ImageType\",\n      bid.\"TransferSyntaxUID\",\n      bid.\"SeriesNumber\",\n      bid.\"aws_bucket\",\n      bid.\"crdc_series_uuid\",\n      CAST(bid.\"Exposure\" AS FLOAT) AS \"Exposure\",  -- Use CAST directly\n      CAST(ipp.value AS FLOAT) AS \"zImagePosition\", -- Use CAST directly\n      CONCAT(ipp2.value, '/', ipp3.value) AS \"xyImagePosition\",\n      LEAD(CAST(ipp.value AS FLOAT)) OVER (PARTITION BY bid.\"SeriesInstanceUID\" ORDER BY CAST(ipp.value AS FLOAT)) - CAST(ipp.value AS FLOAT) AS \"slice_interval\",\n      ARRAY_TO_STRING(bid.\"ImageOrientationPatient\", '/') AS \"iop\",\n      bid.\"PixelSpacing\",\n      bid.\"Rows\" AS \"pixelRows\",\n      bid.\"Columns\" AS \"pixelColumns\",\n      bid.\"instance_size\" AS \"instanceSize\"\n    FROM\n      IDC.IDC_V17.\"DICOM_ALL\" AS bid\n    LEFT JOIN LATERAL FLATTEN(input => bid.\"ImagePositionPatient\") AS ipp\n    LEFT JOIN LATERAL FLATTEN(input => bid.\"ImagePositionPatient\") AS ipp2\n    LEFT JOIN LATERAL FLATTEN(input => bid.\"ImagePositionPatient\") AS ipp3\n    WHERE\n      bid.\"collection_id\" != 'nlst'\n      AND bid.\"Modality\" = 'CT'\n      AND ipp.index = 2\n      AND ipp2.index = 0\n      AND ipp3.index = 1\n      AND bid.\"SeriesInstanceUID\" NOT IN (SELECT \"SeriesInstanceUID\" FROM localizerAndJpegCompressedSeries)\n  ),\n  \n  -- Cross product calculation\n  crossProduct AS (\n    SELECT\n      nld.\"SOPInstanceUID\",  -- Added table alias nld\n      nld.\"SeriesInstanceUID\",  -- Added table alias nld\n      OBJECT_CONSTRUCT(\n        'x', (\"x_vector\"[1] * \"y_vector\"[2] - \"x_vector\"[2] * \"y_vector\"[1]),\n        'y', (\"x_vector\"[2] * \"y_vector\"[0] - \"x_vector\"[0] * \"y_vector\"[2]),\n        'z', (\"x_vector\"[0] * \"y_vector\"[1] - \"x_vector\"[1] * \"y_vector\"[0])\n      ) AS \"xyCrossProduct\"\n    FROM \n      nonLocalizerRawData AS nld  -- Added alias for nonLocalizerRawData\n    JOIN imageOrientation AS io ON nld.\"SeriesInstanceUID\" = io.\"SeriesInstanceUID\"\n    JOIN imageOrientationY AS ioy ON nld.\"SeriesInstanceUID\" = ioy.\"SeriesInstanceUID\"\n  ),\n  \n  -- Cross product elements extraction and row numbering\n  crossProductElements AS (\n    SELECT\n      cp.\"SOPInstanceUID\",  \n      cp.\"SeriesInstanceUID\",  \n      elem.value,\n      ROW_NUMBER() OVER (PARTITION BY cp.\"SOPInstanceUID\", cp.\"SeriesInstanceUID\" ORDER BY elem.value) AS rn\n    FROM \n      crossProduct AS cp  \n    -- Use LATERAL FLATTEN to explode the cross product object into individual 'x', 'y', and 'z'\n    JOIN LATERAL FLATTEN(input => ARRAY_CONSTRUCT(\n          cp.\"xyCrossProduct\"['x'],\n          cp.\"xyCrossProduct\"['y'],\n          cp.\"xyCrossProduct\"['z']\n    )) AS elem -- Simplified 'elem.value' reference here\n  ),\n  \n  -- Dot product calculation\n  dotProduct AS (\n    SELECT\n      cpe.\"SOPInstanceUID\",  \n      cpe.\"SeriesInstanceUID\",  \n      SUM(\n        CASE \n          WHEN cpe.rn = 1 THEN cpe.value * 0  -- x * 0\n          WHEN cpe.rn = 2 THEN cpe.value * 0  -- y * 0\n          WHEN cpe.rn = 3 THEN cpe.value * 1  -- z * 1\n        END\n      ) AS \"xyDotProduct\"\n    FROM \n      crossProductElements AS cpe\n    GROUP BY \n      cpe.\"SOPInstanceUID\",  \n      cpe.\"SeriesInstanceUID\"\n  ),\n  \n  -- Geometry checks for series consistency\n  geometryChecks AS (\n    SELECT\n      gc.\"SeriesInstanceUID\",  -- Added table alias gc\n      gc.\"SeriesNumber\",\n      gc.\"aws_bucket\",\n      gc.\"crdc_series_uuid\",\n      gc.\"StudyInstanceUID\",\n      gc.\"PatientID\",\n      ARRAY_AGG(DISTINCT gc.\"slice_interval\") AS \"sliceIntervalDifferences\",\n      ARRAY_AGG(DISTINCT gc.\"Exposure\") AS \"distinctExposures\",\n      COUNT(DISTINCT gc.\"iop\") AS \"iopCount\",\n      COUNT(DISTINCT gc.\"PixelSpacing\") AS \"pixelSpacingCount\",\n      COUNT(DISTINCT gc.\"zImagePosition\") AS \"positionCount\",\n      COUNT(DISTINCT gc.\"xyImagePosition\") AS \"xyPositionCount\",\n      COUNT(DISTINCT gc.\"SOPInstanceUID\") AS \"sopInstanceCount\",\n      COUNT(DISTINCT gc.\"SliceThickness\") AS \"sliceThicknessCount\",\n      COUNT(DISTINCT gc.\"Exposure\") AS \"exposureCount\",\n      COUNT(DISTINCT gc.\"pixelRows\") AS \"pixelRowCount\",\n      COUNT(DISTINCT gc.\"pixelColumns\") AS \"pixelColumnCount\",\n      dp.\"xyDotProduct\",  -- Added xyDotProduct from dotProduct\n      SUM(gc.\"instanceSize\") / 1024 / 1024 AS \"seriesSizeInMiB\"\n    FROM \n      nonLocalizerRawData AS gc  -- Added table alias gc\n    JOIN dotProduct AS dp ON gc.\"SeriesInstanceUID\" = dp.\"SeriesInstanceUID\" \n    AND gc.\"SOPInstanceUID\" = dp.\"SOPInstanceUID\"\n    GROUP BY\n      gc.\"SeriesInstanceUID\", \n      gc.\"SeriesNumber\",\n      gc.\"aws_bucket\",\n      gc.\"crdc_series_uuid\",\n      gc.\"StudyInstanceUID\",\n      gc.\"PatientID\",\n      dp.\"xyDotProduct\"  -- Include xyDotProduct in GROUP BY\n    HAVING\n      COUNT(DISTINCT gc.\"iop\") = 1 \n      AND COUNT(DISTINCT gc.\"PixelSpacing\") = 1  \n      AND COUNT(DISTINCT gc.\"SOPInstanceUID\") = COUNT(DISTINCT gc.\"zImagePosition\") \n      AND COUNT(DISTINCT gc.\"xyImagePosition\") = 1\n      AND COUNT(DISTINCT gc.\"pixelRows\") = 1 \n      AND COUNT(DISTINCT gc.\"pixelColumns\") = 1 \n      AND ABS(dp.\"xyDotProduct\") BETWEEN 0.99 AND 1.01\n  )\n\nSELECT\n  geometryChecks.\"SeriesInstanceUID\",  -- Added table alias\n  geometryChecks.\"SeriesNumber\",  -- Added table alias\n  geometryChecks.\"PatientID\",  -- Added table alias\n  geometryChecks.\"seriesSizeInMiB\"\nFROM\n  geometryChecks\nORDER BY\n  geometryChecks.\"seriesSizeInMiB\" DESC\nLIMIT 5;",
        "db_id": "IDC",
        "No. of candidate columns": 2100,
        "No. of gold tables": 4
    },
    {
        "instance_id": "bq330",
        "question": "Which Colorado zip code has the highest concentration of bank locations per block group, based on the overlap between zip codes and block groups?",
        "external_knowledge": "overlap_ratio.md",
        "question_toks": [
            "Which",
            "Colorado",
            "zip",
            "code",
            "has",
            "the",
            "highest",
            "concentration",
            "of",
            "bank",
            "locations",
            "per",
            "block",
            "group,",
            "based",
            "on",
            "the",
            "overlap",
            "between",
            "zip",
            "codes",
            "and",
            "block",
            "groups?"
        ],
        "query": "",
        "db_id": "fda",
        "No. of candidate columns": 1202,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq398",
        "question": "What are the top three debt indicators for Russia based on the highest debt values?",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "are",
            "the",
            "top",
            "three",
            "debt",
            "indicators",
            "for",
            "Russia",
            "based",
            "on",
            "the",
            "highest",
            "debt",
            "values?"
        ],
        "query": "",
        "db_id": "world_bank",
        "No. of candidate columns": 314,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq399",
        "question": "Which high-income country had the highest average crude birth rate respectively in each region, and what are their corresponding average birth rate, during the 1980s?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "high-income",
            "country",
            "had",
            "the",
            "highest",
            "average",
            "crude",
            "birth",
            "rate",
            "respectively",
            "in",
            "each",
            "region,",
            "and",
            "what",
            "are",
            "their",
            "corresponding",
            "average",
            "birth",
            "rate,",
            "during",
            "the",
            "1980s?"
        ],
        "query": "WITH country_data AS ( \n  SELECT \n    country_code, \n    short_name AS country,\n    region, \n    income_group \n  FROM \n    bigquery-public-data.world_bank_wdi.country_summary\n)\n, birth_rate_data AS (\n  SELECT \n    data.country_code, \n    country_data.country,\n    country_data.region,\n    AVG(value) AS avg_birth_rate\n  FROM \n    bigquery-public-data.world_bank_wdi.indicators_data data \n  LEFT JOIN \n    country_data \n  ON \n    data.country_code = country_data.country_code\n  WHERE \n    indicator_code = \"SP.DYN.CBRT.IN\" -- Birth Rate\n    AND EXTRACT(YEAR FROM PARSE_DATE('%Y', CAST(year AS STRING))) BETWEEN 1980 AND 1989 -- 1980s\n    AND country_data.income_group = \"High income\" -- High-income group\n  GROUP BY \n    data.country_code, \n    country_data.country,\n    country_data.region\n)\n, ranked_birth_rates AS (\n  SELECT\n    region,\n    country,\n    avg_birth_rate,\n    RANK() OVER(PARTITION BY region ORDER BY avg_birth_rate DESC) AS rank\n  FROM\n    birth_rate_data\n)\nSELECT \n  region, \n  country, \n  avg_birth_rate\nFROM \n  ranked_birth_rates\nWHERE \n  rank = 1\nORDER BY \n  region;",
        "db_id": "world_bank",
        "No. of candidate columns": 314,
        "No. of gold tables": 2
    },
    {
        "instance_id": "bq457",
        "question": "Get details of repositories that use specific feature toggle libraries. For each repository, include the full name with owner, hosting platform type, size in bytes, primary programming language, fork source name (if any), last update timestamp, the artifact and library names of the feature toggle used, and the library's programming languages. Include repositories that depend on the specified feature toggle libraries, defined by their artifact names, library names, platforms, and languages.",
        "external_knowledge": "feature_toggle_libraries.md",
        "question_toks": [
            "Get",
            "details",
            "of",
            "repositories",
            "that",
            "use",
            "specific",
            "feature",
            "toggle",
            "libraries.",
            "For",
            "each",
            "repository,",
            "include",
            "the",
            "full",
            "name",
            "with",
            "owner,",
            "hosting",
            "platform",
            "type,",
            "size",
            "in",
            "bytes,",
            "primary",
            "programming",
            "language,",
            "fork",
            "source",
            "name",
            "(if",
            "any),",
            "last",
            "update",
            "timestamp,",
            "the",
            "artifact",
            "and",
            "library",
            "names",
            "of",
            "the",
            "feature",
            "toggle",
            "used,",
            "and",
            "the",
            "library's",
            "programming",
            "languages.",
            "Include",
            "repositories",
            "that",
            "depend",
            "on",
            "the",
            "specified",
            "feature",
            "toggle",
            "libraries,",
            "defined",
            "by",
            "their",
            "artifact",
            "names,",
            "library",
            "names,",
            "platforms,",
            "and",
            "languages."
        ],
        "query": "",
        "db_id": "libraries_io",
        "No. of candidate columns": 163,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq227",
        "question": "Could you provide the annual percentage shares, rounded to two decimal places, of the top 5 minor crime categories from 2008 in London's total crimes, with each year displayed in one row?",
        "external_knowledge": null,
        "question_toks": [
            "Could",
            "you",
            "provide",
            "the",
            "annual",
            "percentage",
            "shares,",
            "rounded",
            "to",
            "two",
            "decimal",
            "places,",
            "of",
            "the",
            "top",
            "5",
            "minor",
            "crime",
            "categories",
            "from",
            "2008",
            "in",
            "London's",
            "total",
            "crimes,",
            "with",
            "each",
            "year",
            "displayed",
            "in",
            "one",
            "row?"
        ],
        "query": "",
        "db_id": "london",
        "No. of candidate columns": 39,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq229",
        "question": "Can you provide a count of how many image URLs are categorized as ‘cat’ (with label '/m/01yrx' and full confidence) and how many contain no such cat labels(categorized as ‘other’) at all? ",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "provide",
            "a",
            "count",
            "of",
            "how",
            "many",
            "image",
            "URLs",
            "are",
            "categorized",
            "as",
            "‘cat’",
            "(with",
            "label",
            "'/m/01yrx'",
            "and",
            "full",
            "confidence)",
            "and",
            "how",
            "many",
            "contain",
            "no",
            "such",
            "cat",
            "labels(categorized",
            "as",
            "‘other’)",
            "at",
            "all?",
            ""
        ],
        "query": "",
        "db_id": "open_images",
        "No. of candidate columns": 30,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq331",
        "question": "Find the top three users who have authored the first message in forum topics, ranked in descending order by their message scores, where a message score is defined as the number of distinct users who voted on that message. For each of these users, provide their username and the absolute difference between their message score and the average message score across all first messages in forum topics.",
        "external_knowledge": null,
        "question_toks": [
            "Find",
            "the",
            "top",
            "three",
            "users",
            "who",
            "have",
            "authored",
            "the",
            "first",
            "message",
            "in",
            "forum",
            "topics,",
            "ranked",
            "in",
            "descending",
            "order",
            "by",
            "their",
            "message",
            "scores,",
            "where",
            "a",
            "message",
            "score",
            "is",
            "defined",
            "as",
            "the",
            "number",
            "of",
            "distinct",
            "users",
            "who",
            "voted",
            "on",
            "that",
            "message.",
            "For",
            "each",
            "of",
            "these",
            "users,",
            "provide",
            "their",
            "username",
            "and",
            "the",
            "absolute",
            "difference",
            "between",
            "their",
            "message",
            "score",
            "and",
            "the",
            "average",
            "message",
            "score",
            "across",
            "all",
            "first",
            "messages",
            "in",
            "forum",
            "topics."
        ],
        "query": "",
        "db_id": "META_KAGGLE",
        "No. of candidate columns": 237,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq393",
        "question": "Can you tell me the ID and corresponding month number of the user with the highest month number who became inactive after their last recorded activity month, considering data only up until September 10, 2024?",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "tell",
            "me",
            "the",
            "ID",
            "and",
            "corresponding",
            "month",
            "number",
            "of",
            "the",
            "user",
            "with",
            "the",
            "highest",
            "month",
            "number",
            "who",
            "became",
            "inactive",
            "after",
            "their",
            "last",
            "recorded",
            "activity",
            "month,",
            "considering",
            "data",
            "only",
            "up",
            "until",
            "September",
            "10,",
            "2024?"
        ],
        "query": "",
        "db_id": "hacker_news",
        "No. of candidate columns": 14,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq403",
        "question": "Which three years in 2012-2017 have the smallest absolute difference between median revenue and median functional expenses for organizations filing IRS 990 forms? Please output three years and respective differences.",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "three",
            "years",
            "in",
            "2012-2017",
            "have",
            "the",
            "smallest",
            "absolute",
            "difference",
            "between",
            "median",
            "revenue",
            "and",
            "median",
            "functional",
            "expenses",
            "for",
            "organizations",
            "filing",
            "IRS",
            "990",
            "forms?",
            "Please",
            "output",
            "three",
            "years",
            "and",
            "respective",
            "differences."
        ],
        "query": "",
        "db_id": "irs_990",
        "No. of candidate columns": 2549,
        "No. of gold tables": 0
    },
    {
        "instance_id": "ga001",
        "question": "I want to know the preferences of customers who purchased the Google Navy Speckled Tee in December 2020. What other product was purchased with the highest total quantity alongside this item?",
        "external_knowledge": null,
        "question_toks": [
            "I",
            "want",
            "to",
            "know",
            "the",
            "preferences",
            "of",
            "customers",
            "who",
            "purchased",
            "the",
            "Google",
            "Navy",
            "Speckled",
            "Tee",
            "in",
            "December",
            "2020.",
            "What",
            "other",
            "product",
            "was",
            "purchased",
            "with",
            "the",
            "highest",
            "total",
            "quantity",
            "alongside",
            "this",
            "item?"
        ],
        "query": "WITH\n  Params AS (\n    SELECT 'Google Navy Speckled Tee' AS selected_product\n  ),\n  PurchaseEvents AS (\n    SELECT\n      user_pseudo_id,\n      items\n    FROM\n      `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n    WHERE\n      _TABLE_SUFFIX BETWEEN '20201201' AND '20201231'\n      AND event_name = 'purchase'\n  ),\n  ProductABuyers AS (\n    SELECT DISTINCT\n      user_pseudo_id\n    FROM\n      Params,\n      PurchaseEvents,\n      UNNEST(items) AS items\n    WHERE\n      items.item_name = selected_product\n  )\nSELECT\n  items.item_name AS item_name,\n  SUM(items.quantity) AS item_quantity\nFROM\n  Params,\n  PurchaseEvents,\n  UNNEST(items) AS items\nWHERE\n  user_pseudo_id IN (SELECT user_pseudo_id FROM ProductABuyers)\n  AND items.item_name != selected_product\nGROUP BY 1\nORDER BY item_quantity DESC\nLIMIT 1;",
        "db_id": "ga4",
        "No. of candidate columns": 2116,
        "No. of gold tables": 20
    },
    {
        "instance_id": "ga002",
        "question": "Tell me the most purchased other products and their quantities by customers who bought the Google Red Speckled Tee each month for the three months starting from November 2020.",
        "external_knowledge": null,
        "question_toks": [
            "Tell",
            "me",
            "the",
            "most",
            "purchased",
            "other",
            "products",
            "and",
            "their",
            "quantities",
            "by",
            "customers",
            "who",
            "bought",
            "the",
            "Google",
            "Red",
            "Speckled",
            "Tee",
            "each",
            "month",
            "for",
            "the",
            "three",
            "months",
            "starting",
            "from",
            "November",
            "2020."
        ],
        "query": "WITH\nParams AS (\n  SELECT 'Google Red Speckled Tee' AS selected_product\n),\nDateRanges AS (\n  SELECT '20201101' AS start_date, '20201130' AS end_date, '202011' AS period UNION ALL\n  SELECT '20201201', '20201231', '202012' UNION ALL\n  SELECT '20210101', '20210131', '202101'\n),\nPurchaseEvents AS (\n  SELECT\n    period,\n    user_pseudo_id,\n    items\n  FROM\n    DateRanges\n  JOIN\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n    ON _TABLE_SUFFIX BETWEEN start_date AND end_date\n  WHERE\n    event_name = 'purchase'\n),\nProductABuyers AS (\n  SELECT DISTINCT\n    period,\n    user_pseudo_id\n  FROM\n    Params,\n    PurchaseEvents,\n    UNNEST(items) AS items\n  WHERE\n    items.item_name = selected_product\n),\nTopProducts AS (\n  SELECT\n    pe.period,\n    items.item_name AS item_name,\n    SUM(items.quantity) AS item_quantity\n  FROM\n    Params,\n    PurchaseEvents pe,\n    UNNEST(items) AS items\n  WHERE\n    user_pseudo_id IN (SELECT user_pseudo_id FROM ProductABuyers pb WHERE pb.period = pe.period)\n    AND items.item_name != selected_product\n  GROUP BY\n    pe.period, items.item_name\n),\nTopProductPerPeriod AS (\n  SELECT\n    period,\n    item_name,\n    item_quantity\n  FROM (\n    SELECT\n      period,\n      item_name,\n      item_quantity,\n      RANK() OVER (PARTITION BY period ORDER BY item_quantity DESC) AS rank\n    FROM\n      TopProducts\n  )\n  WHERE\n    rank = 1\n)\nSELECT\n  period,\n  item_name,\n  item_quantity\nFROM\n  TopProductPerPeriod\nORDER BY\n  period;",
        "db_id": "ga4",
        "No. of candidate columns": 2116,
        "No. of gold tables": 20
    },
    {
        "instance_id": "ga003",
        "question": "I'm trying to evaluate which board types were most effective on September 15, 2018. Can you find out the average scores for each board type from the quick play mode completions on that day?",
        "external_knowledge": null,
        "question_toks": [
            "I'm",
            "trying",
            "to",
            "evaluate",
            "which",
            "board",
            "types",
            "were",
            "most",
            "effective",
            "on",
            "September",
            "15,",
            "2018.",
            "Can",
            "you",
            "find",
            "out",
            "the",
            "average",
            "scores",
            "for",
            "each",
            "board",
            "type",
            "from",
            "the",
            "quick",
            "play",
            "mode",
            "completions",
            "on",
            "that",
            "day?"
        ],
        "query": "WITH EventData AS (\n    SELECT \n        user_pseudo_id, \n        event_timestamp, \n        param\n    FROM \n        `firebase-public-project.analytics_153293282.events_20180915`,\n        UNNEST(event_params) AS param\n    WHERE \n        event_name = \"level_complete_quickplay\"\n        AND (param.key = \"value\" OR param.key = \"board\")\n),\nProcessedData AS (\n    SELECT \n        user_pseudo_id, \n        event_timestamp, \n        MAX(IF(param.key = \"value\", param.value.int_value, NULL)) AS score,\n        MAX(IF(param.key = \"board\", param.value.string_value, NULL)) AS board_type\n    FROM \n        EventData\n    GROUP BY \n        user_pseudo_id, \n        event_timestamp\n)\nSELECT \n    ANY_VALUE(board_type) AS board, \n    AVG(score) AS average_score\nFROM \n    ProcessedData\nGROUP BY \n    board_type",
        "db_id": "firebase",
        "No. of candidate columns": 2148,
        "No. of gold tables": 1
    },
    {
        "instance_id": "ga004",
        "question": "Can you figure out the average difference in pageviews between users who bought something and those who didn’t in December 2020? Just label anyone who was involved in purchase events as a purchaser.",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "figure",
            "out",
            "the",
            "average",
            "difference",
            "in",
            "pageviews",
            "between",
            "users",
            "who",
            "bought",
            "something",
            "and",
            "those",
            "who",
            "didn’t",
            "in",
            "December",
            "2020?",
            "Just",
            "label",
            "anyone",
            "who",
            "was",
            "involved",
            "in",
            "purchase",
            "events",
            "as",
            "a",
            "purchaser."
        ],
        "query": "WITH\n  UserInfo AS (\n    SELECT\n      user_pseudo_id,\n      COUNTIF(event_name = 'page_view') AS page_view_count,\n      COUNTIF(event_name IN ('in_app_purchase', 'purchase')) AS purchase_event_count\n    FROM `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n    WHERE _TABLE_SUFFIX BETWEEN '20201201' AND '20201231'\n    GROUP BY 1\n  ),\n  Averages AS (\n    SELECT\n      (purchase_event_count > 0) AS purchaser,\n      COUNT(*) AS user_count,\n      SUM(page_view_count) AS total_page_views,\n      SUM(page_view_count) / COUNT(*) AS avg_page_views\n    FROM UserInfo\n    GROUP BY 1\n  )\n\nSELECT\n  MAX(CASE WHEN purchaser THEN avg_page_views ELSE 0 END) -\n  MAX(CASE WHEN NOT purchaser THEN avg_page_views ELSE 0 END) AS avg_page_views_difference\nFROM Averages;",
        "db_id": "ga4",
        "No. of candidate columns": 2116,
        "No. of gold tables": 20
    },
    {
        "instance_id": "ga017",
        "question": "How many distinct users viewed the most frequently visited page during January 2021?",
        "external_knowledge": null,
        "question_toks": [
            "How",
            "many",
            "distinct",
            "users",
            "viewed",
            "the",
            "most",
            "frequently",
            "visited",
            "page",
            "during",
            "January",
            "2021?"
        ],
        "query": "WITH unnested_events AS (\n  SELECT\n    MAX(CASE WHEN event_params.key = 'page_location' THEN event_params.value.string_value END) AS page_location,\n    user_pseudo_id,\n    event_timestamp\n  FROM\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`,\n    UNNEST(event_params) AS event_params\n  WHERE\n    _TABLE_SUFFIX BETWEEN '20210101' AND '20210131'\n    AND event_name = 'page_view'\n  GROUP BY user_pseudo_id,event_timestamp\n),\ntemp AS (\n    SELECT\n    page_location,\n    COUNT(*) AS event_count,\n    COUNT(DISTINCT user_pseudo_id) AS users\n    FROM\n    unnested_events\n    GROUP BY page_location\n    ORDER BY event_count DESC\n)\n\nSELECT users \nFROM\ntemp\nLIMIT 1",
        "db_id": "ga4",
        "No. of candidate columns": 2116,
        "No. of gold tables": 20
    },
    {
        "instance_id": "ga007",
        "question": "Please find out what percentage of the page views on January 2, 2021, were for PDP type pages.",
        "external_knowledge": "ga4_page_category.md",
        "question_toks": [
            "Please",
            "find",
            "out",
            "what",
            "percentage",
            "of",
            "the",
            "page",
            "views",
            "on",
            "January",
            "2,",
            "2021,",
            "were",
            "for",
            "PDP",
            "type",
            "pages."
        ],
        "query": "",
        "db_id": "ga4",
        "No. of candidate columns": 2116,
        "No. of gold tables": 0
    },
    {
        "instance_id": "ga013",
        "question": "I want to know all the pages visited by user 1402138.5184246691 on January 2, 2021. Please show the names of these pages and adjust the names to PDP or PLP where necessary.",
        "external_knowledge": "ga4_page_category.md",
        "question_toks": [
            "I",
            "want",
            "to",
            "know",
            "all",
            "the",
            "pages",
            "visited",
            "by",
            "user",
            "1402138.5184246691",
            "on",
            "January",
            "2,",
            "2021.",
            "Please",
            "show",
            "the",
            "names",
            "of",
            "these",
            "pages",
            "and",
            "adjust",
            "the",
            "names",
            "to",
            "PDP",
            "or",
            "PLP",
            "where",
            "necessary."
        ],
        "query": "",
        "db_id": "ga4",
        "No. of candidate columns": 2116,
        "No. of gold tables": 0
    },
    {
        "instance_id": "ga032",
        "question": "Can you pull up the sequence of pages our customer 1362228 visited on January 28th 2021, linking them with '>>' between each page? I want to see their navigation flow through our site. Please refer to the docs to convert the corresponding page title to \"PDP\" or \"PLP\" if necessary and merge adjacent identical page titles into one.",
        "external_knowledge": "ga4_page_category.md",
        "question_toks": [
            "Can",
            "you",
            "pull",
            "up",
            "the",
            "sequence",
            "of",
            "pages",
            "our",
            "customer",
            "1362228",
            "visited",
            "on",
            "January",
            "28th",
            "2021,",
            "linking",
            "them",
            "with",
            "'>>'",
            "between",
            "each",
            "page?",
            "I",
            "want",
            "to",
            "see",
            "their",
            "navigation",
            "flow",
            "through",
            "our",
            "site.",
            "Please",
            "refer",
            "to",
            "the",
            "docs",
            "to",
            "convert",
            "the",
            "corresponding",
            "page",
            "title",
            "to",
            "\"PDP\"",
            "or",
            "\"PLP\"",
            "if",
            "necessary",
            "and",
            "merge",
            "adjacent",
            "identical",
            "page",
            "titles",
            "into",
            "one."
        ],
        "query": "",
        "db_id": "ga4",
        "No. of candidate columns": 2116,
        "No. of gold tables": 0
    },
    {
        "instance_id": "ga010",
        "question": "Can you give me an overview of our website traffic for December 2020? I'm particularly interested in the channel with the fourth highest number of sessions.",
        "external_knowledge": "ga4_dimensions_and_metrics.md",
        "question_toks": [
            "Can",
            "you",
            "give",
            "me",
            "an",
            "overview",
            "of",
            "our",
            "website",
            "traffic",
            "for",
            "December",
            "2020?",
            "I'm",
            "particularly",
            "interested",
            "in",
            "the",
            "channel",
            "with",
            "the",
            "fourth",
            "highest",
            "number",
            "of",
            "sessions."
        ],
        "query": "WITH prep AS (\n  SELECT\n    user_pseudo_id,\n    (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'ga_session_id') AS session_id,\n    ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'source') IGNORE NULLS \n              ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS source,\n    ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'medium') IGNORE NULLS \n              ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS medium,\n    ARRAY_AGG((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'campaign') IGNORE NULLS \n              ORDER BY event_timestamp)[SAFE_OFFSET(0)] AS campaign\n  FROM\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n  WHERE\n    _TABLE_SUFFIX BETWEEN '20201201' AND '20201231'\n  GROUP BY\n    user_pseudo_id,\n    session_id\n)\nSELECT\n  -- session default channel grouping (dimension | the channel group associated with a session) \n  CASE \n    WHEN source = '(direct)' AND (medium IN ('(not set)','(none)')) THEN 'Direct'\n    WHEN REGEXP_CONTAINS(campaign, 'cross-network') THEN 'Cross-network'\n    WHEN (REGEXP_CONTAINS(source,'alibaba|amazon|google shopping|shopify|etsy|ebay|stripe|walmart')\n        OR REGEXP_CONTAINS(campaign, '^(.*(([^a-df-z]|^)shop|shopping).*)$'))\n        AND REGEXP_CONTAINS(medium, '^(.*cp.*|ppc|paid.*)$') THEN 'Paid Shopping'\n    WHEN REGEXP_CONTAINS(source,'baidu|bing|duckduckgo|ecosia|google|yahoo|yandex')\n        AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Search'\n    WHEN REGEXP_CONTAINS(source,'badoo|facebook|fb|instagram|linkedin|pinterest|tiktok|twitter|whatsapp')\n        AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Social'\n    WHEN REGEXP_CONTAINS(source,'dailymotion|disneyplus|netflix|youtube|vimeo|twitch|vimeo|youtube')\n        AND REGEXP_CONTAINS(medium,'^(.*cp.*|ppc|paid.*)$') THEN 'Paid Video'\n    WHEN medium IN ('display', 'banner', 'expandable', 'interstitial', 'cpm') THEN 'Display'\n    WHEN REGEXP_CONTAINS(source,'alibaba|amazon|google shopping|shopify|etsy|ebay|stripe|walmart')\n        OR REGEXP_CONTAINS(campaign, '^(.*(([^a-df-z]|^)shop|shopping).*)$') THEN 'Organic Shopping'\n    WHEN REGEXP_CONTAINS(source,'badoo|facebook|fb|instagram|linkedin|pinterest|tiktok|twitter|whatsapp')\n        OR medium IN ('social','social-network','social-media','sm','social network','social media') THEN 'Organic Social'\n    WHEN REGEXP_CONTAINS(source,'dailymotion|disneyplus|netflix|youtube|vimeo|twitch|vimeo|youtube')\n        OR REGEXP_CONTAINS(medium,'^(.*video.*)$') THEN 'Organic Video'\n    WHEN REGEXP_CONTAINS(source,'baidu|bing|duckduckgo|ecosia|google|yahoo|yandex')\n        OR medium = 'organic' THEN 'Organic Search'\n    WHEN REGEXP_CONTAINS(source,'email|e-mail|e_mail|e mail')\n        OR REGEXP_CONTAINS(medium,'email|e-mail|e_mail|e mail') THEN 'Email'\n    WHEN medium = 'affiliate' THEN 'Affiliates'\n    WHEN medium = 'referral' THEN 'Referral'\n    WHEN medium = 'audio' THEN 'Audio'\n    WHEN medium = 'sms' THEN 'SMS'\n    WHEN medium LIKE '%push'\n        OR REGEXP_CONTAINS(medium,'mobile|notification') THEN 'Mobile Push Notifications'\n    ELSE 'Unassigned' \n  END AS channel_grouping_session\nFROM\n  prep\nGROUP BY\n  channel_grouping_session\nORDER BY\n  COUNT(DISTINCT CONCAT(user_pseudo_id, session_id)) DESC\nLIMIT 1 OFFSET 3",
        "db_id": "ga4",
        "No. of candidate columns": 2116,
        "No. of gold tables": 20
    },
    {
        "instance_id": "ga014",
        "question": "Can you provide the total number of sessions for each traffic channel in December 2020, using the information from the 'event_params'",
        "external_knowledge": "ga4_dimensions_and_metrics.md",
        "question_toks": [
            "Can",
            "you",
            "provide",
            "the",
            "total",
            "number",
            "of",
            "sessions",
            "for",
            "each",
            "traffic",
            "channel",
            "in",
            "December",
            "2020,",
            "using",
            "the",
            "information",
            "from",
            "the",
            "'event_params'"
        ],
        "query": "",
        "db_id": "ga4",
        "No. of candidate columns": 2116,
        "No. of gold tables": 0
    },
    {
        "instance_id": "ga011",
        "question": "What is the page with the second highest total page views, after cleaning up its URL (removing extra slashes) and extracting the correct page path, on the website 'shop.googlemerchandisestore.com' during December 2020?",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "is",
            "the",
            "page",
            "with",
            "the",
            "second",
            "highest",
            "total",
            "page",
            "views,",
            "after",
            "cleaning",
            "up",
            "its",
            "URL",
            "(removing",
            "extra",
            "slashes)",
            "and",
            "extracting",
            "the",
            "correct",
            "page",
            "path,",
            "on",
            "the",
            "website",
            "'shop.googlemerchandisestore.com'",
            "during",
            "December",
            "2020?"
        ],
        "query": "",
        "db_id": "ga4",
        "No. of candidate columns": 2116,
        "No. of gold tables": 0
    },
    {
        "instance_id": "ga019",
        "question": "Could you determine what percentage of users either did not uninstall our app within seven days or never uninstalled it after installing during August and September 2018?",
        "external_knowledge": null,
        "question_toks": [
            "Could",
            "you",
            "determine",
            "what",
            "percentage",
            "of",
            "users",
            "either",
            "did",
            "not",
            "uninstall",
            "our",
            "app",
            "within",
            "seven",
            "days",
            "or",
            "never",
            "uninstalled",
            "it",
            "after",
            "installing",
            "during",
            "August",
            "and",
            "September",
            "2018?"
        ],
        "query": "WITH\n--List of users who installed\nsept_cohort AS (\n  SELECT DISTINCT user_pseudo_id,\n  FORMAT_DATE('%Y-%m-%d', PARSE_DATE('%Y%m%d', event_date)) AS date_first_open,\n  FROM `firebase-public-project.analytics_153293282.events_*`\n  WHERE event_name = 'first_open'\n  AND _TABLE_SUFFIX BETWEEN '20180801' and '20180930'\n),\n--Get the list of users who uninstalled\nuninstallers AS (\n  SELECT DISTINCT user_pseudo_id,\n  FORMAT_DATE('%Y-%m-%d', PARSE_DATE('%Y%m%d', event_date)) AS date_app_remove,\n  FROM `firebase-public-project.analytics_153293282.events_*`\n  WHERE event_name = 'app_remove'\n  AND _TABLE_SUFFIX BETWEEN '20180801' and '20180930'\n),\n--Join the 2 tables and compute for # of days to uninstall\njoined AS (\n  SELECT a.*,\n  b.date_app_remove,\n  DATE_DIFF(DATE(b.date_app_remove), DATE(a.date_first_open), DAY) AS days_to_uninstall\n  FROM sept_cohort a\n  LEFT JOIN uninstallers b\n  ON a.user_pseudo_id = b.user_pseudo_id\n)\n--Compute for the percentage\nSELECT\nCOUNT(DISTINCT\nCASE WHEN days_to_uninstall > 7 OR days_to_uninstall IS NULL THEN user_pseudo_id END) /\nCOUNT(DISTINCT user_pseudo_id)\nAS percent_users_7_days\nFROM joined",
        "db_id": "firebase",
        "No. of candidate columns": 2148,
        "No. of gold tables": 20
    },
    {
        "instance_id": "ga030",
        "question": "Can you group users by the week of their first session start, starting from July 2, 2018? For each group, calculate the retention rate in the fourth week (i.e., the percentage of users from the original group who returned in the fourth week after their first session). Please identify the cohort with the highest retention rate in the fourth week, and name the group by the Monday date of the cohort's first session week. Return the result in the format \"YYYY-MM-DD\".",
        "external_knowledge": "retention_rate.md",
        "question_toks": [
            "Can",
            "you",
            "group",
            "users",
            "by",
            "the",
            "week",
            "of",
            "their",
            "first",
            "session",
            "start,",
            "starting",
            "from",
            "July",
            "2,",
            "2018?",
            "For",
            "each",
            "group,",
            "calculate",
            "the",
            "retention",
            "rate",
            "in",
            "the",
            "fourth",
            "week",
            "(i.e.,",
            "the",
            "percentage",
            "of",
            "users",
            "from",
            "the",
            "original",
            "group",
            "who",
            "returned",
            "in",
            "the",
            "fourth",
            "week",
            "after",
            "their",
            "first",
            "session).",
            "Please",
            "identify",
            "the",
            "cohort",
            "with",
            "the",
            "highest",
            "retention",
            "rate",
            "in",
            "the",
            "fourth",
            "week,",
            "and",
            "name",
            "the",
            "group",
            "by",
            "the",
            "Monday",
            "date",
            "of",
            "the",
            "cohort's",
            "first",
            "session",
            "week.",
            "Return",
            "the",
            "result",
            "in",
            "the",
            "format",
            "\"YYYY-MM-DD\"."
        ],
        "query": "",
        "db_id": "firebase",
        "No. of candidate columns": 2148,
        "No. of gold tables": 0
    },
    {
        "instance_id": "ga005",
        "question": "Conduct a weekly cohort analysis for user retention starting from July 9, 2018, grouping users by the week of their first session start event. Calculate the retention rates for each cohort in the subsequent two weeks. Specifically, measure the percentage of users from the original cohort who returned in week 2 (two weeks after their first session). Only include users whose first session start event occurred after July 9, 2018. The data is available up to October 2, 2018 (meaning the last cohort group is for the week of September 17, 2018). For this analysis, retention is calculated based on the first session start date, and cohorts are grouped weekly starting from the first session.",
        "external_knowledge": "retention_rate.md",
        "question_toks": [
            "Conduct",
            "a",
            "weekly",
            "cohort",
            "analysis",
            "for",
            "user",
            "retention",
            "starting",
            "from",
            "July",
            "9,",
            "2018,",
            "grouping",
            "users",
            "by",
            "the",
            "week",
            "of",
            "their",
            "first",
            "session",
            "start",
            "event.",
            "Calculate",
            "the",
            "retention",
            "rates",
            "for",
            "each",
            "cohort",
            "in",
            "the",
            "subsequent",
            "two",
            "weeks.",
            "Specifically,",
            "measure",
            "the",
            "percentage",
            "of",
            "users",
            "from",
            "the",
            "original",
            "cohort",
            "who",
            "returned",
            "in",
            "week",
            "2",
            "(two",
            "weeks",
            "after",
            "their",
            "first",
            "session).",
            "Only",
            "include",
            "users",
            "whose",
            "first",
            "session",
            "start",
            "event",
            "occurred",
            "after",
            "July",
            "9,",
            "2018.",
            "The",
            "data",
            "is",
            "available",
            "up",
            "to",
            "October",
            "2,",
            "2018",
            "(meaning",
            "the",
            "last",
            "cohort",
            "group",
            "is",
            "for",
            "the",
            "week",
            "of",
            "September",
            "17,",
            "2018).",
            "For",
            "this",
            "analysis,",
            "retention",
            "is",
            "calculated",
            "based",
            "on",
            "the",
            "first",
            "session",
            "start",
            "date,",
            "and",
            "cohorts",
            "are",
            "grouped",
            "weekly",
            "starting",
            "from",
            "the",
            "first",
            "session."
        ],
        "query": "",
        "db_id": "firebase",
        "No. of candidate columns": 2148,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local003",
        "question": "According to the RFM definition document, calculate the average sales per order for each customer within distinct RFM segments, considering only 'delivered' orders. Use the customer unique identifier. Clearly define how to calculate Recency based on the latest purchase timestamp and specify the criteria for classifying RFM segments. The average sales should be computed as the total spend divided by the total number of orders. Please analyze and report the differences in average sales across the RFM segments",
        "external_knowledge": "RFM.md",
        "question_toks": [
            "According",
            "to",
            "the",
            "RFM",
            "definition",
            "document,",
            "calculate",
            "the",
            "average",
            "sales",
            "per",
            "order",
            "for",
            "each",
            "customer",
            "within",
            "distinct",
            "RFM",
            "segments,",
            "considering",
            "only",
            "'delivered'",
            "orders.",
            "Use",
            "the",
            "customer",
            "unique",
            "identifier.",
            "Clearly",
            "define",
            "how",
            "to",
            "calculate",
            "Recency",
            "based",
            "on",
            "the",
            "latest",
            "purchase",
            "timestamp",
            "and",
            "specify",
            "the",
            "criteria",
            "for",
            "classifying",
            "RFM",
            "segments.",
            "The",
            "average",
            "sales",
            "should",
            "be",
            "computed",
            "as",
            "the",
            "total",
            "spend",
            "divided",
            "by",
            "the",
            "total",
            "number",
            "of",
            "orders.",
            "Please",
            "analyze",
            "and",
            "report",
            "the",
            "differences",
            "in",
            "average",
            "sales",
            "across",
            "the",
            "RFM",
            "segments"
        ],
        "query": "WITH RecencyScore AS (\n    SELECT customer_unique_id,\n           MAX(order_purchase_timestamp) AS last_purchase,\n           NTILE(5) OVER (ORDER BY MAX(order_purchase_timestamp) DESC) AS recency\n    FROM orders\n        JOIN customers USING (customer_id)\n    WHERE order_status = 'delivered'\n    GROUP BY customer_unique_id\n),\nFrequencyScore AS (\n    SELECT customer_unique_id,\n           COUNT(order_id) AS total_orders,\n           NTILE(5) OVER (ORDER BY COUNT(order_id) DESC) AS frequency\n    FROM orders\n        JOIN customers USING (customer_id)\n    WHERE order_status = 'delivered'\n    GROUP BY customer_unique_id\n),\nMonetaryScore AS (\n    SELECT customer_unique_id,\n           SUM(price) AS total_spent,\n           NTILE(5) OVER (ORDER BY SUM(price) DESC) AS monetary\n    FROM orders\n        JOIN order_items USING (order_id)\n        JOIN customers USING (customer_id)\n    WHERE order_status = 'delivered'\n    GROUP BY customer_unique_id\n),\n\n-- 2. Assign each customer to a group\nRFM AS (\n    SELECT last_purchase, total_orders, total_spent,\n        CASE\n            WHEN recency = 1 AND frequency + monetary IN (1, 2, 3, 4) THEN \"Champions\"\n            WHEN recency IN (4, 5) AND frequency + monetary IN (1, 2) THEN \"Can't Lose Them\"\n            WHEN recency IN (4, 5) AND frequency + monetary IN (3, 4, 5, 6) THEN \"Hibernating\"\n            WHEN recency IN (4, 5) AND frequency + monetary IN (7, 8, 9, 10) THEN \"Lost\"\n            WHEN recency IN (2, 3) AND frequency + monetary IN (1, 2, 3, 4) THEN \"Loyal Customers\"\n            WHEN recency = 3 AND frequency + monetary IN (5, 6) THEN \"Needs Attention\"\n            WHEN recency = 1 AND frequency + monetary IN (7, 8) THEN \"Recent Users\"\n            WHEN recency = 1 AND frequency + monetary IN (5, 6) OR\n                recency = 2 AND frequency + monetary IN (5, 6, 7, 8) THEN \"Potentital Loyalists\"\n            WHEN recency = 1 AND frequency + monetary IN (9, 10) THEN \"Price Sensitive\"\n            WHEN recency = 2 AND frequency + monetary IN (9, 10) THEN \"Promising\"\n            WHEN recency = 3 AND frequency + monetary IN (7, 8, 9, 10) THEN \"About to Sleep\"\n        END AS RFM_Bucket\n    FROM RecencyScore\n        JOIN FrequencyScore USING (customer_unique_id)\n        JOIN MonetaryScore USING (customer_unique_id)\n)\n\nSELECT RFM_Bucket, \n       AVG(total_spent / total_orders) AS avg_sales_per_customer\nFROM RFM\nGROUP BY RFM_Bucket",
        "db_id": "E_commerce",
        "No. of candidate columns": 70,
        "No. of gold tables": 7
    },
    {
        "instance_id": "local009",
        "question": "What is the distance of the longest route where Abakan is either the departure or destination city (in kilometers)?",
        "external_knowledge": "haversine_formula.md",
        "question_toks": [
            "What",
            "is",
            "the",
            "distance",
            "of",
            "the",
            "longest",
            "route",
            "where",
            "Abakan",
            "is",
            "either",
            "the",
            "departure",
            "or",
            "destination",
            "city",
            "(in",
            "kilometers)?"
        ],
        "query": "",
        "db_id": "Airlines",
        "No. of candidate columns": 35,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local010",
        "question": "Distribute all the unique city pairs into the distance ranges 0, 1000, 2000, 3000, 4000, 5000, and 6000+, based on their average distance of all routes between them. Then how many pairs are there in the distance range with the fewest unique city paires?",
        "external_knowledge": "haversine_formula.md",
        "question_toks": [
            "Distribute",
            "all",
            "the",
            "unique",
            "city",
            "pairs",
            "into",
            "the",
            "distance",
            "ranges",
            "0,",
            "1000,",
            "2000,",
            "3000,",
            "4000,",
            "5000,",
            "and",
            "6000+,",
            "based",
            "on",
            "their",
            "average",
            "distance",
            "of",
            "all",
            "routes",
            "between",
            "them.",
            "Then",
            "how",
            "many",
            "pairs",
            "are",
            "there",
            "in",
            "the",
            "distance",
            "range",
            "with",
            "the",
            "fewest",
            "unique",
            "city",
            "paires?"
        ],
        "query": "",
        "db_id": "Airlines",
        "No. of candidate columns": 35,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local015",
        "question": "Please calculate, separately for motorcycle collisions involving riders who were wearing helmets and those who were not wearing helmets, the percentage of motorcyclist fatalities per collision. For each group, compute this by dividing the total number of motorcyclist fatalities by the total number of collisions involving that group.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "calculate,",
            "separately",
            "for",
            "motorcycle",
            "collisions",
            "involving",
            "riders",
            "who",
            "were",
            "wearing",
            "helmets",
            "and",
            "those",
            "who",
            "were",
            "not",
            "wearing",
            "helmets,",
            "the",
            "percentage",
            "of",
            "motorcyclist",
            "fatalities",
            "per",
            "collision.",
            "For",
            "each",
            "group,",
            "compute",
            "this",
            "by",
            "dividing",
            "the",
            "total",
            "number",
            "of",
            "motorcyclist",
            "fatalities",
            "by",
            "the",
            "total",
            "number",
            "of",
            "collisions",
            "involving",
            "that",
            "group."
        ],
        "query": "",
        "db_id": "California_Traffic_Collision",
        "No. of candidate columns": 120,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local017",
        "question": "In which year were the two most common causes of traffic accidents different from those in other years?",
        "external_knowledge": null,
        "question_toks": [
            "In",
            "which",
            "year",
            "were",
            "the",
            "two",
            "most",
            "common",
            "causes",
            "of",
            "traffic",
            "accidents",
            "different",
            "from",
            "those",
            "in",
            "other",
            "years?"
        ],
        "query": "WITH AnnualTotals AS (\n    SELECT \n        STRFTIME('%Y', collision_date) AS Year, \n        COUNT(case_id) AS AnnualTotal\n    FROM \n        collisions\n    GROUP BY \n        Year\n),\nCategoryTotals AS (\n    SELECT \n        STRFTIME('%Y', collision_date) AS Year,\n        pcf_violation_category AS Category,\n        COUNT(case_id) AS Subtotal\n    FROM \n        collisions\n    GROUP BY \n        Year, Category\n),\nCategoryPercentages AS (\n    SELECT \n        ct.Year,\n        ct.Category,\n        ROUND((ct.Subtotal * 100.0) / at.AnnualTotal, 1) AS PercentageOfAnnualRoadIncidents\n    FROM \n        CategoryTotals ct\n    JOIN \n        AnnualTotals at ON ct.Year = at.Year\n),\nRankedCategories AS (\n    SELECT\n        Year,\n        Category,\n        PercentageOfAnnualRoadIncidents,\n        ROW_NUMBER() OVER (PARTITION BY Year ORDER BY PercentageOfAnnualRoadIncidents DESC) AS Rank\n    FROM\n        CategoryPercentages\n),\nTopTwoCategories AS (\n    SELECT\n        Year,\n        GROUP_CONCAT(Category, ', ') AS TopCategories\n    FROM\n        RankedCategories\n    WHERE\n        Rank <= 2\n    GROUP BY\n        Year\n),\nUniqueYear AS (\n    SELECT\n        Year\n    FROM\n        TopTwoCategories\n    GROUP BY\n        TopCategories\n    HAVING COUNT(Year) = 1\n),\nresults AS (\nSELECT \n    rc.Year, \n    rc.Category, \n    rc.PercentageOfAnnualRoadIncidents\nFROM \n    UniqueYear u\nJOIN \n    RankedCategories rc ON u.Year = rc.Year\nWHERE \n    rc.Rank <= 2\n)\n\nSELECT distinct Year FROM results",
        "db_id": "California_Traffic_Collision",
        "No. of candidate columns": 120,
        "No. of gold tables": 2
    },
    {
        "instance_id": "local018",
        "question": "For the primary collision factor violation category that was the most common cause of traffic accidents in 2021, how many percentage points did its share of annual road incidents in 2021 decrease compared to its share in 2011?",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "the",
            "primary",
            "collision",
            "factor",
            "violation",
            "category",
            "that",
            "was",
            "the",
            "most",
            "common",
            "cause",
            "of",
            "traffic",
            "accidents",
            "in",
            "2021,",
            "how",
            "many",
            "percentage",
            "points",
            "did",
            "its",
            "share",
            "of",
            "annual",
            "road",
            "incidents",
            "in",
            "2021",
            "decrease",
            "compared",
            "to",
            "its",
            "share",
            "in",
            "2011?"
        ],
        "query": "",
        "db_id": "California_Traffic_Collision",
        "No. of candidate columns": 120,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local019",
        "question": "For the NXT title that had the shortest match (excluding titles with \"title change\"), what were the names of the two wrestlers involved?",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "the",
            "NXT",
            "title",
            "that",
            "had",
            "the",
            "shortest",
            "match",
            "(excluding",
            "titles",
            "with",
            "\"title",
            "change\"),",
            "what",
            "were",
            "the",
            "names",
            "of",
            "the",
            "two",
            "wrestlers",
            "involved?"
        ],
        "query": "WITH MatchDetails AS (\n    SELECT\n        b.name AS titles,\n        m.duration AS match_duration,\n        w1.name || ' vs ' || w2.name AS matches,\n        m.win_type AS win_type,\n        l.name AS location,\n        e.name AS event,\n        ROW_NUMBER() OVER (PARTITION BY b.name ORDER BY m.duration ASC) AS rank\n    FROM \n        Belts b\n    INNER JOIN Matches m ON m.title_id = b.id\n    INNER JOIN Wrestlers w1 ON w1.id = m.winner_id\n    INNER JOIN Wrestlers w2 ON w2.id = m.loser_id\n    INNER JOIN Cards c ON c.id = m.card_id\n    INNER JOIN Locations l ON l.id = c.location_id\n    INNER JOIN Events e ON e.id = c.event_id\n    INNER JOIN Promotions p ON p.id = c.promotion_id\n    WHERE\n        p.name = 'NXT'\n        AND m.duration <> ''\n        AND b.name <> ''\n        AND b.name NOT IN (\n            SELECT name \n            FROM Belts \n            WHERE name LIKE '%title change%'\n        )\n),\nRank1 AS (\nSELECT \n    titles,\n    match_duration,\n    matches,\n    win_type,\n    location,\n    event\nFROM \n    MatchDetails\nWHERE \n    rank = 1\n)\nSELECT\n    SUBSTR(matches, 1, INSTR(matches, ' vs ') - 1) AS wrestler1,\n    SUBSTR(matches, INSTR(matches, ' vs ') + 4) AS wrestler2\nFROM\nRank1\nORDER BY match_duration \nLIMIT 1",
        "db_id": "WWE",
        "No. of candidate columns": 35,
        "No. of gold tables": 9
    },
    {
        "instance_id": "local026",
        "question": "Please help me identify the top 3 bowlers who, in the overs where the maximum runs were conceded in each match, gave up the highest number of runs in a single over across all matches. For each of these bowlers, provide the match in which they conceded these maximum runs. Only consider overs that had the most runs conceded within their respective matches, and among these, determine which bowlers conceded the most runs in a single over overall.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "help",
            "me",
            "identify",
            "the",
            "top",
            "3",
            "bowlers",
            "who,",
            "in",
            "the",
            "overs",
            "where",
            "the",
            "maximum",
            "runs",
            "were",
            "conceded",
            "in",
            "each",
            "match,",
            "gave",
            "up",
            "the",
            "highest",
            "number",
            "of",
            "runs",
            "in",
            "a",
            "single",
            "over",
            "across",
            "all",
            "matches.",
            "For",
            "each",
            "of",
            "these",
            "bowlers,",
            "provide",
            "the",
            "match",
            "in",
            "which",
            "they",
            "conceded",
            "these",
            "maximum",
            "runs.",
            "Only",
            "consider",
            "overs",
            "that",
            "had",
            "the",
            "most",
            "runs",
            "conceded",
            "within",
            "their",
            "respective",
            "matches,",
            "and",
            "among",
            "these,",
            "determine",
            "which",
            "bowlers",
            "conceded",
            "the",
            "most",
            "runs",
            "in",
            "a",
            "single",
            "over",
            "overall."
        ],
        "query": "",
        "db_id": "IPL",
        "No. of candidate columns": 52,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local032",
        "question": "Could you help me find the sellers respectively with the highest number of distinct customers, highest profit, highest number of distinct orders, and most 5-star ratings, in delivered orders, along with their corresponding values? ",
        "external_knowledge": null,
        "question_toks": [
            "Could",
            "you",
            "help",
            "me",
            "find",
            "the",
            "sellers",
            "respectively",
            "with",
            "the",
            "highest",
            "number",
            "of",
            "distinct",
            "customers,",
            "highest",
            "profit,",
            "highest",
            "number",
            "of",
            "distinct",
            "orders,",
            "and",
            "most",
            "5-star",
            "ratings,",
            "in",
            "delivered",
            "orders,",
            "along",
            "with",
            "their",
            "corresponding",
            "values?",
            ""
        ],
        "query": "",
        "db_id": "Brazilian_E_Commerce",
        "No. of candidate columns": 62,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local049",
        "question": "Can you help me calculate the average number of new unicorn companies per year in the top industry from 2019 to 2021?",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "help",
            "me",
            "calculate",
            "the",
            "average",
            "number",
            "of",
            "new",
            "unicorn",
            "companies",
            "per",
            "year",
            "in",
            "the",
            "top",
            "industry",
            "from",
            "2019",
            "to",
            "2021?"
        ],
        "query": "",
        "db_id": "modern_data",
        "No. of candidate columns": 77,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local067",
        "question": "Can you provide the highest and lowest profits for Italian customers segmented into ten evenly divided tiers based on their December 2021 sales profits?",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "provide",
            "the",
            "highest",
            "and",
            "lowest",
            "profits",
            "for",
            "Italian",
            "customers",
            "segmented",
            "into",
            "ten",
            "evenly",
            "divided",
            "tiers",
            "based",
            "on",
            "their",
            "December",
            "2021",
            "sales",
            "profits?"
        ],
        "query": "",
        "db_id": "complex_oracle",
        "No. of candidate columns": 140,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local070",
        "question": "Please examine our records for Chinese cities in July 2021 and identify both the shortest and longest streaks of consecutive date entries. List the dates along with their corresponding city names, capitalizing the first letter of each city name, for these streaks.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "examine",
            "our",
            "records",
            "for",
            "Chinese",
            "cities",
            "in",
            "July",
            "2021",
            "and",
            "identify",
            "both",
            "the",
            "shortest",
            "and",
            "longest",
            "streaks",
            "of",
            "consecutive",
            "date",
            "entries.",
            "List",
            "the",
            "dates",
            "along",
            "with",
            "their",
            "corresponding",
            "city",
            "names,",
            "capitalizing",
            "the",
            "first",
            "letter",
            "of",
            "each",
            "city",
            "name,",
            "for",
            "these",
            "streaks."
        ],
        "query": "",
        "db_id": "city_legislation",
        "No. of candidate columns": 133,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local066",
        "question": "Based on our customer pizza order information, summarize the total quantity of each ingredient used in the pizzas we delivered. Output the name and quantity for each ingredient.",
        "external_knowledge": null,
        "question_toks": [
            "Based",
            "on",
            "our",
            "customer",
            "pizza",
            "order",
            "information,",
            "summarize",
            "the",
            "total",
            "quantity",
            "of",
            "each",
            "ingredient",
            "used",
            "in",
            "the",
            "pizzas",
            "we",
            "delivered.",
            "Output",
            "the",
            "name",
            "and",
            "quantity",
            "for",
            "each",
            "ingredient."
        ],
        "query": "WITH cte_cleaned_customer_orders AS (\n    SELECT\n        *,\n        ROW_NUMBER() OVER () AS original_row_number\n    FROM \n        pizza_clean_customer_orders\n),\nsplit_regular_toppings AS (\n    SELECT\n        pizza_id,\n        TRIM(SUBSTR(toppings, 1, INSTR(toppings || ',', ',') - 1)) AS topping_id,\n        SUBSTR(toppings || ',', INSTR(toppings || ',', ',') + 1) AS remaining_toppings\n    FROM \n        pizza_recipes\n    UNION ALL\n    SELECT\n        pizza_id,\n        TRIM(SUBSTR(remaining_toppings, 1, INSTR(remaining_toppings, ',') - 1)) AS topping_id,\n        SUBSTR(remaining_toppings, INSTR(remaining_toppings, ',') + 1) AS remaining_toppings\n    FROM \n        split_regular_toppings\n    WHERE\n        remaining_toppings <> ''\n),\ncte_base_toppings AS (\n    SELECT\n        t1.order_id,\n        t1.customer_id,\n        t1.pizza_id,\n        t1.order_time,\n        t1.original_row_number,\n        t2.topping_id\n    FROM \n        cte_cleaned_customer_orders AS t1\n    LEFT JOIN \n        split_regular_toppings AS t2\n    ON \n        t1.pizza_id = t2.pizza_id\n),\nsplit_exclusions AS (\n    SELECT\n        order_id,\n        customer_id,\n        pizza_id,\n        order_time,\n        original_row_number,\n        TRIM(SUBSTR(exclusions, 1, INSTR(exclusions || ',', ',') - 1)) AS topping_id,\n        SUBSTR(exclusions || ',', INSTR(exclusions || ',', ',') + 1) AS remaining_exclusions\n    FROM \n        cte_cleaned_customer_orders\n    WHERE \n        exclusions IS NOT NULL\n    UNION ALL\n    SELECT\n        order_id,\n        customer_id,\n        pizza_id,\n        order_time,\n        original_row_number,\n        TRIM(SUBSTR(remaining_exclusions, 1, INSTR(remaining_exclusions, ',') - 1)) AS topping_id,\n        SUBSTR(remaining_exclusions, INSTR(remaining_exclusions, ',') + 1) AS remaining_exclusions\n    FROM \n        split_exclusions\n    WHERE\n        remaining_exclusions <> ''\n),\nsplit_extras AS (\n    SELECT\n        order_id,\n        customer_id,\n        pizza_id,\n        order_time,\n        original_row_number,\n        TRIM(SUBSTR(extras, 1, INSTR(extras || ',', ',') - 1)) AS topping_id,\n        SUBSTR(extras || ',', INSTR(extras || ',', ',') + 1) AS remaining_extras\n    FROM \n        cte_cleaned_customer_orders\n    WHERE \n        extras IS NOT NULL\n    UNION ALL\n    SELECT\n        order_id,\n        customer_id,\n        pizza_id,\n        order_time,\n        original_row_number,\n        TRIM(SUBSTR(remaining_extras, 1, INSTR(remaining_extras, ',') - 1)) AS topping_id,\n        SUBSTR(remaining_extras, INSTR(remaining_extras, ',') + 1) AS remaining_extras\n    FROM \n        split_extras\n    WHERE\n        remaining_extras <> ''\n),\ncte_combined_orders AS (\n    SELECT \n        order_id,\n        customer_id,\n        pizza_id,\n        order_time,\n        original_row_number,\n        topping_id\n    FROM \n        cte_base_toppings\n    WHERE topping_id NOT IN (SELECT topping_id FROM split_exclusions WHERE split_exclusions.order_id = cte_base_toppings.order_id)\n    UNION ALL\n    SELECT \n        order_id,\n        customer_id,\n        pizza_id,\n        order_time,\n        original_row_number,\n        topping_id\n    FROM \n        split_extras\n)\nSELECT\n    t2.topping_name,\n    COUNT(*) AS topping_count\nFROM \n    cte_combined_orders AS t1\nJOIN \n    pizza_toppings AS t2\nON \n    t1.topping_id = t2.topping_id\nGROUP BY \n    t2.topping_name\nORDER BY \n    topping_count DESC;",
        "db_id": "modern_data",
        "No. of candidate columns": 77,
        "No. of gold tables": 3
    },
    {
        "instance_id": "local298",
        "question": "For each month, calculate the total balance from all users for the previous month (measured as of the 1st of each month), replacing any negative balances with zero. Ensure that data from the first month is used only as a baseline for calculating previous total balance, and exclude it from the final output. Sort the results in ascending order by month. ",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "each",
            "month,",
            "calculate",
            "the",
            "total",
            "balance",
            "from",
            "all",
            "users",
            "for",
            "the",
            "previous",
            "month",
            "(measured",
            "as",
            "of",
            "the",
            "1st",
            "of",
            "each",
            "month),",
            "replacing",
            "any",
            "negative",
            "balances",
            "with",
            "zero.",
            "Ensure",
            "that",
            "data",
            "from",
            "the",
            "first",
            "month",
            "is",
            "used",
            "only",
            "as",
            "a",
            "baseline",
            "for",
            "calculating",
            "previous",
            "total",
            "balance,",
            "and",
            "exclude",
            "it",
            "from",
            "the",
            "final",
            "output.",
            "Sort",
            "the",
            "results",
            "in",
            "ascending",
            "order",
            "by",
            "month.",
            ""
        ],
        "query": "",
        "db_id": "bank_sales_trading",
        "No. of candidate columns": 106,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local299",
        "question": "Could you calculate each user’s average balance over the past 30 days, computed daily? Then, for each month (based on the 1st of each month), find the highest of these daily averages for each user. Add up these maximum values across all users for each month as the final result. Please use the first month as a baseline for previous balances and exclude it from the output.",
        "external_knowledge": null,
        "question_toks": [
            "Could",
            "you",
            "calculate",
            "each",
            "user’s",
            "average",
            "balance",
            "over",
            "the",
            "past",
            "30",
            "days,",
            "computed",
            "daily?",
            "Then,",
            "for",
            "each",
            "month",
            "(based",
            "on",
            "the",
            "1st",
            "of",
            "each",
            "month),",
            "find",
            "the",
            "highest",
            "of",
            "these",
            "daily",
            "averages",
            "for",
            "each",
            "user.",
            "Add",
            "up",
            "these",
            "maximum",
            "values",
            "across",
            "all",
            "users",
            "for",
            "each",
            "month",
            "as",
            "the",
            "final",
            "result.",
            "Please",
            "use",
            "the",
            "first",
            "month",
            "as",
            "a",
            "baseline",
            "for",
            "previous",
            "balances",
            "and",
            "exclude",
            "it",
            "from",
            "the",
            "output."
        ],
        "query": "",
        "db_id": "bank_sales_trading",
        "No. of candidate columns": 106,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local077",
        "question": "Please analyze our interest data from September 2018 to August 2019. For each month, calculate the average composition for each interest by dividing the composition by the index value. Identify the interest with the highest average composition value each month and report its average composition as the max index composition for that month. Compute the three-month rolling average of these monthly max index compositions. Ensure the output includes the date, the interest name, the max index composition for that month, the rolling average, and the names and max index compositions of the top interests from one month ago and two months ago.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "analyze",
            "our",
            "interest",
            "data",
            "from",
            "September",
            "2018",
            "to",
            "August",
            "2019.",
            "For",
            "each",
            "month,",
            "calculate",
            "the",
            "average",
            "composition",
            "for",
            "each",
            "interest",
            "by",
            "dividing",
            "the",
            "composition",
            "by",
            "the",
            "index",
            "value.",
            "Identify",
            "the",
            "interest",
            "with",
            "the",
            "highest",
            "average",
            "composition",
            "value",
            "each",
            "month",
            "and",
            "report",
            "its",
            "average",
            "composition",
            "as",
            "the",
            "max",
            "index",
            "composition",
            "for",
            "that",
            "month.",
            "Compute",
            "the",
            "three-month",
            "rolling",
            "average",
            "of",
            "these",
            "monthly",
            "max",
            "index",
            "compositions.",
            "Ensure",
            "the",
            "output",
            "includes",
            "the",
            "date,",
            "the",
            "interest",
            "name,",
            "the",
            "max",
            "index",
            "composition",
            "for",
            "that",
            "month,",
            "the",
            "rolling",
            "average,",
            "and",
            "the",
            "names",
            "and",
            "max",
            "index",
            "compositions",
            "of",
            "the",
            "top",
            "interests",
            "from",
            "one",
            "month",
            "ago",
            "and",
            "two",
            "months",
            "ago."
        ],
        "query": "",
        "db_id": "bank_sales_trading",
        "No. of candidate columns": 106,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local096",
        "question": "For each year, calculate the proportion of films that had exclusively female actors, considering actors with gender 'Male' or 'None' (i.e., unknown or unspecified gender) as non-female. Show the proportion of female-actor-only films and the total number of all films for each year.",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "each",
            "year,",
            "calculate",
            "the",
            "proportion",
            "of",
            "films",
            "that",
            "had",
            "exclusively",
            "female",
            "actors,",
            "considering",
            "actors",
            "with",
            "gender",
            "'Male'",
            "or",
            "'None'",
            "(i.e.,",
            "unknown",
            "or",
            "unspecified",
            "gender)",
            "as",
            "non-female.",
            "Show",
            "the",
            "proportion",
            "of",
            "female-actor-only",
            "films",
            "and",
            "the",
            "total",
            "number",
            "of",
            "all",
            "films",
            "for",
            "each",
            "year."
        ],
        "query": "",
        "db_id": "Db-IMDB",
        "No. of candidate columns": 50,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local097",
        "question": "Could you analyze our data and identify which ten-year period starting from any movie release year present in the data had the largest number of films, considering consecutive ten-year periods beginning at each unique year? Only output the start year and the total count for that specific period.",
        "external_knowledge": null,
        "question_toks": [
            "Could",
            "you",
            "analyze",
            "our",
            "data",
            "and",
            "identify",
            "which",
            "ten-year",
            "period",
            "starting",
            "from",
            "any",
            "movie",
            "release",
            "year",
            "present",
            "in",
            "the",
            "data",
            "had",
            "the",
            "largest",
            "number",
            "of",
            "films,",
            "considering",
            "consecutive",
            "ten-year",
            "periods",
            "beginning",
            "at",
            "each",
            "unique",
            "year?",
            "Only",
            "output",
            "the",
            "start",
            "year",
            "and",
            "the",
            "total",
            "count",
            "for",
            "that",
            "specific",
            "period."
        ],
        "query": "",
        "db_id": "Db-IMDB",
        "No. of candidate columns": 50,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local100",
        "question": "Find out how many actors have a 'Shahrukh number' of 2? This means they acted in a film with someone who acted with Shahrukh Khan, but not directly with him.",
        "external_knowledge": null,
        "question_toks": [
            "Find",
            "out",
            "how",
            "many",
            "actors",
            "have",
            "a",
            "'Shahrukh",
            "number'",
            "of",
            "2?",
            "This",
            "means",
            "they",
            "acted",
            "in",
            "a",
            "film",
            "with",
            "someone",
            "who",
            "acted",
            "with",
            "Shahrukh",
            "Khan,",
            "but",
            "not",
            "directly",
            "with",
            "him."
        ],
        "query": "",
        "db_id": "Db-IMDB",
        "No. of candidate columns": 50,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local114",
        "question": "Provide a detailed web sales report for each region, including the number of orders, total sales amount, and the name and sales amount of all sales representatives who achieved the highest total sales amount in that region (include all representatives in case of a tie).",
        "external_knowledge": null,
        "question_toks": [
            "Provide",
            "a",
            "detailed",
            "web",
            "sales",
            "report",
            "for",
            "each",
            "region,",
            "including",
            "the",
            "number",
            "of",
            "orders,",
            "total",
            "sales",
            "amount,",
            "and",
            "the",
            "name",
            "and",
            "sales",
            "amount",
            "of",
            "all",
            "sales",
            "representatives",
            "who",
            "achieved",
            "the",
            "highest",
            "total",
            "sales",
            "amount",
            "in",
            "that",
            "region",
            "(include",
            "all",
            "representatives",
            "in",
            "case",
            "of",
            "a",
            "tie)."
        ],
        "query": "",
        "db_id": "education_business",
        "No. of candidate columns": 98,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local128",
        "question": "List the bowlers, match number, game number, handicap score, tournament date, and location for only those bowlers who won their game with a handicap score of 190 or less at Thunderbird Lanes, Totem Lanes, and Bolero Lanes.",
        "external_knowledge": null,
        "question_toks": [
            "List",
            "the",
            "bowlers,",
            "match",
            "number,",
            "game",
            "number,",
            "handicap",
            "score,",
            "tournament",
            "date,",
            "and",
            "location",
            "for",
            "only",
            "those",
            "bowlers",
            "who",
            "won",
            "their",
            "game",
            "with",
            "a",
            "handicap",
            "score",
            "of",
            "190",
            "or",
            "less",
            "at",
            "Thunderbird",
            "Lanes,",
            "Totem",
            "Lanes,",
            "and",
            "Bolero",
            "Lanes."
        ],
        "query": "",
        "db_id": "BowlingLeague",
        "No. of candidate columns": 56,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local130",
        "question": "Could you provide a list of last names for all students who have completed English courses, including their quintile ranks based on their individual grades in those courses (without averaging), where the quintiles are determined by ranking students according to the number of students who have grades greater than or equal to theirs, and sorted from the highest to the lowest grade quintile?",
        "external_knowledge": null,
        "question_toks": [
            "Could",
            "you",
            "provide",
            "a",
            "list",
            "of",
            "last",
            "names",
            "for",
            "all",
            "students",
            "who",
            "have",
            "completed",
            "English",
            "courses,",
            "including",
            "their",
            "quintile",
            "ranks",
            "based",
            "on",
            "their",
            "individual",
            "grades",
            "in",
            "those",
            "courses",
            "(without",
            "averaging),",
            "where",
            "the",
            "quintiles",
            "are",
            "determined",
            "by",
            "ranking",
            "students",
            "according",
            "to",
            "the",
            "number",
            "of",
            "students",
            "who",
            "have",
            "grades",
            "greater",
            "than",
            "or",
            "equal",
            "to",
            "theirs,",
            "and",
            "sorted",
            "from",
            "the",
            "highest",
            "to",
            "the",
            "lowest",
            "grade",
            "quintile?"
        ],
        "query": "",
        "db_id": "school_scheduling",
        "No. of candidate columns": 77,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local133",
        "question": "Given a database of musical styles and user preferences, where each user ranks up to three preferred styles as their first, second, and third choices, assign 3 points for each first-choice ranking, 2 points for each second-choice ranking, and 1 point for each third-choice ranking. Calculate the total weighted score for each musical style that has been ranked by at least one user. Then, compute the absolute difference between each style's total weighted score and the average total weighted score across all such styles.",
        "external_knowledge": null,
        "question_toks": [
            "Given",
            "a",
            "database",
            "of",
            "musical",
            "styles",
            "and",
            "user",
            "preferences,",
            "where",
            "each",
            "user",
            "ranks",
            "up",
            "to",
            "three",
            "preferred",
            "styles",
            "as",
            "their",
            "first,",
            "second,",
            "and",
            "third",
            "choices,",
            "assign",
            "3",
            "points",
            "for",
            "each",
            "first-choice",
            "ranking,",
            "2",
            "points",
            "for",
            "each",
            "second-choice",
            "ranking,",
            "and",
            "1",
            "point",
            "for",
            "each",
            "third-choice",
            "ranking.",
            "Calculate",
            "the",
            "total",
            "weighted",
            "score",
            "for",
            "each",
            "musical",
            "style",
            "that",
            "has",
            "been",
            "ranked",
            "by",
            "at",
            "least",
            "one",
            "user.",
            "Then,",
            "compute",
            "the",
            "absolute",
            "difference",
            "between",
            "each",
            "style's",
            "total",
            "weighted",
            "score",
            "and",
            "the",
            "average",
            "total",
            "weighted",
            "score",
            "across",
            "all",
            "such",
            "styles."
        ],
        "query": "",
        "db_id": "EntertainmentAgency",
        "No. of candidate columns": 76,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local152",
        "question": "Can you provide the top 9 directors by movie count, including their ID, name, number of movies, average inter-movie duration (rounded to the nearest integer), average rating (rounded to 2 decimals), total votes, minimum and maximum ratings, and total movie duration? Sort the output first by movie count in descending order and then by total movie duration in descending order.",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "provide",
            "the",
            "top",
            "9",
            "directors",
            "by",
            "movie",
            "count,",
            "including",
            "their",
            "ID,",
            "name,",
            "number",
            "of",
            "movies,",
            "average",
            "inter-movie",
            "duration",
            "(rounded",
            "to",
            "the",
            "nearest",
            "integer),",
            "average",
            "rating",
            "(rounded",
            "to",
            "2",
            "decimals),",
            "total",
            "votes,",
            "minimum",
            "and",
            "maximum",
            "ratings,",
            "and",
            "total",
            "movie",
            "duration?",
            "Sort",
            "the",
            "output",
            "first",
            "by",
            "movie",
            "count",
            "in",
            "descending",
            "order",
            "and",
            "then",
            "by",
            "total",
            "movie",
            "duration",
            "in",
            "descending",
            "order."
        ],
        "query": "",
        "db_id": "imdb_movies",
        "No. of candidate columns": 38,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local230",
        "question": "Determine the top three genres with the most movies rated above 8, and then identify the top four directors who have directed the most films rated above 8 within those genres. List these directors and their respective movie counts.",
        "external_knowledge": null,
        "question_toks": [
            "Determine",
            "the",
            "top",
            "three",
            "genres",
            "with",
            "the",
            "most",
            "movies",
            "rated",
            "above",
            "8,",
            "and",
            "then",
            "identify",
            "the",
            "top",
            "four",
            "directors",
            "who",
            "have",
            "directed",
            "the",
            "most",
            "films",
            "rated",
            "above",
            "8",
            "within",
            "those",
            "genres.",
            "List",
            "these",
            "directors",
            "and",
            "their",
            "respective",
            "movie",
            "counts."
        ],
        "query": "",
        "db_id": "imdb_movies",
        "No. of candidate columns": 38,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local156",
        "question": "Analyze the annual average purchase price per Bitcoin by region, computed as the total dollar amount spent divided by the total quantity purchased each year, excluding the first year's data for each region. Then, for each year, rank the regions based on these average purchase prices, and calculate the annual percentage change in cost for each region compared to the previous year.",
        "external_knowledge": null,
        "question_toks": [
            "Analyze",
            "the",
            "annual",
            "average",
            "purchase",
            "price",
            "per",
            "Bitcoin",
            "by",
            "region,",
            "computed",
            "as",
            "the",
            "total",
            "dollar",
            "amount",
            "spent",
            "divided",
            "by",
            "the",
            "total",
            "quantity",
            "purchased",
            "each",
            "year,",
            "excluding",
            "the",
            "first",
            "year's",
            "data",
            "for",
            "each",
            "region.",
            "Then,",
            "for",
            "each",
            "year,",
            "rank",
            "the",
            "regions",
            "based",
            "on",
            "these",
            "average",
            "purchase",
            "prices,",
            "and",
            "calculate",
            "the",
            "annual",
            "percentage",
            "change",
            "in",
            "cost",
            "for",
            "each",
            "region",
            "compared",
            "to",
            "the",
            "previous",
            "year."
        ],
        "query": "",
        "db_id": "bank_sales_trading",
        "No. of candidate columns": 106,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local169",
        "question": "What is the proportion of legislators who started their first term between 1917 and 1999 that remained in office on December 31st of each year, tracked annually for up to 20 years following their initial term start?",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "is",
            "the",
            "proportion",
            "of",
            "legislators",
            "who",
            "started",
            "their",
            "first",
            "term",
            "between",
            "1917",
            "and",
            "1999",
            "that",
            "remained",
            "in",
            "office",
            "on",
            "December",
            "31st",
            "of",
            "each",
            "year,",
            "tracked",
            "annually",
            "for",
            "up",
            "to",
            "20",
            "years",
            "following",
            "their",
            "initial",
            "term",
            "start?"
        ],
        "query": "",
        "db_id": "city_legislation",
        "No. of candidate columns": 133,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local167",
        "question": "Based on the state each female legislator first represented, which state has the highest number of female legislators whose terms included December 31st at any point, and what is that count? Please provide the state's abbreviation.",
        "external_knowledge": null,
        "question_toks": [
            "Based",
            "on",
            "the",
            "state",
            "each",
            "female",
            "legislator",
            "first",
            "represented,",
            "which",
            "state",
            "has",
            "the",
            "highest",
            "number",
            "of",
            "female",
            "legislators",
            "whose",
            "terms",
            "included",
            "December",
            "31st",
            "at",
            "any",
            "point,",
            "and",
            "what",
            "is",
            "that",
            "count?",
            "Please",
            "provide",
            "the",
            "state's",
            "abbreviation."
        ],
        "query": "",
        "db_id": "city_legislation",
        "No. of candidate columns": 133,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local170",
        "question": "Identify the state abbreviations where, for both male and female legislators who began serving in that state, the retention rate of the initial cohort is greater than zero at each of the intervals 0, 2, 4, 6, 8, and 10 years after their initial term start date during the first 10 years of service.",
        "external_knowledge": null,
        "question_toks": [
            "Identify",
            "the",
            "state",
            "abbreviations",
            "where,",
            "for",
            "both",
            "male",
            "and",
            "female",
            "legislators",
            "who",
            "began",
            "serving",
            "in",
            "that",
            "state,",
            "the",
            "retention",
            "rate",
            "of",
            "the",
            "initial",
            "cohort",
            "is",
            "greater",
            "than",
            "zero",
            "at",
            "each",
            "of",
            "the",
            "intervals",
            "0,",
            "2,",
            "4,",
            "6,",
            "8,",
            "and",
            "10",
            "years",
            "after",
            "their",
            "initial",
            "term",
            "start",
            "date",
            "during",
            "the",
            "first",
            "10",
            "years",
            "of",
            "service."
        ],
        "query": "",
        "db_id": "city_legislation",
        "No. of candidate columns": 133,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local194",
        "question": "Please provide a list of the top three revenue-generating films for each actor, along with the average revenue per actor in those films, calculated by dividing the total film revenue equally among the actors for each film.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "provide",
            "a",
            "list",
            "of",
            "the",
            "top",
            "three",
            "revenue-generating",
            "films",
            "for",
            "each",
            "actor,",
            "along",
            "with",
            "the",
            "average",
            "revenue",
            "per",
            "actor",
            "in",
            "those",
            "films,",
            "calculated",
            "by",
            "dividing",
            "the",
            "total",
            "film",
            "revenue",
            "equally",
            "among",
            "the",
            "actors",
            "for",
            "each",
            "film."
        ],
        "query": "",
        "db_id": "sqlite-sakila",
        "No. of candidate columns": 120,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local201",
        "question": "Identify the first 10 words, sorted alphabetically, that are 4 to 5 characters long, start with 'r', and have at least one anagram of the same length, considering case-sensitive letters. Provide the count of such anagrams for each word.",
        "external_knowledge": null,
        "question_toks": [
            "Identify",
            "the",
            "first",
            "10",
            "words,",
            "sorted",
            "alphabetically,",
            "that",
            "are",
            "4",
            "to",
            "5",
            "characters",
            "long,",
            "start",
            "with",
            "'r',",
            "and",
            "have",
            "at",
            "least",
            "one",
            "anagram",
            "of",
            "the",
            "same",
            "length,",
            "considering",
            "case-sensitive",
            "letters.",
            "Provide",
            "the",
            "count",
            "of",
            "such",
            "anagrams",
            "for",
            "each",
            "word."
        ],
        "query": "",
        "db_id": "modern_data",
        "No. of candidate columns": 77,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local220",
        "question": "Which player has participated in the highest number of winning matches and which player has participated in the highest number of losing matches, considering only matches where they actually played (excluding null entries) and where their team won or lost (excluding draws)?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "player",
            "has",
            "participated",
            "in",
            "the",
            "highest",
            "number",
            "of",
            "winning",
            "matches",
            "and",
            "which",
            "player",
            "has",
            "participated",
            "in",
            "the",
            "highest",
            "number",
            "of",
            "losing",
            "matches,",
            "considering",
            "only",
            "matches",
            "where",
            "they",
            "actually",
            "played",
            "(excluding",
            "null",
            "entries)",
            "and",
            "where",
            "their",
            "team",
            "won",
            "or",
            "lost",
            "(excluding",
            "draws)?"
        ],
        "query": "",
        "db_id": "EU_soccer",
        "No. of candidate columns": 233,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local229",
        "question": "Find the IDs of players who scored the highest number of partnership runs for each match. The output should include the IDs of two players, each with their individual scores and the total partnership score. For each pair, the player with the higher individual score should be listed as player 1, and the player with the lower score as player 2. In cases where both players have the same score, the player with the higher ID should be player 1, and the player with the lower ID should be player 2. There can be multiple rows for a single match.",
        "external_knowledge": null,
        "question_toks": [
            "Find",
            "the",
            "IDs",
            "of",
            "players",
            "who",
            "scored",
            "the",
            "highest",
            "number",
            "of",
            "partnership",
            "runs",
            "for",
            "each",
            "match.",
            "The",
            "output",
            "should",
            "include",
            "the",
            "IDs",
            "of",
            "two",
            "players,",
            "each",
            "with",
            "their",
            "individual",
            "scores",
            "and",
            "the",
            "total",
            "partnership",
            "score.",
            "For",
            "each",
            "pair,",
            "the",
            "player",
            "with",
            "the",
            "higher",
            "individual",
            "score",
            "should",
            "be",
            "listed",
            "as",
            "player",
            "1,",
            "and",
            "the",
            "player",
            "with",
            "the",
            "lower",
            "score",
            "as",
            "player",
            "2.",
            "In",
            "cases",
            "where",
            "both",
            "players",
            "have",
            "the",
            "same",
            "score,",
            "the",
            "player",
            "with",
            "the",
            "higher",
            "ID",
            "should",
            "be",
            "player",
            "1,",
            "and",
            "the",
            "player",
            "with",
            "the",
            "lower",
            "ID",
            "should",
            "be",
            "player",
            "2.",
            "There",
            "can",
            "be",
            "multiple",
            "rows",
            "for",
            "a",
            "single",
            "match."
        ],
        "query": "",
        "db_id": "IPL",
        "No. of candidate columns": 52,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local258",
        "question": "Calculate the total number of wickets taken by each bowler (excluding run-outs and other dismissals not attributed to the bowler), their economy rate (total runs conceded divided by total overs bowled, considering only runs scored off the bat and ignoring any extra runs like wides and no-balls), their strike rate (average number of balls bowled per wicket taken), and their best bowling performance in a single match (the match with the most wickets taken by the bowler, formatted as \"wickets-runs\" where runs are the runs conceded excluding extras).",
        "external_knowledge": "baseball_game_special_words_definition.md",
        "question_toks": [
            "Calculate",
            "the",
            "total",
            "number",
            "of",
            "wickets",
            "taken",
            "by",
            "each",
            "bowler",
            "(excluding",
            "run-outs",
            "and",
            "other",
            "dismissals",
            "not",
            "attributed",
            "to",
            "the",
            "bowler),",
            "their",
            "economy",
            "rate",
            "(total",
            "runs",
            "conceded",
            "divided",
            "by",
            "total",
            "overs",
            "bowled,",
            "considering",
            "only",
            "runs",
            "scored",
            "off",
            "the",
            "bat",
            "and",
            "ignoring",
            "any",
            "extra",
            "runs",
            "like",
            "wides",
            "and",
            "no-balls),",
            "their",
            "strike",
            "rate",
            "(average",
            "number",
            "of",
            "balls",
            "bowled",
            "per",
            "wicket",
            "taken),",
            "and",
            "their",
            "best",
            "bowling",
            "performance",
            "in",
            "a",
            "single",
            "match",
            "(the",
            "match",
            "with",
            "the",
            "most",
            "wickets",
            "taken",
            "by",
            "the",
            "bowler,",
            "formatted",
            "as",
            "\"wickets-runs\"",
            "where",
            "runs",
            "are",
            "the",
            "runs",
            "conceded",
            "excluding",
            "extras)."
        ],
        "query": "",
        "db_id": "IPL",
        "No. of candidate columns": 52,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local259",
        "question": "For each player, list their ID, name, their most frequent role across all matches, batting hand, bowling skill, total runs scored, total matches played, total times they were dismissed, batting average (total runs divided by total dismissals), highest score in a single match, the number of matches in which they scored at least 30 runs, at least 50 runs, and at least 100 runs, total balls faced in their career, strike rate (total runs divided by total balls faced, multiplied by 100), total wickets taken, economy rate (average runs conceded per over), and their best bowling performance in a single match (most wickets taken in a match, formatted as \"wickets taken-runs given\", where the best performance is the one with the most wickets, and if tied, the fewest runs conceded). Ignore the extra runs data.",
        "external_knowledge": "baseball_game_special_words_definition.md",
        "question_toks": [
            "For",
            "each",
            "player,",
            "list",
            "their",
            "ID,",
            "name,",
            "their",
            "most",
            "frequent",
            "role",
            "across",
            "all",
            "matches,",
            "batting",
            "hand,",
            "bowling",
            "skill,",
            "total",
            "runs",
            "scored,",
            "total",
            "matches",
            "played,",
            "total",
            "times",
            "they",
            "were",
            "dismissed,",
            "batting",
            "average",
            "(total",
            "runs",
            "divided",
            "by",
            "total",
            "dismissals),",
            "highest",
            "score",
            "in",
            "a",
            "single",
            "match,",
            "the",
            "number",
            "of",
            "matches",
            "in",
            "which",
            "they",
            "scored",
            "at",
            "least",
            "30",
            "runs,",
            "at",
            "least",
            "50",
            "runs,",
            "and",
            "at",
            "least",
            "100",
            "runs,",
            "total",
            "balls",
            "faced",
            "in",
            "their",
            "career,",
            "strike",
            "rate",
            "(total",
            "runs",
            "divided",
            "by",
            "total",
            "balls",
            "faced,",
            "multiplied",
            "by",
            "100),",
            "total",
            "wickets",
            "taken,",
            "economy",
            "rate",
            "(average",
            "runs",
            "conceded",
            "per",
            "over),",
            "and",
            "their",
            "best",
            "bowling",
            "performance",
            "in",
            "a",
            "single",
            "match",
            "(most",
            "wickets",
            "taken",
            "in",
            "a",
            "match,",
            "formatted",
            "as",
            "\"wickets",
            "taken-runs",
            "given\",",
            "where",
            "the",
            "best",
            "performance",
            "is",
            "the",
            "one",
            "with",
            "the",
            "most",
            "wickets,",
            "and",
            "if",
            "tied,",
            "the",
            "fewest",
            "runs",
            "conceded).",
            "Ignore",
            "the",
            "extra",
            "runs",
            "data."
        ],
        "query": "",
        "db_id": "IPL",
        "No. of candidate columns": 52,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local264",
        "question": "Which model category (L1_model) appears the most frequently across all steps and versions when comparing traditional models to the Stack model, and what is the total count of its occurrences?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "model",
            "category",
            "(L1_model)",
            "appears",
            "the",
            "most",
            "frequently",
            "across",
            "all",
            "steps",
            "and",
            "versions",
            "when",
            "comparing",
            "traditional",
            "models",
            "to",
            "the",
            "Stack",
            "model,",
            "and",
            "what",
            "is",
            "the",
            "total",
            "count",
            "of",
            "its",
            "occurrences?"
        ],
        "query": "",
        "db_id": "stacking",
        "No. of candidate columns": 53,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local272",
        "question": "For order 423, identify the product IDs, aisles, and positions from which to pick the exact quantities needed for each order line, ensuring that the total picked quantity for each product matches the cumulative quantities ordered without exceeding the available inventory in warehouse 1. Calculate the quantities to be picked from each location by prioritizing inventory with earlier purchased dates and smaller quantities, and ensure that picking respects the sequence and cumulative quantities of the order lines for products with multiple entries.",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "order",
            "423,",
            "identify",
            "the",
            "product",
            "IDs,",
            "aisles,",
            "and",
            "positions",
            "from",
            "which",
            "to",
            "pick",
            "the",
            "exact",
            "quantities",
            "needed",
            "for",
            "each",
            "order",
            "line,",
            "ensuring",
            "that",
            "the",
            "total",
            "picked",
            "quantity",
            "for",
            "each",
            "product",
            "matches",
            "the",
            "cumulative",
            "quantities",
            "ordered",
            "without",
            "exceeding",
            "the",
            "available",
            "inventory",
            "in",
            "warehouse",
            "1.",
            "Calculate",
            "the",
            "quantities",
            "to",
            "be",
            "picked",
            "from",
            "each",
            "location",
            "by",
            "prioritizing",
            "inventory",
            "with",
            "earlier",
            "purchased",
            "dates",
            "and",
            "smaller",
            "quantities,",
            "and",
            "ensure",
            "that",
            "picking",
            "respects",
            "the",
            "sequence",
            "and",
            "cumulative",
            "quantities",
            "of",
            "the",
            "order",
            "lines",
            "for",
            "products",
            "with",
            "multiple",
            "entries."
        ],
        "query": "",
        "db_id": "oracle_sql",
        "No. of candidate columns": 124,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local285",
        "question": "For veg whsle data, can you analyze our financial performance over the years 2020 to 2023? I need insights into the average wholesale price, maximum wholesale price, minimum wholesale price, wholesale price difference, total wholesale price, total selling price, average loss rate, total loss, and profit for each category within each year. Round all calculated values to two decimal places.",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "veg",
            "whsle",
            "data,",
            "can",
            "you",
            "analyze",
            "our",
            "financial",
            "performance",
            "over",
            "the",
            "years",
            "2020",
            "to",
            "2023?",
            "I",
            "need",
            "insights",
            "into",
            "the",
            "average",
            "wholesale",
            "price,",
            "maximum",
            "wholesale",
            "price,",
            "minimum",
            "wholesale",
            "price,",
            "wholesale",
            "price",
            "difference,",
            "total",
            "wholesale",
            "price,",
            "total",
            "selling",
            "price,",
            "average",
            "loss",
            "rate,",
            "total",
            "loss,",
            "and",
            "profit",
            "for",
            "each",
            "category",
            "within",
            "each",
            "year.",
            "Round",
            "all",
            "calculated",
            "values",
            "to",
            "two",
            "decimal",
            "places."
        ],
        "query": "",
        "db_id": "bank_sales_trading",
        "No. of candidate columns": 106,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local286",
        "question": "Prepare a comprehensive performance report on our sellers, focusing on total sales, average item price, average review scores, and packing times. Ensure that the report includes only those sellers who have sold a quantity of more than 100 products and highlight the product category names in English with the highest sales volume.",
        "external_knowledge": null,
        "question_toks": [
            "Prepare",
            "a",
            "comprehensive",
            "performance",
            "report",
            "on",
            "our",
            "sellers,",
            "focusing",
            "on",
            "total",
            "sales,",
            "average",
            "item",
            "price,",
            "average",
            "review",
            "scores,",
            "and",
            "packing",
            "times.",
            "Ensure",
            "that",
            "the",
            "report",
            "includes",
            "only",
            "those",
            "sellers",
            "who",
            "have",
            "sold",
            "a",
            "quantity",
            "of",
            "more",
            "than",
            "100",
            "products",
            "and",
            "highlight",
            "the",
            "product",
            "category",
            "names",
            "in",
            "English",
            "with",
            "the",
            "highest",
            "sales",
            "volume."
        ],
        "query": "",
        "db_id": "electronic_sales",
        "No. of candidate columns": 61,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local302",
        "question": "Analyze the average percentage change in sales between the 12 weeks before and after June 15, 2020, for each attribute type: region, platform, age band, demographic, and customer type. For each attribute type, calculate the average percentage change in sales across all its attribute values. Identify the attribute type with the highest negative impact on sales and provide its average percentage change in sales.",
        "external_knowledge": null,
        "question_toks": [
            "Analyze",
            "the",
            "average",
            "percentage",
            "change",
            "in",
            "sales",
            "between",
            "the",
            "12",
            "weeks",
            "before",
            "and",
            "after",
            "June",
            "15,",
            "2020,",
            "for",
            "each",
            "attribute",
            "type:",
            "region,",
            "platform,",
            "age",
            "band,",
            "demographic,",
            "and",
            "customer",
            "type.",
            "For",
            "each",
            "attribute",
            "type,",
            "calculate",
            "the",
            "average",
            "percentage",
            "change",
            "in",
            "sales",
            "across",
            "all",
            "its",
            "attribute",
            "values.",
            "Identify",
            "the",
            "attribute",
            "type",
            "with",
            "the",
            "highest",
            "negative",
            "impact",
            "on",
            "sales",
            "and",
            "provide",
            "its",
            "average",
            "percentage",
            "change",
            "in",
            "sales."
        ],
        "query": "",
        "db_id": "bank_sales_trading",
        "No. of candidate columns": 106,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local330",
        "question": "Using only the data from the log table, compute for each web page  the number of unique user sessions where that page is either the first landing page or the exit page of the session based on the timestamp.",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "only",
            "the",
            "data",
            "from",
            "the",
            "log",
            "table,",
            "compute",
            "for",
            "each",
            "web",
            "page",
            "",
            "the",
            "number",
            "of",
            "unique",
            "user",
            "sessions",
            "where",
            "that",
            "page",
            "is",
            "either",
            "the",
            "first",
            "landing",
            "page",
            "or",
            "the",
            "exit",
            "page",
            "of",
            "the",
            "session",
            "based",
            "on",
            "the",
            "timestamp."
        ],
        "query": "",
        "db_id": "log",
        "No. of candidate columns": 88,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local360",
        "question": "Identify the sessions with the minimal number of events occurring before the first '/detail' click or '/complete' conversion within the session, considering only events with non-empty search types. If multiple sessions share this minimum count, include all of them. For each session, display the associated paths and search types.",
        "external_knowledge": null,
        "question_toks": [
            "Identify",
            "the",
            "sessions",
            "with",
            "the",
            "minimal",
            "number",
            "of",
            "events",
            "occurring",
            "before",
            "the",
            "first",
            "'/detail'",
            "click",
            "or",
            "'/complete'",
            "conversion",
            "within",
            "the",
            "session,",
            "considering",
            "only",
            "events",
            "with",
            "non-empty",
            "search",
            "types.",
            "If",
            "multiple",
            "sessions",
            "share",
            "this",
            "minimum",
            "count,",
            "include",
            "all",
            "of",
            "them.",
            "For",
            "each",
            "session,",
            "display",
            "the",
            "associated",
            "paths",
            "and",
            "search",
            "types."
        ],
        "query": "",
        "db_id": "log",
        "No. of candidate columns": 88,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local335",
        "question": "In Formula 1 seasons since 2001, considering only drivers who scored points in a season, which five constructors have had the most seasons where their drivers scored the fewest total points among all point-scoring drivers in that season?",
        "external_knowledge": null,
        "question_toks": [
            "In",
            "Formula",
            "1",
            "seasons",
            "since",
            "2001,",
            "considering",
            "only",
            "drivers",
            "who",
            "scored",
            "points",
            "in",
            "a",
            "season,",
            "which",
            "five",
            "constructors",
            "have",
            "had",
            "the",
            "most",
            "seasons",
            "where",
            "their",
            "drivers",
            "scored",
            "the",
            "fewest",
            "total",
            "points",
            "among",
            "all",
            "point-scoring",
            "drivers",
            "in",
            "that",
            "season?"
        ],
        "query": "",
        "db_id": "f1",
        "No. of candidate columns": 228,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local311",
        "question": "Which constructors had the top 3 combined points from their best driver and team, and in which years did they achieve them?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "constructors",
            "had",
            "the",
            "top",
            "3",
            "combined",
            "points",
            "from",
            "their",
            "best",
            "driver",
            "and",
            "team,",
            "and",
            "in",
            "which",
            "years",
            "did",
            "they",
            "achieve",
            "them?"
        ],
        "query": "",
        "db_id": "f1",
        "No. of candidate columns": 228,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local355",
        "question": "Calculate the average first and last rounds of races missed by drivers each year. Only include drivers who missed fewer than three races annually and who switched teams between the race immediately before their first missed race and the race immediately after their last missed race.",
        "external_knowledge": null,
        "question_toks": [
            "Calculate",
            "the",
            "average",
            "first",
            "and",
            "last",
            "rounds",
            "of",
            "races",
            "missed",
            "by",
            "drivers",
            "each",
            "year.",
            "Only",
            "include",
            "drivers",
            "who",
            "missed",
            "fewer",
            "than",
            "three",
            "races",
            "annually",
            "and",
            "who",
            "switched",
            "teams",
            "between",
            "the",
            "race",
            "immediately",
            "before",
            "their",
            "first",
            "missed",
            "race",
            "and",
            "the",
            "race",
            "immediately",
            "after",
            "their",
            "last",
            "missed",
            "race."
        ],
        "query": "",
        "db_id": "f1",
        "No. of candidate columns": 228,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local356",
        "question": "Provide the full names of drivers who have been overtaken on track more times than they have overtaken others on track during race laps, excluding position changes due to pit stops, retirements, or movements at the start of the race.",
        "external_knowledge": null,
        "question_toks": [
            "Provide",
            "the",
            "full",
            "names",
            "of",
            "drivers",
            "who",
            "have",
            "been",
            "overtaken",
            "on",
            "track",
            "more",
            "times",
            "than",
            "they",
            "have",
            "overtaken",
            "others",
            "on",
            "track",
            "during",
            "race",
            "laps,",
            "excluding",
            "position",
            "changes",
            "due",
            "to",
            "pit",
            "stops,",
            "retirements,",
            "or",
            "movements",
            "at",
            "the",
            "start",
            "of",
            "the",
            "race."
        ],
        "query": "",
        "db_id": "f1",
        "No. of candidate columns": 228,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf001",
        "question": "Assuming today is April 1, 2024, I would like to know the daily snowfall amounts greater than 6 inches for each U.S. postal code during the week ending after the first two full weeks of the previous year. Show the postal code, date, and snowfall amount.",
        "external_knowledge": null,
        "question_toks": [
            "Assuming",
            "today",
            "is",
            "April",
            "1,",
            "2024,",
            "I",
            "would",
            "like",
            "to",
            "know",
            "the",
            "daily",
            "snowfall",
            "amounts",
            "greater",
            "than",
            "6",
            "inches",
            "for",
            "each",
            "U.S.",
            "postal",
            "code",
            "during",
            "the",
            "week",
            "ending",
            "after",
            "the",
            "first",
            "two",
            "full",
            "weeks",
            "of",
            "the",
            "previous",
            "year.",
            "Show",
            "the",
            "postal",
            "code,",
            "date,",
            "and",
            "snowfall",
            "amount."
        ],
        "query": "WITH timestamps AS\n(   \n    SELECT\n        DATE_TRUNC(year,DATEADD(year,-1,DATE '2024-08-29')) AS ref_timestamp,\n        LAST_DAY(DATEADD(week,2 + CAST(WEEKISO(ref_timestamp) != 1 AS INTEGER),ref_timestamp),week) AS end_week,\n        DATEADD(day, day_num - 7, end_week) AS date_valid_std\n    FROM\n    (   \n        SELECT\n            ROW_NUMBER() OVER (ORDER BY SEQ1()) AS day_num\n        FROM\n            TABLE(GENERATOR(rowcount => 7))\n    ) \n)\nSELECT\n    country,\n    postal_code,\n    date_valid_std,\n    tot_snowfall_in \nFROM \n    GLOBAL_WEATHER__CLIMATE_DATA_FOR_BI.standard_tile.history_day\nNATURAL INNER JOIN\n    timestamps\nWHERE\n    country='US' AND\n    tot_snowfall_in > 6.0 \nORDER BY \n    postal_code,date_valid_std\n;",
        "db_id": "GLOBAL_WEATHER__CLIMATE_DATA_FOR_BI",
        "No. of candidate columns": 215,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf003",
        "question": "From 2015 to 2020, which zip code in Census Zip Code Tabulation Areas had the second-highest annual population growth rate, given a minimum estimate of 25,000 people over a 5-year period? Include the zip code, state abbreviation, and growth rate.",
        "external_knowledge": null,
        "question_toks": [
            "From",
            "2015",
            "to",
            "2020,",
            "which",
            "zip",
            "code",
            "in",
            "Census",
            "Zip",
            "Code",
            "Tabulation",
            "Areas",
            "had",
            "the",
            "second-highest",
            "annual",
            "population",
            "growth",
            "rate,",
            "given",
            "a",
            "minimum",
            "estimate",
            "of",
            "25,000",
            "people",
            "over",
            "a",
            "5-year",
            "period?",
            "Include",
            "the",
            "zip",
            "code,",
            "state",
            "abbreviation,",
            "and",
            "growth",
            "rate."
        ],
        "query": "",
        "db_id": "GLOBAL_GOVERNMENT",
        "No. of candidate columns": 443,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf002",
        "question": "As of December 31, 2022, list the top 10 active banks with assets exceeding $10 billion, ranked by the highest percentage of uninsured assets, where the percentage is calculated as one minus the value of the '% Insured (Estimated)' variable from quarterly estimates. Provide the names of these banks and their respective percentages of uninsured assets.",
        "external_knowledge": null,
        "question_toks": [
            "As",
            "of",
            "December",
            "31,",
            "2022,",
            "list",
            "the",
            "top",
            "10",
            "active",
            "banks",
            "with",
            "assets",
            "exceeding",
            "$10",
            "billion,",
            "ranked",
            "by",
            "the",
            "highest",
            "percentage",
            "of",
            "uninsured",
            "assets,",
            "where",
            "the",
            "percentage",
            "is",
            "calculated",
            "as",
            "one",
            "minus",
            "the",
            "value",
            "of",
            "the",
            "'%",
            "Insured",
            "(Estimated)'",
            "variable",
            "from",
            "quarterly",
            "estimates.",
            "Provide",
            "the",
            "names",
            "of",
            "these",
            "banks",
            "and",
            "their",
            "respective",
            "percentages",
            "of",
            "uninsured",
            "assets."
        ],
        "query": "WITH big_banks AS (\n    SELECT id_rssd\n    FROM FINANCE__ECONOMICS.CYBERSYN.financial_institution_timeseries\n    WHERE variable = 'ASSET'\n      AND date = '2022-12-31'\n      AND value > 1E10\n)\nSELECT name\nFROM FINANCE__ECONOMICS.CYBERSYN.financial_institution_timeseries AS ts\nINNER JOIN FINANCE__ECONOMICS.CYBERSYN.financial_institution_attributes AS att ON (ts.variable = att.variable)\nINNER JOIN FINANCE__ECONOMICS.CYBERSYN.financial_institution_entities AS ent ON (ts.id_rssd = ent.id_rssd)\nINNER JOIN big_banks ON (big_banks.id_rssd = ts.id_rssd)\nWHERE ts.date = '2022-12-31'\n  AND att.variable_name = '% Insured (Estimated)'\n  AND att.frequency = 'Quarterly'\n  AND ent.is_active = True\nORDER BY (1 - value) DESC\nLIMIT 10;",
        "db_id": "FINANCE__ECONOMICS",
        "No. of candidate columns": 441,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf008",
        "question": "Determine the percentage change in gross income inflow and the seasonally-adjusted purchase-only home price index for the Phoenix-Mesa-Scottsdale, AZ Metro Area from January 1, 2023, to December 31, 2023. Gross income inflow refers to the total adjusted gross income from all financial entities within the specified metro area",
        "external_knowledge": null,
        "question_toks": [
            "Determine",
            "the",
            "percentage",
            "change",
            "in",
            "gross",
            "income",
            "inflow",
            "and",
            "the",
            "seasonally-adjusted",
            "purchase-only",
            "home",
            "price",
            "index",
            "for",
            "the",
            "Phoenix-Mesa-Scottsdale,",
            "AZ",
            "Metro",
            "Area",
            "from",
            "January",
            "1,",
            "2023,",
            "to",
            "December",
            "31,",
            "2023.",
            "Gross",
            "income",
            "inflow",
            "refers",
            "to",
            "the",
            "total",
            "adjusted",
            "gross",
            "income",
            "from",
            "all",
            "financial",
            "entities",
            "within",
            "the",
            "specified",
            "metro",
            "area"
        ],
        "query": "",
        "db_id": "US_REAL_ESTATE",
        "No. of candidate columns": 243,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf010",
        "question": "What are the cumulative ratios of mortgages near default in California for each recorded date in 2023, including those that are 90 to 180 days past due, in forbearance, or undergoing foreclosure, bankruptcy, or deed-in-lieu processes?",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "are",
            "the",
            "cumulative",
            "ratios",
            "of",
            "mortgages",
            "near",
            "default",
            "in",
            "California",
            "for",
            "each",
            "recorded",
            "date",
            "in",
            "2023,",
            "including",
            "those",
            "that",
            "are",
            "90",
            "to",
            "180",
            "days",
            "past",
            "due,",
            "in",
            "forbearance,",
            "or",
            "undergoing",
            "foreclosure,",
            "bankruptcy,",
            "or",
            "deed-in-lieu",
            "processes?"
        ],
        "query": "",
        "db_id": "US_REAL_ESTATE",
        "No. of candidate columns": 243,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf018",
        "question": "Examine user engagement with push notifications within a specified one-hour window on June 1, 2023.",
        "temporal": "Yes",
        "external_knowledge": "PushNotificationAnalysis.md",
        "question_toks": [
            "Examine",
            "user",
            "engagement",
            "with",
            "push",
            "notifications",
            "within",
            "a",
            "specified",
            "one-hour",
            "window",
            "on",
            "June",
            "1,",
            "2023."
        ],
        "query": "WITH push_send AS (\n    SELECT\n        id,\n        app_group_id,\n        user_id,\n        campaign_id,\n        message_variation_id,\n        platform,\n        ad_tracking_enabled,\n        TO_TIMESTAMP(TIME) AS \"TIME\",\n        'Send' AS \"EVENT_TYPE\"\n    FROM\n        BRAZE_USER_EVENT_DEMO_DATASET.PUBLIC.USERS_MESSAGES_PUSHNOTIFICATION_SEND_VIEW\n    WHERE\n        TO_TIMESTAMP(TIME) BETWEEN '2023-06-01 08:00:00' AND '2023-06-01 09:00:00'\n),\npush_bounce AS (\n    SELECT\n        id,\n        app_group_id,\n        user_id,\n        campaign_id,\n        message_variation_id,\n        platform,\n        ad_tracking_enabled,\n        TO_TIMESTAMP(TIME) AS \"TIME\",\n        'Bounce' AS \"EVENT_TYPE\"\n    FROM\n        BRAZE_USER_EVENT_DEMO_DATASET.PUBLIC.USERS_MESSAGES_PUSHNOTIFICATION_BOUNCE_VIEW\n    WHERE\n        TO_TIMESTAMP(TIME) BETWEEN '2023-06-01 08:00:00' AND '2023-06-01 09:00:00'\n),\npush_open AS (\n    SELECT\n        id,\n        app_group_id,\n        user_id,\n        campaign_id,\n        message_variation_id,\n        platform,\n        ad_tracking_enabled,\n        TO_TIMESTAMP(TIME) AS \"TIME\",\n        'Open' AS \"EVENT_TYPE\",\n        carrier,\n        browser,\n        device_model\n    FROM\n        BRAZE_USER_EVENT_DEMO_DATASET.PUBLIC.USERS_MESSAGES_PUSHNOTIFICATION_OPEN_VIEW\n    WHERE\n        TO_TIMESTAMP(TIME) BETWEEN '2023-06-01 08:00:00' AND '2023-06-01 09:00:00'\n),\npush_open_influence AS (\n    SELECT\n        id,\n        app_group_id,\n        user_id,\n        campaign_id,\n        message_variation_id,\n        platform,\n        TO_TIMESTAMP(TIME) AS \"TIME\",\n        'Influenced Open' AS \"EVENT_TYPE\",\n        carrier,\n        browser,\n        device_model\n    FROM\n        BRAZE_USER_EVENT_DEMO_DATASET.PUBLIC.USERS_MESSAGES_PUSHNOTIFICATION_INFLUENCEDOPEN_VIEW\n    WHERE\n        TO_TIMESTAMP(TIME) BETWEEN '2023-06-01 08:00:00' AND '2023-06-01 09:00:00'\n)\nSELECT\n    ps.app_group_id,\n    ps.campaign_id,\n    ps.user_id,\n    ps.time,\n    po.time push_open_time,\n    ps.message_variation_id,\n    ps.platform,\n    ps.ad_tracking_enabled,\n    po.carrier,\n    po.browser,\n    po.device_model,\n    COUNT(\n        DISTINCT ps.id\n    ) push_notification_sends,\n    COUNT(\n        DISTINCT ps.user_id\n    ) unique_push_notification_sends,\n    COUNT(\n        DISTINCT pb.id\n    ) push_notification_bounced,\n    COUNT(\n        DISTINCT pb.user_id\n    ) unique_push_notification_bounced,\n    COUNT(\n        DISTINCT po.id\n    ) push_notification_open,\n    COUNT(\n        DISTINCT po.user_id\n    ) unique_push_notification_opened,\n    COUNT(\n        DISTINCT poi.id\n    ) push_notification_influenced_open,\n    COUNT(\n        DISTINCT poi.user_id\n    ) unique_push_notification_influenced_open\nFROM\n    push_send ps\n    LEFT JOIN push_bounce pb\n    ON ps.message_variation_id = pb.message_variation_id\n    AND ps.user_id = pb.user_id\n    AND ps.app_group_id = pb.app_group_id\n    LEFT JOIN push_open po\n    ON ps.message_variation_id = po.message_variation_id\n    AND ps.user_id = po.user_id\n    AND ps.app_group_id = po.app_group_id\n    LEFT JOIN push_open_influence poi\n    ON ps.message_variation_id = poi.message_variation_id\n    AND ps.user_id = poi.user_id\n    AND ps.app_group_id = poi.app_group_id\nGROUP BY\n    1,2,3,4,5,6,7,8,9,10,11;",
        "db_id": "BRAZE_USER_EVENT_DEMO_DATASET",
        "No. of candidate columns": 1780,
        "No. of gold tables": 4
    },
    {
        "instance_id": "sf035",
        "question": "How many unique users started sessions each day within each app group between June 1, 2023, and June 7, 2023? Also show the app group ID and the start day of the session.",
        "external_knowledge": null,
        "question_toks": [
            "How",
            "many",
            "unique",
            "users",
            "started",
            "sessions",
            "each",
            "day",
            "within",
            "each",
            "app",
            "group",
            "between",
            "June",
            "1,",
            "2023,",
            "and",
            "June",
            "7,",
            "2023?",
            "Also",
            "show",
            "the",
            "app",
            "group",
            "ID",
            "and",
            "the",
            "start",
            "day",
            "of",
            "the",
            "session."
        ],
        "query": "",
        "db_id": "BRAZE_USER_EVENT_DEMO_DATASET",
        "No. of candidate columns": 1780,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf040",
        "question": "Find the top 10 northernmost addresses in Florida's largest zip code area. What are their address numbers, street names, and types?",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Find",
            "the",
            "top",
            "10",
            "northernmost",
            "addresses",
            "in",
            "Florida's",
            "largest",
            "zip",
            "code",
            "area.",
            "What",
            "are",
            "their",
            "address",
            "numbers,",
            "street",
            "names,",
            "and",
            "types?"
        ],
        "query": "WITH zip_areas AS (\n    SELECT\n        geo.geo_id,\n        geo.geo_name AS zip,\n        states.related_geo_name AS state,\n        countries.related_geo_name AS country,\n        ST_AREA(TRY_TO_GEOGRAPHY(value)) AS area\n    FROM US_ADDRESSES__POI.CYBERSYN.geography_index AS geo\n    JOIN US_ADDRESSES__POI.CYBERSYN.geography_relationships AS states\n        ON (geo.geo_id = states.geo_id AND states.related_level = 'State')\n    JOIN US_ADDRESSES__POI.CYBERSYN.geography_relationships AS countries\n        ON (geo.geo_id = countries.geo_id AND countries.related_level = 'Country')\n    JOIN US_ADDRESSES__POI.CYBERSYN.geography_characteristics AS chars\n        ON (geo.geo_id = chars.geo_id AND chars.relationship_type = 'coordinates_geojson')\n    WHERE geo.level = 'CensusZipCodeTabulationArea'\n),\n\nzip_area_ranks AS (\n    SELECT\n        *,\n        ROW_NUMBER() OVER (PARTITION BY country, state ORDER BY area DESC, geo_id) AS zip_area_rank\n    FROM zip_areas\n)\n\nSELECT addr.number, addr.street, addr.street_type\nFROM US_ADDRESSES__POI.CYBERSYN.us_addresses AS addr\nJOIN zip_area_ranks AS areas\n    ON (addr.id_zip = areas.geo_id)\nWHERE addr.state = 'FL' AND areas.country = 'United States' AND areas.zip_area_rank = 1\nORDER BY LATITUDE DESC\nLIMIT 10;",
        "db_id": "US_ADDRESSES__POI",
        "No. of candidate columns": 61,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf009",
        "question": "A real estate company is looking for a comparison of the building types in Amsterdam and Rotterdam. They need to know the total surface area and the number of buildings for each type of building in both cities. Can you provide the building class and subclass, along with the total surface area and the number of buildings for both Amsterdam and Rotterdam?",
        "external_knowledge": null,
        "question_toks": [
            "A",
            "real",
            "estate",
            "company",
            "is",
            "looking",
            "for",
            "a",
            "comparison",
            "of",
            "the",
            "building",
            "types",
            "in",
            "Amsterdam",
            "and",
            "Rotterdam.",
            "They",
            "need",
            "to",
            "know",
            "the",
            "total",
            "surface",
            "area",
            "and",
            "the",
            "number",
            "of",
            "buildings",
            "for",
            "each",
            "type",
            "of",
            "building",
            "in",
            "both",
            "cities.",
            "Can",
            "you",
            "provide",
            "the",
            "building",
            "class",
            "and",
            "subclass,",
            "along",
            "with",
            "the",
            "total",
            "surface",
            "area",
            "and",
            "the",
            "number",
            "of",
            "buildings",
            "for",
            "both",
            "Amsterdam",
            "and",
            "Rotterdam?"
        ],
        "query": "",
        "db_id": "NETHERLANDS_OPEN_MAP_DATA",
        "No. of candidate columns": 91,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf013",
        "question": "Determine the total length of roads for each class and subclass in Amsterdam and Rotterdam, based on specific QUADKEY segments '12020210' and '12020211'? Show the class, subclass, and total road lengths for both cities",
        "external_knowledge": null,
        "question_toks": [
            "Determine",
            "the",
            "total",
            "length",
            "of",
            "roads",
            "for",
            "each",
            "class",
            "and",
            "subclass",
            "in",
            "Amsterdam",
            "and",
            "Rotterdam,",
            "based",
            "on",
            "specific",
            "QUADKEY",
            "segments",
            "'12020210'",
            "and",
            "'12020211'?",
            "Show",
            "the",
            "class,",
            "subclass,",
            "and",
            "total",
            "road",
            "lengths",
            "for",
            "both",
            "cities"
        ],
        "query": "",
        "db_id": "NETHERLANDS_OPEN_MAP_DATA",
        "No. of candidate columns": 91,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf041",
        "question": "Produce a report for ERCOT on October 1, 2022, that combines hourly data on day-ahead and real-time prices from node ID 10000697078, load forecasts (datatypeid 19060) and actual loads, plus wind (forecast datatypeid 9285, actual datatypeid 16) and solar (forecast datatypeid 662, actual datatypeid 650) generation forecasts and actuals from object ID 10000712973. This report should include time zone alignments, peak classifications, and net load calculations, providing insights into daily operational dynamics and efficiency.",
        "temporal": "Yes",
        "external_knowledge": "ERCOT_Daily_Market_Dynamics_Report.md",
        "question_toks": [
            "Produce",
            "a",
            "report",
            "for",
            "ERCOT",
            "on",
            "October",
            "1,",
            "2022,",
            "that",
            "combines",
            "hourly",
            "data",
            "on",
            "day-ahead",
            "and",
            "real-time",
            "prices",
            "from",
            "node",
            "ID",
            "10000697078,",
            "load",
            "forecasts",
            "(datatypeid",
            "19060)",
            "and",
            "actual",
            "loads,",
            "plus",
            "wind",
            "(forecast",
            "datatypeid",
            "9285,",
            "actual",
            "datatypeid",
            "16)",
            "and",
            "solar",
            "(forecast",
            "datatypeid",
            "662,",
            "actual",
            "datatypeid",
            "650)",
            "generation",
            "forecasts",
            "and",
            "actuals",
            "from",
            "object",
            "ID",
            "10000712973.",
            "This",
            "report",
            "should",
            "include",
            "time",
            "zone",
            "alignments,",
            "peak",
            "classifications,",
            "and",
            "net",
            "load",
            "calculations,",
            "providing",
            "insights",
            "into",
            "daily",
            "operational",
            "dynamics",
            "and",
            "efficiency."
        ],
        "query": "",
        "db_id": "YES_ENERGY__SAMPLE_DATA",
        "No. of candidate columns": 218,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq002",
        "question": "During the first half of 2017,  focusing on hits product revenue, which traffic source generated the highest total product revenue, and what were the maximum daily, weekly, and monthly product revenues (in millions) for that top-performing source over this period?",
        "external_knowledge": "google_analytics_sample.ga_sessions.md",
        "question_toks": [
            "During",
            "the",
            "first",
            "half",
            "of",
            "2017,",
            "",
            "focusing",
            "on",
            "hits",
            "product",
            "revenue,",
            "which",
            "traffic",
            "source",
            "generated",
            "the",
            "highest",
            "total",
            "product",
            "revenue,",
            "and",
            "what",
            "were",
            "the",
            "maximum",
            "daily,",
            "weekly,",
            "and",
            "monthly",
            "product",
            "revenues",
            "(in",
            "millions)",
            "for",
            "that",
            "top-performing",
            "source",
            "over",
            "this",
            "period?"
        ],
        "query": "",
        "db_id": "ga360",
        "No. of candidate columns": 5522,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq003",
        "question": "Between April 1 and July 31 of 2017, using the hits product revenue data along with the totals transactions to classify sessions as purchase (transactions ≥ 1 and productRevenue not null) or non-purchase (transactions null and productRevenue null), compare the average pageviews per visitor for each group by month",
        "external_knowledge": "google_analytics_sample.ga_sessions.md",
        "question_toks": [
            "Between",
            "April",
            "1",
            "and",
            "July",
            "31",
            "of",
            "2017,",
            "using",
            "the",
            "hits",
            "product",
            "revenue",
            "data",
            "along",
            "with",
            "the",
            "totals",
            "transactions",
            "to",
            "classify",
            "sessions",
            "as",
            "purchase",
            "(transactions",
            "≥",
            "1",
            "and",
            "productRevenue",
            "not",
            "null)",
            "or",
            "non-purchase",
            "(transactions",
            "null",
            "and",
            "productRevenue",
            "null),",
            "compare",
            "the",
            "average",
            "pageviews",
            "per",
            "visitor",
            "for",
            "each",
            "group",
            "by",
            "month"
        ],
        "query": "",
        "db_id": "ga360",
        "No. of candidate columns": 5522,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq004",
        "question": "In July 2017, among all visitors who bought any YouTube-related product, which distinct product—excluding those containing ‘YouTube’ in the product name—had the highest total quantity purchased?",
        "external_knowledge": "google_analytics_sample.ga_sessions.md",
        "question_toks": [
            "In",
            "July",
            "2017,",
            "among",
            "all",
            "visitors",
            "who",
            "bought",
            "any",
            "YouTube-related",
            "product,",
            "which",
            "distinct",
            "product—excluding",
            "those",
            "containing",
            "‘YouTube’",
            "in",
            "the",
            "product",
            "name—had",
            "the",
            "highest",
            "total",
            "quantity",
            "purchased?"
        ],
        "query": "",
        "db_id": "ga360",
        "No. of candidate columns": 5522,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq008",
        "question": "In January 2017, among visitors whose campaign name contains 'Data Share' and who accessed any page starting with '/home', which page did they most commonly visit next, and what is the maximum time (in seconds) they spent on the '/home' page before moving on?",
        "external_knowledge": "google_analytics_sample.ga_sessions.md",
        "question_toks": [
            "In",
            "January",
            "2017,",
            "among",
            "visitors",
            "whose",
            "campaign",
            "name",
            "contains",
            "'Data",
            "Share'",
            "and",
            "who",
            "accessed",
            "any",
            "page",
            "starting",
            "with",
            "'/home',",
            "which",
            "page",
            "did",
            "they",
            "most",
            "commonly",
            "visit",
            "next,",
            "and",
            "what",
            "is",
            "the",
            "maximum",
            "time",
            "(in",
            "seconds)",
            "they",
            "spent",
            "on",
            "the",
            "'/home'",
            "page",
            "before",
            "moving",
            "on?"
        ],
        "query": "",
        "db_id": "ga360",
        "No. of candidate columns": 5522,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq275",
        "question": "which visitor IDs belong to users whose first transaction occurred on a mobile device on a later date than their first visit?",
        "external_knowledge": null,
        "question_toks": [
            "which",
            "visitor",
            "IDs",
            "belong",
            "to",
            "users",
            "whose",
            "first",
            "transaction",
            "occurred",
            "on",
            "a",
            "mobile",
            "device",
            "on",
            "a",
            "later",
            "date",
            "than",
            "their",
            "first",
            "visit?"
        ],
        "query": "WITH \n  visit AS (\n    SELECT fullvisitorid, MIN(date) AS date_first_visit\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` \n    GROUP BY fullvisitorid\n  ),\n  \n  transactions AS (\n    SELECT fullvisitorid, MIN(date) AS date_transactions, 1 AS transaction\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga, \n    UNNEST(ga.hits) AS hits \n    WHERE hits.transaction.transactionId IS NOT NULL \n    GROUP BY fullvisitorid\n  ),\n\n  device_transactions AS (\n    SELECT DISTINCT fullvisitorid, date, device.deviceCategory AS device_transaction\n    FROM `bigquery-public-data.google_analytics_sample.ga_sessions_*` AS ga, \n    UNNEST(ga.hits) AS hits \n    WHERE hits.transaction.transactionId IS NOT NULL\n  ),\n\n  visits_transactions AS (\n    SELECT visit.fullvisitorid, date_first_visit, date_transactions, device_transaction\n    FROM visit \n    LEFT JOIN transactions ON visit.fullvisitorid = transactions.fullvisitorid\n    LEFT JOIN device_transactions ON visit.fullvisitorid = device_transactions.fullvisitorid \n    AND transactions.date_transactions = device_transactions.date\n  )\n\nSELECT fullvisitorid \nFROM visits_transactions\nWHERE DATE_DIFF(PARSE_DATE('%Y%m%d', date_transactions), PARSE_DATE('%Y%m%d', date_first_visit), DAY) > 0\nAND device_transaction = \"mobile\";",
        "db_id": "ga360",
        "No. of candidate columns": 5522,
        "No. of gold tables": 20
    },
    {
        "instance_id": "sf_bq247",
        "question": "From the publications dataset, first identify the top six families with the most publications whose family_id is not '-1'. Then, using the abs_and_emb table (joined on publication_number), provide each of those families’ IDs alongside every non-empty abstract associated with their publications.",
        "external_knowledge": null,
        "question_toks": [
            "From",
            "the",
            "publications",
            "dataset,",
            "first",
            "identify",
            "the",
            "top",
            "six",
            "families",
            "with",
            "the",
            "most",
            "publications",
            "whose",
            "family_id",
            "is",
            "not",
            "'-1'.",
            "Then,",
            "using",
            "the",
            "abs_and_emb",
            "table",
            "(joined",
            "on",
            "publication_number),",
            "provide",
            "each",
            "of",
            "those",
            "families’",
            "IDs",
            "alongside",
            "every",
            "non-empty",
            "abstract",
            "associated",
            "with",
            "their",
            "publications."
        ],
        "query": "",
        "db_id": "PATENTS_GOOGLE",
        "No. of candidate columns": 87,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq215",
        "question": "Which US patent (with a B2 kind code and a grant date between 2015 and 2018) has the highest originality score calculated as 1 - (the sum of squared occurrences of distinct 4-digit IPC codes in its backward citations divided by the square of the total occurrences of these 4-digit IPC codes)?",
        "external_knowledge": "patents_info.md",
        "question_toks": [
            "Which",
            "US",
            "patent",
            "(with",
            "a",
            "B2",
            "kind",
            "code",
            "and",
            "a",
            "grant",
            "date",
            "between",
            "2015",
            "and",
            "2018)",
            "has",
            "the",
            "highest",
            "originality",
            "score",
            "calculated",
            "as",
            "1",
            "-",
            "(the",
            "sum",
            "of",
            "squared",
            "occurrences",
            "of",
            "distinct",
            "4-digit",
            "IPC",
            "codes",
            "in",
            "its",
            "backward",
            "citations",
            "divided",
            "by",
            "the",
            "square",
            "of",
            "the",
            "total",
            "occurrences",
            "of",
            "these",
            "4-digit",
            "IPC",
            "codes)?"
        ],
        "query": "",
        "db_id": "PATENTS",
        "No. of candidate columns": 79,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq221",
        "question": "Identify the CPC technology areas with the highest exponential moving average of patent filings each year (with a smoothing factor of 0.2), considering only the first CPC code for each patent that has a valid filing date and a non-empty application number, and report the full CPC title along with the best year associated with the highest exponential moving average for each CPC group at level 5.",
        "external_knowledge": "sliding_windows_calculation_cpc.md",
        "question_toks": [
            "Identify",
            "the",
            "CPC",
            "technology",
            "areas",
            "with",
            "the",
            "highest",
            "exponential",
            "moving",
            "average",
            "of",
            "patent",
            "filings",
            "each",
            "year",
            "(with",
            "a",
            "smoothing",
            "factor",
            "of",
            "0.2),",
            "considering",
            "only",
            "the",
            "first",
            "CPC",
            "code",
            "for",
            "each",
            "patent",
            "that",
            "has",
            "a",
            "valid",
            "filing",
            "date",
            "and",
            "a",
            "non-empty",
            "application",
            "number,",
            "and",
            "report",
            "the",
            "full",
            "CPC",
            "title",
            "along",
            "with",
            "the",
            "best",
            "year",
            "associated",
            "with",
            "the",
            "highest",
            "exponential",
            "moving",
            "average",
            "for",
            "each",
            "CPC",
            "group",
            "at",
            "level",
            "5."
        ],
        "query": "WITH patent_cpcs AS (\n    SELECT\n        cd.\"parents\",\n        CAST(FLOOR(\"filing_date\" / 10000) AS INT) AS \"filing_year\"\n    FROM (\n        SELECT\n            MAX(\"cpc\") AS \"cpc\", MAX(\"filing_date\") AS \"filing_date\"\n        FROM\n            PATENTS.PATENTS.PUBLICATIONS\n        WHERE \n            \"application_number\" != ''\n        GROUP BY\n            \"application_number\"\n    ) AS publications\n    , LATERAL FLATTEN(INPUT => \"cpc\") AS cpcs\n    JOIN\n        PATENTS.PATENTS.CPC_DEFINITION cd ON cd.\"symbol\" = cpcs.value:\"code\"\n    WHERE \n        cpcs.value:\"first\" = TRUE\n          AND \"filing_date\" > 0\n\n),\nyearly_counts AS (\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        COUNT(*) AS \"cnt\"\n    FROM (\n        SELECT\n            cpc_parent.value::STRING AS \"cpc_group\",\n            \"filing_year\"\n        FROM patent_cpcs,\n             LATERAL FLATTEN(input => patent_cpcs.\"parents\") AS cpc_parent\n    )\n    GROUP BY \"cpc_group\", \"filing_year\"\n),\nordered_counts AS (\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        \"cnt\",\n        ROW_NUMBER() OVER (PARTITION BY \"cpc_group\" ORDER BY \"filing_year\" ASC) AS rn\n    FROM yearly_counts\n),\nrecursive_ema AS (\n    -- Anchor member: first year per cpc_group\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        \"cnt\",\n        \"cnt\" * 0.2 + 0 * 0.8 AS \"ema\",\n        rn\n    FROM ordered_counts\n    WHERE rn = 1\n\n    UNION ALL\n\n    -- Recursive member: subsequent years\n    SELECT\n        oc.\"cpc_group\",\n        oc.\"filing_year\",\n        oc.\"cnt\",\n        oc.\"cnt\" * 0.2 + re.\"ema\" * 0.8 AS \"ema\",\n        oc.rn\n    FROM ordered_counts oc\n    JOIN recursive_ema re\n        ON oc.\"cpc_group\" = re.\"cpc_group\"\n       AND oc.rn = re.rn + 1\n),\nmax_ema AS (\n    SELECT\n        \"cpc_group\",\n        \"filing_year\",\n        \"ema\"\n    FROM recursive_ema\n),\nranked_ema AS (\n    SELECT\n        me.\"cpc_group\",\n        me.\"filing_year\",\n        me.\"ema\",\n        ROW_NUMBER() OVER (\n            PARTITION BY me.\"cpc_group\" \n            ORDER BY me.\"ema\" DESC, me.\"filing_year\" DESC\n        ) AS rn_rank\n    FROM max_ema me\n)\nSELECT \n    c.\"titleFull\",\n    REPLACE(r.\"cpc_group\", '\"', '') AS \"cpc_group\",\n    r.\"filing_year\" AS \"best_filing_year\"\nFROM ranked_ema r\nJOIN \"PATENTS\".\"PATENTS\".\"CPC_DEFINITION\" c \n    ON r.\"cpc_group\" = c.\"symbol\"\nWHERE \n    c.\"level\" = 5\n    AND r.rn_rank = 1\nORDER BY \n    c.\"titleFull\", \n    \"cpc_group\" ASC;",
        "db_id": "PATENTS",
        "No. of candidate columns": 79,
        "No. of gold tables": 3
    },
    {
        "instance_id": "sf_bq207",
        "question": "Could you provide the earliest publication numbers, corresponding application numbers, claim numbers, and word counts for the top 100 independent patent claims, based on the highest word count, retrieved from claims stats within uspto_oce_claims (filtered by ind_flg='1'), matched with their publication numbers from uspto_oce_claims match, and further joined with patents publications to ensure only the earliest publication for each application is included, ordered by descending word count, and limited to the top 100 results?",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Could",
            "you",
            "provide",
            "the",
            "earliest",
            "publication",
            "numbers,",
            "corresponding",
            "application",
            "numbers,",
            "claim",
            "numbers,",
            "and",
            "word",
            "counts",
            "for",
            "the",
            "top",
            "100",
            "independent",
            "patent",
            "claims,",
            "based",
            "on",
            "the",
            "highest",
            "word",
            "count,",
            "retrieved",
            "from",
            "claims",
            "stats",
            "within",
            "uspto_oce_claims",
            "(filtered",
            "by",
            "ind_flg='1'),",
            "matched",
            "with",
            "their",
            "publication",
            "numbers",
            "from",
            "uspto_oce_claims",
            "match,",
            "and",
            "further",
            "joined",
            "with",
            "patents",
            "publications",
            "to",
            "ensure",
            "only",
            "the",
            "earliest",
            "publication",
            "for",
            "each",
            "application",
            "is",
            "included,",
            "ordered",
            "by",
            "descending",
            "word",
            "count,",
            "and",
            "limited",
            "to",
            "the",
            "top",
            "100",
            "results?"
        ],
        "query": "",
        "db_id": "PATENTS_USPTO",
        "No. of candidate columns": 419,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq100",
        "question": "How can we identify the top 10 most frequently used packages in GitHub repository contents by looking for import statements enclosed in parentheses, splitting any multi-line imports by newlines, extracting package names that appear within double quotes, counting how often these packages appear, ignoring any null results, and finally ordering them in descending order of their frequency? The final answer should remove the quotation marks.",
        "external_knowledge": null,
        "question_toks": [
            "How",
            "can",
            "we",
            "identify",
            "the",
            "top",
            "10",
            "most",
            "frequently",
            "used",
            "packages",
            "in",
            "GitHub",
            "repository",
            "contents",
            "by",
            "looking",
            "for",
            "import",
            "statements",
            "enclosed",
            "in",
            "parentheses,",
            "splitting",
            "any",
            "multi-line",
            "imports",
            "by",
            "newlines,",
            "extracting",
            "package",
            "names",
            "that",
            "appear",
            "within",
            "double",
            "quotes,",
            "counting",
            "how",
            "often",
            "these",
            "packages",
            "appear,",
            "ignoring",
            "any",
            "null",
            "results,",
            "and",
            "finally",
            "ordering",
            "them",
            "in",
            "descending",
            "order",
            "of",
            "their",
            "frequency?",
            "The",
            "final",
            "answer",
            "should",
            "remove",
            "the",
            "quotation",
            "marks."
        ],
        "query": "",
        "db_id": "GITHUB_REPOS",
        "No. of candidate columns": 34,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq101",
        "question": "From GitHub Repos contents, how can we identify the top 10 most frequently imported package names in Java source files by splitting each file's content into lines, filtering for valid import statements, extracting only the package portion using a suitable regex, grouping by these extracted package names, counting their occurrences, and finally returning the 10 packages that appear most often in descending order of frequency?",
        "external_knowledge": null,
        "question_toks": [
            "From",
            "GitHub",
            "Repos",
            "contents,",
            "how",
            "can",
            "we",
            "identify",
            "the",
            "top",
            "10",
            "most",
            "frequently",
            "imported",
            "package",
            "names",
            "in",
            "Java",
            "source",
            "files",
            "by",
            "splitting",
            "each",
            "file's",
            "content",
            "into",
            "lines,",
            "filtering",
            "for",
            "valid",
            "import",
            "statements,",
            "extracting",
            "only",
            "the",
            "package",
            "portion",
            "using",
            "a",
            "suitable",
            "regex,",
            "grouping",
            "by",
            "these",
            "extracted",
            "package",
            "names,",
            "counting",
            "their",
            "occurrences,",
            "and",
            "finally",
            "returning",
            "the",
            "10",
            "packages",
            "that",
            "appear",
            "most",
            "often",
            "in",
            "descending",
            "order",
            "of",
            "frequency?"
        ],
        "query": "",
        "db_id": "GITHUB_REPOS",
        "No. of candidate columns": 34,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq182",
        "question": "Which primary programming languages, determined by the highest number of bytes in each repository, had at least 100 PullRequestEvents on January 18, 2023 across all their repositories?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "primary",
            "programming",
            "languages,",
            "determined",
            "by",
            "the",
            "highest",
            "number",
            "of",
            "bytes",
            "in",
            "each",
            "repository,",
            "had",
            "at",
            "least",
            "100",
            "PullRequestEvents",
            "on",
            "January",
            "18,",
            "2023",
            "across",
            "all",
            "their",
            "repositories?"
        ],
        "query": "WITH\n  event_data AS (\n    SELECT\n      \"type\",\n      EXTRACT(YEAR FROM TO_TIMESTAMP(\"created_at\" / 1000000)) AS \"year\",\n      EXTRACT(QUARTER FROM TO_TIMESTAMP(\"created_at\" / 1000000)) AS \"quarter\",\n      REGEXP_REPLACE(\n        \"repo\"::variant:\"url\"::string,\n        'https:\\\\/\\\\/github\\\\.com\\\\/|https:\\\\/\\\\/api\\\\.github\\\\.com\\\\/repos\\\\/',\n        ''\n      ) AS \"name\"\n    FROM GITHUB_REPOS_DATE.DAY._20230118\n  ),\n\n  repo_languages AS (\n    SELECT\n      \"repo_name\" AS \"name\",\n      \"lang\"\n    FROM (\n      SELECT\n        \"repo_name\",\n        FIRST_VALUE(\"language\") OVER (\n          PARTITION BY \"repo_name\" ORDER BY \"bytes\" DESC\n        ) AS \"lang\"\n      FROM (\n        SELECT\n          \"repo_name\",\n          \"language\".value:\"name\" AS \"language\",\n          \"language\".value:\"bytes\" AS \"bytes\"\n        FROM GITHUB_REPOS_DATE.GITHUB_REPOS.LANGUAGES,\n        LATERAL FLATTEN(INPUT => \"language\") AS \"language\"\n      )\n    )\n    WHERE \"lang\" IS NOT NULL\n    GROUP BY \"repo_name\", \"lang\"\n  ),\n\n  joined_data AS (\n    SELECT\n      a.\"type\" AS \"type\",\n      b.\"lang\" AS \"language\",\n      a.\"year\" AS \"year\",\n      a.\"quarter\" AS \"quarter\"\n    FROM event_data a\n    JOIN repo_languages b\n      ON a.\"name\" = b.\"name\"\n  ),\n\n  count_data AS (\n    SELECT\n      \"language\",\n      \"year\",\n      \"quarter\",\n      \"type\",\n      COUNT(*) AS \"count\"\n    FROM joined_data\n    GROUP BY \"type\", \"language\", \"year\", \"quarter\"\n    ORDER BY \"year\", \"quarter\", \"count\" DESC\n  )\n\nSELECT\n  REPLACE(\"language\", '\"', '') AS \"language_name\",\n  \"count\"\nFROM count_data\nWHERE \"count\" >= 5\n  AND \"type\" = 'PullRequestEvent';",
        "db_id": "GITHUB_REPOS_DATE",
        "No. of candidate columns": 304,
        "No. of gold tables": 1
    },
    {
        "instance_id": "sf_bq217",
        "question": "On January 18, 2023, how many pull requests were created in GitHub repositories that include JavaScript as one of their programming languages, according to the data from githubarchive 20230118 and the language records in github_repos languages?",
        "external_knowledge": null,
        "question_toks": [
            "On",
            "January",
            "18,",
            "2023,",
            "how",
            "many",
            "pull",
            "requests",
            "were",
            "created",
            "in",
            "GitHub",
            "repositories",
            "that",
            "include",
            "JavaScript",
            "as",
            "one",
            "of",
            "their",
            "programming",
            "languages,",
            "according",
            "to",
            "the",
            "data",
            "from",
            "githubarchive",
            "20230118",
            "and",
            "the",
            "language",
            "records",
            "in",
            "github_repos",
            "languages?"
        ],
        "query": "",
        "db_id": "GITHUB_REPOS_DATE",
        "No. of candidate columns": 304,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq191",
        "question": "From the 2017 GitHub WatchEvent data, find the top two repositories that have more than 300 distinct watchers, ensuring the results are joined with the 'sample_files' table so that we return each repository's name along with its distinct watcher count, and limit the output to the two repositories with the highest watcher counts.",
        "external_knowledge": null,
        "question_toks": [
            "From",
            "the",
            "2017",
            "GitHub",
            "WatchEvent",
            "data,",
            "find",
            "the",
            "top",
            "two",
            "repositories",
            "that",
            "have",
            "more",
            "than",
            "300",
            "distinct",
            "watchers,",
            "ensuring",
            "the",
            "results",
            "are",
            "joined",
            "with",
            "the",
            "'sample_files'",
            "table",
            "so",
            "that",
            "we",
            "return",
            "each",
            "repository's",
            "name",
            "along",
            "with",
            "its",
            "distinct",
            "watcher",
            "count,",
            "and",
            "limit",
            "the",
            "output",
            "to",
            "the",
            "two",
            "repositories",
            "with",
            "the",
            "highest",
            "watcher",
            "counts."
        ],
        "query": "",
        "db_id": "GITHUB_REPOS_DATE",
        "No. of candidate columns": 304,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq225",
        "question": "From the GitHub repository files in 'github_repos.sample_files' joined with 'github_repos.sample_contents', which 10 programming languages occur most frequently (based on recognized file extensions) in files that have non-empty content, ordered by their file counts in descending order?",
        "external_knowledge": "lang_and_ext.md",
        "question_toks": [
            "From",
            "the",
            "GitHub",
            "repository",
            "files",
            "in",
            "'github_repos.sample_files'",
            "joined",
            "with",
            "'github_repos.sample_contents',",
            "which",
            "10",
            "programming",
            "languages",
            "occur",
            "most",
            "frequently",
            "(based",
            "on",
            "recognized",
            "file",
            "extensions)",
            "in",
            "files",
            "that",
            "have",
            "non-empty",
            "content,",
            "ordered",
            "by",
            "their",
            "file",
            "counts",
            "in",
            "descending",
            "order?"
        ],
        "query": "",
        "db_id": "GITHUB_REPOS",
        "No. of candidate columns": 34,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq233",
        "question": "Can you analyze the joined data from github repos files and github_repos contents, focusing only on files ending with '.py' or '.r', then extract Python modules from 'import' or 'from ... import' lines and R libraries from 'library(...)' lines, count their occurrences, and finally list the results sorted by language and by the number of occurrences in descending order?",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "analyze",
            "the",
            "joined",
            "data",
            "from",
            "github",
            "repos",
            "files",
            "and",
            "github_repos",
            "contents,",
            "focusing",
            "only",
            "on",
            "files",
            "ending",
            "with",
            "'.py'",
            "or",
            "'.r',",
            "then",
            "extract",
            "Python",
            "modules",
            "from",
            "'import'",
            "or",
            "'from",
            "...",
            "import'",
            "lines",
            "and",
            "R",
            "libraries",
            "from",
            "'library(...)'",
            "lines,",
            "count",
            "their",
            "occurrences,",
            "and",
            "finally",
            "list",
            "the",
            "results",
            "sorted",
            "by",
            "language",
            "and",
            "by",
            "the",
            "number",
            "of",
            "occurrences",
            "in",
            "descending",
            "order?"
        ],
        "query": "WITH extracted_modules AS (\nSELECT \n    el.\"file_id\" AS \"file_id\", \n    el.\"repo_name\", \n    el.\"path\" AS \"path_\", \n    REPLACE(line.value, '\"', '') AS \"line_\",\n    CASE\n        WHEN ENDSWITH(el.\"path\", '.py') THEN 'python'\n        WHEN ENDSWITH(el.\"path\", '.r') THEN 'r'\n        ELSE NULL\n    END AS \"language\",\n    CASE\n        WHEN ENDSWITH(el.\"path\", '.py') THEN\n            ARRAY_CAT(\n                ARRAY_CONSTRUCT(REGEXP_SUBSTR(line.value, '\\\\bimport\\\\s+(\\\\w+)', 1, 1, 'e')),\n                ARRAY_CONSTRUCT(REGEXP_SUBSTR(line.value, '\\\\bfrom\\\\s+(\\\\w+)', 1, 1, 'e'))\n            )\n        WHEN ENDSWITH(el.\"path\", '.r') THEN\n            ARRAY_CONSTRUCT(REGEXP_SUBSTR(line.value, 'library\\\\s*\\\\(\\\\s*([^\\\\s)]+)\\\\s*\\\\)', 1, 1, 'e'))\n        ELSE ARRAY_CONSTRUCT()\n    END AS \"modules\"\nFROM (\n    SELECT\n        ct.\"id\" AS \"file_id\", \n        fl.\"repo_name\" AS \"repo_name\", \n        fl.\"path\", \n        SPLIT(REPLACE(ct.\"content\", '\\n', ' \\n'), '\\n') AS \"lines\"\n    FROM \n        GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_FILES AS fl\n    JOIN \n        GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_CONTENTS AS ct \n        ON fl.\"id\" = ct.\"id\"\n) AS el,\nLATERAL FLATTEN(input => el.\"lines\") AS line \nWHERE\n    (\n        ENDSWITH(\"path_\", '.py') \n        AND \n        (\n            \"line_\" LIKE 'import %' \n            OR \n            \"line_\" LIKE 'from %'\n        )\n    )\n    OR\n    (\n        ENDSWITH(\"path_\", '.r') \n        AND \n        \"line_\" LIKE 'library%('\n    )\n\n),\nmodule_counts AS (\n    SELECT \n        em.\"language\",\n        f.value::STRING AS \"module\",\n        COUNT(*) AS \"occurrence_count\"\n    FROM \n        extracted_modules AS em,\n        LATERAL FLATTEN(input => em.\"modules\") AS f\n    WHERE \n        em.\"modules\" IS NOT NULL\n        AND f.value IS NOT NULL\n    GROUP BY \n        em.\"language\", \n        f.value\n),\npython AS (\n    SELECT \n        \"language\",\n        \"module\",\n        \"occurrence_count\"\n    FROM \n        module_counts\n    WHERE \n        \"language\" = 'python'\n),\nrlanguage AS (\n    SELECT \n        \"language\",\n        \"module\",\n        \"occurrence_count\"\n    FROM \n        module_counts AS mc_inner\n    WHERE \n        \"language\" = 'r'\n)\nSELECT \n    *\nFROM \n    python\nUNION ALL\nSELECT \n    *\nFROM \n    rlanguage\nORDER BY \n    \"language\", \n    \"occurrence_count\" DESC;",
        "db_id": "GITHUB_REPOS",
        "No. of candidate columns": 34,
        "No. of gold tables": 2
    },
    {
        "instance_id": "sf_bq248",
        "question": "Among all repositories that do not use any programming language whose name (case-insensitively) includes the substring \"python,\" what is the proportion of files whose paths include \"readme.md\" and whose contents contain the phrase \"Copyright (c)\"?",
        "external_knowledge": null,
        "question_toks": [
            "Among",
            "all",
            "repositories",
            "that",
            "do",
            "not",
            "use",
            "any",
            "programming",
            "language",
            "whose",
            "name",
            "(case-insensitively)",
            "includes",
            "the",
            "substring",
            "\"python,\"",
            "what",
            "is",
            "the",
            "proportion",
            "of",
            "files",
            "whose",
            "paths",
            "include",
            "\"readme.md\"",
            "and",
            "whose",
            "contents",
            "contain",
            "the",
            "phrase",
            "\"Copyright",
            "(c)\"?"
        ],
        "query": "WITH requests AS (\n    SELECT \n        D.\"id\",\n        D.\"content\",\n        E.\"repo_name\",\n        E.\"path\"\n    FROM \n        (\n            SELECT \n                \"id\",\n                \"content\"\n            FROM \n                GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS\n            GROUP BY \n                \"id\", \"content\"\n        ) AS D\n    INNER JOIN \n        (\n            SELECT \n                C.\"id\",\n                C.\"repo_name\",\n                C.\"path\"\n            FROM \n                (\n                    SELECT \n                        \"id\",\n                        \"repo_name\",\n                        \"path\"\n                    FROM \n                        GITHUB_REPOS.GITHUB_REPOS.SAMPLE_FILES\n                    WHERE \n                        LOWER(\"path\") LIKE '%readme.md'\n                    GROUP BY \n                        \"path\", \"id\", \"repo_name\"\n                ) AS C\n            INNER JOIN \n                (\n                    SELECT \n                        \"repo_name\",\n                        language_struct.value:\"name\"::STRING AS \"language_name\"\n                    FROM \n                        GITHUB_REPOS.GITHUB_REPOS.LANGUAGES,\n                        LATERAL FLATTEN(input => \"language\") AS language_struct\n                    WHERE \n                        LOWER(language_struct.value:\"name\"::STRING) NOT LIKE '%python%'\n                    GROUP BY \n                        \"language_name\", \"repo_name\"\n                ) AS F\n            ON \n                C.\"repo_name\" = F.\"repo_name\"\n        ) AS E\n    ON \n        D.\"id\" = E.\"id\"\n)\nSELECT \n    (SELECT COUNT(*) FROM requests WHERE \"content\" LIKE '%Copyright (c)%') / COUNT(*) AS \"proportion\"\nFROM \n    requests;",
        "db_id": "GITHUB_REPOS",
        "No. of candidate columns": 34,
        "No. of gold tables": 3
    },
    {
        "instance_id": "sf_bq193",
        "question": "Retrieve all non-empty, non-commented lines from `README.md` files in GitHub repositories, excluding lines that are comments (either starting with `#` for Markdown or `//` for code comments). For each line, calculate how often each unique line appears across all repositories and return a comma-separated list of the programming languages used in each repository containing that line, sorted alphabetically, with the results ordered by the frequency of occurrence in descending order.",
        "external_knowledge": null,
        "question_toks": [
            "Retrieve",
            "all",
            "non-empty,",
            "non-commented",
            "lines",
            "from",
            "`README.md`",
            "files",
            "in",
            "GitHub",
            "repositories,",
            "excluding",
            "lines",
            "that",
            "are",
            "comments",
            "(either",
            "starting",
            "with",
            "`#`",
            "for",
            "Markdown",
            "or",
            "`//`",
            "for",
            "code",
            "comments).",
            "For",
            "each",
            "line,",
            "calculate",
            "how",
            "often",
            "each",
            "unique",
            "line",
            "appears",
            "across",
            "all",
            "repositories",
            "and",
            "return",
            "a",
            "comma-separated",
            "list",
            "of",
            "the",
            "programming",
            "languages",
            "used",
            "in",
            "each",
            "repository",
            "containing",
            "that",
            "line,",
            "sorted",
            "alphabetically,",
            "with",
            "the",
            "results",
            "ordered",
            "by",
            "the",
            "frequency",
            "of",
            "occurrence",
            "in",
            "descending",
            "order."
        ],
        "query": "WITH content_extracted AS (\n    SELECT \n        \"D\".\"id\" AS \"id\",\n        \"repo_name\",\n        \"path\",\n        SPLIT(\"content\", '\\n') AS \"lines\",\n        \"language_name\"\n    FROM \n        (\n            SELECT \n                \"id\",\n                \"content\"\n            FROM \n                \"GITHUB_REPOS\".\"GITHUB_REPOS\".\"SAMPLE_CONTENTS\"\n        ) AS \"D\"\n    INNER JOIN \n        (\n            SELECT \n                \"id\",\n                \"C\".\"repo_name\" AS \"repo_name\",\n                \"path\",\n                \"language_name\"\n            FROM \n                (\n                    SELECT \n                        \"id\",\n                        \"repo_name\",\n                        \"path\"\n                    FROM \n                        \"GITHUB_REPOS\".\"GITHUB_REPOS\".\"SAMPLE_FILES\"\n                    WHERE \n                        LOWER(\"path\") LIKE '%readme.md'\n                ) AS \"C\"\n            INNER JOIN \n                (\n                    SELECT \n                        \"repo_name\",\n                        \"language_struct\".value:\"name\" AS \"language_name\"\n                    FROM \n                        (\n                            SELECT \n                                \"repo_name\", \n                                \"language\"\n                            FROM \n                                \"GITHUB_REPOS\".\"GITHUB_REPOS\".\"LANGUAGES\"\n                        )\n                    CROSS JOIN \n                        LATERAL FLATTEN(INPUT => \"language\") AS \"language_struct\"\n                ) AS \"F\"\n            ON \n                \"C\".\"repo_name\" = \"F\".\"repo_name\"\n        ) AS \"E\"\n    ON \n        \"E\".\"id\" = \"D\".\"id\"\n),\nnon_empty_lines AS (\n    SELECT \n        \"line\".value AS \"line_\",\n        \"language_name\"\n    FROM \n        content_extracted,\n        LATERAL FLATTEN(INPUT => \"lines\") AS \"line\"\n    WHERE \n        TRIM(\"line\".value) != ''\n        AND NOT STARTSWITH(TRIM(\"line\".value), '#')\n        AND NOT STARTSWITH(TRIM(\"line\".value), '//')\n),\naggregated_languages AS (\n    SELECT \n        \"line_\",\n        COUNT(*) AS \"frequency\",\n        ARRAY_AGG(\"language_name\") AS \"languages\"\n    FROM \n        non_empty_lines\n    GROUP BY \n        \"line_\"\n)\n\nSELECT \n    REGEXP_REPLACE(\"line_\", '^\"|\"$', '') AS \"line\",\n    \"frequency\",\n    ARRAY_TO_STRING(ARRAY_SORT(\"languages\"), ', ') AS \"languages_sorted\"\nFROM \n    aggregated_languages\nORDER BY \n    \"frequency\" DESC;",
        "db_id": "GITHUB_REPOS",
        "No. of candidate columns": 34,
        "No. of gold tables": 3
    },
    {
        "instance_id": "sf_bq295",
        "question": "Using the 2017 GitHub Archive data for watch events, which three repositories that include at least one Python file (with a .py extension) smaller than 15,000 bytes and containing the substring \"def \" in its content have the highest total number of watch events for that year?",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "the",
            "2017",
            "GitHub",
            "Archive",
            "data",
            "for",
            "watch",
            "events,",
            "which",
            "three",
            "repositories",
            "that",
            "include",
            "at",
            "least",
            "one",
            "Python",
            "file",
            "(with",
            "a",
            ".py",
            "extension)",
            "smaller",
            "than",
            "15,000",
            "bytes",
            "and",
            "containing",
            "the",
            "substring",
            "\"def",
            "\"",
            "in",
            "its",
            "content",
            "have",
            "the",
            "highest",
            "total",
            "number",
            "of",
            "watch",
            "events",
            "for",
            "that",
            "year?"
        ],
        "query": "WITH watched_repos AS (\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201701\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201702\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201703\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201704\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201705\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201706\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201707\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201708\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201709\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201710\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201711\n    WHERE\n        \"type\" = 'WatchEvent'\n    UNION ALL\n    SELECT\n        PARSE_JSON(\"repo\"):\"name\"::STRING AS \"repo\"\n    FROM \n        GITHUB_REPOS_DATE.MONTH._201712\n    WHERE\n        \"type\" = 'WatchEvent'\n),\n\nrepo_watch_counts AS (\n    SELECT\n        \"repo\",\n        COUNT(*) AS \"watch_count\"\n    FROM\n        watched_repos\n    GROUP BY\n        \"repo\"\n)\n\nSELECT\n    REPLACE(r.\"repo\", '\"', '') AS \"repo\",\n    r.\"watch_count\"\nFROM\n    GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_FILES AS f\nJOIN\n    GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_CONTENTS AS c\n    ON f.\"id\" = c.\"id\"\nJOIN \n    repo_watch_counts AS r\n    ON f.\"repo_name\" = r.\"repo\"\nWHERE\n    f.\"path\" LIKE '%.py' \n    AND c.\"size\" < 15000 \n    AND POSITION('def ' IN c.\"content\") > 0\nGROUP BY\n    r.\"repo\", r.\"watch_count\"\nORDER BY\n    r.\"watch_count\" DESC\nLIMIT \n    3;",
        "db_id": "GITHUB_REPOS_DATE",
        "No. of candidate columns": 304,
        "No. of gold tables": 3
    },
    {
        "instance_id": "sf_bq194",
        "question": "Among all Python (*.py), R (*.r, *.R, *.Rmd, *.rmd), and IPython notebook (*.ipynb) files in the GitHub sample dataset, which library or module is identified as the second most frequently imported or loaded based on the extracted import statements?",
        "external_knowledge": null,
        "question_toks": [
            "Among",
            "all",
            "Python",
            "(*.py),",
            "R",
            "(*.r,",
            "*.R,",
            "*.Rmd,",
            "*.rmd),",
            "and",
            "IPython",
            "notebook",
            "(*.ipynb)",
            "files",
            "in",
            "the",
            "GitHub",
            "sample",
            "dataset,",
            "which",
            "library",
            "or",
            "module",
            "is",
            "identified",
            "as",
            "the",
            "second",
            "most",
            "frequently",
            "imported",
            "or",
            "loaded",
            "based",
            "on",
            "the",
            "extracted",
            "import",
            "statements?"
        ],
        "query": "",
        "db_id": "GITHUB_REPOS",
        "No. of candidate columns": 34,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq019",
        "question": "In the 2014 CMS Medicare inpatient charges data, which DRG definition has the highest total number of discharges, and among the top three cities with the most discharges for that DRG definition, what are their respective weighted average total payments (weighted by total discharges)",
        "external_knowledge": null,
        "question_toks": [
            "In",
            "the",
            "2014",
            "CMS",
            "Medicare",
            "inpatient",
            "charges",
            "data,",
            "which",
            "DRG",
            "definition",
            "has",
            "the",
            "highest",
            "total",
            "number",
            "of",
            "discharges,",
            "and",
            "among",
            "the",
            "top",
            "three",
            "cities",
            "with",
            "the",
            "most",
            "discharges",
            "for",
            "that",
            "DRG",
            "definition,",
            "what",
            "are",
            "their",
            "respective",
            "weighted",
            "average",
            "total",
            "payments",
            "(weighted",
            "by",
            "total",
            "discharges)"
        ],
        "query": "",
        "db_id": "cms_data",
        "No. of candidate columns": 865,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq177",
        "question": "For the provider whose total inpatient Medicare cost from 2011 through 2015 is the highest (computed as the sum of average_medicare_payments multiplied by total_discharges), please list that provider’s yearly average inpatient cost and yearly average outpatient cost for each calendar year in this period, where the inpatient cost is calculated as the average of (average_medicare_payments × total_discharges) and the outpatient cost is calculated as the average of (average_total_payments × outpatient_services).",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "the",
            "provider",
            "whose",
            "total",
            "inpatient",
            "Medicare",
            "cost",
            "from",
            "2011",
            "through",
            "2015",
            "is",
            "the",
            "highest",
            "(computed",
            "as",
            "the",
            "sum",
            "of",
            "average_medicare_payments",
            "multiplied",
            "by",
            "total_discharges),",
            "please",
            "list",
            "that",
            "provider’s",
            "yearly",
            "average",
            "inpatient",
            "cost",
            "and",
            "yearly",
            "average",
            "outpatient",
            "cost",
            "for",
            "each",
            "calendar",
            "year",
            "in",
            "this",
            "period,",
            "where",
            "the",
            "inpatient",
            "cost",
            "is",
            "calculated",
            "as",
            "the",
            "average",
            "of",
            "(average_medicare_payments",
            "×",
            "total_discharges)",
            "and",
            "the",
            "outpatient",
            "cost",
            "is",
            "calculated",
            "as",
            "the",
            "average",
            "of",
            "(average_total_payments",
            "×",
            "outpatient_services)."
        ],
        "query": "",
        "db_id": "cms_data",
        "No. of candidate columns": 865,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq356",
        "question": "Among all NOAA GSOD weather stations that recorded valid daily temperature data (non-missing temp, max, min) in 2019 and whose period of record began on or before January 1, 2000, and continued through at least June 30, 2019, how many of these stations achieved 90% or more of the maximum possible number of valid temperature-record days in 2019?",
        "external_knowledge": null,
        "question_toks": [
            "Among",
            "all",
            "NOAA",
            "GSOD",
            "weather",
            "stations",
            "that",
            "recorded",
            "valid",
            "daily",
            "temperature",
            "data",
            "(non-missing",
            "temp,",
            "max,",
            "min)",
            "in",
            "2019",
            "and",
            "whose",
            "period",
            "of",
            "record",
            "began",
            "on",
            "or",
            "before",
            "January",
            "1,",
            "2000,",
            "and",
            "continued",
            "through",
            "at",
            "least",
            "June",
            "30,",
            "2019,",
            "how",
            "many",
            "of",
            "these",
            "stations",
            "achieved",
            "90%",
            "or",
            "more",
            "of",
            "the",
            "maximum",
            "possible",
            "number",
            "of",
            "valid",
            "temperature-record",
            "days",
            "in",
            "2019?"
        ],
        "query": "",
        "db_id": "noaa_data",
        "No. of candidate columns": 7278,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq042",
        "question": "Can you help me retrieve the average temperature, average wind speed, and precipitation for LaGuardia Airport in NYC on June 12 for each year from 2011 through 2020, specifically using the station ID 725030?",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "help",
            "me",
            "retrieve",
            "the",
            "average",
            "temperature,",
            "average",
            "wind",
            "speed,",
            "and",
            "precipitation",
            "for",
            "LaGuardia",
            "Airport",
            "in",
            "NYC",
            "on",
            "June",
            "12",
            "for",
            "each",
            "year",
            "from",
            "2011",
            "through",
            "2020,",
            "specifically",
            "using",
            "the",
            "station",
            "ID",
            "725030?"
        ],
        "query": "",
        "db_id": "noaa_data",
        "No. of candidate columns": 7278,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq045",
        "question": "Which weather stations in Washington State recorded more than 150 rainy days in 2023 but fewer rainy days compared to 2022? Defining a “rainy day” as one having precipitation greater than zero millimeters and not equal to 99.99. Only include stations with valid precipitation data.",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "weather",
            "stations",
            "in",
            "Washington",
            "State",
            "recorded",
            "more",
            "than",
            "150",
            "rainy",
            "days",
            "in",
            "2023",
            "but",
            "fewer",
            "rainy",
            "days",
            "compared",
            "to",
            "2022?",
            "Defining",
            "a",
            "“rainy",
            "day”",
            "as",
            "one",
            "having",
            "precipitation",
            "greater",
            "than",
            "zero",
            "millimeters",
            "and",
            "not",
            "equal",
            "to",
            "99.99.",
            "Only",
            "include",
            "stations",
            "with",
            "valid",
            "precipitation",
            "data."
        ],
        "query": "",
        "db_id": "noaa_data",
        "No. of candidate columns": 7278,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq047",
        "question": "Could you analyze the relationship between each complaint type and daily temperature in New York City, specifically using temperature data from LaGuardia (STN=725030) and JFK (STN=744860) airports for the 10 years starting in 2008, and then determine, for each complaint type that has more than 5000 total occurrences and shows a strong correlation (absolute value > 0.5) with temperature, the total number of complaints, the total number of days with valid temperature records, and the Pearson correlation coefficients (rounded to four decimals) between temperature and both the daily complaint count as well as the daily percentage of total complaints, excluding any days with missing or invalid temperature data (such as 9999.9)?",
        "external_knowledge": null,
        "question_toks": [
            "Could",
            "you",
            "analyze",
            "the",
            "relationship",
            "between",
            "each",
            "complaint",
            "type",
            "and",
            "daily",
            "temperature",
            "in",
            "New",
            "York",
            "City,",
            "specifically",
            "using",
            "temperature",
            "data",
            "from",
            "LaGuardia",
            "(STN=725030)",
            "and",
            "JFK",
            "(STN=744860)",
            "airports",
            "for",
            "the",
            "10",
            "years",
            "starting",
            "in",
            "2008,",
            "and",
            "then",
            "determine,",
            "for",
            "each",
            "complaint",
            "type",
            "that",
            "has",
            "more",
            "than",
            "5000",
            "total",
            "occurrences",
            "and",
            "shows",
            "a",
            "strong",
            "correlation",
            "(absolute",
            "value",
            ">",
            "0.5)",
            "with",
            "temperature,",
            "the",
            "total",
            "number",
            "of",
            "complaints,",
            "the",
            "total",
            "number",
            "of",
            "days",
            "with",
            "valid",
            "temperature",
            "records,",
            "and",
            "the",
            "Pearson",
            "correlation",
            "coefficients",
            "(rounded",
            "to",
            "four",
            "decimals)",
            "between",
            "temperature",
            "and",
            "both",
            "the",
            "daily",
            "complaint",
            "count",
            "as",
            "well",
            "as",
            "the",
            "daily",
            "percentage",
            "of",
            "total",
            "complaints,",
            "excluding",
            "any",
            "days",
            "with",
            "missing",
            "or",
            "invalid",
            "temperature",
            "data",
            "(such",
            "as",
            "9999.9)?"
        ],
        "query": "",
        "db_id": "new_york_noaa",
        "No. of candidate columns": 3571,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq048",
        "question": "Which complaint types with more than 3000 total requests from 2011 to 2020 show the strongest positive and negative Pearson correlations with the daily average wind speed measured at station 744860 (JFK Airport), based on daily complaint proportions (the ratio of type-specific complaints to total daily complaints)? Please provide the complaint types and their correlation coefficients, rounded to four decimal places.",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "complaint",
            "types",
            "with",
            "more",
            "than",
            "3000",
            "total",
            "requests",
            "from",
            "2011",
            "to",
            "2020",
            "show",
            "the",
            "strongest",
            "positive",
            "and",
            "negative",
            "Pearson",
            "correlations",
            "with",
            "the",
            "daily",
            "average",
            "wind",
            "speed",
            "measured",
            "at",
            "station",
            "744860",
            "(JFK",
            "Airport),",
            "based",
            "on",
            "daily",
            "complaint",
            "proportions",
            "(the",
            "ratio",
            "of",
            "type-specific",
            "complaints",
            "to",
            "total",
            "daily",
            "complaints)?",
            "Please",
            "provide",
            "the",
            "complaint",
            "types",
            "and",
            "their",
            "correlation",
            "coefficients,",
            "rounded",
            "to",
            "four",
            "decimal",
            "places."
        ],
        "query": "",
        "db_id": "new_york_noaa",
        "No. of candidate columns": 3571,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq131",
        "question": "What is the number of bus stops for the bus network with the most stops within the multipolygon boundary of Denmark (as defined by Wikidata ID 'Q35'), analyzed through planet features?",
        "external_knowledge": "functions_st_dwithin.md",
        "question_toks": [
            "What",
            "is",
            "the",
            "number",
            "of",
            "bus",
            "stops",
            "for",
            "the",
            "bus",
            "network",
            "with",
            "the",
            "most",
            "stops",
            "within",
            "the",
            "multipolygon",
            "boundary",
            "of",
            "Denmark",
            "(as",
            "defined",
            "by",
            "Wikidata",
            "ID",
            "'Q35'),",
            "analyzed",
            "through",
            "planet",
            "features?"
        ],
        "query": "",
        "db_id": "GEO_OPENSTREETMAP",
        "No. of candidate columns": 86,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq429",
        "question": "Which are the top five states with the greatest average difference in median income between 2015 and 2018 at the ZIP code level, and what is the corresponding average number of vulnerable employees across wholesale trade, natural resources and construction, arts and entertainment, information, and retail trade industries in 2017 according to the ACS Five-Year Estimates and ZIP code boundaries data?",
        "external_knowledge": "avg_vulnerable_weights.md",
        "question_toks": [
            "Which",
            "are",
            "the",
            "top",
            "five",
            "states",
            "with",
            "the",
            "greatest",
            "average",
            "difference",
            "in",
            "median",
            "income",
            "between",
            "2015",
            "and",
            "2018",
            "at",
            "the",
            "ZIP",
            "code",
            "level,",
            "and",
            "what",
            "is",
            "the",
            "corresponding",
            "average",
            "number",
            "of",
            "vulnerable",
            "employees",
            "across",
            "wholesale",
            "trade,",
            "natural",
            "resources",
            "and",
            "construction,",
            "arts",
            "and",
            "entertainment,",
            "information,",
            "and",
            "retail",
            "trade",
            "industries",
            "in",
            "2017",
            "according",
            "to",
            "the",
            "ACS",
            "Five-Year",
            "Estimates",
            "and",
            "ZIP",
            "code",
            "boundaries",
            "data?"
        ],
        "query": "WITH median_income_diff_by_zipcode AS (\n  WITH acs_2018 AS (\n    SELECT\n      \"geo_id\",\n      \"median_income\" AS \"median_income_2018\"\n    FROM\n      CENSUS_BUREAU_ACS_2.CENSUS_BUREAU_ACS.\"ZIP_CODES_2018_5YR\"\n  ),\n  acs_2015 AS (\n    SELECT\n      \"geo_id\",\n      \"median_income\" AS \"median_income_2015\"\n    FROM\n      CENSUS_BUREAU_ACS_2.CENSUS_BUREAU_ACS.\"ZIP_CODES_2015_5YR\"\n  ),\n  acs_diff AS (\n    SELECT\n      a18.\"geo_id\",\n      (a18.\"median_income_2018\" - a15.\"median_income_2015\") AS \"median_income_diff\"\n    FROM\n      acs_2018 a18\n    JOIN\n      acs_2015 a15 ON a18.\"geo_id\" = a15.\"geo_id\"\n  )\n  SELECT\n    \"geo_id\",\n    AVG(\"median_income_diff\") AS \"avg_median_income_diff\"\n  FROM\n    acs_diff\n  WHERE\n    \"median_income_diff\" IS NOT NULL\n  GROUP BY \"geo_id\"\n),\nbase_census AS (\n  SELECT\n    geo.\"state_name\",\n    AVG(i.\"avg_median_income_diff\") AS \"avg_median_income_diff\",\n    AVG(\n      \"employed_wholesale_trade\" * 0.38423645320197042 +\n      \"occupation_natural_resources_construction_maintenance\" * 0.48071410777129553 +\n      \"employed_arts_entertainment_recreation_accommodation_food\" * 0.89455676291236841 +\n      \"employed_information\" * 0.31315240083507306 +\n      \"employed_retail_trade\" * 0.51\n    ) AS \"avg_vulnerable\"\n  FROM\n    CENSUS_BUREAU_ACS_2.CENSUS_BUREAU_ACS.\"ZIP_CODES_2017_5YR\" AS census\n  JOIN\n    median_income_diff_by_zipcode i ON CAST(census.\"geo_id\" AS STRING) = i.\"geo_id\"\n  JOIN\n    CENSUS_BUREAU_ACS_2.GEO_US_BOUNDARIES.\"ZIP_CODES\" geo ON census.\"geo_id\" = geo.\"zip_code\"\n  GROUP BY geo.\"state_name\"\n)\n\nSELECT \n  \"state_name\",\n  \"avg_median_income_diff\",\n  \"avg_vulnerable\"\nFROM \n  base_census\nORDER BY \n  \"avg_median_income_diff\" DESC\nLIMIT 5;",
        "db_id": "CENSUS_BUREAU_ACS_2",
        "No. of candidate columns": 68434,
        "No. of gold tables": 4
    },
    {
        "instance_id": "sf_bq073",
        "question": "Using data on ZIP-level median income differences between 2015 and 2018, along with the 2017 ACS employment figures, list each state in descending order of total vulnerable workers, where “vulnerable” is defined as 38% of wholesale trade employees and 41% of manufacturing employees in 2017. Your results should include the state name, the number of vulnerable wholesale trade workers, the number of vulnerable manufacturing workers, and the combined total of these vulnerable workers.",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "data",
            "on",
            "ZIP-level",
            "median",
            "income",
            "differences",
            "between",
            "2015",
            "and",
            "2018,",
            "along",
            "with",
            "the",
            "2017",
            "ACS",
            "employment",
            "figures,",
            "list",
            "each",
            "state",
            "in",
            "descending",
            "order",
            "of",
            "total",
            "vulnerable",
            "workers,",
            "where",
            "“vulnerable”",
            "is",
            "defined",
            "as",
            "38%",
            "of",
            "wholesale",
            "trade",
            "employees",
            "and",
            "41%",
            "of",
            "manufacturing",
            "employees",
            "in",
            "2017.",
            "Your",
            "results",
            "should",
            "include",
            "the",
            "state",
            "name,",
            "the",
            "number",
            "of",
            "vulnerable",
            "wholesale",
            "trade",
            "workers,",
            "the",
            "number",
            "of",
            "vulnerable",
            "manufacturing",
            "workers,",
            "and",
            "the",
            "combined",
            "total",
            "of",
            "these",
            "vulnerable",
            "workers."
        ],
        "query": "",
        "db_id": "CENSUS_BUREAU_ACS_2",
        "No. of candidate columns": 68434,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq348",
        "question": "Within the rectangular area defined by the geogpoints (31.1798246, 18.4519921), (54.3798246, 18.4519921), (54.3798246, 33.6519921), and (31.1798246, 33.6519921), which are the top three usernames responsible for the highest number of historical nodes, originally tagged with the amenities ‘hospital’, ‘clinic’, or ‘doctors’, that do not appear anymore in the current planet_nodes dataset?",
        "external_knowledge": "functions_st_intersects_polygon_line.md",
        "question_toks": [
            "Within",
            "the",
            "rectangular",
            "area",
            "defined",
            "by",
            "the",
            "geogpoints",
            "(31.1798246,",
            "18.4519921),",
            "(54.3798246,",
            "18.4519921),",
            "(54.3798246,",
            "33.6519921),",
            "and",
            "(31.1798246,",
            "33.6519921),",
            "which",
            "are",
            "the",
            "top",
            "three",
            "usernames",
            "responsible",
            "for",
            "the",
            "highest",
            "number",
            "of",
            "historical",
            "nodes,",
            "originally",
            "tagged",
            "with",
            "the",
            "amenities",
            "‘hospital’,",
            "‘clinic’,",
            "or",
            "‘doctors’,",
            "that",
            "do",
            "not",
            "appear",
            "anymore",
            "in",
            "the",
            "current",
            "planet_nodes",
            "dataset?"
        ],
        "query": "",
        "db_id": "GEO_OPENSTREETMAP",
        "No. of candidate columns": 86,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq254",
        "question": "Among all multipolygons located within the same geographic area as the multipolygon associated with Wikidata item Q191, but lacking a 'wikidata' tag themselves, which two rank highest by the number of points that lie within their boundaries, and what are their names?",
        "external_knowledge": "functions_st_dwithin.md",
        "question_toks": [
            "Among",
            "all",
            "multipolygons",
            "located",
            "within",
            "the",
            "same",
            "geographic",
            "area",
            "as",
            "the",
            "multipolygon",
            "associated",
            "with",
            "Wikidata",
            "item",
            "Q191,",
            "but",
            "lacking",
            "a",
            "'wikidata'",
            "tag",
            "themselves,",
            "which",
            "two",
            "rank",
            "highest",
            "by",
            "the",
            "number",
            "of",
            "points",
            "that",
            "lie",
            "within",
            "their",
            "boundaries,",
            "and",
            "what",
            "are",
            "their",
            "names?"
        ],
        "query": "WITH bounding_area AS (\n    SELECT \"geometry\" AS geometry\n    FROM GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_FEATURES,\n    LATERAL FLATTEN(INPUT => \"all_tags\") AS tag\n    WHERE \"feature_type\" = 'multipolygons'\n      AND tag.value:\"key\" = 'wikidata'\n      AND tag.value:\"value\" = 'Q191'\n),\nbounding_area_features AS (\n    SELECT \n        planet_features.\"osm_id\", \n        planet_features.\"feature_type\", \n        planet_features.\"geometry\", \n        planet_features.\"all_tags\"\n    FROM GEO_OPENSTREETMAP.GEO_OPENSTREETMAP.PLANET_FEATURES AS planet_features,\n         bounding_area\n    WHERE ST_DWITHIN(\n        ST_GEOGFROMWKB(planet_features.\"geometry\"), \n        ST_GEOGFROMWKB(bounding_area.geometry), \n        0.0\n    )\n),\nosm_id_with_wikidata AS (\n    SELECT DISTINCT\n        baf.\"osm_id\"\n    FROM bounding_area_features AS baf,\n         LATERAL FLATTEN(INPUT => baf.\"all_tags\") AS tag\n    WHERE tag.value:\"key\" = 'wikidata'\n),\n\npolygons_wo_wikidata AS (\n    SELECT \n        baf.\"osm_id\",\n        tag.value:\"value\" as name,\n        baf.\"geometry\" as geometry\n    FROM bounding_area_features AS baf\n    LEFT JOIN osm_id_with_wikidata AS wd\n      ON baf.\"osm_id\" = wd.\"osm_id\",\n    LATERAL FLATTEN(INPUT => \"all_tags\") AS tag\n    WHERE wd.\"osm_id\" IS NULL\n    AND baf.\"osm_id\" IS NOT NULL\n    AND baf.\"feature_type\" = 'multipolygons'\n    AND tag.value:\"key\" = 'name'\n)\n\nSELECT \n    TRIM(pww.name) as name\nFROM bounding_area_features AS baf\nJOIN polygons_wo_wikidata AS pww\n    ON ST_DWITHIN(\n        ST_GEOGFROMWKB(baf.\"geometry\"), \n        ST_GEOGFROMWKB(pww.geometry), \n        0.0\n    )\nLEFT JOIN osm_id_with_wikidata AS wd\n    ON baf.\"osm_id\" = wd.\"osm_id\"\nWHERE wd.\"osm_id\" IS NOT NULL\n  AND baf.\"feature_type\" = 'points'\nGROUP BY pww.name\nORDER BY COUNT(baf.\"osm_id\") DESC\nLIMIT 2",
        "db_id": "GEO_OPENSTREETMAP",
        "No. of candidate columns": 86,
        "No. of gold tables": 2
    },
    {
        "instance_id": "sf_bq250",
        "question": "Based on the most recent 1km population grid data in Singapore before January 2023, using ST_CONVEXHULL to aggregate all population grid centroids into a bounding region and ST_INTERSECTS to identify hospitals from OpenStreetMap’s planet layer (layer_code in (2110, 2120)) that fall within this region, then calculating the distance from each grid cell to its nearest hospital, what is the total population of the grid cell that is farthest from any hospital?",
        "external_knowledge": "OpenStreetMap_data_in_layered_GIS_format.md",
        "question_toks": [
            "Based",
            "on",
            "the",
            "most",
            "recent",
            "1km",
            "population",
            "grid",
            "data",
            "in",
            "Singapore",
            "before",
            "January",
            "2023,",
            "using",
            "ST_CONVEXHULL",
            "to",
            "aggregate",
            "all",
            "population",
            "grid",
            "centroids",
            "into",
            "a",
            "bounding",
            "region",
            "and",
            "ST_INTERSECTS",
            "to",
            "identify",
            "hospitals",
            "from",
            "OpenStreetMap’s",
            "planet",
            "layer",
            "(layer_code",
            "in",
            "(2110,",
            "2120))",
            "that",
            "fall",
            "within",
            "this",
            "region,",
            "then",
            "calculating",
            "the",
            "distance",
            "from",
            "each",
            "grid",
            "cell",
            "to",
            "its",
            "nearest",
            "hospital,",
            "what",
            "is",
            "the",
            "total",
            "population",
            "of",
            "the",
            "grid",
            "cell",
            "that",
            "is",
            "farthest",
            "from",
            "any",
            "hospital?"
        ],
        "query": "WITH country_name AS (\n  SELECT 'Singapore' AS value\n),\n\nlast_updated AS (\n  SELECT\n    MAX(\"last_updated\") AS value\n  FROM GEO_OPENSTREETMAP_WORLDPOP.WORLDPOP.POPULATION_GRID_1KM AS pop\n    INNER JOIN country_name ON (pop.\"country_name\" = country_name.value)\n  WHERE \"last_updated\" < '2023-01-01'\n),\n\naggregated_population AS (\n  SELECT\n    \"geo_id\",\n    SUM(\"population\") AS sum_population,\n    ST_POINT(\"longitude_centroid\", \"latitude_centroid\") AS centr  -- 计算每个 geo_id 的中心点\n  FROM\n    GEO_OPENSTREETMAP_WORLDPOP.WORLDPOP.POPULATION_GRID_1KM AS pop\n    INNER JOIN country_name ON (pop.\"country_name\" = country_name.value)\n    INNER JOIN last_updated ON (pop.\"last_updated\" = last_updated.value)\n  GROUP BY \"geo_id\", \"longitude_centroid\", \"latitude_centroid\"\n),\n\npopulation AS (\n  SELECT\n    SUM(sum_population) AS sum_population,\n    ST_ENVELOPE(ST_UNION_AGG(centr)) AS boundingbox  -- 使用 ST_ENVELOPE 来代替 ST_CONVEXHULL\n  FROM aggregated_population\n),\n\nhospitals AS (\n  SELECT\n    layer.\"geometry\"\n  FROM\n    GEO_OPENSTREETMAP_WORLDPOP.GEO_OPENSTREETMAP.PLANET_LAYERS AS layer\n    INNER JOIN population ON ST_INTERSECTS(population.boundingbox, ST_GEOGFROMWKB(layer.\"geometry\"))\n  WHERE\n    layer.\"layer_code\" IN (2110, 2120)\n),\n\ndistances AS (\n  SELECT\n    pop.\"geo_id\",\n    pop.\"population\",\n    MIN(ST_DISTANCE(ST_GEOGFROMWKB(pop.\"geog\"), ST_GEOGFROMWKB(hospitals.\"geometry\"))) AS distance\n  FROM\n    GEO_OPENSTREETMAP_WORLDPOP.WORLDPOP.POPULATION_GRID_1KM AS pop\n    INNER JOIN country_name ON pop.\"country_name\" = country_name.value\n    INNER JOIN last_updated ON pop.\"last_updated\" = last_updated.value\n    CROSS JOIN hospitals\n  WHERE pop.\"population\" > 0\n  GROUP BY \"geo_id\", \"population\"\n)\n\nSELECT\n  SUM(pd.\"population\") AS population\nFROM\n  distances pd\nCROSS JOIN population p\nGROUP BY distance\nORDER BY distance DESC\nLIMIT 1;",
        "db_id": "GEO_OPENSTREETMAP_WORLDPOP",
        "No. of candidate columns": 94,
        "No. of gold tables": 4
    },
    {
        "instance_id": "sf_bq083",
        "question": "Can you calculate the daily change in the market value of USDC tokens (address `0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48`) for 2023, based on Ethereum transactions? The change should be computed from minting (input pattern `0x40c10f19%`) and burning (input pattern `0x42966c68%`) operations. For each transaction, minting should be positive and burning negative. Extract the relevant amount from the 'input' field as a hexadecimal, convert it to millions, express it in USD format. Group the results by date and order them in descending order.",
        "external_knowledge": "Total_Market_Value_Change.md",
        "question_toks": [
            "Can",
            "you",
            "calculate",
            "the",
            "daily",
            "change",
            "in",
            "the",
            "market",
            "value",
            "of",
            "USDC",
            "tokens",
            "(address",
            "`0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48`)",
            "for",
            "2023,",
            "based",
            "on",
            "Ethereum",
            "transactions?",
            "The",
            "change",
            "should",
            "be",
            "computed",
            "from",
            "minting",
            "(input",
            "pattern",
            "`0x40c10f19%`)",
            "and",
            "burning",
            "(input",
            "pattern",
            "`0x42966c68%`)",
            "operations.",
            "For",
            "each",
            "transaction,",
            "minting",
            "should",
            "be",
            "positive",
            "and",
            "burning",
            "negative.",
            "Extract",
            "the",
            "relevant",
            "amount",
            "from",
            "the",
            "'input'",
            "field",
            "as",
            "a",
            "hexadecimal,",
            "convert",
            "it",
            "to",
            "millions,",
            "express",
            "it",
            "in",
            "USD",
            "format.",
            "Group",
            "the",
            "results",
            "by",
            "date",
            "and",
            "order",
            "them",
            "in",
            "descending",
            "order."
        ],
        "query": "SELECT \n  TO_DATE(TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000)) AS \"Date\",  -- 将时间戳转换为日期格式，除以1000000\n  TO_CHAR(SUM(\n      CASE\n          WHEN \"input\" LIKE '0x40c10f19%' THEN 1\n          ELSE -1\n      END * \n      CAST(CONCAT('0x', LTRIM(SUBSTRING(\"input\", \n                                       CASE \n                                           WHEN \"input\" LIKE '0x40c10f19%' THEN 75\n                                           ELSE 11\n                                       END, 64), '0')) AS FLOAT) / 1000000)\n  , '$999,999,999,999') AS \"Δ Total Market Value\"\nFROM \n  \"CRYPTO\".\"CRYPTO_ETHEREUM\".\"TRANSACTIONS\"\nWHERE \n  TO_DATE(TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000)) BETWEEN '2023-01-01' AND '2023-12-31'\n  AND \"to_address\" = '0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48'  -- USDC Token\n  AND (\"input\" LIKE '0x42966c68%' -- Burn\n       OR \"input\" LIKE '0x40c10f19%' -- Mint\n  )\nGROUP BY \n  TO_DATE(TO_TIMESTAMP_NTZ(\"block_timestamp\" / 1000000))\nORDER BY \n  \"Date\" DESC;",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 1
    },
    {
        "instance_id": "sf_bq184",
        "question": "Using only the traces, can you calculate daily cumulative counts of smart contracts created by external addresses (where the trace_address is NULL) versus those created by other contracts (where the trace_address is NOT NULL) for each date from 2017-01-01 through 2021-12-31, ensuring that all dates in this range are included even if no new contracts were created on some days, and showing monotonically increasing cumulative totals for both categories?",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "only",
            "the",
            "traces,",
            "can",
            "you",
            "calculate",
            "daily",
            "cumulative",
            "counts",
            "of",
            "smart",
            "contracts",
            "created",
            "by",
            "external",
            "addresses",
            "(where",
            "the",
            "trace_address",
            "is",
            "NULL)",
            "versus",
            "those",
            "created",
            "by",
            "other",
            "contracts",
            "(where",
            "the",
            "trace_address",
            "is",
            "NOT",
            "NULL)",
            "for",
            "each",
            "date",
            "from",
            "2017-01-01",
            "through",
            "2021-12-31,",
            "ensuring",
            "that",
            "all",
            "dates",
            "in",
            "this",
            "range",
            "are",
            "included",
            "even",
            "if",
            "no",
            "new",
            "contracts",
            "were",
            "created",
            "on",
            "some",
            "days,",
            "and",
            "showing",
            "monotonically",
            "increasing",
            "cumulative",
            "totals",
            "for",
            "both",
            "categories?"
        ],
        "query": "",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq256",
        "question": "Determine the final Ether balance of the Ethereum address that initiated the highest number of successful transactions prior to September 1, 2021 (UTC), excluding calls of type delegatecall, callcode, or staticcall and including all relevant incoming and outgoing transfers, miner rewards, and gas fee deductions, with the final balance presented in Ether after converting from the native unit.",
        "external_knowledge": null,
        "question_toks": [
            "Determine",
            "the",
            "final",
            "Ether",
            "balance",
            "of",
            "the",
            "Ethereum",
            "address",
            "that",
            "initiated",
            "the",
            "highest",
            "number",
            "of",
            "successful",
            "transactions",
            "prior",
            "to",
            "September",
            "1,",
            "2021",
            "(UTC),",
            "excluding",
            "calls",
            "of",
            "type",
            "delegatecall,",
            "callcode,",
            "or",
            "staticcall",
            "and",
            "including",
            "all",
            "relevant",
            "incoming",
            "and",
            "outgoing",
            "transfers,",
            "miner",
            "rewards,",
            "and",
            "gas",
            "fee",
            "deductions,",
            "with",
            "the",
            "final",
            "balance",
            "presented",
            "in",
            "Ether",
            "after",
            "converting",
            "from",
            "the",
            "native",
            "unit."
        ],
        "query": "",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq342",
        "question": "What is the difference between the average hourly changes in transaction values for the Ethereum token 0x68e54af74b22acaccffa04ccaad13be16ed14eac, specifically considering only transactions where the address 0x8babf0ba311aab914c00e8fda7e8558a8b66de5d was the sender or the address 0xfbd6c6b112214d949dcdfb1217153bc0a742862f was the receiver, between January 1, 2019, and December 31, 2020, when comparing 2019 to 2020?",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "is",
            "the",
            "difference",
            "between",
            "the",
            "average",
            "hourly",
            "changes",
            "in",
            "transaction",
            "values",
            "for",
            "the",
            "Ethereum",
            "token",
            "0x68e54af74b22acaccffa04ccaad13be16ed14eac,",
            "specifically",
            "considering",
            "only",
            "transactions",
            "where",
            "the",
            "address",
            "0x8babf0ba311aab914c00e8fda7e8558a8b66de5d",
            "was",
            "the",
            "sender",
            "or",
            "the",
            "address",
            "0xfbd6c6b112214d949dcdfb1217153bc0a742862f",
            "was",
            "the",
            "receiver,",
            "between",
            "January",
            "1,",
            "2019,",
            "and",
            "December",
            "31,",
            "2020,",
            "when",
            "comparing",
            "2019",
            "to",
            "2020?"
        ],
        "query": "",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq335",
        "question": "Among all Bitcoin addresses that have at least one transaction in October 2017 (combining both inputs and outputs), which address conducted its final transaction on the latest date in that month, and, among any addresses sharing that same latest date, which one has the highest sum of transaction values?",
        "external_knowledge": null,
        "question_toks": [
            "Among",
            "all",
            "Bitcoin",
            "addresses",
            "that",
            "have",
            "at",
            "least",
            "one",
            "transaction",
            "in",
            "October",
            "2017",
            "(combining",
            "both",
            "inputs",
            "and",
            "outputs),",
            "which",
            "address",
            "conducted",
            "its",
            "final",
            "transaction",
            "on",
            "the",
            "latest",
            "date",
            "in",
            "that",
            "month,",
            "and,",
            "among",
            "any",
            "addresses",
            "sharing",
            "that",
            "same",
            "latest",
            "date,",
            "which",
            "one",
            "has",
            "the",
            "highest",
            "sum",
            "of",
            "transaction",
            "values?"
        ],
        "query": "",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq068",
        "question": "Using double-entry bookkeeping principles by treating transaction inputs as debits (negative values) and outputs as credits (positive values) for all Bitcoin Cash transactions between 2014-03-01 and 2014-04-01, how can we calculate the maximum and minimum final balances grouped by address type from these transactions?",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "double-entry",
            "bookkeeping",
            "principles",
            "by",
            "treating",
            "transaction",
            "inputs",
            "as",
            "debits",
            "(negative",
            "values)",
            "and",
            "outputs",
            "as",
            "credits",
            "(positive",
            "values)",
            "for",
            "all",
            "Bitcoin",
            "Cash",
            "transactions",
            "between",
            "2014-03-01",
            "and",
            "2014-04-01,",
            "how",
            "can",
            "we",
            "calculate",
            "the",
            "maximum",
            "and",
            "minimum",
            "final",
            "balances",
            "grouped",
            "by",
            "address",
            "type",
            "from",
            "these",
            "transactions?"
        ],
        "query": "WITH double_entry_book AS (\n    -- debits\n    SELECT\n        ARRAY_TO_STRING(\"inputs\".value:addresses, ',') AS \"address\",  -- Use the correct JSON path notation\n        \"inputs\".value:type AS \"type\",\n        - \"inputs\".value:value AS \"value\"\n    FROM CRYPTO.CRYPTO_BITCOIN_CASH.TRANSACTIONS,\n         LATERAL FLATTEN(INPUT => \"inputs\") AS \"inputs\"\n    WHERE TO_TIMESTAMP(\"block_timestamp\" / 1000000) >= '2014-03-01' \n      AND TO_TIMESTAMP(\"block_timestamp\" / 1000000) < '2014-04-01'\n\n    UNION ALL\n \n    -- credits\n    SELECT\n        ARRAY_TO_STRING(\"outputs\".value:addresses, ',') AS \"address\",  -- Use the correct JSON path notation\n        \"outputs\".value:type AS \"type\",\n        \"outputs\".value:value AS \"value\"\n    FROM CRYPTO.CRYPTO_BITCOIN_CASH.TRANSACTIONS, \n         LATERAL FLATTEN(INPUT => \"outputs\") AS \"outputs\"\n    WHERE TO_TIMESTAMP(\"block_timestamp\" / 1000000) >= '2014-03-01' \n      AND TO_TIMESTAMP(\"block_timestamp\" / 1000000) < '2014-04-01'\n),\naddress_balances AS (\n    SELECT \n        \"address\",\n        \"type\",\n        SUM(\"value\") AS \"balance\"\n    FROM double_entry_book\n    GROUP BY \"address\", \"type\"\n),\nmax_min_balances AS (\n    SELECT\n        \"type\",\n        MAX(\"balance\") AS max_balance,\n        MIN(\"balance\") AS min_balance\n    FROM address_balances\n    GROUP BY \"type\"\n)\nSELECT\n    REPLACE(\"type\", '\"', '') AS \"type\",  -- Replace double quotes with nothing\n    max_balance,\n    min_balance\nFROM max_min_balances\nORDER BY \"type\";",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 2
    },
    {
        "instance_id": "sf_bq092",
        "question": "In April 2023, considering Dash transaction data tracked using double-entry bookkeeping to separately account for debits and credits from each address, what are the highest and lowest resulting balances across all addresses when filtering records by their block timestamps for that month?",
        "external_knowledge": null,
        "question_toks": [
            "In",
            "April",
            "2023,",
            "considering",
            "Dash",
            "transaction",
            "data",
            "tracked",
            "using",
            "double-entry",
            "bookkeeping",
            "to",
            "separately",
            "account",
            "for",
            "debits",
            "and",
            "credits",
            "from",
            "each",
            "address,",
            "what",
            "are",
            "the",
            "highest",
            "and",
            "lowest",
            "resulting",
            "balances",
            "across",
            "all",
            "addresses",
            "when",
            "filtering",
            "records",
            "by",
            "their",
            "block",
            "timestamps",
            "for",
            "that",
            "month?"
        ],
        "query": "",
        "db_id": "CRYPTO",
        "No. of candidate columns": 497,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq051",
        "question": "Calculate the average daily number of Citibike trips in New York City during 2016, categorizing days as rainy if the total precipitation exceeds 5 millimeters (obtained by dividing the raw precipitation value by 10), and non-rainy otherwise. Use data from the nearest GHCN station located within 50 km of (40.7128, -74.0060) that has valid, unflagged measurements, then compare the resulting average Citibike trips on rainy days versus non-rainy days.",
        "external_knowledge": null,
        "question_toks": [
            "Calculate",
            "the",
            "average",
            "daily",
            "number",
            "of",
            "Citibike",
            "trips",
            "in",
            "New",
            "York",
            "City",
            "during",
            "2016,",
            "categorizing",
            "days",
            "as",
            "rainy",
            "if",
            "the",
            "total",
            "precipitation",
            "exceeds",
            "5",
            "millimeters",
            "(obtained",
            "by",
            "dividing",
            "the",
            "raw",
            "precipitation",
            "value",
            "by",
            "10),",
            "and",
            "non-rainy",
            "otherwise.",
            "Use",
            "data",
            "from",
            "the",
            "nearest",
            "GHCN",
            "station",
            "located",
            "within",
            "50",
            "km",
            "of",
            "(40.7128,",
            "-74.0060)",
            "that",
            "has",
            "valid,",
            "unflagged",
            "measurements,",
            "then",
            "compare",
            "the",
            "resulting",
            "average",
            "Citibike",
            "trips",
            "on",
            "rainy",
            "days",
            "versus",
            "non-rainy",
            "days."
        ],
        "query": "",
        "db_id": "new_york_ghcn",
        "No. of candidate columns": 2624,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq053",
        "question": "Calculate the change in the number of living trees of each fall color in New York City from 1995 to 2015 by computing, for each tree species, the difference between the number of trees not marked as dead in 1995 and the number of trees alive in 2015, matching species by the uppercase form of their scientific names from the tree_species table. Then, group the species by their fall color and sum these differences to determine the total change in the number of trees for each fall color.",
        "external_knowledge": null,
        "question_toks": [
            "Calculate",
            "the",
            "change",
            "in",
            "the",
            "number",
            "of",
            "living",
            "trees",
            "of",
            "each",
            "fall",
            "color",
            "in",
            "New",
            "York",
            "City",
            "from",
            "1995",
            "to",
            "2015",
            "by",
            "computing,",
            "for",
            "each",
            "tree",
            "species,",
            "the",
            "difference",
            "between",
            "the",
            "number",
            "of",
            "trees",
            "not",
            "marked",
            "as",
            "dead",
            "in",
            "1995",
            "and",
            "the",
            "number",
            "of",
            "trees",
            "alive",
            "in",
            "2015,",
            "matching",
            "species",
            "by",
            "the",
            "uppercase",
            "form",
            "of",
            "their",
            "scientific",
            "names",
            "from",
            "the",
            "tree_species",
            "table.",
            "Then,",
            "group",
            "the",
            "species",
            "by",
            "their",
            "fall",
            "color",
            "and",
            "sum",
            "these",
            "differences",
            "to",
            "determine",
            "the",
            "total",
            "change",
            "in",
            "the",
            "number",
            "of",
            "trees",
            "for",
            "each",
            "fall",
            "color."
        ],
        "query": "",
        "db_id": "new_york",
        "No. of candidate columns": 483,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq054",
        "question": "Please provide the top 10 tree species in New York, using their uppercase Latin names where the Latin name is not empty and including their common names, showing the total number of trees, the counts of alive and dead trees for each year, and the corresponding growth in these counts from 1995 to 2015, then order by the difference in total tree counts between these years.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "provide",
            "the",
            "top",
            "10",
            "tree",
            "species",
            "in",
            "New",
            "York,",
            "using",
            "their",
            "uppercase",
            "Latin",
            "names",
            "where",
            "the",
            "Latin",
            "name",
            "is",
            "not",
            "empty",
            "and",
            "including",
            "their",
            "common",
            "names,",
            "showing",
            "the",
            "total",
            "number",
            "of",
            "trees,",
            "the",
            "counts",
            "of",
            "alive",
            "and",
            "dead",
            "trees",
            "for",
            "each",
            "year,",
            "and",
            "the",
            "corresponding",
            "growth",
            "in",
            "these",
            "counts",
            "from",
            "1995",
            "to",
            "2015,",
            "then",
            "order",
            "by",
            "the",
            "difference",
            "in",
            "total",
            "tree",
            "counts",
            "between",
            "these",
            "years."
        ],
        "query": "",
        "db_id": "new_york",
        "No. of candidate columns": 483,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq202",
        "question": "For the station that had the highest number of Citibike trips starting there in 2018, which numeric day of the week and which hour of the day had the greatest number of trips based on the start time of those trips?",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "the",
            "station",
            "that",
            "had",
            "the",
            "highest",
            "number",
            "of",
            "Citibike",
            "trips",
            "starting",
            "there",
            "in",
            "2018,",
            "which",
            "numeric",
            "day",
            "of",
            "the",
            "week",
            "and",
            "which",
            "hour",
            "of",
            "the",
            "day",
            "had",
            "the",
            "greatest",
            "number",
            "of",
            "trips",
            "based",
            "on",
            "the",
            "start",
            "time",
            "of",
            "those",
            "trips?"
        ],
        "query": "",
        "db_id": "new_york",
        "No. of candidate columns": 483,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq040",
        "question": "For NYC yellow taxi trips between January 1 and January 7, 2016, excluding any trips picked up in ‘EWR’ or ‘Staten Island,’ determine the proportion of rides that fall into each tip category in each pickup borough. Only include trips where the dropoff time is after the pickup time, the passenger count is greater than zero, and trip_distance, tip_amount, tolls_amount, mta_tax, fare_amount, and total_amount are all non-negative. Classify the tip percentage as follows: 0% (no tip), up to 5%, 5% to 10%, 10% to 15%, 15% to 20%, 20% to 25%, and more than 25%.",
        "external_knowledge": "taxi_tip_rate.md",
        "question_toks": [
            "For",
            "NYC",
            "yellow",
            "taxi",
            "trips",
            "between",
            "January",
            "1",
            "and",
            "January",
            "7,",
            "2016,",
            "excluding",
            "any",
            "trips",
            "picked",
            "up",
            "in",
            "‘EWR’",
            "or",
            "‘Staten",
            "Island,’",
            "determine",
            "the",
            "proportion",
            "of",
            "rides",
            "that",
            "fall",
            "into",
            "each",
            "tip",
            "category",
            "in",
            "each",
            "pickup",
            "borough.",
            "Only",
            "include",
            "trips",
            "where",
            "the",
            "dropoff",
            "time",
            "is",
            "after",
            "the",
            "pickup",
            "time,",
            "the",
            "passenger",
            "count",
            "is",
            "greater",
            "than",
            "zero,",
            "and",
            "trip_distance,",
            "tip_amount,",
            "tolls_amount,",
            "mta_tax,",
            "fare_amount,",
            "and",
            "total_amount",
            "are",
            "all",
            "non-negative.",
            "Classify",
            "the",
            "tip",
            "percentage",
            "as",
            "follows:",
            "0%",
            "(no",
            "tip),",
            "up",
            "to",
            "5%,",
            "5%",
            "to",
            "10%,",
            "10%",
            "to",
            "15%,",
            "15%",
            "to",
            "20%,",
            "20%",
            "to",
            "25%,",
            "and",
            "more",
            "than",
            "25%."
        ],
        "query": "",
        "db_id": "new_york_plus",
        "No. of candidate columns": 853,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq039",
        "question": "Find the top 10 taxi trips in New York City between July 1 and July 7, 2016 (ensuring both pickup and dropoff times fall within these dates) where the passenger count is greater than five, the trip distance is at least ten miles, and there are no negative fare-related amounts (including tip, tolls, mta tax, fare, and total costs). Exclude any trips where the dropoff time is not strictly after the pickup time, then sort the results by total fare amount in descending order. Finally, display each trip’s pickup zone, dropoff zone, trip duration in seconds, driving speed in miles per hour, and tip rate as a percentage of the total fare amount.",
        "external_knowledge": null,
        "question_toks": [
            "Find",
            "the",
            "top",
            "10",
            "taxi",
            "trips",
            "in",
            "New",
            "York",
            "City",
            "between",
            "July",
            "1",
            "and",
            "July",
            "7,",
            "2016",
            "(ensuring",
            "both",
            "pickup",
            "and",
            "dropoff",
            "times",
            "fall",
            "within",
            "these",
            "dates)",
            "where",
            "the",
            "passenger",
            "count",
            "is",
            "greater",
            "than",
            "five,",
            "the",
            "trip",
            "distance",
            "is",
            "at",
            "least",
            "ten",
            "miles,",
            "and",
            "there",
            "are",
            "no",
            "negative",
            "fare-related",
            "amounts",
            "(including",
            "tip,",
            "tolls,",
            "mta",
            "tax,",
            "fare,",
            "and",
            "total",
            "costs).",
            "Exclude",
            "any",
            "trips",
            "where",
            "the",
            "dropoff",
            "time",
            "is",
            "not",
            "strictly",
            "after",
            "the",
            "pickup",
            "time,",
            "then",
            "sort",
            "the",
            "results",
            "by",
            "total",
            "fare",
            "amount",
            "in",
            "descending",
            "order.",
            "Finally,",
            "display",
            "each",
            "trip’s",
            "pickup",
            "zone,",
            "dropoff",
            "zone,",
            "trip",
            "duration",
            "in",
            "seconds,",
            "driving",
            "speed",
            "in",
            "miles",
            "per",
            "hour,",
            "and",
            "tip",
            "rate",
            "as",
            "a",
            "percentage",
            "of",
            "the",
            "total",
            "fare",
            "amount."
        ],
        "query": "",
        "db_id": "new_york_plus",
        "No. of candidate columns": 853,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq203",
        "question": "For each New York City borough, how many subway stations are there in total, how many have at least one entrance that is marked both as an actual entry and as ADA-compliant, and what percentage of the total stations in each borough does this represent, listing boroughs from the highest to the lowest percentage?",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "each",
            "New",
            "York",
            "City",
            "borough,",
            "how",
            "many",
            "subway",
            "stations",
            "are",
            "there",
            "in",
            "total,",
            "how",
            "many",
            "have",
            "at",
            "least",
            "one",
            "entrance",
            "that",
            "is",
            "marked",
            "both",
            "as",
            "an",
            "actual",
            "entry",
            "and",
            "as",
            "ADA-compliant,",
            "and",
            "what",
            "percentage",
            "of",
            "the",
            "total",
            "stations",
            "in",
            "each",
            "borough",
            "does",
            "this",
            "represent,",
            "listing",
            "boroughs",
            "from",
            "the",
            "highest",
            "to",
            "the",
            "lowest",
            "percentage?"
        ],
        "query": "WITH stations_n_entrances AS (\n      SELECT borough_name,s.station_name,entry,ada_compliant\n      FROM `bigquery-public-data.new_york_subway.stations` s\n      JOIN `bigquery-public-data.new_york_subway.station_entrances` se\n      ON s.station_name = se.station_name\n      )\n\nSELECT se.borough_name, COUNT(DISTINCT se.station_name) num_stations,\n      COUNT(DISTINCT adas.station_name) num_stations_w_compliant_entrance, \n      (100*COUNT(DISTINCT adas.station_name))/(COUNT(DISTINCT se.station_name)) percent_compliant_stations\nFROM `stations_n_entrances` se\nLEFT JOIN `stations_n_entrances` adas\nON se.station_name = adas.station_name\nAND adas.entry AND adas.ada_compliant\nGROUP BY 1\nORDER BY 4 DESC",
        "db_id": "new_york_plus",
        "No. of candidate columns": 853,
        "No. of gold tables": 2
    },
    {
        "instance_id": "bq186",
        "question": "Please find, for each year-month combination (in the format YYYYMM) derived from the start date of bike share trips in San Francisco, the first trip duration in minutes, the last trip duration in minutes, the highest trip duration in minutes, and the lowest trip duration in minutes, where ‘first’ and ‘last’ are determined by the chronological order of the trip start date, then group your results by this year-month and sort them by the same year-month key.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "find,",
            "for",
            "each",
            "year-month",
            "combination",
            "(in",
            "the",
            "format",
            "YYYYMM)",
            "derived",
            "from",
            "the",
            "start",
            "date",
            "of",
            "bike",
            "share",
            "trips",
            "in",
            "San",
            "Francisco,",
            "the",
            "first",
            "trip",
            "duration",
            "in",
            "minutes,",
            "the",
            "last",
            "trip",
            "duration",
            "in",
            "minutes,",
            "the",
            "highest",
            "trip",
            "duration",
            "in",
            "minutes,",
            "and",
            "the",
            "lowest",
            "trip",
            "duration",
            "in",
            "minutes,",
            "where",
            "‘first’",
            "and",
            "‘last’",
            "are",
            "determined",
            "by",
            "the",
            "chronological",
            "order",
            "of",
            "the",
            "trip",
            "start",
            "date,",
            "then",
            "group",
            "your",
            "results",
            "by",
            "this",
            "year-month",
            "and",
            "sort",
            "them",
            "by",
            "the",
            "same",
            "year-month",
            "key."
        ],
        "query": "",
        "db_id": "san_francisco",
        "No. of candidate columns": 118,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq294",
        "question": "Could you provide the details of the top 5 longest bike share trips that started between July 1, 2017, and December 31, 2017, including the trip ID, duration in seconds, start date, start station name, route (derived from start station name to end station name), bike number, subscriber type, member's birth year, the member's current age (calculated using the current year), an age classification based on whether the member is younger than 40, between 40 and 60, or older than 60, the member's gender, and the name of the region of the start station? Please exclude any trips where the start station name, member's birth year, or member's gender is not specified.",
        "temporal": "Yes",
        "external_knowledge": "trip_info.md",
        "question_toks": [
            "Could",
            "you",
            "provide",
            "the",
            "details",
            "of",
            "the",
            "top",
            "5",
            "longest",
            "bike",
            "share",
            "trips",
            "that",
            "started",
            "between",
            "July",
            "1,",
            "2017,",
            "and",
            "December",
            "31,",
            "2017,",
            "including",
            "the",
            "trip",
            "ID,",
            "duration",
            "in",
            "seconds,",
            "start",
            "date,",
            "start",
            "station",
            "name,",
            "route",
            "(derived",
            "from",
            "start",
            "station",
            "name",
            "to",
            "end",
            "station",
            "name),",
            "bike",
            "number,",
            "subscriber",
            "type,",
            "member's",
            "birth",
            "year,",
            "the",
            "member's",
            "current",
            "age",
            "(calculated",
            "using",
            "the",
            "current",
            "year),",
            "an",
            "age",
            "classification",
            "based",
            "on",
            "whether",
            "the",
            "member",
            "is",
            "younger",
            "than",
            "40,",
            "between",
            "40",
            "and",
            "60,",
            "or",
            "older",
            "than",
            "60,",
            "the",
            "member's",
            "gender,",
            "and",
            "the",
            "name",
            "of",
            "the",
            "region",
            "of",
            "the",
            "start",
            "station?",
            "Please",
            "exclude",
            "any",
            "trips",
            "where",
            "the",
            "start",
            "station",
            "name,",
            "member's",
            "birth",
            "year,",
            "or",
            "member's",
            "gender",
            "is",
            "not",
            "specified."
        ],
        "query": "SELECT\n  \"trip_id\",\n  \"duration_sec\",\n  DATE(TO_TIMESTAMP_LTZ(\"start_date\" / 1000000)) AS \"star_date\", -- 将微秒转换为日期\n  \"start_station_name\",\n  CONCAT(\"start_station_name\", ' - ', \"end_station_name\") AS \"route\",\n  \"bike_number\",\n  \"subscriber_type\",\n  \"member_birth_year\",\n  (EXTRACT(YEAR FROM CURRENT_DATE()) - \"member_birth_year\") AS \"age\",\n  CASE\n    WHEN (EXTRACT(YEAR FROM CURRENT_DATE()) - \"member_birth_year\") < 40 THEN 'Young (<40 Y.O)'\n    WHEN (EXTRACT(YEAR FROM CURRENT_DATE()) - \"member_birth_year\") BETWEEN 40 AND 60 THEN 'Adult (40-60 Y.O)'\n    ELSE 'Senior Adult (>60 Y.O)'\n  END AS \"age_class\",\n  \"member_gender\",\n  c.\"name\" AS \"region_name\"\nFROM \"SAN_FRANCISCO_PLUS\".\"SAN_FRANCISCO_BIKESHARE\".\"BIKESHARE_TRIPS\" a\nLEFT JOIN \"SAN_FRANCISCO_PLUS\".\"SAN_FRANCISCO_BIKESHARE\".\"BIKESHARE_STATION_INFO\" b \n  ON a.\"start_station_name\" = b.\"name\"\nLEFT JOIN \"SAN_FRANCISCO_PLUS\".\"SAN_FRANCISCO_BIKESHARE\".\"BIKESHARE_REGIONS\" c \n  ON b.\"region_id\" = c.\"region_id\"\nWHERE TO_TIMESTAMP_LTZ(\"start_date\" / 1000000) BETWEEN '2017-07-01' AND '2017-12-31'\n  AND b.\"name\" IS NOT NULL\n  AND \"member_birth_year\" IS NOT NULL\n  AND \"member_gender\" IS NOT NULL\nORDER BY \"duration_sec\" DESC\nLIMIT 5;",
        "db_id": "SAN_FRANCISCO_PLUS",
        "No. of candidate columns": 278,
        "No. of gold tables": 3
    },
    {
        "instance_id": "bq376",
        "question": "For each neighborhood in San Francisco where at least one bike share station and at least one crime incident are located, provide the neighborhood name along with the total count of bike share stations and the total number of crime incidents in that neighborhood.",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "each",
            "neighborhood",
            "in",
            "San",
            "Francisco",
            "where",
            "at",
            "least",
            "one",
            "bike",
            "share",
            "station",
            "and",
            "at",
            "least",
            "one",
            "crime",
            "incident",
            "are",
            "located,",
            "provide",
            "the",
            "neighborhood",
            "name",
            "along",
            "with",
            "the",
            "total",
            "count",
            "of",
            "bike",
            "share",
            "stations",
            "and",
            "the",
            "total",
            "number",
            "of",
            "crime",
            "incidents",
            "in",
            "that",
            "neighborhood."
        ],
        "query": "WITH station_neighborhoods AS (\n   SELECT\n       bs.station_id,\n       bs.name AS station_name,\n       nb.neighborhood\n   FROM `bigquery-public-data.san_francisco.bikeshare_stations` bs\n   JOIN\n       bigquery-public-data.san_francisco_neighborhoods.boundaries nb\n   ON \n       ST_Intersects(ST_GeogPoint(bs.longitude, bs.latitude), nb.neighborhood_geom)\n),\n\nneighborhood_crime_counts AS (\n   SELECT\n       neighborhood,\n       COUNT(*) AS crime_count\n   FROM (\n       SELECT\n           n.neighborhood\n       FROM\n           bigquery-public-data.san_francisco.sfpd_incidents i\n       JOIN\n           bigquery-public-data.san_francisco_neighborhoods.boundaries n\n       ON\n           ST_Intersects(ST_GeogPoint(i.longitude, i.latitude), n.neighborhood_geom)\n   ) AS incident_neighborhoods\n   GROUP BY\n       neighborhood\n)\n\nSELECT\n  sn.neighborhood,\n  COUNT(station_name) AS station_number,\n  ANY_VALUE(ncc.crime_count) AS crime_number\nFROM\n  station_neighborhoods sn\nJOIN\n  neighborhood_crime_counts ncc\nON\n  sn.neighborhood = ncc.neighborhood\nGROUP BY sn.neighborhood\nORDER BY\n  crime_number ASC",
        "db_id": "san_francisco_plus",
        "No. of candidate columns": 278,
        "No. of gold tables": 3
    },
    {
        "instance_id": "sf_bq188",
        "question": "Among all product categories in the dataset, which category has the highest total quantity purchased, and for that category, what is the average time in minutes that users spend on each product page visit, calculated as the average difference between the time the product page is viewed and the time of the next event within the same session",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Among",
            "all",
            "product",
            "categories",
            "in",
            "the",
            "dataset,",
            "which",
            "category",
            "has",
            "the",
            "highest",
            "total",
            "quantity",
            "purchased,",
            "and",
            "for",
            "that",
            "category,",
            "what",
            "is",
            "the",
            "average",
            "time",
            "in",
            "minutes",
            "that",
            "users",
            "spend",
            "on",
            "each",
            "product",
            "page",
            "visit,",
            "calculated",
            "as",
            "the",
            "average",
            "difference",
            "between",
            "the",
            "time",
            "the",
            "product",
            "page",
            "is",
            "viewed",
            "and",
            "the",
            "time",
            "of",
            "the",
            "next",
            "event",
            "within",
            "the",
            "same",
            "session"
        ],
        "query": "",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq258",
        "question": "Generate a monthly report for each product category , where each row corresponds to orders that have a status of 'Complete' and were delivered before the year 2022, grouping by the month and year of delivery. For each category, calculate the total revenue (the sum of sale_price), the total number of completed orders, and compute the month-over-month percentage growth for both revenue and orders by comparing each month’s totals to the previous month’s. Then, for the same orders, aggregate and show the total cost (from product costs), total profit (revenue minus total cost), and finally the profit-to-cost ratio for each month.",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Generate",
            "a",
            "monthly",
            "report",
            "for",
            "each",
            "product",
            "category",
            ",",
            "where",
            "each",
            "row",
            "corresponds",
            "to",
            "orders",
            "that",
            "have",
            "a",
            "status",
            "of",
            "'Complete'",
            "and",
            "were",
            "delivered",
            "before",
            "the",
            "year",
            "2022,",
            "grouping",
            "by",
            "the",
            "month",
            "and",
            "year",
            "of",
            "delivery.",
            "For",
            "each",
            "category,",
            "calculate",
            "the",
            "total",
            "revenue",
            "(the",
            "sum",
            "of",
            "sale_price),",
            "the",
            "total",
            "number",
            "of",
            "completed",
            "orders,",
            "and",
            "compute",
            "the",
            "month-over-month",
            "percentage",
            "growth",
            "for",
            "both",
            "revenue",
            "and",
            "orders",
            "by",
            "comparing",
            "each",
            "month’s",
            "totals",
            "to",
            "the",
            "previous",
            "month’s.",
            "Then,",
            "for",
            "the",
            "same",
            "orders,",
            "aggregate",
            "and",
            "show",
            "the",
            "total",
            "cost",
            "(from",
            "product",
            "costs),",
            "total",
            "profit",
            "(revenue",
            "minus",
            "total",
            "cost),",
            "and",
            "finally",
            "the",
            "profit-to-cost",
            "ratio",
            "for",
            "each",
            "month."
        ],
        "query": "",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq260",
        "question": "From January 1, 2019, to April 30, 2022, how many users are at the youngest age and how many users are at the oldest age for each gender in the e-commerce platform, counting both youngest and oldest users separately for each gender?",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "From",
            "January",
            "1,",
            "2019,",
            "to",
            "April",
            "30,",
            "2022,",
            "how",
            "many",
            "users",
            "are",
            "at",
            "the",
            "youngest",
            "age",
            "and",
            "how",
            "many",
            "users",
            "are",
            "at",
            "the",
            "oldest",
            "age",
            "for",
            "each",
            "gender",
            "in",
            "the",
            "e-commerce",
            "platform,",
            "counting",
            "both",
            "youngest",
            "and",
            "oldest",
            "users",
            "separately",
            "for",
            "each",
            "gender?"
        ],
        "query": "WITH filtered_users AS (\n    SELECT \n        \"first_name\", \n        \"last_name\", \n        \"gender\", \n        \"age\",\n        CAST(TO_TIMESTAMP(\"created_at\" / 1000000.0) AS DATE) AS \"created_at\"\n    FROM \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\"\n    WHERE \n        CAST(TO_TIMESTAMP(\"created_at\" / 1000000.0) AS DATE) BETWEEN '2019-01-01' AND '2022-04-30'\n),\nyoungest_ages AS (\n    SELECT \n        \"gender\", \n        MIN(\"age\") AS \"age\"\n    FROM \n        filtered_users\n    GROUP BY \n        \"gender\"\n),\noldest_ages AS (\n    SELECT \n        \"gender\", \n        MAX(\"age\") AS \"age\"\n    FROM \n        filtered_users\n    GROUP BY \n        \"gender\"\n),\nyoungest_oldest AS (\n    SELECT \n        u.\"first_name\", \n        u.\"last_name\", \n        u.\"gender\", \n        u.\"age\", \n        'youngest' AS \"tag\"\n    FROM \n        filtered_users u\n    JOIN \n        youngest_ages y\n    ON \n        u.\"gender\" = y.\"gender\" AND u.\"age\" = y.\"age\"\n    \n    UNION ALL\n    \n    SELECT \n        u.\"first_name\", \n        u.\"last_name\", \n        u.\"gender\", \n        u.\"age\", \n        'oldest' AS \"tag\"\n    FROM \n        filtered_users u\n    JOIN \n        oldest_ages o\n    ON \n        u.\"gender\" = o.\"gender\" AND u.\"age\" = o.\"age\"\n)\nSELECT \n    \"tag\", \n    \"gender\", \n    COUNT(*) AS \"num\"\nFROM \n    youngest_oldest\nGROUP BY \n    \"tag\", \"gender\"\nORDER BY \n    \"tag\", \"gender\";",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 1
    },
    {
        "instance_id": "sf_bq261",
        "question": "For each month prior to January 2024, identify the product that achieved the highest total profit (calculated as the sum of sale_price minus the product’s cost) across all order items, then report the total cost and total profit for that top product per month, including all order items regardless of their status, and present the results chronologically by month.",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "each",
            "month",
            "prior",
            "to",
            "January",
            "2024,",
            "identify",
            "the",
            "product",
            "that",
            "achieved",
            "the",
            "highest",
            "total",
            "profit",
            "(calculated",
            "as",
            "the",
            "sum",
            "of",
            "sale_price",
            "minus",
            "the",
            "product’s",
            "cost)",
            "across",
            "all",
            "order",
            "items,",
            "then",
            "report",
            "the",
            "total",
            "cost",
            "and",
            "total",
            "profit",
            "for",
            "that",
            "top",
            "product",
            "per",
            "month,",
            "including",
            "all",
            "order",
            "items",
            "regardless",
            "of",
            "their",
            "status,",
            "and",
            "present",
            "the",
            "results",
            "chronologically",
            "by",
            "month."
        ],
        "query": "",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq262",
        "question": "Generate a monthly analysis report for e-commerce sales from June 2019 to December 2019 that includes, for each product category and each month, the total number of orders, total revenue, and total profit, along with their month-over-month growth rates using the data from June 2019 as the basis for calculating growth starting from July 2019. Ensure that all orders are included regardless of their status, and present the results sorted in ascending order by month (formatted as \"2019-07\") and then by product category. Omitting June 2019 from the final output but using it for the growth calculations.",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Generate",
            "a",
            "monthly",
            "analysis",
            "report",
            "for",
            "e-commerce",
            "sales",
            "from",
            "June",
            "2019",
            "to",
            "December",
            "2019",
            "that",
            "includes,",
            "for",
            "each",
            "product",
            "category",
            "and",
            "each",
            "month,",
            "the",
            "total",
            "number",
            "of",
            "orders,",
            "total",
            "revenue,",
            "and",
            "total",
            "profit,",
            "along",
            "with",
            "their",
            "month-over-month",
            "growth",
            "rates",
            "using",
            "the",
            "data",
            "from",
            "June",
            "2019",
            "as",
            "the",
            "basis",
            "for",
            "calculating",
            "growth",
            "starting",
            "from",
            "July",
            "2019.",
            "Ensure",
            "that",
            "all",
            "orders",
            "are",
            "included",
            "regardless",
            "of",
            "their",
            "status,",
            "and",
            "present",
            "the",
            "results",
            "sorted",
            "in",
            "ascending",
            "order",
            "by",
            "month",
            "(formatted",
            "as",
            "\"2019-07\")",
            "and",
            "then",
            "by",
            "product",
            "category.",
            "Omitting",
            "June",
            "2019",
            "from",
            "the",
            "final",
            "output",
            "but",
            "using",
            "it",
            "for",
            "the",
            "growth",
            "calculations."
        ],
        "query": "",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq190",
        "question": "Determine the number of users who are the youngest and oldest for each gender (male and female) separately, among those who signed up between January 1, 2019, and April 30, 2022. For each gender, identify the minimum and maximum ages within this date range, and count how many users fall into these respective age groups.",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Determine",
            "the",
            "number",
            "of",
            "users",
            "who",
            "are",
            "the",
            "youngest",
            "and",
            "oldest",
            "for",
            "each",
            "gender",
            "(male",
            "and",
            "female)",
            "separately,",
            "among",
            "those",
            "who",
            "signed",
            "up",
            "between",
            "January",
            "1,",
            "2019,",
            "and",
            "April",
            "30,",
            "2022.",
            "For",
            "each",
            "gender,",
            "identify",
            "the",
            "minimum",
            "and",
            "maximum",
            "ages",
            "within",
            "this",
            "date",
            "range,",
            "and",
            "count",
            "how",
            "many",
            "users",
            "fall",
            "into",
            "these",
            "respective",
            "age",
            "groups."
        ],
        "query": "",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq263",
        "question": "Please create a month-by-month report for the year 2023 that focuses on the 'Sleep & Lounge' category, showing for each month the total sales, total cost, number of complete orders, total profit, and the profit-to-cost ratio, ensuring that the order is marked as 'Complete,' the creation date is between January 1, 2023, and December 31, 2023, and the cost data is accurately associated with the corresponding product through the order items.",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "create",
            "a",
            "month-by-month",
            "report",
            "for",
            "the",
            "year",
            "2023",
            "that",
            "focuses",
            "on",
            "the",
            "'Sleep",
            "&",
            "Lounge'",
            "category,",
            "showing",
            "for",
            "each",
            "month",
            "the",
            "total",
            "sales,",
            "total",
            "cost,",
            "number",
            "of",
            "complete",
            "orders,",
            "total",
            "profit,",
            "and",
            "the",
            "profit-to-cost",
            "ratio,",
            "ensuring",
            "that",
            "the",
            "order",
            "is",
            "marked",
            "as",
            "'Complete,'",
            "the",
            "creation",
            "date",
            "is",
            "between",
            "January",
            "1,",
            "2023,",
            "and",
            "December",
            "31,",
            "2023,",
            "and",
            "the",
            "cost",
            "data",
            "is",
            "accurately",
            "associated",
            "with",
            "the",
            "corresponding",
            "product",
            "through",
            "the",
            "order",
            "items."
        ],
        "query": "WITH d AS (\n    SELECT\n        a.\"order_id\", \n        TO_CHAR(TO_TIMESTAMP(a.\"created_at\" / 1000000.0), 'YYYY-MM') AS \"month\",  -- 格式化为年月\n        TO_CHAR(TO_TIMESTAMP(a.\"created_at\" / 1000000.0), 'YYYY') AS \"year\",  -- 格式化为年份\n        b.\"product_id\", b.\"sale_price\", c.\"category\", c.\"cost\"\n    FROM \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDERS\" AS a\n    JOIN \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDER_ITEMS\" AS b\n        ON a.\"order_id\" = b.\"order_id\"\n    JOIN \n        \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"PRODUCTS\" AS c\n        ON b.\"product_id\" = c.\"id\"\n    WHERE \n        a.\"status\" = 'Complete'\n        AND TO_TIMESTAMP(a.\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2023-01-01') AND TO_TIMESTAMP('2023-12-31')\n        AND c.\"category\" = 'Sleep & Lounge'\n),\n\ne AS (\n    SELECT \n        \"month\", \n        \"year\", \n        \"sale_price\", \n        \"category\", \n        \"cost\",\n        SUM(\"sale_price\") OVER (PARTITION BY \"month\", \"category\") AS \"TPV\",\n        SUM(\"cost\") OVER (PARTITION BY \"month\", \"category\") AS \"total_cost\",\n        COUNT(DISTINCT \"order_id\") OVER (PARTITION BY \"month\", \"category\") AS \"TPO\",\n        SUM(\"sale_price\" - \"cost\") OVER (PARTITION BY \"month\", \"category\") AS \"total_profit\",\n        SUM((\"sale_price\" - \"cost\") / \"cost\") OVER (PARTITION BY \"month\", \"category\") AS \"Profit_to_cost_ratio\"\n    FROM \n        d\n)\n\nSELECT DISTINCT \n    \"month\", \n    \"category\", \n    \"TPV\", \n    \"total_cost\", \n    \"TPO\", \n    \"total_profit\", \n    \"Profit_to_cost_ratio\"\nFROM \n    e\nORDER BY \n    \"month\";",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 3
    },
    {
        "instance_id": "sf_bq265",
        "question": "Can you list the email addresses of the top 10 users who registered in 2019 and made purchases in 2019, ranking them by their highest average order value, where average order value is calculated by multiplying the number of items in each order by the sale price, summing this total across all orders for each user, and then dividing by the total number of orders?",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "list",
            "the",
            "email",
            "addresses",
            "of",
            "the",
            "top",
            "10",
            "users",
            "who",
            "registered",
            "in",
            "2019",
            "and",
            "made",
            "purchases",
            "in",
            "2019,",
            "ranking",
            "them",
            "by",
            "their",
            "highest",
            "average",
            "order",
            "value,",
            "where",
            "average",
            "order",
            "value",
            "is",
            "calculated",
            "by",
            "multiplying",
            "the",
            "number",
            "of",
            "items",
            "in",
            "each",
            "order",
            "by",
            "the",
            "sale",
            "price,",
            "summing",
            "this",
            "total",
            "across",
            "all",
            "orders",
            "for",
            "each",
            "user,",
            "and",
            "then",
            "dividing",
            "by",
            "the",
            "total",
            "number",
            "of",
            "orders?"
        ],
        "query": "WITH\n  main AS (\n    SELECT\n      \"id\" AS \"user_id\",\n      \"email\",\n      \"gender\",\n      \"country\",\n      \"traffic_source\"\n    FROM\n      \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"USERS\"\n    WHERE\n      TO_TIMESTAMP(\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2019-01-01') AND TO_TIMESTAMP('2019-12-31')\n  ),\n\n  daate AS (\n    SELECT\n      \"user_id\",\n      \"order_id\",\n      CAST(TO_TIMESTAMP(\"created_at\" / 1000000.0) AS DATE) AS \"order_date\",\n      \"num_of_item\"\n    FROM\n      \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDERS\"\n    WHERE\n      TO_TIMESTAMP(\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2019-01-01') AND TO_TIMESTAMP('2019-12-31')\n  ),\n\n  orders AS (\n    SELECT\n      \"user_id\",\n      \"order_id\",\n      \"product_id\",\n      \"sale_price\",\n      \"status\"\n    FROM\n      \"THELOOK_ECOMMERCE\".\"THELOOK_ECOMMERCE\".\"ORDER_ITEMS\"\n    WHERE\n      TO_TIMESTAMP(\"created_at\" / 1000000.0) BETWEEN TO_TIMESTAMP('2019-01-01') AND TO_TIMESTAMP('2019-12-31')\n  ),\n\n  nest AS (\n    SELECT\n      o.\"user_id\",\n      o.\"order_id\",\n      o.\"product_id\",\n      d.\"order_date\",\n      d.\"num_of_item\",\n      ROUND(o.\"sale_price\", 2) AS \"sale_price\",\n      ROUND(d.\"num_of_item\" * o.\"sale_price\", 2) AS \"total_sale\"\n    FROM\n      orders o\n    INNER JOIN\n      daate d\n    ON\n      o.\"order_id\" = d.\"order_id\"\n    ORDER BY\n      o.\"user_id\"\n  ),\n\n  type AS (\n    SELECT\n      \"user_id\",\n      MIN(nest.\"order_date\") AS \"cohort_date\",\n      MAX(nest.\"order_date\") AS \"latest_shopping_date\",\n      DATEDIFF(MONTH, MIN(nest.\"order_date\"), MAX(nest.\"order_date\")) AS \"lifespan_months\",\n      ROUND(SUM(\"total_sale\"), 2) AS \"ltv\",\n      COUNT(\"order_id\") AS \"no_of_order\"\n    FROM\n      nest\n    GROUP BY\n      \"user_id\"\n  ),\n\n  kite AS (\n    SELECT\n      m.\"user_id\",\n      m.\"email\",\n      m.\"gender\",\n      m.\"country\",\n      m.\"traffic_source\",\n      EXTRACT(YEAR FROM n.\"cohort_date\") AS \"cohort_year\",\n      n.\"latest_shopping_date\",\n      n.\"lifespan_months\",\n      n.\"ltv\",\n      n.\"no_of_order\",\n      ROUND(n.\"ltv\" / n.\"no_of_order\", 2) AS \"avg_order_value\"\n    FROM\n      main m\n    INNER JOIN\n      type n\n    ON\n      m.\"user_id\" = n.\"user_id\"\n  )\n\nSELECT\n  \"email\"\nFROM\n  kite\nORDER BY\n  \"avg_order_value\" DESC\nLIMIT 10;",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 3
    },
    {
        "instance_id": "sf_bq333",
        "question": "Which three browsers have the shortest average session duration—calculated by the difference in seconds between the earliest and latest timestamps for each user’s session—while only including browsers that have more than 10 total sessions, and what are their respective average session durations?",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "three",
            "browsers",
            "have",
            "the",
            "shortest",
            "average",
            "session",
            "duration—calculated",
            "by",
            "the",
            "difference",
            "in",
            "seconds",
            "between",
            "the",
            "earliest",
            "and",
            "latest",
            "timestamps",
            "for",
            "each",
            "user’s",
            "session—while",
            "only",
            "including",
            "browsers",
            "that",
            "have",
            "more",
            "than",
            "10",
            "total",
            "sessions,",
            "and",
            "what",
            "are",
            "their",
            "respective",
            "average",
            "session",
            "durations?"
        ],
        "query": "",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq272",
        "question": "Please provide the names of the top three most profitable products for each month from January 2019 through August 2022, excluding any products associated with orders that were canceled or returned. For each product in each month, the profit should be calculated as the sum of the sale prices of all order items minus the sum of the costs of those sold items in that month.",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "provide",
            "the",
            "names",
            "of",
            "the",
            "top",
            "three",
            "most",
            "profitable",
            "products",
            "for",
            "each",
            "month",
            "from",
            "January",
            "2019",
            "through",
            "August",
            "2022,",
            "excluding",
            "any",
            "products",
            "associated",
            "with",
            "orders",
            "that",
            "were",
            "canceled",
            "or",
            "returned.",
            "For",
            "each",
            "product",
            "in",
            "each",
            "month,",
            "the",
            "profit",
            "should",
            "be",
            "calculated",
            "as",
            "the",
            "sum",
            "of",
            "the",
            "sale",
            "prices",
            "of",
            "all",
            "order",
            "items",
            "minus",
            "the",
            "sum",
            "of",
            "the",
            "costs",
            "of",
            "those",
            "sold",
            "items",
            "in",
            "that",
            "month."
        ],
        "query": "",
        "db_id": "THELOOK_ECOMMERCE",
        "No. of candidate columns": 73,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq086",
        "question": "You need to calculate the percentage of each country's population that had been confirmed with COVID-19 by June 30, 2020. The population data for 2018 can be found in the World Bank dataset, and the cumulative COVID-19 confirmed cases data is available in the COVID-19 Open Data dataset. Calculate the percentage of each country's population, that was cumulatively confirmed to have COVID-19",
        "external_knowledge": null,
        "question_toks": [
            "You",
            "need",
            "to",
            "calculate",
            "the",
            "percentage",
            "of",
            "each",
            "country's",
            "population",
            "that",
            "had",
            "been",
            "confirmed",
            "with",
            "COVID-19",
            "by",
            "June",
            "30,",
            "2020.",
            "The",
            "population",
            "data",
            "for",
            "2018",
            "can",
            "be",
            "found",
            "in",
            "the",
            "World",
            "Bank",
            "dataset,",
            "and",
            "the",
            "cumulative",
            "COVID-19",
            "confirmed",
            "cases",
            "data",
            "is",
            "available",
            "in",
            "the",
            "COVID-19",
            "Open",
            "Data",
            "dataset.",
            "Calculate",
            "the",
            "percentage",
            "of",
            "each",
            "country's",
            "population,",
            "that",
            "was",
            "cumulatively",
            "confirmed",
            "to",
            "have",
            "COVID-19"
        ],
        "query": "",
        "db_id": "covid19_open_world_bank",
        "No. of candidate columns": 1015,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq087",
        "question": "Please calculate the overall percentage change in the average weekly search frequency for the symptom 'Anosmia' across the five New York City counties—Bronx County, Queens County, Kings County, New York County, and Richmond County—by comparing the combined data from January 1, 2019, through December 31, 2019, with the combined data from January 1, 2020, through December 31, 2020.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "calculate",
            "the",
            "overall",
            "percentage",
            "change",
            "in",
            "the",
            "average",
            "weekly",
            "search",
            "frequency",
            "for",
            "the",
            "symptom",
            "'Anosmia'",
            "across",
            "the",
            "five",
            "New",
            "York",
            "City",
            "counties—Bronx",
            "County,",
            "Queens",
            "County,",
            "Kings",
            "County,",
            "New",
            "York",
            "County,",
            "and",
            "Richmond",
            "County—by",
            "comparing",
            "the",
            "combined",
            "data",
            "from",
            "January",
            "1,",
            "2019,",
            "through",
            "December",
            "31,",
            "2019,",
            "with",
            "the",
            "combined",
            "data",
            "from",
            "January",
            "1,",
            "2020,",
            "through",
            "December",
            "31,",
            "2020."
        ],
        "query": "",
        "db_id": "covid19_symptom_search",
        "No. of candidate columns": 2580,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq137",
        "question": "Please find all zip code areas located within 10 kilometers of the coordinates (-122.3321, 47.6062) by joining the 2010 census population data (summing only male and female populations with no age constraints) and the zip code area information, and return each area’s polygon, land and water area in meters, latitude and longitude, state code, state name, city, county, and total population.",
        "external_knowledge": "functions_st_dwithin.md",
        "question_toks": [
            "Please",
            "find",
            "all",
            "zip",
            "code",
            "areas",
            "located",
            "within",
            "10",
            "kilometers",
            "of",
            "the",
            "coordinates",
            "(-122.3321,",
            "47.6062)",
            "by",
            "joining",
            "the",
            "2010",
            "census",
            "population",
            "data",
            "(summing",
            "only",
            "male",
            "and",
            "female",
            "populations",
            "with",
            "no",
            "age",
            "constraints)",
            "and",
            "the",
            "zip",
            "code",
            "area",
            "information,",
            "and",
            "return",
            "each",
            "area’s",
            "polygon,",
            "land",
            "and",
            "water",
            "area",
            "in",
            "meters,",
            "latitude",
            "and",
            "longitude,",
            "state",
            "code,",
            "state",
            "name,",
            "city,",
            "county,",
            "and",
            "total",
            "population."
        ],
        "query": "",
        "db_id": "census_bureau_usa",
        "No. of candidate columns": 132,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq064",
        "question": "Using the 2017 U.S. Census Tract data from the BigQuery public datasets, you need to proportionally allocate each tract's population and income to the zip codes based on the overlapping area between their geographic boundaries. Then, filter the results to include only those zip codes located within a 5-mile radius of a specific point in Washington State, with coordinates at latitude 47.685833°N and longitude -122.191667°W. Finally, calculate the total population and the average individual income for each zip code (rounded to one decimal place) and sort the results by the average individual income in descending order.",
        "external_knowledge": "functions_st_intersects_area.md",
        "question_toks": [
            "Using",
            "the",
            "2017",
            "U.S.",
            "Census",
            "Tract",
            "data",
            "from",
            "the",
            "BigQuery",
            "public",
            "datasets,",
            "you",
            "need",
            "to",
            "proportionally",
            "allocate",
            "each",
            "tract's",
            "population",
            "and",
            "income",
            "to",
            "the",
            "zip",
            "codes",
            "based",
            "on",
            "the",
            "overlapping",
            "area",
            "between",
            "their",
            "geographic",
            "boundaries.",
            "Then,",
            "filter",
            "the",
            "results",
            "to",
            "include",
            "only",
            "those",
            "zip",
            "codes",
            "located",
            "within",
            "a",
            "5-mile",
            "radius",
            "of",
            "a",
            "specific",
            "point",
            "in",
            "Washington",
            "State,",
            "with",
            "coordinates",
            "at",
            "latitude",
            "47.685833°N",
            "and",
            "longitude",
            "-122.191667°W.",
            "Finally,",
            "calculate",
            "the",
            "total",
            "population",
            "and",
            "the",
            "average",
            "individual",
            "income",
            "for",
            "each",
            "zip",
            "code",
            "(rounded",
            "to",
            "one",
            "decimal",
            "place)",
            "and",
            "sort",
            "the",
            "results",
            "by",
            "the",
            "average",
            "individual",
            "income",
            "in",
            "descending",
            "order."
        ],
        "query": "",
        "db_id": "census_bureau_acs_1",
        "No. of candidate columns": 69183,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq427",
        "question": "Could you determine, for each shot type, the average x and y coordinates (adjusted to ensure consistency regarding the left or right basket), the average number of shot attempts, and the average number of successful shots, considering only shots taken before March 15, 2018, excluding those with null shot types or coordinates, ensuring the shots are on the correct side of the court based on the team's basket.",
        "external_knowledge": "basketball.md",
        "question_toks": [
            "Could",
            "you",
            "determine,",
            "for",
            "each",
            "shot",
            "type,",
            "the",
            "average",
            "x",
            "and",
            "y",
            "coordinates",
            "(adjusted",
            "to",
            "ensure",
            "consistency",
            "regarding",
            "the",
            "left",
            "or",
            "right",
            "basket),",
            "the",
            "average",
            "number",
            "of",
            "shot",
            "attempts,",
            "and",
            "the",
            "average",
            "number",
            "of",
            "successful",
            "shots,",
            "considering",
            "only",
            "shots",
            "taken",
            "before",
            "March",
            "15,",
            "2018,",
            "excluding",
            "those",
            "with",
            "null",
            "shot",
            "types",
            "or",
            "coordinates,",
            "ensuring",
            "the",
            "shots",
            "are",
            "on",
            "the",
            "correct",
            "side",
            "of",
            "the",
            "court",
            "based",
            "on",
            "the",
            "team's",
            "basket."
        ],
        "query": "",
        "db_id": "ncaa_basketball",
        "No. of candidate columns": 505,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq112",
        "question": "Between 1998 and 2017, for Allegheny County in the Pittsburgh area, did the average annual wages for all industries keep pace with the inflation of all consumer items, and what were the respective percentage growth rates (to two decimal places) for wages and the CPI over that period?",
        "external_knowledge": null,
        "question_toks": [
            "Between",
            "1998",
            "and",
            "2017,",
            "for",
            "Allegheny",
            "County",
            "in",
            "the",
            "Pittsburgh",
            "area,",
            "did",
            "the",
            "average",
            "annual",
            "wages",
            "for",
            "all",
            "industries",
            "keep",
            "pace",
            "with",
            "the",
            "inflation",
            "of",
            "all",
            "consumer",
            "items,",
            "and",
            "what",
            "were",
            "the",
            "respective",
            "percentage",
            "growth",
            "rates",
            "(to",
            "two",
            "decimal",
            "places)",
            "for",
            "wages",
            "and",
            "the",
            "CPI",
            "over",
            "that",
            "period?"
        ],
        "query": "WITH geo AS (\n  SELECT DISTINCT geo_id\n  FROM `bigquery-public-data.geo_us_boundaries.counties`\n  WHERE county_name = \"Allegheny\" \n),\navg_wage_1998 AS(\n  SELECT\n    ROUND(AVG(avg_wkly_wage_10_total_all_industries) * 52, 2) AS wages_1998\n  FROM\n    `bigquery-public-data.bls_qcew.1998*`\n  WHERE\n    geoid = (SELECT geo_id FROM geo) --Selecting Allgeheny County\n),\n    \navg_wage_2017 AS (\n  SELECT\n    ROUND(AVG(avg_wkly_wage_10_total_all_industries) * 52, 2) AS wages_2017\n  FROM\n    `bigquery-public-data.bls_qcew.2017*`\n  WHERE\n    geoid = (SELECT geo_id FROM geo) --Selecting Allgeheny County\n),\n\navg_cpi_1998 AS (\n  SELECT\n    AVG(value) AS cpi_1998\n  FROM\n    `bigquery-public-data.bls.cpi_u` c\n  WHERE\n    year = 1998\n    AND item_code in (\n      SELECT DISTINCT item_code FROM `bigquery-public-data.bls.cpi_u` WHERE LOWER(item_name) = \"all items\"\n    )\n    AND area_code = (\n      SELECT DISTINCT area_code FROM `bigquery-public-data.bls.cpi_u` WHERE area_name LIKE '%Pittsburgh%'\n    )\n), \n-- A104 is the code for Pittsburgh, PA\n-- SA0 is the code for all items\n    \navg_cpi_2017 AS(\n  SELECT\n    AVG(value) AS cpi_2017\n  FROM\n    `bigquery-public-data.bls.cpi_u` c\n  WHERE\n    year = 2017\n    AND item_code in (\n      SELECT DISTINCT item_code FROM `bigquery-public-data.bls.cpi_u` WHERE LOWER(item_name) = \"all items\"\n    )\n    AND area_code = (\n      SELECT DISTINCT area_code FROM `bigquery-public-data.bls.cpi_u` WHERE area_name LIKE '%Pittsburgh%'\n    )\n)\n-- A104 is the code for Pittsburgh, PA\n-- SA0 is the code for all items\n\nSELECT\n  ROUND((wages_2017 - wages_1998) / wages_1998 * 100, 2) AS wages_percent_change,\n  ROUND((cpi_2017 - cpi_1998) / cpi_1998 * 100, 2) AS cpi_percent_change\nFROM\n  avg_wage_2017,\n  avg_wage_1998,\n  avg_cpi_2017,\n  avg_cpi_1998",
        "db_id": "bls",
        "No. of candidate columns": 23205,
        "No. of gold tables": 7
    },
    {
        "instance_id": "bq055",
        "question": "Can you provide the top three races with the largest percentage differences between Google's 2021 overall hiring data from dar non intersectional hiring and the average percentages in the 2021 BLS data for the technology sectors specifically defined as 'Internet publishing and broadcasting and web search portals,' 'Software publishers,' 'Data processing, hosting, and related services,' or the industry group 'Computer systems design and related services,' along with their respective differences?",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "provide",
            "the",
            "top",
            "three",
            "races",
            "with",
            "the",
            "largest",
            "percentage",
            "differences",
            "between",
            "Google's",
            "2021",
            "overall",
            "hiring",
            "data",
            "from",
            "dar",
            "non",
            "intersectional",
            "hiring",
            "and",
            "the",
            "average",
            "percentages",
            "in",
            "the",
            "2021",
            "BLS",
            "data",
            "for",
            "the",
            "technology",
            "sectors",
            "specifically",
            "defined",
            "as",
            "'Internet",
            "publishing",
            "and",
            "broadcasting",
            "and",
            "web",
            "search",
            "portals,'",
            "'Software",
            "publishers,'",
            "'Data",
            "processing,",
            "hosting,",
            "and",
            "related",
            "services,'",
            "or",
            "the",
            "industry",
            "group",
            "'Computer",
            "systems",
            "design",
            "and",
            "related",
            "services,'",
            "along",
            "with",
            "their",
            "respective",
            "differences?"
        ],
        "query": "",
        "db_id": "google_dei",
        "No. of candidate columns": 23134,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq075",
        "question": "Could you provide a combined 2021 report comparing racial (Asian, Black, Hispanic/Latinx, White) and gender (U.S. Women, U.S. Men) distributions across Google’s overall workforce hiring, Google’s overall workforce representation, and the BLS data specifically for the technology sectors defined as Internet publishing and broadcasting and web search portals or Computer systems design and related services?",
        "external_knowledge": null,
        "question_toks": [
            "Could",
            "you",
            "provide",
            "a",
            "combined",
            "2021",
            "report",
            "comparing",
            "racial",
            "(Asian,",
            "Black,",
            "Hispanic/Latinx,",
            "White)",
            "and",
            "gender",
            "(U.S.",
            "Women,",
            "U.S.",
            "Men)",
            "distributions",
            "across",
            "Google’s",
            "overall",
            "workforce",
            "hiring,",
            "Google’s",
            "overall",
            "workforce",
            "representation,",
            "and",
            "the",
            "BLS",
            "data",
            "specifically",
            "for",
            "the",
            "technology",
            "sectors",
            "defined",
            "as",
            "Internet",
            "publishing",
            "and",
            "broadcasting",
            "and",
            "web",
            "search",
            "portals",
            "or",
            "Computer",
            "systems",
            "design",
            "and",
            "related",
            "services?"
        ],
        "query": "",
        "db_id": "google_dei",
        "No. of candidate columns": 23134,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq084",
        "question": "For each month in the year 2023, how many total transactions occurred (counting all transaction records without removing duplicates of transaction hashes), and how many transactions per second were processed each month, where the transactions-per-second value is calculated by dividing the monthly total count by the exact number of seconds in that month, including the correct leap-year logic if applicable based on the extracted year from the transaction timestamp? Show the monthly transaction count, the computed transactions per second, the year, and the month, and present the rows in descending order of the monthly transaction count.",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "each",
            "month",
            "in",
            "the",
            "year",
            "2023,",
            "how",
            "many",
            "total",
            "transactions",
            "occurred",
            "(counting",
            "all",
            "transaction",
            "records",
            "without",
            "removing",
            "duplicates",
            "of",
            "transaction",
            "hashes),",
            "and",
            "how",
            "many",
            "transactions",
            "per",
            "second",
            "were",
            "processed",
            "each",
            "month,",
            "where",
            "the",
            "transactions-per-second",
            "value",
            "is",
            "calculated",
            "by",
            "dividing",
            "the",
            "monthly",
            "total",
            "count",
            "by",
            "the",
            "exact",
            "number",
            "of",
            "seconds",
            "in",
            "that",
            "month,",
            "including",
            "the",
            "correct",
            "leap-year",
            "logic",
            "if",
            "applicable",
            "based",
            "on",
            "the",
            "extracted",
            "year",
            "from",
            "the",
            "transaction",
            "timestamp?",
            "Show",
            "the",
            "monthly",
            "transaction",
            "count,",
            "the",
            "computed",
            "transactions",
            "per",
            "second,",
            "the",
            "year,",
            "and",
            "the",
            "month,",
            "and",
            "present",
            "the",
            "rows",
            "in",
            "descending",
            "order",
            "of",
            "the",
            "monthly",
            "transaction",
            "count."
        ],
        "query": "",
        "db_id": "GOOG_BLOCKCHAIN",
        "No. of candidate columns": 22,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq416",
        "question": "Could you retrieve the top three largest USDT transfers on the TRON blockchain by listing the block numbers, source addresses, destination addresses (in TronLink format), and transfer amounts, using the USDT contract address '0xa614f803b6fd780986a42c78ec9c7f77e6ded13c' and the transfer event signature '0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef', dividing the raw transfer value by 1,000,000 to convert it into the final USDT amount, and then ordering the results by the largest transferred amounts first?",
        "external_knowledge": "blockchain_data_transformations.md",
        "question_toks": [
            "Could",
            "you",
            "retrieve",
            "the",
            "top",
            "three",
            "largest",
            "USDT",
            "transfers",
            "on",
            "the",
            "TRON",
            "blockchain",
            "by",
            "listing",
            "the",
            "block",
            "numbers,",
            "source",
            "addresses,",
            "destination",
            "addresses",
            "(in",
            "TronLink",
            "format),",
            "and",
            "transfer",
            "amounts,",
            "using",
            "the",
            "USDT",
            "contract",
            "address",
            "'0xa614f803b6fd780986a42c78ec9c7f77e6ded13c'",
            "and",
            "the",
            "transfer",
            "event",
            "signature",
            "'0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef',",
            "dividing",
            "the",
            "raw",
            "transfer",
            "value",
            "by",
            "1,000,000",
            "to",
            "convert",
            "it",
            "into",
            "the",
            "final",
            "USDT",
            "amount,",
            "and",
            "then",
            "ordering",
            "the",
            "results",
            "by",
            "the",
            "largest",
            "transferred",
            "amounts",
            "first?"
        ],
        "query": "",
        "db_id": "GOOG_BLOCKCHAIN",
        "No. of candidate columns": 22,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq226",
        "question": "Which sender address, represented as a complete URL on https://cronoscan.com, has been used most frequently on the Cronos blockchain in transactions to non-null 'to_address' fields, within blocks larger than 4096 bytes, since January 1, 2023?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "sender",
            "address,",
            "represented",
            "as",
            "a",
            "complete",
            "URL",
            "on",
            "https://cronoscan.com,",
            "has",
            "been",
            "used",
            "most",
            "frequently",
            "on",
            "the",
            "Cronos",
            "blockchain",
            "in",
            "transactions",
            "to",
            "non-null",
            "'to_address'",
            "fields,",
            "within",
            "blocks",
            "larger",
            "than",
            "4096",
            "bytes,",
            "since",
            "January",
            "1,",
            "2023?"
        ],
        "query": "",
        "db_id": "GOOG_BLOCKCHAIN",
        "No. of candidate columns": 22,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq325",
        "question": "Please identify the top 10 genes with the strongest associations across all studies by first selecting, for each gene within each study, the variant with the lowest p-value, and then ranking all such gene–variant pairs to return the 10 genes with the smallest p-values overall.",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "identify",
            "the",
            "top",
            "10",
            "genes",
            "with",
            "the",
            "strongest",
            "associations",
            "across",
            "all",
            "studies",
            "by",
            "first",
            "selecting,",
            "for",
            "each",
            "gene",
            "within",
            "each",
            "study,",
            "the",
            "variant",
            "with",
            "the",
            "lowest",
            "p-value,",
            "and",
            "then",
            "ranking",
            "all",
            "such",
            "gene–variant",
            "pairs",
            "to",
            "return",
            "the",
            "10",
            "genes",
            "with",
            "the",
            "smallest",
            "p-values",
            "overall."
        ],
        "query": "",
        "db_id": "OPEN_TARGETS_GENETICS_2",
        "No. of candidate columns": 293,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq220",
        "question": "Based on the condition, plot_tree, and population tables in bigquery-public-data.usfs_fia, for the evaluation_type set to 'EXPCURR' and condition_status_code equal to 1, which states had the largest average subplot size and the largest average macroplot size, respectively, for each of the years 2015, 2016, and 2017? Please include the type of plot (subplot or macroplot), the specific year, the state, and the corresponding average size in your results.",
        "external_knowledge": "subplot_macroplot_size.md",
        "question_toks": [
            "Based",
            "on",
            "the",
            "condition,",
            "plot_tree,",
            "and",
            "population",
            "tables",
            "in",
            "bigquery-public-data.usfs_fia,",
            "for",
            "the",
            "evaluation_type",
            "set",
            "to",
            "'EXPCURR'",
            "and",
            "condition_status_code",
            "equal",
            "to",
            "1,",
            "which",
            "states",
            "had",
            "the",
            "largest",
            "average",
            "subplot",
            "size",
            "and",
            "the",
            "largest",
            "average",
            "macroplot",
            "size,",
            "respectively,",
            "for",
            "each",
            "of",
            "the",
            "years",
            "2015,",
            "2016,",
            "and",
            "2017?",
            "Please",
            "include",
            "the",
            "type",
            "of",
            "plot",
            "(subplot",
            "or",
            "macroplot),",
            "the",
            "specific",
            "year,",
            "the",
            "state,",
            "and",
            "the",
            "corresponding",
            "average",
            "size",
            "in",
            "your",
            "results."
        ],
        "query": "",
        "db_id": "usfs_fia",
        "No. of candidate columns": 1050,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq276",
        "question": "Can you provide a comprehensive list of all ports in region number 6585 that lie within U.S. state boundaries and have been affected by named storms in the North Atlantic basin with wind speeds of at least 35 knots and a Saffir-Simpson classification of at least minimal tropical storm strength, including for each port its name, the state name, the distinct years in which storms occurred, the total count of distinct storms, the distinct storm names, the average storm category, the average wind speed, and the respective geometries for both the port and the tropical storm areas?",
        "temporal": "Yes",
        "external_knowledge": "persistent_udfs_routines.md",
        "question_toks": [
            "Can",
            "you",
            "provide",
            "a",
            "comprehensive",
            "list",
            "of",
            "all",
            "ports",
            "in",
            "region",
            "number",
            "6585",
            "that",
            "lie",
            "within",
            "U.S.",
            "state",
            "boundaries",
            "and",
            "have",
            "been",
            "affected",
            "by",
            "named",
            "storms",
            "in",
            "the",
            "North",
            "Atlantic",
            "basin",
            "with",
            "wind",
            "speeds",
            "of",
            "at",
            "least",
            "35",
            "knots",
            "and",
            "a",
            "Saffir-Simpson",
            "classification",
            "of",
            "at",
            "least",
            "minimal",
            "tropical",
            "storm",
            "strength,",
            "including",
            "for",
            "each",
            "port",
            "its",
            "name,",
            "the",
            "state",
            "name,",
            "the",
            "distinct",
            "years",
            "in",
            "which",
            "storms",
            "occurred,",
            "the",
            "total",
            "count",
            "of",
            "distinct",
            "storms,",
            "the",
            "distinct",
            "storm",
            "names,",
            "the",
            "average",
            "storm",
            "category,",
            "the",
            "average",
            "wind",
            "speed,",
            "and",
            "the",
            "respective",
            "geometries",
            "for",
            "both",
            "the",
            "port",
            "and",
            "the",
            "tropical",
            "storm",
            "areas?"
        ],
        "query": "",
        "db_id": "NOAA_PORTS",
        "No. of candidate columns": 401,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq277",
        "question": "Which single port, listed under region number '6585', is located within a U.S. state boundary and appears most frequently inside the geographic areas of named tropical storms with wind speeds of at least 35 knots in the North Atlantic basin, excluding those labeled 'NOT_NAMED'?",
        "external_knowledge": "persistent_udfs_routines.md",
        "question_toks": [
            "Which",
            "single",
            "port,",
            "listed",
            "under",
            "region",
            "number",
            "'6585',",
            "is",
            "located",
            "within",
            "a",
            "U.S.",
            "state",
            "boundary",
            "and",
            "appears",
            "most",
            "frequently",
            "inside",
            "the",
            "geographic",
            "areas",
            "of",
            "named",
            "tropical",
            "storms",
            "with",
            "wind",
            "speeds",
            "of",
            "at",
            "least",
            "35",
            "knots",
            "in",
            "the",
            "North",
            "Atlantic",
            "basin,",
            "excluding",
            "those",
            "labeled",
            "'NOT_NAMED'?"
        ],
        "query": "",
        "db_id": "noaa_ports",
        "No. of candidate columns": 414,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq445",
        "question": "Using the gnomAD v2.1.1 genomes data for chromosome 17, determine the smallest start position and largest end position of any variant whose nested VEP annotations contain the symbol 'BRCA1'. Then, for all variants whose positions fall within that gene region, retrieve the 'Protein_position' values only if the 'Consequence' includes 'missense_variant', sort them in ascending order by 'Protein_position', and finally output the first such result.",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "the",
            "gnomAD",
            "v2.1.1",
            "genomes",
            "data",
            "for",
            "chromosome",
            "17,",
            "determine",
            "the",
            "smallest",
            "start",
            "position",
            "and",
            "largest",
            "end",
            "position",
            "of",
            "any",
            "variant",
            "whose",
            "nested",
            "VEP",
            "annotations",
            "contain",
            "the",
            "symbol",
            "'BRCA1'.",
            "Then,",
            "for",
            "all",
            "variants",
            "whose",
            "positions",
            "fall",
            "within",
            "that",
            "gene",
            "region,",
            "retrieve",
            "the",
            "'Protein_position'",
            "values",
            "only",
            "if",
            "the",
            "'Consequence'",
            "includes",
            "'missense_variant',",
            "sort",
            "them",
            "in",
            "ascending",
            "order",
            "by",
            "'Protein_position',",
            "and",
            "finally",
            "output",
            "the",
            "first",
            "such",
            "result."
        ],
        "query": "",
        "db_id": "gnomAD",
        "No. of candidate columns": 10264,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq411",
        "question": "Please retrieve the top three Google Trends search terms (ranks 1, 2, and 3) from top_terms for each weekday (Monday through Friday) between September 1, 2024, and September 14, 2024, grouped by the refresh_date column and ordered in descending order of refresh_date.",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "retrieve",
            "the",
            "top",
            "three",
            "Google",
            "Trends",
            "search",
            "terms",
            "(ranks",
            "1,",
            "2,",
            "and",
            "3)",
            "from",
            "top_terms",
            "for",
            "each",
            "weekday",
            "(Monday",
            "through",
            "Friday)",
            "between",
            "September",
            "1,",
            "2024,",
            "and",
            "September",
            "14,",
            "2024,",
            "grouped",
            "by",
            "the",
            "refresh_date",
            "column",
            "and",
            "ordered",
            "in",
            "descending",
            "order",
            "of",
            "refresh_date."
        ],
        "query": "",
        "db_id": "GOOGLE_TRENDS",
        "No. of candidate columns": 34,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq105",
        "question": "According to the 2015 and 2016 accident and driver distraction, and excluding cases where the driver’s distraction status is recorded as 'Not Distracted,' 'Unknown if Distracted,' or 'Not Reported,' how many traffic accidents per 100,000 people were caused by driver distraction in each U.S. state for those two years, based on 2010 census population data, and which five states each year had the highest rates?",
        "external_knowledge": null,
        "question_toks": [
            "According",
            "to",
            "the",
            "2015",
            "and",
            "2016",
            "accident",
            "and",
            "driver",
            "distraction,",
            "and",
            "excluding",
            "cases",
            "where",
            "the",
            "driver’s",
            "distraction",
            "status",
            "is",
            "recorded",
            "as",
            "'Not",
            "Distracted,'",
            "'Unknown",
            "if",
            "Distracted,'",
            "or",
            "'Not",
            "Reported,'",
            "how",
            "many",
            "traffic",
            "accidents",
            "per",
            "100,000",
            "people",
            "were",
            "caused",
            "by",
            "driver",
            "distraction",
            "in",
            "each",
            "U.S.",
            "state",
            "for",
            "those",
            "two",
            "years,",
            "based",
            "on",
            "2010",
            "census",
            "population",
            "data,",
            "and",
            "which",
            "five",
            "states",
            "each",
            "year",
            "had",
            "the",
            "highest",
            "rates?"
        ],
        "query": "",
        "db_id": "nhtsa_traffic_fatalities_plus",
        "No. of candidate columns": 498,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq108",
        "question": "Within the 2015 dataset for accidents that occurred from January through August and involved more than one distinct person, what percentage of these accidents had more than one individual with a severe injury (injury severity = 4)",
        "external_knowledge": null,
        "question_toks": [
            "Within",
            "the",
            "2015",
            "dataset",
            "for",
            "accidents",
            "that",
            "occurred",
            "from",
            "January",
            "through",
            "August",
            "and",
            "involved",
            "more",
            "than",
            "one",
            "distinct",
            "person,",
            "what",
            "percentage",
            "of",
            "these",
            "accidents",
            "had",
            "more",
            "than",
            "one",
            "individual",
            "with",
            "a",
            "severe",
            "injury",
            "(injury",
            "severity",
            "=",
            "4)"
        ],
        "query": "",
        "db_id": "nhtsa_traffic_fatalities",
        "No. of candidate columns": 366,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq067",
        "question": "I want to create a labeled dataset from the National Highway Traffic Safety Administration traffic fatality data that predicts whether a traffic accident involving more than one distinct person results in more than one fatality, where the label is 1 if an accident has more than one person with an injury severity code of 4 (fatal injury) and 0 otherwise. For each accident, include the numeric predictors: state_number, the vehicle body_type, the number_of_drunk_drivers, the day_of_week, the hour_of_crash, and a binary indicator for whether the accident occurred in a work zone (1 if it is not “None,” otherwise 0). Also, engineer a feature for the average absolute difference between travel_speed and speed_limit per accident, only considering travel speeds up to 151 mph (excluding codes 997, 998, 999) and speed limits up to 80 mph (excluding codes 98, 99), and categorize this average speed difference into levels from 0 to 4 in 20 mph increments with lower bounds inclusive and upper bounds exclusive. Finally, only include accidents that involve more than one distinct person.",
        "external_knowledge": "nhtsa_traffic_fatalities.md",
        "question_toks": [
            "I",
            "want",
            "to",
            "create",
            "a",
            "labeled",
            "dataset",
            "from",
            "the",
            "National",
            "Highway",
            "Traffic",
            "Safety",
            "Administration",
            "traffic",
            "fatality",
            "data",
            "that",
            "predicts",
            "whether",
            "a",
            "traffic",
            "accident",
            "involving",
            "more",
            "than",
            "one",
            "distinct",
            "person",
            "results",
            "in",
            "more",
            "than",
            "one",
            "fatality,",
            "where",
            "the",
            "label",
            "is",
            "1",
            "if",
            "an",
            "accident",
            "has",
            "more",
            "than",
            "one",
            "person",
            "with",
            "an",
            "injury",
            "severity",
            "code",
            "of",
            "4",
            "(fatal",
            "injury)",
            "and",
            "0",
            "otherwise.",
            "For",
            "each",
            "accident,",
            "include",
            "the",
            "numeric",
            "predictors:",
            "state_number,",
            "the",
            "vehicle",
            "body_type,",
            "the",
            "number_of_drunk_drivers,",
            "the",
            "day_of_week,",
            "the",
            "hour_of_crash,",
            "and",
            "a",
            "binary",
            "indicator",
            "for",
            "whether",
            "the",
            "accident",
            "occurred",
            "in",
            "a",
            "work",
            "zone",
            "(1",
            "if",
            "it",
            "is",
            "not",
            "“None,”",
            "otherwise",
            "0).",
            "Also,",
            "engineer",
            "a",
            "feature",
            "for",
            "the",
            "average",
            "absolute",
            "difference",
            "between",
            "travel_speed",
            "and",
            "speed_limit",
            "per",
            "accident,",
            "only",
            "considering",
            "travel",
            "speeds",
            "up",
            "to",
            "151",
            "mph",
            "(excluding",
            "codes",
            "997,",
            "998,",
            "999)",
            "and",
            "speed",
            "limits",
            "up",
            "to",
            "80",
            "mph",
            "(excluding",
            "codes",
            "98,",
            "99),",
            "and",
            "categorize",
            "this",
            "average",
            "speed",
            "difference",
            "into",
            "levels",
            "from",
            "0",
            "to",
            "4",
            "in",
            "20",
            "mph",
            "increments",
            "with",
            "lower",
            "bounds",
            "inclusive",
            "and",
            "upper",
            "bounds",
            "exclusive.",
            "Finally,",
            "only",
            "include",
            "accidents",
            "that",
            "involve",
            "more",
            "than",
            "one",
            "distinct",
            "person."
        ],
        "query": "",
        "db_id": "nhtsa_traffic_fatalities",
        "No. of candidate columns": 366,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq114",
        "question": "Which three cities have the largest difference between their 1990 EPA PM2.5 measurements (using units_of_measure = 'Micrograms/cubic meter (LC)' and parameter_name = 'Acceptable PM2.5 AQI & Speciation Mass') and their 2020 OpenAQ PM2.5 measurements (where pollutant = 'pm25' based on the year extracted from the timestamp), with both datasets matched by latitude and longitude rounded to two decimals, and the difference ordered from greatest to least?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "three",
            "cities",
            "have",
            "the",
            "largest",
            "difference",
            "between",
            "their",
            "1990",
            "EPA",
            "PM2.5",
            "measurements",
            "(using",
            "units_of_measure",
            "=",
            "'Micrograms/cubic",
            "meter",
            "(LC)'",
            "and",
            "parameter_name",
            "=",
            "'Acceptable",
            "PM2.5",
            "AQI",
            "&",
            "Speciation",
            "Mass')",
            "and",
            "their",
            "2020",
            "OpenAQ",
            "PM2.5",
            "measurements",
            "(where",
            "pollutant",
            "=",
            "'pm25'",
            "based",
            "on",
            "the",
            "year",
            "extracted",
            "from",
            "the",
            "timestamp),",
            "with",
            "both",
            "datasets",
            "matched",
            "by",
            "latitude",
            "and",
            "longitude",
            "rounded",
            "to",
            "two",
            "decimals,",
            "and",
            "the",
            "difference",
            "ordered",
            "from",
            "greatest",
            "to",
            "least?"
        ],
        "query": "SELECT\n  aq.city,\n  epa.arithmetic_mean,\n  aq.value,\n  aq.timestamp,\n  (epa.arithmetic_mean - aq.value)\nFROM\n  `bigquery-public-data.openaq.global_air_quality` AS aq\nJOIN\n  `bigquery-public-data.epa_historical_air_quality.air_quality_annual_summary` AS epa\nON\n  ROUND(aq.latitude, 2) = ROUND(epa.latitude, 2)\n  AND ROUND(aq.longitude, 2) = ROUND(epa.longitude, 2)\nWHERE\n  epa.units_of_measure = \"Micrograms/cubic meter (LC)\"\n  AND epa.parameter_name = \"Acceptable PM2.5 AQI & Speciation Mass\"\n  AND epa.year = 1990\n  AND aq.pollutant = \"pm25\"\n  AND EXTRACT(YEAR FROM aq.timestamp) = 2020\nORDER BY\n  (epa.arithmetic_mean - aq.value) DESC\nLIMIT 3",
        "db_id": "openaq",
        "No. of candidate columns": 891,
        "No. of gold tables": 2
    },
    {
        "instance_id": "bq116",
        "question": "Which U.S. state reported the highest total annual revenue in billions of dollars during fiscal year 2016, considering companies that provided four quarters of data and reported measure tags in ('Revenues','SalesRevenueNet','SalesRevenueGoodsNet'), excluding any entries where the state field (stprba) is null or empty?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "U.S.",
            "state",
            "reported",
            "the",
            "highest",
            "total",
            "annual",
            "revenue",
            "in",
            "billions",
            "of",
            "dollars",
            "during",
            "fiscal",
            "year",
            "2016,",
            "considering",
            "companies",
            "that",
            "provided",
            "four",
            "quarters",
            "of",
            "data",
            "and",
            "reported",
            "measure",
            "tags",
            "in",
            "('Revenues','SalesRevenueNet','SalesRevenueGoodsNet'),",
            "excluding",
            "any",
            "entries",
            "where",
            "the",
            "state",
            "field",
            "(stprba)",
            "is",
            "null",
            "or",
            "empty?"
        ],
        "query": "",
        "db_id": "sec_quarterly_financials",
        "No. of candidate columns": 147,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq015",
        "question": "Identify and rank the top 10 tags from Stack Overflow questions that were referenced in Hacker News comments on or after 2014 by counting how many times each question was mentioned, then splitting the questions’ tag strings by the '|' delimiter, grouping by tag",
        "external_knowledge": null,
        "question_toks": [
            "Identify",
            "and",
            "rank",
            "the",
            "top",
            "10",
            "tags",
            "from",
            "Stack",
            "Overflow",
            "questions",
            "that",
            "were",
            "referenced",
            "in",
            "Hacker",
            "News",
            "comments",
            "on",
            "or",
            "after",
            "2014",
            "by",
            "counting",
            "how",
            "many",
            "times",
            "each",
            "question",
            "was",
            "mentioned,",
            "then",
            "splitting",
            "the",
            "questions’",
            "tag",
            "strings",
            "by",
            "the",
            "'|'",
            "delimiter,",
            "grouping",
            "by",
            "tag"
        ],
        "query": "",
        "db_id": "stackoverflow_plus",
        "No. of candidate columns": 345,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq123",
        "question": "You need to determine which day of the week has the third highest percentage of questions on Stack Overflow that receive an answer within an hour. To do this, use the question creation date from the posts_questions table and the earliest answer creation date from the posts_answers table. Once you’ve calculated the percentage of questions that get answered within an hour for each day, identify the day with the third highest percentage and report that percentage.",
        "external_knowledge": null,
        "question_toks": [
            "You",
            "need",
            "to",
            "determine",
            "which",
            "day",
            "of",
            "the",
            "week",
            "has",
            "the",
            "third",
            "highest",
            "percentage",
            "of",
            "questions",
            "on",
            "Stack",
            "Overflow",
            "that",
            "receive",
            "an",
            "answer",
            "within",
            "an",
            "hour.",
            "To",
            "do",
            "this,",
            "use",
            "the",
            "question",
            "creation",
            "date",
            "from",
            "the",
            "posts_questions",
            "table",
            "and",
            "the",
            "earliest",
            "answer",
            "creation",
            "date",
            "from",
            "the",
            "posts_answers",
            "table.",
            "Once",
            "you’ve",
            "calculated",
            "the",
            "percentage",
            "of",
            "questions",
            "that",
            "get",
            "answered",
            "within",
            "an",
            "hour",
            "for",
            "each",
            "day,",
            "identify",
            "the",
            "day",
            "with",
            "the",
            "third",
            "highest",
            "percentage",
            "and",
            "report",
            "that",
            "percentage."
        ],
        "query": "",
        "db_id": "stackoverflow",
        "No. of candidate columns": 228,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq303",
        "question": "From July 1, 2019 through December 31, 2019, for all users with IDs between 16712208 and 18712208 on Stack Overflow, retrieve the user ID and the tags of the relevant question for each of their contributions, including comments on both questions and answers, any answers they posted, and any questions they authored, making sure to correctly associate the comment or answer with its parent question’s tags.",
        "external_knowledge": null,
        "question_toks": [
            "From",
            "July",
            "1,",
            "2019",
            "through",
            "December",
            "31,",
            "2019,",
            "for",
            "all",
            "users",
            "with",
            "IDs",
            "between",
            "16712208",
            "and",
            "18712208",
            "on",
            "Stack",
            "Overflow,",
            "retrieve",
            "the",
            "user",
            "ID",
            "and",
            "the",
            "tags",
            "of",
            "the",
            "relevant",
            "question",
            "for",
            "each",
            "of",
            "their",
            "contributions,",
            "including",
            "comments",
            "on",
            "both",
            "questions",
            "and",
            "answers,",
            "any",
            "answers",
            "they",
            "posted,",
            "and",
            "any",
            "questions",
            "they",
            "authored,",
            "making",
            "sure",
            "to",
            "correctly",
            "associate",
            "the",
            "comment",
            "or",
            "answer",
            "with",
            "its",
            "parent",
            "question’s",
            "tags."
        ],
        "query": "SELECT u_id, tags\nFROM (\n    -- select comments with tags from the post\n    SELECT cm.u_id, cm.creation_date, cm.text, pq.tags, \"comment\" as type\n    FROM (\n            SELECT a.parent_id as q_id, c.user_id as u_id, c.creation_date as creation_date, c.text as text\n            FROM `bigquery-public-data.stackoverflow.comments` as c\n            INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` as a ON (a.id = c.post_id)\n            WHERE c.user_id BETWEEN 16712208 AND 18712208\n              AND DATE(c.creation_date) BETWEEN '2019-07-01' AND '2019-12-31'\n            \n            UNION ALL \n            \n            SELECT q.id as q_id, c.user_id as u_id, c.creation_date as creation_date, c.text as text\n            FROM `bigquery-public-data.stackoverflow.comments` as c\n            INNER JOIN `bigquery-public-data.stackoverflow.posts_questions` as q ON (q.id = c.post_id)\n            WHERE c.user_id BETWEEN 16712208 AND 18712208\n              AND DATE(c.creation_date) BETWEEN '2019-07-01' AND '2019-12-31'\n        ) as cm\n    INNER JOIN `bigquery-public-data.stackoverflow.posts_questions` as pq ON (pq.id = cm.q_id)\n        \n    UNION ALL\n    -- select answers with tags related to the post\n    SELECT pa.owner_user_id as u_id, pa.creation_date as creation_date, pa.body as text, pq.tags as tags, \"answer\" as type\n    FROM `bigquery-public-data.stackoverflow.posts_answers` as pa\n    LEFT OUTER JOIN `bigquery-public-data.stackoverflow.posts_questions` as pq ON pq.id = pa.parent_id\n    WHERE pa.owner_user_id BETWEEN 16712208 AND 18712208\n      AND DATE(pa.creation_date) BETWEEN '2019-07-01' AND '2019-12-31'\n    \n    UNION ALL\n    -- select posts\n    SELECT pq.owner_user_id as u_id, pq.creation_date as creation_date, pq.body as text, pq.tags as tags, \"question\" as type\n    FROM `bigquery-public-data.stackoverflow.posts_questions` as pq\n    WHERE pq.owner_user_id BETWEEN 16712208 AND 18712208\n      AND DATE(pq.creation_date) BETWEEN '2019-07-01' AND '2019-12-31'\n)\nORDER BY u_id, creation_date;",
        "db_id": "stackoverflow",
        "No. of candidate columns": 228,
        "No. of gold tables": 17
    },
    {
        "instance_id": "bq305",
        "question": "Which 10 users have the highest combined view counts for questions they are associated with, where a user is considered associated if they own the question, or their answer is the accepted answer, or their answer's score is greater than 5, or their answer's score exceeds 20% of the total answer scores for that question (and is above 0), or their answer is among the top three highest-scoring answers for that question?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "10",
            "users",
            "have",
            "the",
            "highest",
            "combined",
            "view",
            "counts",
            "for",
            "questions",
            "they",
            "are",
            "associated",
            "with,",
            "where",
            "a",
            "user",
            "is",
            "considered",
            "associated",
            "if",
            "they",
            "own",
            "the",
            "question,",
            "or",
            "their",
            "answer",
            "is",
            "the",
            "accepted",
            "answer,",
            "or",
            "their",
            "answer's",
            "score",
            "is",
            "greater",
            "than",
            "5,",
            "or",
            "their",
            "answer's",
            "score",
            "exceeds",
            "20%",
            "of",
            "the",
            "total",
            "answer",
            "scores",
            "for",
            "that",
            "question",
            "(and",
            "is",
            "above",
            "0),",
            "or",
            "their",
            "answer",
            "is",
            "among",
            "the",
            "top",
            "three",
            "highest-scoring",
            "answers",
            "for",
            "that",
            "question?"
        ],
        "query": "",
        "db_id": "stackoverflow",
        "No. of candidate columns": 228,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq306",
        "question": "Identify the top 10 tags for user 1908967, based only on answers posted before June 7, 2018, where each tag’s score is 10 times the number of upvotes (vote_type_id=2) and 15 times the number of accepted answers (vote_type_id=1). Derive tags from the questions associated with those answers, and consider only the upvotes and accepted answers for those answers. Return the tags with the highest total scores in descending order, limited to 10 tags.",
        "external_knowledge": null,
        "question_toks": [
            "Identify",
            "the",
            "top",
            "10",
            "tags",
            "for",
            "user",
            "1908967,",
            "based",
            "only",
            "on",
            "answers",
            "posted",
            "before",
            "June",
            "7,",
            "2018,",
            "where",
            "each",
            "tag’s",
            "score",
            "is",
            "10",
            "times",
            "the",
            "number",
            "of",
            "upvotes",
            "(vote_type_id=2)",
            "and",
            "15",
            "times",
            "the",
            "number",
            "of",
            "accepted",
            "answers",
            "(vote_type_id=1).",
            "Derive",
            "tags",
            "from",
            "the",
            "questions",
            "associated",
            "with",
            "those",
            "answers,",
            "and",
            "consider",
            "only",
            "the",
            "upvotes",
            "and",
            "accepted",
            "answers",
            "for",
            "those",
            "answers.",
            "Return",
            "the",
            "tags",
            "with",
            "the",
            "highest",
            "total",
            "scores",
            "in",
            "descending",
            "order,",
            "limited",
            "to",
            "10",
            "tags."
        ],
        "query": "",
        "db_id": "stackoverflow",
        "No. of candidate columns": 228,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq200",
        "question": "Using data from both the regular season and the post-season, identify the pitcher who achieved the highest non-zero pitch speed for each team by confirming whether the pitcher’s ID appears in the relevant home or away player lists for that game, then retrieve that pitcher’s full name along with the maximum valid pitch speed they achieved while playing for that specific team.",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "data",
            "from",
            "both",
            "the",
            "regular",
            "season",
            "and",
            "the",
            "post-season,",
            "identify",
            "the",
            "pitcher",
            "who",
            "achieved",
            "the",
            "highest",
            "non-zero",
            "pitch",
            "speed",
            "for",
            "each",
            "team",
            "by",
            "confirming",
            "whether",
            "the",
            "pitcher’s",
            "ID",
            "appears",
            "in",
            "the",
            "relevant",
            "home",
            "or",
            "away",
            "player",
            "lists",
            "for",
            "that",
            "game,",
            "then",
            "retrieve",
            "that",
            "pitcher’s",
            "full",
            "name",
            "along",
            "with",
            "the",
            "maximum",
            "valid",
            "pitch",
            "speed",
            "they",
            "achieved",
            "while",
            "playing",
            "for",
            "that",
            "specific",
            "team."
        ],
        "query": "",
        "db_id": "mlb",
        "No. of candidate columns": 306,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq459",
        "question": "Please find the top 10 most relevant articles by only processing each article’s 'body' field, where each body is tokenized with no stopwords, each remaining token is turned into a GloVe-based word vector and weighted by dividing each dimension by the 0.4th power of its word frequency, then these weighted vectors are summed and normalized to get a unit vector for each article. Perform the same weighting and normalization on the query phrase 'Epigenetics and cerebral organoids: promising directions in autism spectrum disorders' and compute the cosine similarity between the query vector and each article vector. Finally, return the id, date, title, and the cosine similarity score for the top 10 articles with the highest similarity.",
        "external_knowledge": "tokenize_func.md",
        "question_toks": [
            "Please",
            "find",
            "the",
            "top",
            "10",
            "most",
            "relevant",
            "articles",
            "by",
            "only",
            "processing",
            "each",
            "article’s",
            "'body'",
            "field,",
            "where",
            "each",
            "body",
            "is",
            "tokenized",
            "with",
            "no",
            "stopwords,",
            "each",
            "remaining",
            "token",
            "is",
            "turned",
            "into",
            "a",
            "GloVe-based",
            "word",
            "vector",
            "and",
            "weighted",
            "by",
            "dividing",
            "each",
            "dimension",
            "by",
            "the",
            "0.4th",
            "power",
            "of",
            "its",
            "word",
            "frequency,",
            "then",
            "these",
            "weighted",
            "vectors",
            "are",
            "summed",
            "and",
            "normalized",
            "to",
            "get",
            "a",
            "unit",
            "vector",
            "for",
            "each",
            "article.",
            "Perform",
            "the",
            "same",
            "weighting",
            "and",
            "normalization",
            "on",
            "the",
            "query",
            "phrase",
            "'Epigenetics",
            "and",
            "cerebral",
            "organoids:",
            "promising",
            "directions",
            "in",
            "autism",
            "spectrum",
            "disorders'",
            "and",
            "compute",
            "the",
            "cosine",
            "similarity",
            "between",
            "the",
            "query",
            "vector",
            "and",
            "each",
            "article",
            "vector.",
            "Finally,",
            "return",
            "the",
            "id,",
            "date,",
            "title,",
            "and",
            "the",
            "cosine",
            "similarity",
            "score",
            "for",
            "the",
            "top",
            "10",
            "articles",
            "with",
            "the",
            "highest",
            "similarity."
        ],
        "query": "",
        "db_id": "WORD_VECTORS_US",
        "No. of candidate columns": 19,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq460",
        "question": "Please process the articles from the 'nature' dataset by first tokenizing the body text into words and removing stopwords. For each remaining word, retrieve its word vector from the glove_vectors table and its frequency from the word_frequencies table, then divide each word vector by the 0.4th power of the word's frequency to weight it. Sum the weighted vectors to obtain an aggregate vector for each article, normalize this aggregate vector to unit length, and then compute the cosine similarity scores between these normalized vectors. Finally, return the IDs, dates, titles, and cosine similarity scores of the top 10 articles most similar to the article with the ID '8a78ef2d-d5f7-4d2d-9b47-5adb25cbd373'.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "process",
            "the",
            "articles",
            "from",
            "the",
            "'nature'",
            "dataset",
            "by",
            "first",
            "tokenizing",
            "the",
            "body",
            "text",
            "into",
            "words",
            "and",
            "removing",
            "stopwords.",
            "For",
            "each",
            "remaining",
            "word,",
            "retrieve",
            "its",
            "word",
            "vector",
            "from",
            "the",
            "glove_vectors",
            "table",
            "and",
            "its",
            "frequency",
            "from",
            "the",
            "word_frequencies",
            "table,",
            "then",
            "divide",
            "each",
            "word",
            "vector",
            "by",
            "the",
            "0.4th",
            "power",
            "of",
            "the",
            "word's",
            "frequency",
            "to",
            "weight",
            "it.",
            "Sum",
            "the",
            "weighted",
            "vectors",
            "to",
            "obtain",
            "an",
            "aggregate",
            "vector",
            "for",
            "each",
            "article,",
            "normalize",
            "this",
            "aggregate",
            "vector",
            "to",
            "unit",
            "length,",
            "and",
            "then",
            "compute",
            "the",
            "cosine",
            "similarity",
            "scores",
            "between",
            "these",
            "normalized",
            "vectors.",
            "Finally,",
            "return",
            "the",
            "IDs,",
            "dates,",
            "titles,",
            "and",
            "cosine",
            "similarity",
            "scores",
            "of",
            "the",
            "top",
            "10",
            "articles",
            "most",
            "similar",
            "to",
            "the",
            "article",
            "with",
            "the",
            "ID",
            "'8a78ef2d-d5f7-4d2d-9b47-5adb25cbd373'."
        ],
        "query": "",
        "db_id": "WORD_VECTORS_US",
        "No. of candidate columns": 19,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq346",
        "question": "In publicly accessible DICOM data where the Modality is 'SEG' and the SOPClassUID is '1.2.840.10008.5.1.4.1.1.66.4', and each segmentation references its original SOPInstanceUID, which five segmentation categories (by 'SegmentedPropertyCategory.CodeMeaning') occur most frequently?",
        "external_knowledge": null,
        "question_toks": [
            "In",
            "publicly",
            "accessible",
            "DICOM",
            "data",
            "where",
            "the",
            "Modality",
            "is",
            "'SEG'",
            "and",
            "the",
            "SOPClassUID",
            "is",
            "'1.2.840.10008.5.1.4.1.1.66.4',",
            "and",
            "each",
            "segmentation",
            "references",
            "its",
            "original",
            "SOPInstanceUID,",
            "which",
            "five",
            "segmentation",
            "categories",
            "(by",
            "'SegmentedPropertyCategory.CodeMeaning')",
            "occur",
            "most",
            "frequently?"
        ],
        "query": "WITH\n  sampled_sops AS (\n    SELECT\n      \"collection_id\",\n      \"SeriesDescription\",\n      \"SeriesInstanceUID\",\n      \"SOPInstanceUID\" AS \"seg_SOPInstanceUID\",\n      COALESCE(\n        \"ReferencedSeriesSequence\"[0].\"ReferencedInstanceSequence\"[0].\"ReferencedSOPInstanceUID\",\n        \"ReferencedImageSequence\"[0].\"ReferencedSOPInstanceUID\",\n        \"SourceImageSequence\"[0].\"ReferencedSOPInstanceUID\"\n      ) AS \"referenced_sop\"\n    FROM\n      \"IDC\".\"IDC_V17\".\"DICOM_ALL\"\n    WHERE\n      \"Modality\" = 'SEG'\n      AND \"SOPClassUID\" = '1.2.840.10008.5.1.4.1.1.66.4'\n      AND \"access\" = 'Public'\n  ),\n  segmentations_data AS (\n    SELECT\n      dicom_all.\"collection_id\",\n      dicom_all.\"PatientID\",\n      dicom_all.\"SOPInstanceUID\",\n      REPLACE(segmentations.\"SegmentedPropertyCategory\":CodeMeaning::STRING, '\"', '') AS \"segmentation_category\",\n      REPLACE(segmentations.\"SegmentedPropertyType\":CodeMeaning::STRING, '\"', '') AS \"segmentation_type\"\n    FROM\n      sampled_sops\n    JOIN\n      \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS dicom_all\n    ON\n      sampled_sops.\"referenced_sop\" = dicom_all.\"SOPInstanceUID\"\n    JOIN\n      \"IDC\".\"IDC_V17\".\"SEGMENTATIONS\" AS segmentations\n    ON\n      segmentations.\"SOPInstanceUID\" = sampled_sops.\"seg_SOPInstanceUID\"\n  )\nSELECT\n  \"segmentation_category\",\n  COUNT(*) AS \"count_\"\nFROM\n  segmentations_data\nGROUP BY\n  \"segmentation_category\"\nORDER BY\n  \"count_\" DESC\nLIMIT 5;",
        "db_id": "IDC",
        "No. of candidate columns": 2100,
        "No. of gold tables": 3
    },
    {
        "instance_id": "sf_bq347",
        "question": "From the union of the specified MR series with SeriesInstanceUID 1.3.6.1.4.1.14519.5.2.1.3671.4754.105976129314091491952445656147 and all associated segmentation instances, which modality has the greatest number of SOP instances in total, and how many are there?",
        "external_knowledge": null,
        "question_toks": [
            "From",
            "the",
            "union",
            "of",
            "the",
            "specified",
            "MR",
            "series",
            "with",
            "SeriesInstanceUID",
            "1.3.6.1.4.1.14519.5.2.1.3671.4754.105976129314091491952445656147",
            "and",
            "all",
            "associated",
            "segmentation",
            "instances,",
            "which",
            "modality",
            "has",
            "the",
            "greatest",
            "number",
            "of",
            "SOP",
            "instances",
            "in",
            "total,",
            "and",
            "how",
            "many",
            "are",
            "there?"
        ],
        "query": "WITH union_mr_seg AS (\n  SELECT\n    \"dicom_all_mr\".\"SOPInstanceUID\",\n    '' AS \"segPropertyTypeCodeMeaning\", \n    '' AS \"segPropertyCategoryCodeMeaning\"\n  FROM\n    \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"dicom_all_mr\"\n  WHERE\n    \"dicom_all_mr\".\"SeriesInstanceUID\" IN ('1.3.6.1.4.1.14519.5.2.1.3671.4754.105976129314091491952445656147')\n    \n  UNION ALL\n\n  SELECT\n    \"dicom_all_seg\".\"SOPInstanceUID\",\n    \"segmentations\".\"SegmentedPropertyType\":\"CodeMeaning\" AS \"segPropertyTypeCodeMeaning\",\n    \"segmentations\".\"SegmentedPropertyCategory\":\"CodeMeaning\" AS \"segPropertyCategoryCodeMeaning\"\n  FROM\n    \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"dicom_all_seg\"\n  JOIN\n    \"IDC\".\"IDC_V17\".\"SEGMENTATIONS\" AS \"segmentations\"\n  ON\n    \"dicom_all_seg\".\"SOPInstanceUID\" = \"segmentations\".\"SOPInstanceUID\"\n)\n\nSELECT\n  \"dc_all\".\"Modality\",\n  COUNT(*) AS \"count_\"\nFROM \n  \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"dc_all\"\nINNER JOIN\n  union_mr_seg\nON \n  \"dc_all\".\"SOPInstanceUID\" = union_mr_seg.\"SOPInstanceUID\"\nGROUP BY\n  \"dc_all\".\"Modality\"\nORDER BY\n  \"count_\" DESC\nLIMIT 1;",
        "db_id": "IDC",
        "No. of candidate columns": 2100,
        "No. of gold tables": 4
    },
    {
        "instance_id": "sf_bq390",
        "question": "In the \"qin_prostate_repeatability\" collection, please provide the distinct StudyInstanceUIDs for studies that include T2-weighted axial MR imaging and also contain anatomical structure segmentations labeled as \"Peripheral zone.\"",
        "external_knowledge": null,
        "question_toks": [
            "In",
            "the",
            "\"qin_prostate_repeatability\"",
            "collection,",
            "please",
            "provide",
            "the",
            "distinct",
            "StudyInstanceUIDs",
            "for",
            "studies",
            "that",
            "include",
            "T2-weighted",
            "axial",
            "MR",
            "imaging",
            "and",
            "also",
            "contain",
            "anatomical",
            "structure",
            "segmentations",
            "labeled",
            "as",
            "\"Peripheral",
            "zone.\""
        ],
        "query": "WITH\n-- Studies that have MR volumes\n\"mr_studies\" AS (\n  SELECT\n    \"dicom_all_mr\".\"StudyInstanceUID\"\n  FROM\n    \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"dicom_all_mr\"\n  WHERE\n    \"Modality\" = 'MR'\n    AND \"collection_id\" = 'qin_prostate_repeatability'\n    AND CONTAINS(\"SeriesDescription\", 'T2 Weighted Axial')\n),\n\n\"seg_studies\" AS (\n  SELECT\n    \"dicom_all_seg\".\"StudyInstanceUID\"\n  FROM\n    \"IDC\".\"IDC_V17\".\"DICOM_ALL\" AS \"dicom_all_seg\"\n  JOIN\n    \"IDC\".\"IDC_V17\".\"SEGMENTATIONS\" AS \"segmentations\"\n  ON\n    \"dicom_all_seg\".\"SOPInstanceUID\" = \"segmentations\".\"SOPInstanceUID\"\n  WHERE\n    \"collection_id\" = 'qin_prostate_repeatability'\n    AND CONTAINS(\"segmentations\".\"SegmentedPropertyType\":\"CodeMeaning\", 'Peripheral zone')\n    AND \"segmentations\".\"SegmentedPropertyCategory\":\"CodeMeaning\" = 'Anatomical Structure'\n)\n\nSELECT DISTINCT\n  \"mr_studies\".\"StudyInstanceUID\"\nFROM\n  \"mr_studies\"\nJOIN\n  \"seg_studies\"\nON\n  \"mr_studies\".\"StudyInstanceUID\" = \"seg_studies\".\"StudyInstanceUID\";",
        "db_id": "IDC",
        "No. of candidate columns": 2100,
        "No. of gold tables": 3
    },
    {
        "instance_id": "sf_bq069",
        "question": "Could you help me generate a report of CT image series from the dicom_all table such that all series from the NLST collection are excluded, any localizers or JPEG-compressed series (transfer syntaxes 1.2.840.10008.1.2.4.70 or 1.2.840.10008.1.2.4.51) are skipped, and only those passing certain geometry checks—namely a single orientation, identical pixel spacing, matching SOP instance and position counts, uniform pixel rows and columns, and a near-unity dot product of image orientation vectors—are included, while also computing slice interval differences, exposure differences, and approximate series size in MB for each qualified series?",
        "external_knowledge": "nonNlstCohort.md",
        "question_toks": [
            "Could",
            "you",
            "help",
            "me",
            "generate",
            "a",
            "report",
            "of",
            "CT",
            "image",
            "series",
            "from",
            "the",
            "dicom_all",
            "table",
            "such",
            "that",
            "all",
            "series",
            "from",
            "the",
            "NLST",
            "collection",
            "are",
            "excluded,",
            "any",
            "localizers",
            "or",
            "JPEG-compressed",
            "series",
            "(transfer",
            "syntaxes",
            "1.2.840.10008.1.2.4.70",
            "or",
            "1.2.840.10008.1.2.4.51)",
            "are",
            "skipped,",
            "and",
            "only",
            "those",
            "passing",
            "certain",
            "geometry",
            "checks—namely",
            "a",
            "single",
            "orientation,",
            "identical",
            "pixel",
            "spacing,",
            "matching",
            "SOP",
            "instance",
            "and",
            "position",
            "counts,",
            "uniform",
            "pixel",
            "rows",
            "and",
            "columns,",
            "and",
            "a",
            "near-unity",
            "dot",
            "product",
            "of",
            "image",
            "orientation",
            "vectors—are",
            "included,",
            "while",
            "also",
            "computing",
            "slice",
            "interval",
            "differences,",
            "exposure",
            "differences,",
            "and",
            "approximate",
            "series",
            "size",
            "in",
            "MB",
            "for",
            "each",
            "qualified",
            "series?"
        ],
        "query": "",
        "db_id": "IDC",
        "No. of candidate columns": 2100,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq049",
        "question": "Please show the monthly per capita Bourbon Whiskey sales during 2022 in Dubuque County for the zip code that ranks third in total Bourbon Whiskey sales, using only the population aged 21 and older.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "show",
            "the",
            "monthly",
            "per",
            "capita",
            "Bourbon",
            "Whiskey",
            "sales",
            "during",
            "2022",
            "in",
            "Dubuque",
            "County",
            "for",
            "the",
            "zip",
            "code",
            "that",
            "ranks",
            "third",
            "in",
            "total",
            "Bourbon",
            "Whiskey",
            "sales,",
            "using",
            "only",
            "the",
            "population",
            "aged",
            "21",
            "and",
            "older."
        ],
        "query": "",
        "db_id": "iowa_liquor_sales_plus",
        "No. of candidate columns": 36,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq360",
        "question": "Among healthcare providers whose practice location is in Mountain View, CA, and who have a specified specialization in the field healthcare provider taxonomy, identify the top 10 most common specializations based on the count of distinct NPIs. Then determine which of those top 10 has a count of distinct NPIs closest to the average count across those 10 specializations.",
        "external_knowledge": null,
        "question_toks": [
            "Among",
            "healthcare",
            "providers",
            "whose",
            "practice",
            "location",
            "is",
            "in",
            "Mountain",
            "View,",
            "CA,",
            "and",
            "who",
            "have",
            "a",
            "specified",
            "specialization",
            "in",
            "the",
            "field",
            "healthcare",
            "provider",
            "taxonomy,",
            "identify",
            "the",
            "top",
            "10",
            "most",
            "common",
            "specializations",
            "based",
            "on",
            "the",
            "count",
            "of",
            "distinct",
            "NPIs.",
            "Then",
            "determine",
            "which",
            "of",
            "those",
            "top",
            "10",
            "has",
            "a",
            "count",
            "of",
            "distinct",
            "NPIs",
            "closest",
            "to",
            "the",
            "average",
            "count",
            "across",
            "those",
            "10",
            "specializations."
        ],
        "query": "",
        "db_id": "nppes",
        "No. of candidate columns": 918,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq155",
        "question": "In the TCGA-BRCA cohort of patients who are 80 years old or younger at diagnosis and have a pathological stage of Stage I, Stage II, or Stage IIA, calculate the t-statistic derived from the Pearson correlation between the log10-transformed average RNA-Seq expression levels (using HTSeq__Counts + 1) of the gene SNORA31 and the average microRNA-Seq expression levels of all unique microRNAs, only considering pairs with more than 25 samples and where the absolute Pearson correlation coefficient is between 0.3 and 1.0",
        "external_knowledge": null,
        "question_toks": [
            "In",
            "the",
            "TCGA-BRCA",
            "cohort",
            "of",
            "patients",
            "who",
            "are",
            "80",
            "years",
            "old",
            "or",
            "younger",
            "at",
            "diagnosis",
            "and",
            "have",
            "a",
            "pathological",
            "stage",
            "of",
            "Stage",
            "I,",
            "Stage",
            "II,",
            "or",
            "Stage",
            "IIA,",
            "calculate",
            "the",
            "t-statistic",
            "derived",
            "from",
            "the",
            "Pearson",
            "correlation",
            "between",
            "the",
            "log10-transformed",
            "average",
            "RNA-Seq",
            "expression",
            "levels",
            "(using",
            "HTSeq__Counts",
            "+",
            "1)",
            "of",
            "the",
            "gene",
            "SNORA31",
            "and",
            "the",
            "average",
            "microRNA-Seq",
            "expression",
            "levels",
            "of",
            "all",
            "unique",
            "microRNAs,",
            "only",
            "considering",
            "pairs",
            "with",
            "more",
            "than",
            "25",
            "samples",
            "and",
            "where",
            "the",
            "absolute",
            "Pearson",
            "correlation",
            "coefficient",
            "is",
            "between",
            "0.3",
            "and",
            "1.0"
        ],
        "query": "WITH cohort AS (\n    SELECT \"case_barcode\"\n    FROM \"TCGA_HG38_DATA_V0\".\"TCGA_BIOCLIN_V0\".\"CLINICAL\"\n    WHERE \"project_short_name\" = 'TCGA-BRCA'\n        AND \"age_at_diagnosis\" <= 80\n        AND \"pathologic_stage\" IN ('Stage I', 'Stage II', 'Stage IIA')\n),\ntable1 AS (\n    SELECT\n        \"symbol\",\n        \"data\" AS \"rnkdata\",\n        \"ParticipantBarcode\"\n    FROM (\n        SELECT\n            \"gene_name\" AS \"symbol\", \n            AVG(LOG(10, \"HTSeq__Counts\" + 1)) AS \"data\",\n            \"case_barcode\" AS \"ParticipantBarcode\"\n        FROM \"TCGA_HG38_DATA_V0\".\"TCGA_HG38_DATA_V0\".\"RNASEQ_GENE_EXPRESSION\"\n        WHERE \"case_barcode\" IN (SELECT \"case_barcode\" FROM cohort)\n            AND \"gene_name\" = 'SNORA31'\n            AND \"HTSeq__Counts\" IS NOT NULL\n        GROUP BY\n            \"ParticipantBarcode\", \"symbol\"\n    )\n),\ntable2 AS (\n    SELECT\n        \"symbol\",\n        \"data\" AS \"rnkdata\",\n        \"ParticipantBarcode\"\n    FROM (\n        SELECT\n            \"mirna_id\" AS \"symbol\", \n            AVG(\"reads_per_million_miRNA_mapped\") AS \"data\",\n            \"case_barcode\" AS \"ParticipantBarcode\"\n        FROM \"TCGA_HG38_DATA_V0\".\"TCGA_HG38_DATA_V0\".\"MIRNASEQ_EXPRESSION\"\n        WHERE \"case_barcode\" IN (SELECT \"case_barcode\" FROM cohort)\n            AND \"mirna_id\" IS NOT NULL\n            AND \"reads_per_million_miRNA_mapped\" IS NOT NULL\n        GROUP BY\n            \"ParticipantBarcode\", \"symbol\"\n    )\n),\nsumm_table AS (\n    SELECT \n        n1.\"symbol\" AS \"symbol1\",\n        n2.\"symbol\" AS \"symbol2\",\n        COUNT(n1.\"ParticipantBarcode\") AS \"n\",\n        CORR(n1.\"rnkdata\", n2.\"rnkdata\") AS \"correlation\"\n    FROM\n        table1 AS n1\n    INNER JOIN\n        table2 AS n2\n    ON\n        n1.\"ParticipantBarcode\" = n2.\"ParticipantBarcode\"\n    GROUP BY\n        \"symbol1\", \"symbol2\"\n)\n\nSELECT \n    \"symbol1\", \n    \"symbol2\", \n    ABS(\"correlation\") * SQRT(( \"n\" - 2 ) / (1 - \"correlation\" * \"correlation\")) AS \"t\"\nFROM \n    summ_table\nWHERE \n    \"n\" > 25 \n    AND ABS(\"correlation\") >= 0.3 \n    AND ABS(\"correlation\") < 1.0;",
        "db_id": "TCGA_HG38_DATA_V0",
        "No. of candidate columns": 1145,
        "No. of gold tables": 3
    },
    {
        "instance_id": "sf_bq141",
        "question": "Using the TCGA-KIRP dataset, select patients from the 'TCGA_bioclin_v0.Clinical' table who have a non-null clinical_stage and a disease_code of 'KIRP.' Retrieve their gene expression data from the 'TCGA_hg38_data_v0.RNAseq_Gene_Expression' table for the genes 'MT-CO3,' 'MT-CO1,' and 'MT-CO2,' and randomly split the patients into a training set (90%) and a test set (10%) based on their case_barcode via the FARM_FINGERPRINT method. For each clinical stage in the training set, calculate the average HTSeq__FPKM_UQ expression of the three genes. For each patient in the test set, compute the Euclidean distance between the patient’s expression values and the stage-specific averages, and assign that patient to the clinical stage whose average is closest. Finally, output the case_barcode and the predicted clinical stage.",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "the",
            "TCGA-KIRP",
            "dataset,",
            "select",
            "patients",
            "from",
            "the",
            "'TCGA_bioclin_v0.Clinical'",
            "table",
            "who",
            "have",
            "a",
            "non-null",
            "clinical_stage",
            "and",
            "a",
            "disease_code",
            "of",
            "'KIRP.'",
            "Retrieve",
            "their",
            "gene",
            "expression",
            "data",
            "from",
            "the",
            "'TCGA_hg38_data_v0.RNAseq_Gene_Expression'",
            "table",
            "for",
            "the",
            "genes",
            "'MT-CO3,'",
            "'MT-CO1,'",
            "and",
            "'MT-CO2,'",
            "and",
            "randomly",
            "split",
            "the",
            "patients",
            "into",
            "a",
            "training",
            "set",
            "(90%)",
            "and",
            "a",
            "test",
            "set",
            "(10%)",
            "based",
            "on",
            "their",
            "case_barcode",
            "via",
            "the",
            "FARM_FINGERPRINT",
            "method.",
            "For",
            "each",
            "clinical",
            "stage",
            "in",
            "the",
            "training",
            "set,",
            "calculate",
            "the",
            "average",
            "HTSeq__FPKM_UQ",
            "expression",
            "of",
            "the",
            "three",
            "genes.",
            "For",
            "each",
            "patient",
            "in",
            "the",
            "test",
            "set,",
            "compute",
            "the",
            "Euclidean",
            "distance",
            "between",
            "the",
            "patient’s",
            "expression",
            "values",
            "and",
            "the",
            "stage-specific",
            "averages,",
            "and",
            "assign",
            "that",
            "patient",
            "to",
            "the",
            "clinical",
            "stage",
            "whose",
            "average",
            "is",
            "closest.",
            "Finally,",
            "output",
            "the",
            "case_barcode",
            "and",
            "the",
            "predicted",
            "clinical",
            "stage."
        ],
        "query": "",
        "db_id": "TCGA_HG38_DATA_V0",
        "No. of candidate columns": 1145,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq154",
        "question": "Calculate the Kruskal-Wallis H-score among groups of LGG patients for IGF2 gene expression, where each patient’s IGF2 expression is determined by applying log10(normalized_count + 1) and then averaging across samples. Group the patients by ICD-O-3 histology codes, exclude any codes fully enclosed in square brackets, only include groups with more than one patient, and ensure that normalized count is not null. Finally, return the total number of groups, the total number of samples, and the Kruskal-Wallis H-score in descending order.",
        "external_knowledge": "Regulome_Explorer_Kruskal-Wallis_test_for_numerical_and_categorical_data.md",
        "question_toks": [
            "Calculate",
            "the",
            "Kruskal-Wallis",
            "H-score",
            "among",
            "groups",
            "of",
            "LGG",
            "patients",
            "for",
            "IGF2",
            "gene",
            "expression,",
            "where",
            "each",
            "patient’s",
            "IGF2",
            "expression",
            "is",
            "determined",
            "by",
            "applying",
            "log10(normalized_count",
            "+",
            "1)",
            "and",
            "then",
            "averaging",
            "across",
            "samples.",
            "Group",
            "the",
            "patients",
            "by",
            "ICD-O-3",
            "histology",
            "codes,",
            "exclude",
            "any",
            "codes",
            "fully",
            "enclosed",
            "in",
            "square",
            "brackets,",
            "only",
            "include",
            "groups",
            "with",
            "more",
            "than",
            "one",
            "patient,",
            "and",
            "ensure",
            "that",
            "normalized",
            "count",
            "is",
            "not",
            "null.",
            "Finally,",
            "return",
            "the",
            "total",
            "number",
            "of",
            "groups,",
            "the",
            "total",
            "number",
            "of",
            "samples,",
            "and",
            "the",
            "Kruskal-Wallis",
            "H-score",
            "in",
            "descending",
            "order."
        ],
        "query": "",
        "db_id": "PANCANCER_ATLAS_1",
        "No. of candidate columns": 833,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq163",
        "question": "Which 20 genes exhibit the greatest difference in their average X_value expression between male and female epithelial cells, specifically in cluster 41 of MSK-SCLC patients at the 74-year-old human stage, comparing the female and male groups and ordering results by descending difference?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "20",
            "genes",
            "exhibit",
            "the",
            "greatest",
            "difference",
            "in",
            "their",
            "average",
            "X_value",
            "expression",
            "between",
            "male",
            "and",
            "female",
            "epithelial",
            "cells,",
            "specifically",
            "in",
            "cluster",
            "41",
            "of",
            "MSK-SCLC",
            "patients",
            "at",
            "the",
            "74-year-old",
            "human",
            "stage,",
            "comparing",
            "the",
            "female",
            "and",
            "male",
            "groups",
            "and",
            "ordering",
            "results",
            "by",
            "descending",
            "difference?"
        ],
        "query": "",
        "db_id": "HTAN_2",
        "No. of candidate columns": 3428,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq166",
        "question": "Using segment-level copy number data from the copy_number_segment_allelic_hg38_gdc_r23 dataset restricted to 'TCGA-KIRC' samples, merge these segments with the cytogenetic band definitions in 'CytoBands_hg38' to identify each sample’s maximum copy number per cytoband. Classify these maximum copy numbers into amplifications (>3), gains (=3), homozygous deletions (=0), heterozygous deletions (=1), or normal (=2), then calculate the frequency of each subtype out of the total number of distinct cases, and finally present these frequencies as percentages sorted by chromosome and cytoband.",
        "external_knowledge": "Comprehensive_Guide_to_Copy_Number_Variations_in_Cancer_Genomics.md",
        "question_toks": [
            "Using",
            "segment-level",
            "copy",
            "number",
            "data",
            "from",
            "the",
            "copy_number_segment_allelic_hg38_gdc_r23",
            "dataset",
            "restricted",
            "to",
            "'TCGA-KIRC'",
            "samples,",
            "merge",
            "these",
            "segments",
            "with",
            "the",
            "cytogenetic",
            "band",
            "definitions",
            "in",
            "'CytoBands_hg38'",
            "to",
            "identify",
            "each",
            "sample’s",
            "maximum",
            "copy",
            "number",
            "per",
            "cytoband.",
            "Classify",
            "these",
            "maximum",
            "copy",
            "numbers",
            "into",
            "amplifications",
            "(>3),",
            "gains",
            "(=3),",
            "homozygous",
            "deletions",
            "(=0),",
            "heterozygous",
            "deletions",
            "(=1),",
            "or",
            "normal",
            "(=2),",
            "then",
            "calculate",
            "the",
            "frequency",
            "of",
            "each",
            "subtype",
            "out",
            "of",
            "the",
            "total",
            "number",
            "of",
            "distinct",
            "cases,",
            "and",
            "finally",
            "present",
            "these",
            "frequencies",
            "as",
            "percentages",
            "sorted",
            "by",
            "chromosome",
            "and",
            "cytoband."
        ],
        "query": "WITH copy AS (\n  SELECT \n    \"case_barcode\", \n    \"chromosome\", \n    \"start_pos\", \n    \"end_pos\", \n    MAX(\"copy_number\") AS \"copy_number\"\n  FROM \n    \"TCGA_MITELMAN\".\"TCGA_VERSIONED\".\"COPY_NUMBER_SEGMENT_ALLELIC_HG38_GDC_R23\" \n  WHERE  \n    \"project_short_name\" = 'TCGA-KIRC'\n  GROUP BY \n    \"case_barcode\", \n    \"chromosome\", \n    \"start_pos\", \n    \"end_pos\"\n),\ntotal_cases AS (\n  SELECT COUNT(DISTINCT \"case_barcode\") AS \"total\"\n  FROM copy \n),\ncytob AS (\n  SELECT \n    \"chromosome\", \n    \"cytoband_name\", \n    \"hg38_start\", \n    \"hg38_stop\"\n  FROM \n    \"TCGA_MITELMAN\".\"PROD\".\"CYTOBANDS_HG38\"\n),\njoined AS (\n  SELECT \n    cytob.\"chromosome\", \n    cytob.\"cytoband_name\", \n    cytob.\"hg38_start\", \n    cytob.\"hg38_stop\",\n    copy.\"case_barcode\",\n    copy.\"copy_number\"  \n  FROM \n    copy\n  LEFT JOIN cytob\n    ON cytob.\"chromosome\" = copy.\"chromosome\" \n  WHERE \n    (cytob.\"hg38_start\" >= copy.\"start_pos\" AND copy.\"end_pos\" >= cytob.\"hg38_start\")\n    OR (copy.\"start_pos\" >= cytob.\"hg38_start\" AND copy.\"start_pos\" <= cytob.\"hg38_stop\")\n),\ncbands AS (\n  SELECT \n    \"chromosome\", \n    \"cytoband_name\", \n    \"hg38_start\", \n    \"hg38_stop\", \n    \"case_barcode\",\n    MAX(\"copy_number\") AS \"copy_number\"\n  FROM \n    joined\n  GROUP BY \n    \"chromosome\", \n    \"cytoband_name\", \n    \"hg38_start\", \n    \"hg38_stop\", \n    \"case_barcode\"\n),\naberrations AS (\n  SELECT\n    \"chromosome\",\n    \"cytoband_name\",\n    -- Amplifications: more than two copies for diploid > 4\n    SUM( CASE WHEN \"copy_number\" > 3 THEN 1 ELSE 0 END ) AS \"total_amp\",\n    -- Gains: at most two extra copies\n    SUM( CASE WHEN \"copy_number\" = 3 THEN 1 ELSE 0 END ) AS \"total_gain\",\n    -- Homozygous deletions, or complete deletions\n    SUM( CASE WHEN \"copy_number\" = 0 THEN 1 ELSE 0 END ) AS \"total_homodel\",\n    -- Heterozygous deletions, 1 copy lost\n    SUM( CASE WHEN \"copy_number\" = 1 THEN 1 ELSE 0 END ) AS \"total_heterodel\",\n    -- Normal for Diploid = 2\n    SUM( CASE WHEN \"copy_number\" = 2 THEN 1 ELSE 0 END ) AS \"total_normal\"\n  FROM \n    cbands\n  GROUP BY \n    \"chromosome\", \n    \"cytoband_name\"\n)\nSELECT \n  aberrations.\"chromosome\", \n  aberrations.\"cytoband_name\",\n  total_cases.\"total\",  \n  100 * aberrations.\"total_amp\" / total_cases.\"total\" AS \"freq_amp\", \n  100 * aberrations.\"total_gain\" / total_cases.\"total\" AS \"freq_gain\",\n  100 * aberrations.\"total_homodel\" / total_cases.\"total\" AS \"freq_homodel\", \n  100 * aberrations.\"total_heterodel\" / total_cases.\"total\" AS \"freq_heterodel\", \n  100 * aberrations.\"total_normal\" / total_cases.\"total\" AS \"freq_normal\"  \nFROM \n  aberrations, \n  total_cases\nORDER BY \n  aberrations.\"chromosome\", \n  aberrations.\"cytoband_name\";",
        "db_id": "TCGA_MITELMAN",
        "No. of candidate columns": 4272,
        "No. of gold tables": 2
    },
    {
        "instance_id": "bq111",
        "question": "Could you compute, by chromosome, the Pearson correlation between the frequency of copy number aberrations (including amplifications, gains, losses, and deletions) from the Mitelman database for cases with morph = 3111 and topo = 0401, and those computed from TCGA data, returning correlation coefficients and corresponding p-values for each aberration type, ensuring only results with at least five matching records are shown.",
        "external_knowledge": "Correlations_between_Mitelman_and_TCGA_datasets.md",
        "question_toks": [
            "Could",
            "you",
            "compute,",
            "by",
            "chromosome,",
            "the",
            "Pearson",
            "correlation",
            "between",
            "the",
            "frequency",
            "of",
            "copy",
            "number",
            "aberrations",
            "(including",
            "amplifications,",
            "gains,",
            "losses,",
            "and",
            "deletions)",
            "from",
            "the",
            "Mitelman",
            "database",
            "for",
            "cases",
            "with",
            "morph",
            "=",
            "3111",
            "and",
            "topo",
            "=",
            "0401,",
            "and",
            "those",
            "computed",
            "from",
            "TCGA",
            "data,",
            "returning",
            "correlation",
            "coefficients",
            "and",
            "corresponding",
            "p-values",
            "for",
            "each",
            "aberration",
            "type,",
            "ensuring",
            "only",
            "results",
            "with",
            "at",
            "least",
            "five",
            "matching",
            "records",
            "are",
            "shown."
        ],
        "query": "",
        "db_id": "mitelman",
        "No. of candidate columns": 165,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq453",
        "question": "In chromosome 17 between positions 41196311 and 41277499, what are the reference names, start and end positions, reference bases, distinct alternate bases, variant types, and the chi-squared scores (calculated from Hardy-Weinberg equilibrium) along with the total number of genotypes, their observed and expected counts for homozygous reference, heterozygous, and homozygous alternate genotypes, as well as allele frequencies (including those from 1KG), for each variant?",
        "external_knowledge": null,
        "question_toks": [
            "In",
            "chromosome",
            "17",
            "between",
            "positions",
            "41196311",
            "and",
            "41277499,",
            "what",
            "are",
            "the",
            "reference",
            "names,",
            "start",
            "and",
            "end",
            "positions,",
            "reference",
            "bases,",
            "distinct",
            "alternate",
            "bases,",
            "variant",
            "types,",
            "and",
            "the",
            "chi-squared",
            "scores",
            "(calculated",
            "from",
            "Hardy-Weinberg",
            "equilibrium)",
            "along",
            "with",
            "the",
            "total",
            "number",
            "of",
            "genotypes,",
            "their",
            "observed",
            "and",
            "expected",
            "counts",
            "for",
            "homozygous",
            "reference,",
            "heterozygous,",
            "and",
            "homozygous",
            "alternate",
            "genotypes,",
            "as",
            "well",
            "as",
            "allele",
            "frequencies",
            "(including",
            "those",
            "from",
            "1KG),",
            "for",
            "each",
            "variant?"
        ],
        "query": "",
        "db_id": "_1000_genomes",
        "No. of candidate columns": 114,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq283",
        "question": "Among all stations that are currently active, identify those that rank in the top 15 (including ties) based on the total number of trips that start at each station. For each of these stations, return the station ID, the total number of starting trips, the percentage of those trips out of the overall starting trips from active stations, and the average trip duration in minutes. Order the results by the station’s rank.",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "Among",
            "all",
            "stations",
            "that",
            "are",
            "currently",
            "active,",
            "identify",
            "those",
            "that",
            "rank",
            "in",
            "the",
            "top",
            "15",
            "(including",
            "ties)",
            "based",
            "on",
            "the",
            "total",
            "number",
            "of",
            "trips",
            "that",
            "start",
            "at",
            "each",
            "station.",
            "For",
            "each",
            "of",
            "these",
            "stations,",
            "return",
            "the",
            "station",
            "ID,",
            "the",
            "total",
            "number",
            "of",
            "starting",
            "trips,",
            "the",
            "percentage",
            "of",
            "those",
            "trips",
            "out",
            "of",
            "the",
            "overall",
            "starting",
            "trips",
            "from",
            "active",
            "stations,",
            "and",
            "the",
            "average",
            "trip",
            "duration",
            "in",
            "minutes.",
            "Order",
            "the",
            "results",
            "by",
            "the",
            "station’s",
            "rank."
        ],
        "query": "",
        "db_id": "AUSTIN",
        "No. of candidate columns": 119,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq425",
        "question": "Using data from ChEMBL Release 23, retrieve all distinct molecules associated with the company 'SanofiAventis,' listing the trade name and the most recent approval date for each molecule. Make sure to keep only the latest approval date per molecule and ensure the company field precisely matches 'SanofiAventis' without relying on other fields.",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "data",
            "from",
            "ChEMBL",
            "Release",
            "23,",
            "retrieve",
            "all",
            "distinct",
            "molecules",
            "associated",
            "with",
            "the",
            "company",
            "'SanofiAventis,'",
            "listing",
            "the",
            "trade",
            "name",
            "and",
            "the",
            "most",
            "recent",
            "approval",
            "date",
            "for",
            "each",
            "molecule.",
            "Make",
            "sure",
            "to",
            "keep",
            "only",
            "the",
            "latest",
            "approval",
            "date",
            "per",
            "molecule",
            "and",
            "ensure",
            "the",
            "company",
            "field",
            "precisely",
            "matches",
            "'SanofiAventis'",
            "without",
            "relying",
            "on",
            "other",
            "fields."
        ],
        "query": "SELECT *\n  FROM (\n  SELECT\n  molregno,\n  comp.company,\n  prod.trade_name,\n  prod.approval_date,\n  ROW_NUMBER() OVER(PARTITION BY molregno ORDER BY PARSE_DATE('%Y-%m-%d', prod.approval_date) DESC) rn\n  FROM bigquery-public-data.ebi_chembl.compound_records_23 AS cmpd_rec\n  JOIN bigquery-public-data.ebi_chembl.molecule_synonyms_23 AS ms USING (molregno)\n  JOIN bigquery-public-data.ebi_chembl.research_companies_23 AS comp USING (res_stem_id)\n  JOIN bigquery-public-data.ebi_chembl.formulations_23 AS form USING (molregno)\n  JOIN bigquery-public-data.ebi_chembl.products_23 AS prod USING (product_id)\n  ) as subq\n WHERE rn = 1 AND company = 'SanofiAventis'",
        "db_id": "ebi_chembl",
        "No. of candidate columns": 5337,
        "No. of gold tables": 5
    },
    {
        "instance_id": "bq023",
        "question": "Using the 2018 5-Year American Community Survey (ACS) for median incomes at the census tract level and the 2020 Federal Election Commission (FEC) individual contributions dataset filtered for donors in New York, matched to census tract geographies via a ZIP code to census tract crosswalk, calculate and list the average political donation amount and the median income for each census tract located in Kings County (Brooklyn), New York.",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "the",
            "2018",
            "5-Year",
            "American",
            "Community",
            "Survey",
            "(ACS)",
            "for",
            "median",
            "incomes",
            "at",
            "the",
            "census",
            "tract",
            "level",
            "and",
            "the",
            "2020",
            "Federal",
            "Election",
            "Commission",
            "(FEC)",
            "individual",
            "contributions",
            "dataset",
            "filtered",
            "for",
            "donors",
            "in",
            "New",
            "York,",
            "matched",
            "to",
            "census",
            "tract",
            "geographies",
            "via",
            "a",
            "ZIP",
            "code",
            "to",
            "census",
            "tract",
            "crosswalk,",
            "calculate",
            "and",
            "list",
            "the",
            "average",
            "political",
            "donation",
            "amount",
            "and",
            "the",
            "median",
            "income",
            "for",
            "each",
            "census",
            "tract",
            "located",
            "in",
            "Kings",
            "County",
            "(Brooklyn),",
            "New",
            "York."
        ],
        "query": "",
        "db_id": "fec",
        "No. of candidate columns": 71833,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq094",
        "question": "Please provide a list of all 2016 committees that supported at least one candidate and received a total amount of individual contributions between $0 and $200 (inclusive of more than $0 and less than $200) where these small-dollar contributions sum to more than $0 overall. For each qualifying committee, include its name, the number of unique candidates it supported, the candidates’ names in alphabetical order (separated by commas), and the total sum of these small-dollar donations received by the committee.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "provide",
            "a",
            "list",
            "of",
            "all",
            "2016",
            "committees",
            "that",
            "supported",
            "at",
            "least",
            "one",
            "candidate",
            "and",
            "received",
            "a",
            "total",
            "amount",
            "of",
            "individual",
            "contributions",
            "between",
            "$0",
            "and",
            "$200",
            "(inclusive",
            "of",
            "more",
            "than",
            "$0",
            "and",
            "less",
            "than",
            "$200)",
            "where",
            "these",
            "small-dollar",
            "contributions",
            "sum",
            "to",
            "more",
            "than",
            "$0",
            "overall.",
            "For",
            "each",
            "qualifying",
            "committee,",
            "include",
            "its",
            "name,",
            "the",
            "number",
            "of",
            "unique",
            "candidates",
            "it",
            "supported,",
            "the",
            "candidates’",
            "names",
            "in",
            "alphabetical",
            "order",
            "(separated",
            "by",
            "commas),",
            "and",
            "the",
            "total",
            "sum",
            "of",
            "these",
            "small-dollar",
            "donations",
            "received",
            "by",
            "the",
            "committee."
        ],
        "query": "",
        "db_id": "fec",
        "No. of candidate columns": 71833,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq287",
        "question": "Among all Utah ZIP codes, what is the 2017 American Community Survey employment rate for the population aged 16 or older in the ZIP code that has the fewest FDIC-insured bank locations?",
        "external_knowledge": null,
        "question_toks": [
            "Among",
            "all",
            "Utah",
            "ZIP",
            "codes,",
            "what",
            "is",
            "the",
            "2017",
            "American",
            "Community",
            "Survey",
            "employment",
            "rate",
            "for",
            "the",
            "population",
            "aged",
            "16",
            "or",
            "older",
            "in",
            "the",
            "ZIP",
            "code",
            "that",
            "has",
            "the",
            "fewest",
            "FDIC-insured",
            "bank",
            "locations?"
        ],
        "query": "",
        "db_id": "fec",
        "No. of candidate columns": 71833,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq423",
        "question": "Between January 1, 2023, and January 1, 2024, which image-type advertisement on the topic of Health, published by a verified advertiser located in Cyprus, was shown in Croatia, has times_shown_availability_date as NULL (meaning the times shown data is available), utilized demographic information, geo-location targeting, contextual signals, customer lists, and topics of interest without any of these selection methods being unused, and additionally had its first shown date strictly after January 1, 2023, and last shown date strictly before January 1, 2024? Among such ads, provide the page URL of the one with the highest upper bound of times shown.",
        "external_knowledge": null,
        "question_toks": [
            "Between",
            "January",
            "1,",
            "2023,",
            "and",
            "January",
            "1,",
            "2024,",
            "which",
            "image-type",
            "advertisement",
            "on",
            "the",
            "topic",
            "of",
            "Health,",
            "published",
            "by",
            "a",
            "verified",
            "advertiser",
            "located",
            "in",
            "Cyprus,",
            "was",
            "shown",
            "in",
            "Croatia,",
            "has",
            "times_shown_availability_date",
            "as",
            "NULL",
            "(meaning",
            "the",
            "times",
            "shown",
            "data",
            "is",
            "available),",
            "utilized",
            "demographic",
            "information,",
            "geo-location",
            "targeting,",
            "contextual",
            "signals,",
            "customer",
            "lists,",
            "and",
            "topics",
            "of",
            "interest",
            "without",
            "any",
            "of",
            "these",
            "selection",
            "methods",
            "being",
            "unused,",
            "and",
            "additionally",
            "had",
            "its",
            "first",
            "shown",
            "date",
            "strictly",
            "after",
            "January",
            "1,",
            "2023,",
            "and",
            "last",
            "shown",
            "date",
            "strictly",
            "before",
            "January",
            "1,",
            "2024?",
            "Among",
            "such",
            "ads,",
            "provide",
            "the",
            "page",
            "URL",
            "of",
            "the",
            "one",
            "with",
            "the",
            "highest",
            "upper",
            "bound",
            "of",
            "times",
            "shown."
        ],
        "query": "",
        "db_id": "GOOGLE_ADS",
        "No. of candidate columns": 16,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq070",
        "question": "Could you provide a clean, structured dataset from dicom_all table that only includes SM images marked as VOLUME from the TCGA-LUAD and TCGA-LUSC collections, excluding any slides with compression type “other,” where the specimen preparation step explicitly has “Embedding medium” set to “Tissue freezing medium,” and ensuring that the tissue type is only “normal” or “tumor” and the cancer subtype is reported accordingly?",
        "external_knowledge": "dicom_dataset_selection.md",
        "question_toks": [
            "Could",
            "you",
            "provide",
            "a",
            "clean,",
            "structured",
            "dataset",
            "from",
            "dicom_all",
            "table",
            "that",
            "only",
            "includes",
            "SM",
            "images",
            "marked",
            "as",
            "VOLUME",
            "from",
            "the",
            "TCGA-LUAD",
            "and",
            "TCGA-LUSC",
            "collections,",
            "excluding",
            "any",
            "slides",
            "with",
            "compression",
            "type",
            "“other,”",
            "where",
            "the",
            "specimen",
            "preparation",
            "step",
            "explicitly",
            "has",
            "“Embedding",
            "medium”",
            "set",
            "to",
            "“Tissue",
            "freezing",
            "medium,”",
            "and",
            "ensuring",
            "that",
            "the",
            "tissue",
            "type",
            "is",
            "only",
            "“normal”",
            "or",
            "“tumor”",
            "and",
            "the",
            "cancer",
            "subtype",
            "is",
            "reported",
            "accordingly?"
        ],
        "query": "WITH\n  sm_images AS (\n    SELECT\n      \"SeriesInstanceUID\" AS \"digital_slide_id\", \n      \"StudyInstanceUID\" AS \"case_id\",\n      \"ContainerIdentifier\" AS \"physical_slide_id\",\n      \"PatientID\" AS \"patient_id\",\n      \"TotalPixelMatrixColumns\" AS \"width\", \n      \"TotalPixelMatrixRows\" AS \"height\",\n      \"collection_id\",\n      \"crdc_instance_uuid\",\n      \"gcs_url\", \n      CAST(\n        \"SharedFunctionalGroupsSequence\"[0].\"PixelMeasuresSequence\"[0].\"PixelSpacing\"[0] AS FLOAT\n      ) AS \"pixel_spacing\", \n      CASE \"TransferSyntaxUID\"\n          WHEN '1.2.840.10008.1.2.4.50' THEN 'jpeg'\n          WHEN '1.2.840.10008.1.2.4.91' THEN 'jpeg2000'\n          ELSE 'other'\n      END AS \"compression\"\n    FROM\n      IDC.IDC_V17.DICOM_ALL\n    WHERE\n      \"Modality\" = 'SM' \n      AND \"ImageType\"[2] = 'VOLUME'\n  ),\n\n  tissue_types AS (\n    SELECT DISTINCT *\n    FROM (\n      SELECT\n        \"SeriesInstanceUID\" AS \"digital_slide_id\",\n        CASE \"steps_unnested2\".value:\"CodeValue\"::STRING\n            WHEN '17621005' THEN 'normal' -- meaning: 'Normal' (i.e., non-neoplastic)\n            WHEN '86049000' THEN 'tumor'  -- meaning: 'Neoplasm, Primary'\n            ELSE 'other'                 -- meaning: 'Neoplasm, Metastatic'\n        END AS \"tissue_type\"\n      FROM\n        IDC.IDC_V17.DICOM_ALL\n        CROSS JOIN\n          LATERAL FLATTEN(input => \"SpecimenDescriptionSequence\"[0].\"PrimaryAnatomicStructureSequence\") AS \"steps_unnested1\"\n        CROSS JOIN\n          LATERAL FLATTEN(input => \"steps_unnested1\".value:\"PrimaryAnatomicStructureModifierSequence\") AS \"steps_unnested2\"\n    )\n  ),\n\n  specimen_preparation_sequence_items AS (\n    SELECT DISTINCT *\n    FROM (\n      SELECT\n        \"SeriesInstanceUID\" AS \"digital_slide_id\",\n        \"steps_unnested2\".value:\"ConceptNameCodeSequence\"[0].\"CodeMeaning\"::STRING AS \"item_name\",\n        \"steps_unnested2\".value:\"ConceptCodeSequence\"[0].\"CodeMeaning\"::STRING AS \"item_value\"\n      FROM\n        IDC.IDC_V17.DICOM_ALL\n        CROSS JOIN\n          LATERAL FLATTEN(input => \"SpecimenDescriptionSequence\"[0].\"SpecimenPreparationSequence\") AS \"steps_unnested1\"\n        CROSS JOIN\n          LATERAL FLATTEN(input => \"steps_unnested1\".value:\"SpecimenPreparationStepContentItemSequence\") AS \"steps_unnested2\"\n    )\n  )\n\nSELECT\n  a.*,\n  b.\"tissue_type\",\n  REPLACE(REPLACE(a.\"collection_id\", 'tcga_luad', 'luad'), 'tcga_lusc', 'lscc') AS \"cancer_subtype\"\nFROM \n  sm_images AS a\n  JOIN tissue_types AS b \n    ON b.\"digital_slide_id\" = a.\"digital_slide_id\"\n  JOIN specimen_preparation_sequence_items AS c \n    ON c.\"digital_slide_id\" = a.\"digital_slide_id\"\nWHERE\n  (a.\"collection_id\" = 'tcga_luad' OR a.\"collection_id\" = 'tcga_lusc')\n  AND a.\"compression\" != 'other'\n  AND (b.\"tissue_type\" = 'normal' OR b.\"tissue_type\" = 'tumor')\n  AND (c.\"item_name\" = 'Embedding medium' AND c.\"item_value\" = 'Tissue freezing medium')\nORDER BY \n  a.\"crdc_instance_uuid\";",
        "db_id": "IDC",
        "No. of candidate columns": 2100,
        "No. of gold tables": 3
    },
    {
        "instance_id": "sf_bq320",
        "question": "In the dicom_pivot table, how many unique StudyInstanceUID values exactly match the SegmentedPropertyTypeCodeSequence of \"15825003\" (case-insensitive) and also have a collection_id of either \"Community\" or \"nsclc_radiomics\"?",
        "external_knowledge": null,
        "question_toks": [
            "In",
            "the",
            "dicom_pivot",
            "table,",
            "how",
            "many",
            "unique",
            "StudyInstanceUID",
            "values",
            "exactly",
            "match",
            "the",
            "SegmentedPropertyTypeCodeSequence",
            "of",
            "\"15825003\"",
            "(case-insensitive)",
            "and",
            "also",
            "have",
            "a",
            "collection_id",
            "of",
            "either",
            "\"Community\"",
            "or",
            "\"nsclc_radiomics\"?"
        ],
        "query": "SELECT\n  COUNT(*) AS \"total_count\"\nFROM\n  IDC.IDC_V17.DICOM_PIVOT AS \"dicom_pivot\"\nWHERE\n  \"StudyInstanceUID\" IN (\n    SELECT\n      \"StudyInstanceUID\"\n    FROM\n      IDC.IDC_V17.DICOM_PIVOT AS \"dicom_pivot\"\n    WHERE\n      \"StudyInstanceUID\" IN (\n        SELECT\n          \"StudyInstanceUID\"\n        FROM\n          IDC.IDC_V17.DICOM_PIVOT AS \"dicom_pivot\"\n        WHERE\n          LOWER(\"dicom_pivot\".\"SegmentedPropertyTypeCodeSequence\") LIKE LOWER('15825003')\n        GROUP BY\n          \"StudyInstanceUID\"\n        INTERSECT\n        SELECT\n          \"StudyInstanceUID\"\n        FROM\n          IDC.IDC_V17.DICOM_PIVOT AS \"dicom_pivot\"\n        WHERE\n          \"dicom_pivot\".\"collection_id\" IN ('Community', 'nsclc_radiomics')\n        GROUP BY\n          \"StudyInstanceUID\"\n      )\n    GROUP BY\n      \"StudyInstanceUID\"\n  );",
        "db_id": "IDC",
        "No. of candidate columns": 2100,
        "No. of gold tables": 4
    },
    {
        "instance_id": "sf_bq417",
        "question": "Please provide identification details, study and series information, storage location, and total size in MB for the medical images belonging to male patients who are exactly 18 years old based on the numeric portion of the PatientAge field, where the BodyPartExamined is set to 'MEDIASTINUM' and the study date is strictly after September 1, 2014.",
        "external_knowledge": "IDC_data_model.md",
        "question_toks": [
            "Please",
            "provide",
            "identification",
            "details,",
            "study",
            "and",
            "series",
            "information,",
            "storage",
            "location,",
            "and",
            "total",
            "size",
            "in",
            "MB",
            "for",
            "the",
            "medical",
            "images",
            "belonging",
            "to",
            "male",
            "patients",
            "who",
            "are",
            "exactly",
            "18",
            "years",
            "old",
            "based",
            "on",
            "the",
            "numeric",
            "portion",
            "of",
            "the",
            "PatientAge",
            "field,",
            "where",
            "the",
            "BodyPartExamined",
            "is",
            "set",
            "to",
            "'MEDIASTINUM'",
            "and",
            "the",
            "study",
            "date",
            "is",
            "strictly",
            "after",
            "September",
            "1,",
            "2014."
        ],
        "query": "",
        "db_id": "IDC",
        "No. of candidate columns": 2100,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq456",
        "question": "Please retrieve from the dicom_all table each PatientID, StudyInstanceUID, StudyDate, and the CodeMeaning of the FindingSite for patients whose StudyDate is in the year 2001, along with the maximum values of each of the following measurements identified by their CodeMeaning (Elongation, Flatness, Least Axis in 3D Length, Major Axis in 3D Length, Maximum 3D Diameter of a Mesh, Minor Axis in 3D Length, Sphericity, Surface Area of Mesh, Surface to Volume Ratio, Volume from Voxel Summation, and Volume of Mesh), ensuring that the quantitative_measurements table is joined on segmentationInstanceUID matching the SOPInstanceUID in dicom_all, and grouping by PatientID, StudyInstanceUID, StudyDate, and FindingSite CodeMeaning.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "retrieve",
            "from",
            "the",
            "dicom_all",
            "table",
            "each",
            "PatientID,",
            "StudyInstanceUID,",
            "StudyDate,",
            "and",
            "the",
            "CodeMeaning",
            "of",
            "the",
            "FindingSite",
            "for",
            "patients",
            "whose",
            "StudyDate",
            "is",
            "in",
            "the",
            "year",
            "2001,",
            "along",
            "with",
            "the",
            "maximum",
            "values",
            "of",
            "each",
            "of",
            "the",
            "following",
            "measurements",
            "identified",
            "by",
            "their",
            "CodeMeaning",
            "(Elongation,",
            "Flatness,",
            "Least",
            "Axis",
            "in",
            "3D",
            "Length,",
            "Major",
            "Axis",
            "in",
            "3D",
            "Length,",
            "Maximum",
            "3D",
            "Diameter",
            "of",
            "a",
            "Mesh,",
            "Minor",
            "Axis",
            "in",
            "3D",
            "Length,",
            "Sphericity,",
            "Surface",
            "Area",
            "of",
            "Mesh,",
            "Surface",
            "to",
            "Volume",
            "Ratio,",
            "Volume",
            "from",
            "Voxel",
            "Summation,",
            "and",
            "Volume",
            "of",
            "Mesh),",
            "ensuring",
            "that",
            "the",
            "quantitative_measurements",
            "table",
            "is",
            "joined",
            "on",
            "segmentationInstanceUID",
            "matching",
            "the",
            "SOPInstanceUID",
            "in",
            "dicom_all,",
            "and",
            "grouping",
            "by",
            "PatientID,",
            "StudyInstanceUID,",
            "StudyDate,",
            "and",
            "FindingSite",
            "CodeMeaning."
        ],
        "query": "",
        "db_id": "IDC",
        "No. of candidate columns": 2100,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq324",
        "question": "How many frames in total are present across all whole slide microscopy images from the TCGA-BRCA collection that use the SM modality and include an eosin-based staining step in their SpecimenPreparationSequence?",
        "external_knowledge": null,
        "question_toks": [
            "How",
            "many",
            "frames",
            "in",
            "total",
            "are",
            "present",
            "across",
            "all",
            "whole",
            "slide",
            "microscopy",
            "images",
            "from",
            "the",
            "TCGA-BRCA",
            "collection",
            "that",
            "use",
            "the",
            "SM",
            "modality",
            "and",
            "include",
            "an",
            "eosin-based",
            "staining",
            "step",
            "in",
            "their",
            "SpecimenPreparationSequence?"
        ],
        "query": "",
        "db_id": "IDC",
        "No. of candidate columns": 2100,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq418",
        "question": "Determine which three lowest-level Reactome pathways (with TAS evidence) have the highest chi-squared statistics, considering only Homo sapiens targets associated with sorafenib under the conditions that the median assay value is ≤ 100 and both low and high assay values are ≤ 100 or null. For each of these three pathways, how many of these targets and non-targets lie within the pathway and outside it?",
        "external_knowledge": null,
        "question_toks": [
            "Determine",
            "which",
            "three",
            "lowest-level",
            "Reactome",
            "pathways",
            "(with",
            "TAS",
            "evidence)",
            "have",
            "the",
            "highest",
            "chi-squared",
            "statistics,",
            "considering",
            "only",
            "Homo",
            "sapiens",
            "targets",
            "associated",
            "with",
            "sorafenib",
            "under",
            "the",
            "conditions",
            "that",
            "the",
            "median",
            "assay",
            "value",
            "is",
            "≤",
            "100",
            "and",
            "both",
            "low",
            "and",
            "high",
            "assay",
            "values",
            "are",
            "≤",
            "100",
            "or",
            "null.",
            "For",
            "each",
            "of",
            "these",
            "three",
            "pathways,",
            "how",
            "many",
            "of",
            "these",
            "targets",
            "and",
            "non-targets",
            "lie",
            "within",
            "the",
            "pathway",
            "and",
            "outside",
            "it?"
        ],
        "query": "",
        "db_id": "targetome_reactome",
        "No. of candidate columns": 58,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq230",
        "question": "Using the crops dataset, find the total 2022 production figures, measured in bushels, for corn from the 'FIELD CROPS' category and mushrooms from the 'HORTICULTURE' group for each U.S. state. Only include data rows where 'statisticcat_desc' is 'PRODUCTION', 'agg_level_desc' is 'STATE', 'value' is not null, and ensure that for corn the 'unit_desc' is 'BU'. Combine both results so that each state’s 2022 corn and mushroom totals are presented.",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "the",
            "crops",
            "dataset,",
            "find",
            "the",
            "total",
            "2022",
            "production",
            "figures,",
            "measured",
            "in",
            "bushels,",
            "for",
            "corn",
            "from",
            "the",
            "'FIELD",
            "CROPS'",
            "category",
            "and",
            "mushrooms",
            "from",
            "the",
            "'HORTICULTURE'",
            "group",
            "for",
            "each",
            "U.S.",
            "state.",
            "Only",
            "include",
            "data",
            "rows",
            "where",
            "'statisticcat_desc'",
            "is",
            "'PRODUCTION',",
            "'agg_level_desc'",
            "is",
            "'STATE',",
            "'value'",
            "is",
            "not",
            "null,",
            "and",
            "ensure",
            "that",
            "for",
            "corn",
            "the",
            "'unit_desc'",
            "is",
            "'BU'.",
            "Combine",
            "both",
            "results",
            "so",
            "that",
            "each",
            "state’s",
            "2022",
            "corn",
            "and",
            "mushroom",
            "totals",
            "are",
            "presented."
        ],
        "query": "",
        "db_id": "usda_nass_agriculture",
        "No. of candidate columns": 439,
        "No. of gold tables": 0
    },
    {
        "instance_id": "bq326",
        "question": "Based on the World Bank global population dataset and the World Bank health nutrition population dataset, how many countries experienced an increase of more than 1% from the previous year to 2018 in both their total population and per capita current health expenditure (PPP)?",
        "external_knowledge": null,
        "question_toks": [
            "Based",
            "on",
            "the",
            "World",
            "Bank",
            "global",
            "population",
            "dataset",
            "and",
            "the",
            "World",
            "Bank",
            "health",
            "nutrition",
            "population",
            "dataset,",
            "how",
            "many",
            "countries",
            "experienced",
            "an",
            "increase",
            "of",
            "more",
            "than",
            "1%",
            "from",
            "the",
            "previous",
            "year",
            "to",
            "2018",
            "in",
            "both",
            "their",
            "total",
            "population",
            "and",
            "per",
            "capita",
            "current",
            "health",
            "expenditure",
            "(PPP)?"
        ],
        "query": "",
        "db_id": "world_bank",
        "No. of candidate columns": 314,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq370",
        "question": "How many customers have orders and invoices that match at the line-item level and, when aggregated, result in each customer having an equal count of orders and invoices as well as an identical total value for the orders and invoices?",
        "external_knowledge": null,
        "question_toks": [
            "How",
            "many",
            "customers",
            "have",
            "orders",
            "and",
            "invoices",
            "that",
            "match",
            "at",
            "the",
            "line-item",
            "level",
            "and,",
            "when",
            "aggregated,",
            "result",
            "in",
            "each",
            "customer",
            "having",
            "an",
            "equal",
            "count",
            "of",
            "orders",
            "and",
            "invoices",
            "as",
            "well",
            "as",
            "an",
            "identical",
            "total",
            "value",
            "for",
            "the",
            "orders",
            "and",
            "invoices?"
        ],
        "query": "",
        "db_id": "WIDE_WORLD_IMPORTERS",
        "No. of candidate columns": 368,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq371",
        "question": "In the year 2013, considering each invoice’s total value as the product of unit price and quantity and grouping by the quarter (Q1, Q2, Q3, Q4) in which the invoice date occurs, what is the difference between the maximum and minimum average invoice values across these quarters?",
        "external_knowledge": null,
        "question_toks": [
            "In",
            "the",
            "year",
            "2013,",
            "considering",
            "each",
            "invoice’s",
            "total",
            "value",
            "as",
            "the",
            "product",
            "of",
            "unit",
            "price",
            "and",
            "quantity",
            "and",
            "grouping",
            "by",
            "the",
            "quarter",
            "(Q1,",
            "Q2,",
            "Q3,",
            "Q4)",
            "in",
            "which",
            "the",
            "invoice",
            "date",
            "occurs,",
            "what",
            "is",
            "the",
            "difference",
            "between",
            "the",
            "maximum",
            "and",
            "minimum",
            "average",
            "invoice",
            "values",
            "across",
            "these",
            "quarters?"
        ],
        "query": "",
        "db_id": "WIDE_WORLD_IMPORTERS",
        "No. of candidate columns": 368,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq372",
        "question": "Among all orders that do not appear in the invoice table, for each customer category calculate the maximum lost order value, then determine which customer category’s maximum lost order value is closest to the overall average of these maximum lost order values across all categories?",
        "external_knowledge": null,
        "question_toks": [
            "Among",
            "all",
            "orders",
            "that",
            "do",
            "not",
            "appear",
            "in",
            "the",
            "invoice",
            "table,",
            "for",
            "each",
            "customer",
            "category",
            "calculate",
            "the",
            "maximum",
            "lost",
            "order",
            "value,",
            "then",
            "determine",
            "which",
            "customer",
            "category’s",
            "maximum",
            "lost",
            "order",
            "value",
            "is",
            "closest",
            "to",
            "the",
            "overall",
            "average",
            "of",
            "these",
            "maximum",
            "lost",
            "order",
            "values",
            "across",
            "all",
            "categories?"
        ],
        "query": "",
        "db_id": "WIDE_WORLD_IMPORTERS",
        "No. of candidate columns": 368,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq373",
        "question": "Using the invoice date to determine each month of the year 2014, and summing the total invoice line amounts for each customer across these months, what is the median of the resulting average monthly spending across all customers?",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "the",
            "invoice",
            "date",
            "to",
            "determine",
            "each",
            "month",
            "of",
            "the",
            "year",
            "2014,",
            "and",
            "summing",
            "the",
            "total",
            "invoice",
            "line",
            "amounts",
            "for",
            "each",
            "customer",
            "across",
            "these",
            "months,",
            "what",
            "is",
            "the",
            "median",
            "of",
            "the",
            "resulting",
            "average",
            "monthly",
            "spending",
            "across",
            "all",
            "customers?"
        ],
        "query": "",
        "db_id": "WIDE_WORLD_IMPORTERS",
        "No. of candidate columns": 368,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf_bq118",
        "question": "Among individuals identified as white, how much higher is the average number of deaths from ICD-10 codes whose descriptions contain the word “discharge” (specifically excluding “Urethral discharge,” “Discharge of firework,” and “Legal intervention involving firearm discharge”) compared to the average number of deaths from ICD-10 codes whose descriptions contain the word “vehicle,” when aggregated by age groups?",
        "external_knowledge": null,
        "question_toks": [
            "Among",
            "individuals",
            "identified",
            "as",
            "white,",
            "how",
            "much",
            "higher",
            "is",
            "the",
            "average",
            "number",
            "of",
            "deaths",
            "from",
            "ICD-10",
            "codes",
            "whose",
            "descriptions",
            "contain",
            "the",
            "word",
            "“discharge”",
            "(specifically",
            "excluding",
            "“Urethral",
            "discharge,”",
            "“Discharge",
            "of",
            "firework,”",
            "and",
            "“Legal",
            "intervention",
            "involving",
            "firearm",
            "discharge”)",
            "compared",
            "to",
            "the",
            "average",
            "number",
            "of",
            "deaths",
            "from",
            "ICD-10",
            "codes",
            "whose",
            "descriptions",
            "contain",
            "the",
            "word",
            "“vehicle,”",
            "when",
            "aggregated",
            "by",
            "age",
            "groups?"
        ],
        "query": "",
        "db_id": "DEATH",
        "No. of candidate columns": 99,
        "No. of gold tables": 0
    },
    {
        "instance_id": "ga008",
        "question": "Could you provide the total number of page views for each day in November 2020 as well as the average number of page views per user on those days, restricted to users who made at least one purchase in November 2020?",
        "external_knowledge": null,
        "question_toks": [
            "Could",
            "you",
            "provide",
            "the",
            "total",
            "number",
            "of",
            "page",
            "views",
            "for",
            "each",
            "day",
            "in",
            "November",
            "2020",
            "as",
            "well",
            "as",
            "the",
            "average",
            "number",
            "of",
            "page",
            "views",
            "per",
            "user",
            "on",
            "those",
            "days,",
            "restricted",
            "to",
            "users",
            "who",
            "made",
            "at",
            "least",
            "one",
            "purchase",
            "in",
            "November",
            "2020?"
        ],
        "query": "WITH\n  UserInfo AS (\n    SELECT\n      user_pseudo_id,\n      PARSE_DATE('%Y%m%d', event_date) AS event_date,\n      COUNTIF(event_name = 'page_view') AS page_view_count,\n      COUNTIF(event_name = 'purchase') AS purchase_event_count\n    FROM `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n    WHERE _TABLE_SUFFIX BETWEEN '20201101' AND '20201130'\n    GROUP BY 1, 2\n  )\nSELECT\n  event_date,\n  SUM(page_view_count) / COUNT(*) AS avg_page_views,\n  SUM(page_view_count)\nFROM UserInfo\nWHERE purchase_event_count > 0\nGROUP BY event_date\nORDER BY event_date;",
        "db_id": "ga4",
        "No. of candidate columns": 2116,
        "No. of gold tables": 20
    },
    {
        "instance_id": "ga018",
        "question": "On January 2nd, 2021, I want to determine the percentage of times users transition from a product list page (PLP) view to a product detail page (PDP) view within the same session, using only page_view events. Could you calculate how many PLP views eventually led to a PDP view in the same session on that date, and then provide the resulting percentage of PLP-to-PDP transitions?",
        "external_knowledge": "ga4_page_category.md",
        "question_toks": [
            "On",
            "January",
            "2nd,",
            "2021,",
            "I",
            "want",
            "to",
            "determine",
            "the",
            "percentage",
            "of",
            "times",
            "users",
            "transition",
            "from",
            "a",
            "product",
            "list",
            "page",
            "(PLP)",
            "view",
            "to",
            "a",
            "product",
            "detail",
            "page",
            "(PDP)",
            "view",
            "within",
            "the",
            "same",
            "session,",
            "using",
            "only",
            "page_view",
            "events.",
            "Could",
            "you",
            "calculate",
            "how",
            "many",
            "PLP",
            "views",
            "eventually",
            "led",
            "to",
            "a",
            "PDP",
            "view",
            "in",
            "the",
            "same",
            "session",
            "on",
            "that",
            "date,",
            "and",
            "then",
            "provide",
            "the",
            "resulting",
            "percentage",
            "of",
            "PLP-to-PDP",
            "transitions?"
        ],
        "query": "WITH base_table AS (\n  SELECT\n    event_name,\n    event_date,\n    event_timestamp,\n    user_pseudo_id,\n    user_id,\n    device,\n    geo,\n    traffic_source,\n    event_params,\n    user_properties\n  FROM\n    `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*`\n  WHERE\n    _table_suffix = '20210102'\n  AND event_name IN ('page_view')\n)\n, unnested_events AS (\n-- unnests event parameters to get to relevant keys and values\n  SELECT\n    event_date AS date,\n    event_timestamp AS event_timestamp_microseconds,\n    user_pseudo_id,\n    MAX(CASE WHEN c.key = 'ga_session_id' THEN c.value.int_value END) AS visitID,\n    MAX(CASE WHEN c.key = 'ga_session_number' THEN c.value.int_value END) AS visitNumber,\n    MAX(CASE WHEN c.key = 'page_title' THEN c.value.string_value END) AS page_title,\n    MAX(CASE WHEN c.key = 'page_location' THEN c.value.string_value END) AS page_location\n  FROM \n    base_table,\n    UNNEST (event_params) c\n  GROUP BY 1,2,3\n)\n\n, unnested_events_categorised AS (\n-- categorizing Page Titles into PDPs and PLPs\n  SELECT\n  *,\n  CASE WHEN ARRAY_LENGTH(SPLIT(page_location, '/')) >= 5 \n            AND\n            CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+')\n            AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n                  OR\n                  LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n            )\n            THEN 'PDP'\n            WHEN NOT(CONTAINS_SUBSTR(ARRAY_REVERSE(SPLIT(page_location, '/'))[SAFE_OFFSET(0)], '+'))\n            AND (LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(4)]) IN \n                                        ('accessories','apparel','brands','campus+collection','drinkware',\n                                          'electronics','google+redesign',\n                                          'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                          'office','shop+by+brand','small+goods','stationery','wearables'\n                                          )\n                  OR \n                  LOWER(SPLIT(page_location, '/')[SAFE_OFFSET(3)]) IN \n                                          ('accessories','apparel','brands','campus+collection','drinkware',\n                                            'electronics','google+redesign',\n                                            'lifestyle','nest','new+2015+logo','notebooks+journals',\n                                            'office','shop+by+brand','small+goods','stationery','wearables'\n                                            )\n            )\n            THEN 'PLP'\n        ELSE page_title\n        END AS page_title_adjusted \n\n  FROM \n    unnested_events\n)\n\n\n, ranked_screens AS (\n  SELECT\n    *,\n    LAG(page_title_adjusted,1) OVER (PARTITION BY  user_pseudo_id, visitID ORDER BY event_timestamp_microseconds ASC) previous_page,\n    LEAD(page_title_adjusted,1) OVER (PARTITION BY  user_pseudo_id, visitID ORDER BY event_timestamp_microseconds ASC)  next_page\n  FROM \n    unnested_events_categorised\n\n)\n\n,PLPtoPDPTransitions AS (\n  SELECT\n    user_pseudo_id,\n    visitID\n  FROM\n    ranked_screens\n  WHERE\n    page_title_adjusted = 'PLP' AND next_page = 'PDP'\n)\n\n,TotalPLPViews AS (\n  SELECT\n    COUNT(*) AS total_plp_views\n  FROM\n    ranked_screens\n  WHERE\n    page_title_adjusted = 'PLP'\n)\n\n,TotalTransitions AS (\n  SELECT\n    COUNT(*) AS total_transitions\n  FROM\n    PLPtoPDPTransitions\n)\n\nSELECT\n  (total_transitions * 100.0) / total_plp_views AS percentage\nFROM\n  TotalTransitions, TotalPLPViews;",
        "db_id": "ga4",
        "No. of candidate columns": 2116,
        "No. of gold tables": 20
    },
    {
        "instance_id": "ga031",
        "question": "I want to know the user session conversion rate on January 2nd, 2021, using only 'page_view' events. The conversion rate should be calculated as the percentage of user visits that reached both the Home and Checkout Confirmation pages in one session, relative to those that landed on the Home page.",
        "external_knowledge": null,
        "question_toks": [
            "I",
            "want",
            "to",
            "know",
            "the",
            "user",
            "session",
            "conversion",
            "rate",
            "on",
            "January",
            "2nd,",
            "2021,",
            "using",
            "only",
            "'page_view'",
            "events.",
            "The",
            "conversion",
            "rate",
            "should",
            "be",
            "calculated",
            "as",
            "the",
            "percentage",
            "of",
            "user",
            "visits",
            "that",
            "reached",
            "both",
            "the",
            "Home",
            "and",
            "Checkout",
            "Confirmation",
            "pages",
            "in",
            "one",
            "session,",
            "relative",
            "to",
            "those",
            "that",
            "landed",
            "on",
            "the",
            "Home",
            "page."
        ],
        "query": "",
        "db_id": "ga4",
        "No. of candidate columns": 2116,
        "No. of gold tables": 0
    },
    {
        "instance_id": "ga006",
        "question": "For the date range November 1–30, 2020, can you retrieve each user_pseudo_id and its average purchase revenue in USD per session for users who had more than one purchase session, considering only events with event_name='purchase' and a non-null ecommerce.purchase_revenue_in_usd, grouping sessions by the ga_session_id from event_params",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "the",
            "date",
            "range",
            "November",
            "1–30,",
            "2020,",
            "can",
            "you",
            "retrieve",
            "each",
            "user_pseudo_id",
            "and",
            "its",
            "average",
            "purchase",
            "revenue",
            "in",
            "USD",
            "per",
            "session",
            "for",
            "users",
            "who",
            "had",
            "more",
            "than",
            "one",
            "purchase",
            "session,",
            "considering",
            "only",
            "events",
            "with",
            "event_name='purchase'",
            "and",
            "a",
            "non-null",
            "ecommerce.purchase_revenue_in_usd,",
            "grouping",
            "sessions",
            "by",
            "the",
            "ga_session_id",
            "from",
            "event_params"
        ],
        "query": "",
        "db_id": "ga4",
        "No. of candidate columns": 2116,
        "No. of gold tables": 0
    },
    {
        "instance_id": "ga009",
        "question": "Could you tell me the average number of engaged sessions per user for December 2020, counting only those sessions where the event parameter 'session_engaged' is equal to '1' and using 'user_pseudo_id' combined with the 'ga_session_id' to identify distinct sessions?",
        "external_knowledge": null,
        "question_toks": [
            "Could",
            "you",
            "tell",
            "me",
            "the",
            "average",
            "number",
            "of",
            "engaged",
            "sessions",
            "per",
            "user",
            "for",
            "December",
            "2020,",
            "counting",
            "only",
            "those",
            "sessions",
            "where",
            "the",
            "event",
            "parameter",
            "'session_engaged'",
            "is",
            "equal",
            "to",
            "'1'",
            "and",
            "using",
            "'user_pseudo_id'",
            "combined",
            "with",
            "the",
            "'ga_session_id'",
            "to",
            "identify",
            "distinct",
            "sessions?"
        ],
        "query": "",
        "db_id": "ga4",
        "No. of candidate columns": 2116,
        "No. of gold tables": 0
    },
    {
        "instance_id": "ga020",
        "question": "Which quickplay event type had the lowest user retention rate during the second week after their initial engagement, for users who first engaged between August 1 and August 15, 2018, as measured by the presence of session_start events??",
        "external_knowledge": "retention_rate.md",
        "question_toks": [
            "Which",
            "quickplay",
            "event",
            "type",
            "had",
            "the",
            "lowest",
            "user",
            "retention",
            "rate",
            "during",
            "the",
            "second",
            "week",
            "after",
            "their",
            "initial",
            "engagement,",
            "for",
            "users",
            "who",
            "first",
            "engaged",
            "between",
            "August",
            "1",
            "and",
            "August",
            "15,",
            "2018,",
            "as",
            "measured",
            "by",
            "the",
            "presence",
            "of",
            "session_start",
            "events??"
        ],
        "query": "-- Define the date range and calculate the minimum date for filtering results\nWITH dates AS (\n    SELECT \n        DATE('2018-08-01') AS start_date,\n        DATE('2018-08-15') AS end_date\n),\n-- Create a table of active dates for each user within the specified date range\ndates_active_table AS (\n    SELECT\n        user_pseudo_id,\n        PARSE_DATE('%Y%m%d', `event_date`) AS user_active_date\n    FROM \n        `firebase-public-project.analytics_153293282.events_*` \n    WHERE \n        event_name = 'session_start'\n        AND PARSE_DATE('%Y%m%d', `event_date`) BETWEEN (SELECT start_date FROM dates) AND (SELECT end_date FROM dates)\n    GROUP BY \n        user_pseudo_id, user_active_date\n),\n-- Create a table of the earliest quickplay event date for each user within the specified date range\nevent_table AS (\n    SELECT \n        user_pseudo_id,\n        event_name,\n        MIN(PARSE_DATE('%Y%m%d', `event_date`)) AS event_cohort_date\n    FROM \n        `firebase-public-project.analytics_153293282.events_*` \n    WHERE \n        event_name IN ('level_start_quickplay', 'level_end_quickplay', 'level_complete_quickplay', \n                       'level_fail_quickplay', 'level_reset_quickplay', 'level_retry_quickplay')\n        AND PARSE_DATE('%Y%m%d', `event_date`) BETWEEN (SELECT start_date FROM dates) AND (SELECT end_date FROM dates)\n    GROUP BY \n        user_pseudo_id, event_name\n),\n-- Calculate the number of days since each user's initial quickplay event\ndays_since_event_table AS (\n    SELECT\n        events.user_pseudo_id,\n        events.event_name AS event_cohort,\n        events.event_cohort_date,\n        days.user_active_date,\n        DATE_DIFF(days.user_active_date, events.event_cohort_date, DAY) AS days_since_event\n    FROM \n        event_table events\n    LEFT JOIN \n        dates_active_table days ON events.user_pseudo_id = days.user_pseudo_id\n    WHERE \n        events.event_cohort_date <= days.user_active_date\n),\n-- Calculate the weeks since each user's initial quickplay event and count the active days in each week\nweeks_retention AS (\n    SELECT\n        event_cohort,\n        user_pseudo_id,\n        CAST(CASE WHEN days_since_event = 0 THEN 0 ELSE CEIL(days_since_event / 7) END AS INTEGER) AS weeks_since_event,\n        COUNT(DISTINCT days_since_event) AS days_active_since_event -- Count Days Active in Week\n    FROM \n        days_since_event_table\n    GROUP BY \n        event_cohort, user_pseudo_id, weeks_since_event\n),\n-- Aggregate the weekly retention data\naggregated_weekly_retention_table AS (\n    SELECT\n        event_cohort,\n        weeks_since_event,\n        SUM(days_active_since_event) AS weekly_days_active,\n        COUNT(DISTINCT user_pseudo_id) AS retained_users\n    FROM \n        weeks_retention\n    GROUP BY \n        event_cohort, weeks_since_event\n),\nRETENTION_INFO AS (\n-- Select and calculate the weekly retention rate for each event cohort\nSELECT\n    event_cohort,\n    weeks_since_event,\n    weekly_days_active,\n    retained_users,\n    (retained_users / MAX(retained_users) OVER (PARTITION BY event_cohort)) AS retention_rate\nFROM \n    aggregated_weekly_retention_table\nORDER BY \n    event_cohort, weeks_since_event\n)\n\nSELECT event_cohort\nFROM\nRETENTION_INFO\nWHERE weeks_since_event = 2\nORDER BY retention_rate\nLIMIT 1",
        "db_id": "firebase",
        "No. of candidate columns": 2148,
        "No. of gold tables": 20
    },
    {
        "instance_id": "ga022",
        "question": "Could you please help me get the weekly customer retention rate in September 2018 for new customers who first used our app (first_open event) within the first week starting from September 1st, 2018 (timezone in Shanghai)? The retention rates should cover the following weeks 1, 2, and 3 period after the initial use and display them in column format.",
        "external_knowledge": "retention_rate.md",
        "question_toks": [
            "Could",
            "you",
            "please",
            "help",
            "me",
            "get",
            "the",
            "weekly",
            "customer",
            "retention",
            "rate",
            "in",
            "September",
            "2018",
            "for",
            "new",
            "customers",
            "who",
            "first",
            "used",
            "our",
            "app",
            "(first_open",
            "event)",
            "within",
            "the",
            "first",
            "week",
            "starting",
            "from",
            "September",
            "1st,",
            "2018",
            "(timezone",
            "in",
            "Shanghai)?",
            "The",
            "retention",
            "rates",
            "should",
            "cover",
            "the",
            "following",
            "weeks",
            "1,",
            "2,",
            "and",
            "3",
            "period",
            "after",
            "the",
            "initial",
            "use",
            "and",
            "display",
            "them",
            "in",
            "column",
            "format."
        ],
        "query": "WITH analytics_data AS (\n  SELECT user_pseudo_id, event_timestamp, event_name, \n    UNIX_MICROS(TIMESTAMP(\"2018-09-01 00:00:00\", \"+8:00\")) AS start_day,\n    3600*1000*1000*24*7 AS one_week_micros\n  FROM `firebase-public-project.analytics_153293282.events_*`\n  WHERE _table_suffix BETWEEN '20180901' AND '20180930'\n)\n\nSELECT\n week_1_cohort / week_0_cohort AS week_1_pct,\n week_2_cohort / week_0_cohort AS week_2_pct,\n week_3_cohort / week_0_cohort AS week_3_pct\nFROM (\n  WITH week_3_users AS (\n    SELECT DISTINCT user_pseudo_id\n    FROM analytics_data\n    WHERE event_timestamp BETWEEN start_day+(3*one_week_micros) AND start_day+(4*one_week_micros)\n  ),\n  week_2_users AS (\n    SELECT DISTINCT user_pseudo_id\n    FROM analytics_data\n    WHERE event_timestamp BETWEEN start_day+(2*one_week_micros) AND start_day+(3*one_week_micros)\n  ),\n  week_1_users AS (\n    SELECT DISTINCT user_pseudo_id\n    FROM analytics_data\n    WHERE event_timestamp BETWEEN start_day+(1*one_week_micros) AND start_day+(2*one_week_micros)\n  ), \n  week_0_users AS (\n    SELECT DISTINCT user_pseudo_id\n    FROM analytics_data\n    WHERE event_name = 'first_open'\n      AND event_timestamp BETWEEN start_day AND start_day+(1*one_week_micros)\n  )\n  SELECT \n    (SELECT count(*) \n     FROM week_0_users) AS week_0_cohort,\n    (SELECT count(*) \n     FROM week_1_users \n     JOIN week_0_users USING (user_pseudo_id)) AS week_1_cohort,\n    (SELECT count(*) \n     FROM week_2_users \n     JOIN week_0_users USING (user_pseudo_id)) AS week_2_cohort,\n    (SELECT count(*) \n     FROM week_3_users \n     JOIN week_0_users USING (user_pseudo_id)) AS week_3_cohort\n)",
        "db_id": "firebase",
        "No. of candidate columns": 2148,
        "No. of gold tables": 20
    },
    {
        "instance_id": "ga025",
        "question": "For all users who first opened the app in September 2018 and then uninstalled within seven days, I want to know what percentage of them experienced an app crash (app_exception). The calculation should be done by converting the timestamps to dates first, and then calculating the days to uninstall based on the dates. Only users who uninstalled within 7 days and experienced a crash should be considered in the final percentage.",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "all",
            "users",
            "who",
            "first",
            "opened",
            "the",
            "app",
            "in",
            "September",
            "2018",
            "and",
            "then",
            "uninstalled",
            "within",
            "seven",
            "days,",
            "I",
            "want",
            "to",
            "know",
            "what",
            "percentage",
            "of",
            "them",
            "experienced",
            "an",
            "app",
            "crash",
            "(app_exception).",
            "The",
            "calculation",
            "should",
            "be",
            "done",
            "by",
            "converting",
            "the",
            "timestamps",
            "to",
            "dates",
            "first,",
            "and",
            "then",
            "calculating",
            "the",
            "days",
            "to",
            "uninstall",
            "based",
            "on",
            "the",
            "dates.",
            "Only",
            "users",
            "who",
            "uninstalled",
            "within",
            "7",
            "days",
            "and",
            "experienced",
            "a",
            "crash",
            "should",
            "be",
            "considered",
            "in",
            "the",
            "final",
            "percentage."
        ],
        "query": "",
        "db_id": "firebase",
        "No. of candidate columns": 2148,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local002",
        "question": "Can you calculate the 5-day symmetric moving average of predicted toy sales for December 5 to 8, 2018, using daily sales data from January 1, 2017, to August 29, 2018, with a simple linear regression model? Finally provide the sum of those four 5-day moving averages?",
        "external_knowledge": null,
        "question_toks": [
            "Can",
            "you",
            "calculate",
            "the",
            "5-day",
            "symmetric",
            "moving",
            "average",
            "of",
            "predicted",
            "toy",
            "sales",
            "for",
            "December",
            "5",
            "to",
            "8,",
            "2018,",
            "using",
            "daily",
            "sales",
            "data",
            "from",
            "January",
            "1,",
            "2017,",
            "to",
            "August",
            "29,",
            "2018,",
            "with",
            "a",
            "simple",
            "linear",
            "regression",
            "model?",
            "Finally",
            "provide",
            "the",
            "sum",
            "of",
            "those",
            "four",
            "5-day",
            "moving",
            "averages?"
        ],
        "query": "",
        "db_id": "E_commerce",
        "No. of candidate columns": 70,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local025",
        "question": "For each match, considering every innings, please combine runs from both batsman scored and extra runs for each over, then identify the single over with the highest total runs, retrieve the bowler for that over from the ball by ball table, and calculate the average of these highest over totals across all matches, ensuring that all runs and bowler details are accurately reflected.",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "each",
            "match,",
            "considering",
            "every",
            "innings,",
            "please",
            "combine",
            "runs",
            "from",
            "both",
            "batsman",
            "scored",
            "and",
            "extra",
            "runs",
            "for",
            "each",
            "over,",
            "then",
            "identify",
            "the",
            "single",
            "over",
            "with",
            "the",
            "highest",
            "total",
            "runs,",
            "retrieve",
            "the",
            "bowler",
            "for",
            "that",
            "over",
            "from",
            "the",
            "ball",
            "by",
            "ball",
            "table,",
            "and",
            "calculate",
            "the",
            "average",
            "of",
            "these",
            "highest",
            "over",
            "totals",
            "across",
            "all",
            "matches,",
            "ensuring",
            "that",
            "all",
            "runs",
            "and",
            "bowler",
            "details",
            "are",
            "accurately",
            "reflected."
        ],
        "query": "",
        "db_id": "IPL",
        "No. of candidate columns": 52,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local035",
        "question": "In the “olist_geolocation” table, please identify which two consecutive cities, when sorted by geolocation_state, geolocation_city, geolocation_zip_code_prefix, geolocation_lat, and geolocation_lng, have the greatest distance between them based on the difference in distance computed between each city and its immediate predecessor in that ordering.",
        "external_knowledge": "spherical_law.md",
        "question_toks": [
            "In",
            "the",
            "“olist_geolocation”",
            "table,",
            "please",
            "identify",
            "which",
            "two",
            "consecutive",
            "cities,",
            "when",
            "sorted",
            "by",
            "geolocation_state,",
            "geolocation_city,",
            "geolocation_zip_code_prefix,",
            "geolocation_lat,",
            "and",
            "geolocation_lng,",
            "have",
            "the",
            "greatest",
            "distance",
            "between",
            "them",
            "based",
            "on",
            "the",
            "difference",
            "in",
            "distance",
            "computed",
            "between",
            "each",
            "city",
            "and",
            "its",
            "immediate",
            "predecessor",
            "in",
            "that",
            "ordering."
        ],
        "query": "",
        "db_id": "Brazilian_E_Commerce",
        "No. of candidate columns": 62,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local040",
        "question": "In the combined dataset that unifies the trees data with the income data by ZIP code, filling missing ZIP values where necessary, which three boroughs, restricted to records with median and mean income both greater than zero and a valid borough name, contain the highest number of trees, and what is the average mean income for each of these three boroughs?",
        "external_knowledge": null,
        "question_toks": [
            "In",
            "the",
            "combined",
            "dataset",
            "that",
            "unifies",
            "the",
            "trees",
            "data",
            "with",
            "the",
            "income",
            "data",
            "by",
            "ZIP",
            "code,",
            "filling",
            "missing",
            "ZIP",
            "values",
            "where",
            "necessary,",
            "which",
            "three",
            "boroughs,",
            "restricted",
            "to",
            "records",
            "with",
            "median",
            "and",
            "mean",
            "income",
            "both",
            "greater",
            "than",
            "zero",
            "and",
            "a",
            "valid",
            "borough",
            "name,",
            "contain",
            "the",
            "highest",
            "number",
            "of",
            "trees,",
            "and",
            "what",
            "is",
            "the",
            "average",
            "mean",
            "income",
            "for",
            "each",
            "of",
            "these",
            "three",
            "boroughs?"
        ],
        "query": "",
        "db_id": "modern_data",
        "No. of candidate columns": 77,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local060",
        "question": "In the United States, for Q4 2019 and Q4 2020, first select only those cities where total sales (with no promotions) rose by at least 20% from Q4 2019 to Q4 2020. Among these cities, rank products by their overall sales (still excluding promotions) in those quarters and take the top 20%. Then compute each top product’s share of total sales in Q4 2019 and Q4 2020 and calculate the difference in share from Q4 2019 to Q4 2020, returning the results in descending order of that share change.",
        "external_knowledge": null,
        "question_toks": [
            "In",
            "the",
            "United",
            "States,",
            "for",
            "Q4",
            "2019",
            "and",
            "Q4",
            "2020,",
            "first",
            "select",
            "only",
            "those",
            "cities",
            "where",
            "total",
            "sales",
            "(with",
            "no",
            "promotions)",
            "rose",
            "by",
            "at",
            "least",
            "20%",
            "from",
            "Q4",
            "2019",
            "to",
            "Q4",
            "2020.",
            "Among",
            "these",
            "cities,",
            "rank",
            "products",
            "by",
            "their",
            "overall",
            "sales",
            "(still",
            "excluding",
            "promotions)",
            "in",
            "those",
            "quarters",
            "and",
            "take",
            "the",
            "top",
            "20%.",
            "Then",
            "compute",
            "each",
            "top",
            "product’s",
            "share",
            "of",
            "total",
            "sales",
            "in",
            "Q4",
            "2019",
            "and",
            "Q4",
            "2020",
            "and",
            "calculate",
            "the",
            "difference",
            "in",
            "share",
            "from",
            "Q4",
            "2019",
            "to",
            "Q4",
            "2020,",
            "returning",
            "the",
            "results",
            "in",
            "descending",
            "order",
            "of",
            "that",
            "share",
            "change."
        ],
        "query": "",
        "db_id": "complex_oracle",
        "No. of candidate columns": 140,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local063",
        "question": "Among all products sold in the United States with promo_id=999, considering only those cities whose sales increased by at least 20% from Q4 2019 (calendar_quarter_id=1772) to Q4 2020 (calendar_quarter_id=1776), which product that ranks in the top 20% of total sales has the smallest percentage-point change in its share of total sales between these two quarters?",
        "external_knowledge": null,
        "question_toks": [
            "Among",
            "all",
            "products",
            "sold",
            "in",
            "the",
            "United",
            "States",
            "with",
            "promo_id=999,",
            "considering",
            "only",
            "those",
            "cities",
            "whose",
            "sales",
            "increased",
            "by",
            "at",
            "least",
            "20%",
            "from",
            "Q4",
            "2019",
            "(calendar_quarter_id=1772)",
            "to",
            "Q4",
            "2020",
            "(calendar_quarter_id=1776),",
            "which",
            "product",
            "that",
            "ranks",
            "in",
            "the",
            "top",
            "20%",
            "of",
            "total",
            "sales",
            "has",
            "the",
            "smallest",
            "percentage-point",
            "change",
            "in",
            "its",
            "share",
            "of",
            "total",
            "sales",
            "between",
            "these",
            "two",
            "quarters?"
        ],
        "query": "",
        "db_id": "complex_oracle",
        "No. of candidate columns": 140,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local061",
        "question": "What is the average projected monthly sales in USD for France in 2021, considering only product sales with promotions where promo_total_id = 1 and channels where channel_total_id = 1, by taking each product’s monthly sales from 2019 and 2020, calculating the growth rate from 2019 to 2020 for that same product and month, applying this growth rate to project 2021 monthly sales, converting all projected 2021 amounts to USD with the 2021 exchange rates, and finally averaging and listing them by month?",
        "external_knowledge": "projection_calculation.md",
        "question_toks": [
            "What",
            "is",
            "the",
            "average",
            "projected",
            "monthly",
            "sales",
            "in",
            "USD",
            "for",
            "France",
            "in",
            "2021,",
            "considering",
            "only",
            "product",
            "sales",
            "with",
            "promotions",
            "where",
            "promo_total_id",
            "=",
            "1",
            "and",
            "channels",
            "where",
            "channel_total_id",
            "=",
            "1,",
            "by",
            "taking",
            "each",
            "product’s",
            "monthly",
            "sales",
            "from",
            "2019",
            "and",
            "2020,",
            "calculating",
            "the",
            "growth",
            "rate",
            "from",
            "2019",
            "to",
            "2020",
            "for",
            "that",
            "same",
            "product",
            "and",
            "month,",
            "applying",
            "this",
            "growth",
            "rate",
            "to",
            "project",
            "2021",
            "monthly",
            "sales,",
            "converting",
            "all",
            "projected",
            "2021",
            "amounts",
            "to",
            "USD",
            "with",
            "the",
            "2021",
            "exchange",
            "rates,",
            "and",
            "finally",
            "averaging",
            "and",
            "listing",
            "them",
            "by",
            "month?"
        ],
        "query": "",
        "db_id": "complex_oracle",
        "No. of candidate columns": 140,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local050",
        "question": "What is the median of the average monthly projected sales in USD for France in 2021, calculated by using the monthly sales data from 2019 and 2020 (filtered by promo_total_id=1 and channel_total_id=1), applying the growth rate from 2019 to 2020 to project 2021, converting to USD based on the currency table, and then determining the monthly averages before finding their median?",
        "external_knowledge": "projection_calculation.md",
        "question_toks": [
            "What",
            "is",
            "the",
            "median",
            "of",
            "the",
            "average",
            "monthly",
            "projected",
            "sales",
            "in",
            "USD",
            "for",
            "France",
            "in",
            "2021,",
            "calculated",
            "by",
            "using",
            "the",
            "monthly",
            "sales",
            "data",
            "from",
            "2019",
            "and",
            "2020",
            "(filtered",
            "by",
            "promo_total_id=1",
            "and",
            "channel_total_id=1),",
            "applying",
            "the",
            "growth",
            "rate",
            "from",
            "2019",
            "to",
            "2020",
            "to",
            "project",
            "2021,",
            "converting",
            "to",
            "USD",
            "based",
            "on",
            "the",
            "currency",
            "table,",
            "and",
            "then",
            "determining",
            "the",
            "monthly",
            "averages",
            "before",
            "finding",
            "their",
            "median?"
        ],
        "query": "",
        "db_id": "complex_oracle",
        "No. of candidate columns": 140,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local062",
        "question": "Please group all Italian customers into ten buckets for December 2021 by summing their profits from all products purchased (where profit is calculated as quantity_sold multiplied by the difference between unit_price and unit_cost), then divide the overall range of total monthly profits into ten equal intervals. For each bucket, provide the number of customers, and identify the minimum and maximum total profits within that bucket.",
        "external_knowledge": null,
        "question_toks": [
            "Please",
            "group",
            "all",
            "Italian",
            "customers",
            "into",
            "ten",
            "buckets",
            "for",
            "December",
            "2021",
            "by",
            "summing",
            "their",
            "profits",
            "from",
            "all",
            "products",
            "purchased",
            "(where",
            "profit",
            "is",
            "calculated",
            "as",
            "quantity_sold",
            "multiplied",
            "by",
            "the",
            "difference",
            "between",
            "unit_price",
            "and",
            "unit_cost),",
            "then",
            "divide",
            "the",
            "overall",
            "range",
            "of",
            "total",
            "monthly",
            "profits",
            "into",
            "ten",
            "equal",
            "intervals.",
            "For",
            "each",
            "bucket,",
            "provide",
            "the",
            "number",
            "of",
            "customers,",
            "and",
            "identify",
            "the",
            "minimum",
            "and",
            "maximum",
            "total",
            "profits",
            "within",
            "that",
            "bucket."
        ],
        "query": "",
        "db_id": "complex_oracle",
        "No. of candidate columns": 140,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local073",
        "question": "For each pizza order, please list a single result row containing the row ID, order ID, customer ID, pizza name, and the final set of ingredients. The final set of ingredients should be determined by taking the standard toppings from the pizza’s recipe, removing any toppings specified as exclusions, then adding any toppings specified as extras. The resulting ingredients must be presented in alphabetical order, prefixed by ‘2x’ if the same ingredient appears multiple times (for example, if both standard and extra or added multiple times), and concatenated into a string that begins with the pizza name followed by ‘: ’. Group by row ID, order ID, pizza name, and order time so that each order appears once, and return the listing of toppings in ascending order by row ID, ensuring that ‘Meatlovers’ pizzas receive a pizza_id of 1 while all others receive a pizza_id of 2.",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "each",
            "pizza",
            "order,",
            "please",
            "list",
            "a",
            "single",
            "result",
            "row",
            "containing",
            "the",
            "row",
            "ID,",
            "order",
            "ID,",
            "customer",
            "ID,",
            "pizza",
            "name,",
            "and",
            "the",
            "final",
            "set",
            "of",
            "ingredients.",
            "The",
            "final",
            "set",
            "of",
            "ingredients",
            "should",
            "be",
            "determined",
            "by",
            "taking",
            "the",
            "standard",
            "toppings",
            "from",
            "the",
            "pizza’s",
            "recipe,",
            "removing",
            "any",
            "toppings",
            "specified",
            "as",
            "exclusions,",
            "then",
            "adding",
            "any",
            "toppings",
            "specified",
            "as",
            "extras.",
            "The",
            "resulting",
            "ingredients",
            "must",
            "be",
            "presented",
            "in",
            "alphabetical",
            "order,",
            "prefixed",
            "by",
            "‘2x’",
            "if",
            "the",
            "same",
            "ingredient",
            "appears",
            "multiple",
            "times",
            "(for",
            "example,",
            "if",
            "both",
            "standard",
            "and",
            "extra",
            "or",
            "added",
            "multiple",
            "times),",
            "and",
            "concatenated",
            "into",
            "a",
            "string",
            "that",
            "begins",
            "with",
            "the",
            "pizza",
            "name",
            "followed",
            "by",
            "‘:",
            "’.",
            "Group",
            "by",
            "row",
            "ID,",
            "order",
            "ID,",
            "pizza",
            "name,",
            "and",
            "order",
            "time",
            "so",
            "that",
            "each",
            "order",
            "appears",
            "once,",
            "and",
            "return",
            "the",
            "listing",
            "of",
            "toppings",
            "in",
            "ascending",
            "order",
            "by",
            "row",
            "ID,",
            "ensuring",
            "that",
            "‘Meatlovers’",
            "pizzas",
            "receive",
            "a",
            "pizza_id",
            "of",
            "1",
            "while",
            "all",
            "others",
            "receive",
            "a",
            "pizza_id",
            "of",
            "2."
        ],
        "query": "",
        "db_id": "modern_data",
        "No. of candidate columns": 77,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local064",
        "question": "For each customer and each month of 2020, first calculate the month-end balance by adding all deposit amounts and subtracting all withdrawal amounts that occurred during that specific month. Then determine which month in 2020 has the highest count of customers with a positive month-end balance and which month has the lowest count. For each of these two months, compute the average month-end balance across all customers and provide the difference between these two averages",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "each",
            "customer",
            "and",
            "each",
            "month",
            "of",
            "2020,",
            "first",
            "calculate",
            "the",
            "month-end",
            "balance",
            "by",
            "adding",
            "all",
            "deposit",
            "amounts",
            "and",
            "subtracting",
            "all",
            "withdrawal",
            "amounts",
            "that",
            "occurred",
            "during",
            "that",
            "specific",
            "month.",
            "Then",
            "determine",
            "which",
            "month",
            "in",
            "2020",
            "has",
            "the",
            "highest",
            "count",
            "of",
            "customers",
            "with",
            "a",
            "positive",
            "month-end",
            "balance",
            "and",
            "which",
            "month",
            "has",
            "the",
            "lowest",
            "count.",
            "For",
            "each",
            "of",
            "these",
            "two",
            "months,",
            "compute",
            "the",
            "average",
            "month-end",
            "balance",
            "across",
            "all",
            "customers",
            "and",
            "provide",
            "the",
            "difference",
            "between",
            "these",
            "two",
            "averages"
        ],
        "query": "",
        "db_id": "bank_sales_trading",
        "No. of candidate columns": 106,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local297",
        "question": "For each customer, group all deposits and withdrawals by the first day of each month to obtain a monthly net amount, then calculate each month’s closing balance by cumulatively summing these monthly nets. Next, determine the most recent month’s growth rate by comparing its closing balance to the prior month’s balance, treating deposits as positive and withdrawals as negative, and if the previous month’s balance is zero, the growth rate should be the current month’s balance multiplied by 100. Finally, compute the percentage of customers whose most recent month shows a growth rate of more than 5%.",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "each",
            "customer,",
            "group",
            "all",
            "deposits",
            "and",
            "withdrawals",
            "by",
            "the",
            "first",
            "day",
            "of",
            "each",
            "month",
            "to",
            "obtain",
            "a",
            "monthly",
            "net",
            "amount,",
            "then",
            "calculate",
            "each",
            "month’s",
            "closing",
            "balance",
            "by",
            "cumulatively",
            "summing",
            "these",
            "monthly",
            "nets.",
            "Next,",
            "determine",
            "the",
            "most",
            "recent",
            "month’s",
            "growth",
            "rate",
            "by",
            "comparing",
            "its",
            "closing",
            "balance",
            "to",
            "the",
            "prior",
            "month’s",
            "balance,",
            "treating",
            "deposits",
            "as",
            "positive",
            "and",
            "withdrawals",
            "as",
            "negative,",
            "and",
            "if",
            "the",
            "previous",
            "month’s",
            "balance",
            "is",
            "zero,",
            "the",
            "growth",
            "rate",
            "should",
            "be",
            "the",
            "current",
            "month’s",
            "balance",
            "multiplied",
            "by",
            "100.",
            "Finally,",
            "compute",
            "the",
            "percentage",
            "of",
            "customers",
            "whose",
            "most",
            "recent",
            "month",
            "shows",
            "a",
            "growth",
            "rate",
            "of",
            "more",
            "than",
            "5%."
        ],
        "query": "",
        "db_id": "bank_sales_trading",
        "No. of candidate columns": 106,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local098",
        "question": "From the first year each actor appeared in a film to the last, how many actors in the database never had a gap longer than three consecutive years without at least one new movie appearance, meaning there is no four-year span anywhere in their active career without at least a single film credit?",
        "external_knowledge": null,
        "question_toks": [
            "From",
            "the",
            "first",
            "year",
            "each",
            "actor",
            "appeared",
            "in",
            "a",
            "film",
            "to",
            "the",
            "last,",
            "how",
            "many",
            "actors",
            "in",
            "the",
            "database",
            "never",
            "had",
            "a",
            "gap",
            "longer",
            "than",
            "three",
            "consecutive",
            "years",
            "without",
            "at",
            "least",
            "one",
            "new",
            "movie",
            "appearance,",
            "meaning",
            "there",
            "is",
            "no",
            "four-year",
            "span",
            "anywhere",
            "in",
            "their",
            "active",
            "career",
            "without",
            "at",
            "least",
            "a",
            "single",
            "film",
            "credit?"
        ],
        "query": "",
        "db_id": "Db-IMDB",
        "No. of candidate columns": 50,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local157",
        "question": "Using the \"bitcoin_prices\" table, please calculate the daily percentage change in trading volume for each ticker from August 1 to August 10, 2021, ensuring that any volume ending in \"K\" or \"M\" is accurately converted to thousands or millions, any \"-\" volume is treated as zero, only non-zero volumes are used to determine the previous day's volume, and the results are ordered by ticker and date.",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "the",
            "\"bitcoin_prices\"",
            "table,",
            "please",
            "calculate",
            "the",
            "daily",
            "percentage",
            "change",
            "in",
            "trading",
            "volume",
            "for",
            "each",
            "ticker",
            "from",
            "August",
            "1",
            "to",
            "August",
            "10,",
            "2021,",
            "ensuring",
            "that",
            "any",
            "volume",
            "ending",
            "in",
            "\"K\"",
            "or",
            "\"M\"",
            "is",
            "accurately",
            "converted",
            "to",
            "thousands",
            "or",
            "millions,",
            "any",
            "\"-\"",
            "volume",
            "is",
            "treated",
            "as",
            "zero,",
            "only",
            "non-zero",
            "volumes",
            "are",
            "used",
            "to",
            "determine",
            "the",
            "previous",
            "day's",
            "volume,",
            "and",
            "the",
            "results",
            "are",
            "ordered",
            "by",
            "ticker",
            "and",
            "date."
        ],
        "query": "",
        "db_id": "bank_sales_trading",
        "No. of candidate columns": 106,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local168",
        "question": "Among job postings that specifically have the Data Analyst, require a non-null annual average salary, and are remote, what is the overall average salary when considering only the top three most frequently demanded skills for these positions?",
        "external_knowledge": null,
        "question_toks": [
            "Among",
            "job",
            "postings",
            "that",
            "specifically",
            "have",
            "the",
            "Data",
            "Analyst,",
            "require",
            "a",
            "non-null",
            "annual",
            "average",
            "salary,",
            "and",
            "are",
            "remote,",
            "what",
            "is",
            "the",
            "overall",
            "average",
            "salary",
            "when",
            "considering",
            "only",
            "the",
            "top",
            "three",
            "most",
            "frequently",
            "demanded",
            "skills",
            "for",
            "these",
            "positions?"
        ],
        "query": "",
        "db_id": "city_legislation",
        "No. of candidate columns": 133,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local253",
        "question": "Using a Salary Dataset where the salary values need to be cleaned by removing non-numeric characters and converting them to a numeric type, write a detailed SQL query that identifies the top 5 companies by average salary in each of Mumbai, Pune, New Delhi, and Hyderabad, then compares each company’s average salary in those cities to the overall national average salary. The final result should display four columns: Location, Company Name, Average Salary in State, and Average Salary in Country, listing only the top 5 companies in each of the specified locations.",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "a",
            "Salary",
            "Dataset",
            "where",
            "the",
            "salary",
            "values",
            "need",
            "to",
            "be",
            "cleaned",
            "by",
            "removing",
            "non-numeric",
            "characters",
            "and",
            "converting",
            "them",
            "to",
            "a",
            "numeric",
            "type,",
            "write",
            "a",
            "detailed",
            "SQL",
            "query",
            "that",
            "identifies",
            "the",
            "top",
            "5",
            "companies",
            "by",
            "average",
            "salary",
            "in",
            "each",
            "of",
            "Mumbai,",
            "Pune,",
            "New",
            "Delhi,",
            "and",
            "Hyderabad,",
            "then",
            "compares",
            "each",
            "company’s",
            "average",
            "salary",
            "in",
            "those",
            "cities",
            "to",
            "the",
            "overall",
            "national",
            "average",
            "salary.",
            "The",
            "final",
            "result",
            "should",
            "display",
            "four",
            "columns:",
            "Location,",
            "Company",
            "Name,",
            "Average",
            "Salary",
            "in",
            "State,",
            "and",
            "Average",
            "Salary",
            "in",
            "Country,",
            "listing",
            "only",
            "the",
            "top",
            "5",
            "companies",
            "in",
            "each",
            "of",
            "the",
            "specified",
            "locations."
        ],
        "query": "",
        "db_id": "education_business",
        "No. of candidate columns": 98,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local269",
        "question": "What is the average total quantity across all final packaging combinations, considering only the leaf-level items within each combination after fully expanding any nested packaging relationships?",
        "external_knowledge": null,
        "question_toks": [
            "What",
            "is",
            "the",
            "average",
            "total",
            "quantity",
            "across",
            "all",
            "final",
            "packaging",
            "combinations,",
            "considering",
            "only",
            "the",
            "leaf-level",
            "items",
            "within",
            "each",
            "combination",
            "after",
            "fully",
            "expanding",
            "any",
            "nested",
            "packaging",
            "relationships?"
        ],
        "query": "",
        "db_id": "oracle_sql",
        "No. of candidate columns": 124,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local270",
        "question": "Which top-level packaging containers, meaning those not contained within any other packaging, have any item for which the total quantity accumulated across all nested levels in the hierarchy exceeds 500, and what are the names of both these containers and the corresponding items?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "top-level",
            "packaging",
            "containers,",
            "meaning",
            "those",
            "not",
            "contained",
            "within",
            "any",
            "other",
            "packaging,",
            "have",
            "any",
            "item",
            "for",
            "which",
            "the",
            "total",
            "quantity",
            "accumulated",
            "across",
            "all",
            "nested",
            "levels",
            "in",
            "the",
            "hierarchy",
            "exceeds",
            "500,",
            "and",
            "what",
            "are",
            "the",
            "names",
            "of",
            "both",
            "these",
            "containers",
            "and",
            "the",
            "corresponding",
            "items?"
        ],
        "query": "",
        "db_id": "oracle_sql",
        "No. of candidate columns": 124,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local273",
        "question": "Calculate the average pick percentage for each product name, using a first-in-first-out approach that selects from inventory locations based on the earliest purchase date and smallest available quantity, ensuring that the picked quantity reflects only the overlapping range between each order’s required quantity and the inventory’s available quantity, and then grouping and ordering the results by product name?",
        "external_knowledge": null,
        "question_toks": [
            "Calculate",
            "the",
            "average",
            "pick",
            "percentage",
            "for",
            "each",
            "product",
            "name,",
            "using",
            "a",
            "first-in-first-out",
            "approach",
            "that",
            "selects",
            "from",
            "inventory",
            "locations",
            "based",
            "on",
            "the",
            "earliest",
            "purchase",
            "date",
            "and",
            "smallest",
            "available",
            "quantity,",
            "ensuring",
            "that",
            "the",
            "picked",
            "quantity",
            "reflects",
            "only",
            "the",
            "overlapping",
            "range",
            "between",
            "each",
            "order’s",
            "required",
            "quantity",
            "and",
            "the",
            "inventory’s",
            "available",
            "quantity,",
            "and",
            "then",
            "grouping",
            "and",
            "ordering",
            "the",
            "results",
            "by",
            "product",
            "name?"
        ],
        "query": "",
        "db_id": "oracle_sql",
        "No. of candidate columns": 124,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local275",
        "question": "Based on monthly sales data starting in January 2016 and using a centered moving average to adjust for seasonality, which products had a seasonality-adjusted sales ratio that stayed consistently above 2 for every month in the year 2017?",
        "external_knowledge": "calculation_method.md",
        "question_toks": [
            "Based",
            "on",
            "monthly",
            "sales",
            "data",
            "starting",
            "in",
            "January",
            "2016",
            "and",
            "using",
            "a",
            "centered",
            "moving",
            "average",
            "to",
            "adjust",
            "for",
            "seasonality,",
            "which",
            "products",
            "had",
            "a",
            "seasonality-adjusted",
            "sales",
            "ratio",
            "that",
            "stayed",
            "consistently",
            "above",
            "2",
            "for",
            "every",
            "month",
            "in",
            "the",
            "year",
            "2017?"
        ],
        "query": "",
        "db_id": "oracle_sql",
        "No. of candidate columns": 124,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local277",
        "question": "What is the average forecasted annual sales for products 4160 and 7790 during 2018, using monthly sales data starting from January 2016 for the first 36 months, applying seasonality adjustments from time steps 7 through 30, and employing a weighted regression method to estimate sales?",
        "external_knowledge": "calculation_method.md",
        "question_toks": [
            "What",
            "is",
            "the",
            "average",
            "forecasted",
            "annual",
            "sales",
            "for",
            "products",
            "4160",
            "and",
            "7790",
            "during",
            "2018,",
            "using",
            "monthly",
            "sales",
            "data",
            "starting",
            "from",
            "January",
            "2016",
            "for",
            "the",
            "first",
            "36",
            "months,",
            "applying",
            "seasonality",
            "adjustments",
            "from",
            "time",
            "steps",
            "7",
            "through",
            "30,",
            "and",
            "employing",
            "a",
            "weighted",
            "regression",
            "method",
            "to",
            "estimate",
            "sales?"
        ],
        "query": "",
        "db_id": "oracle_sql",
        "No. of candidate columns": 124,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local279",
        "question": "Using a recursive monthly inventory adjustment model starting from December 2018 inventory levels, where we restock a product if its ending inventory drops below the minimum required level, determine for each product the month in 2019 where the absolute difference between its ending inventory and the minimum required level is the smallest, and return the product_id, that month, and the absolute difference.",
        "external_knowledge": null,
        "question_toks": [
            "Using",
            "a",
            "recursive",
            "monthly",
            "inventory",
            "adjustment",
            "model",
            "starting",
            "from",
            "December",
            "2018",
            "inventory",
            "levels,",
            "where",
            "we",
            "restock",
            "a",
            "product",
            "if",
            "its",
            "ending",
            "inventory",
            "drops",
            "below",
            "the",
            "minimum",
            "required",
            "level,",
            "determine",
            "for",
            "each",
            "product",
            "the",
            "month",
            "in",
            "2019",
            "where",
            "the",
            "absolute",
            "difference",
            "between",
            "its",
            "ending",
            "inventory",
            "and",
            "the",
            "minimum",
            "required",
            "level",
            "is",
            "the",
            "smallest,",
            "and",
            "return",
            "the",
            "product_id,",
            "that",
            "month,",
            "and",
            "the",
            "absolute",
            "difference."
        ],
        "query": "",
        "db_id": "oracle_sql",
        "No. of candidate columns": 124,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local283",
        "question": "Analyze the soccer match dataset to determine the champion team for each season across all countries and leagues, awarding 3 points for every win, 1 point for every tie, and 0 points for every loss. For each season, return the champion’s team name, the league, the country, and the total points accumulated.",
        "external_knowledge": null,
        "question_toks": [
            "Analyze",
            "the",
            "soccer",
            "match",
            "dataset",
            "to",
            "determine",
            "the",
            "champion",
            "team",
            "for",
            "each",
            "season",
            "across",
            "all",
            "countries",
            "and",
            "leagues,",
            "awarding",
            "3",
            "points",
            "for",
            "every",
            "win,",
            "1",
            "point",
            "for",
            "every",
            "tie,",
            "and",
            "0",
            "points",
            "for",
            "every",
            "loss.",
            "For",
            "each",
            "season,",
            "return",
            "the",
            "champion’s",
            "team",
            "name,",
            "the",
            "league,",
            "the",
            "country,",
            "and",
            "the",
            "total",
            "points",
            "accumulated."
        ],
        "query": "",
        "db_id": "EU_soccer",
        "No. of candidate columns": 233,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local331",
        "question": "Which three distinct third-page visits are most frequently observed immediately after two consecutive visits to the '/detail' page, and how many times does each third-page visit occur?",
        "external_knowledge": null,
        "question_toks": [
            "Which",
            "three",
            "distinct",
            "third-page",
            "visits",
            "are",
            "most",
            "frequently",
            "observed",
            "immediately",
            "after",
            "two",
            "consecutive",
            "visits",
            "to",
            "the",
            "'/detail'",
            "page,",
            "and",
            "how",
            "many",
            "times",
            "does",
            "each",
            "third-page",
            "visit",
            "occur?"
        ],
        "query": "",
        "db_id": "log",
        "No. of candidate columns": 88,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local344",
        "question": "Considering all races where pit stop data is available, and focusing on instances when a driver was not behind another car on the previous lap but is behind on the current lap (accounting for retirements, pit-stop entries, pit-stop exits, and race starts), how many times has each type of overtake occurred in Formula 1?",
        "external_knowledge": "f1_overtake.md",
        "question_toks": [
            "Considering",
            "all",
            "races",
            "where",
            "pit",
            "stop",
            "data",
            "is",
            "available,",
            "and",
            "focusing",
            "on",
            "instances",
            "when",
            "a",
            "driver",
            "was",
            "not",
            "behind",
            "another",
            "car",
            "on",
            "the",
            "previous",
            "lap",
            "but",
            "is",
            "behind",
            "on",
            "the",
            "current",
            "lap",
            "(accounting",
            "for",
            "retirements,",
            "pit-stop",
            "entries,",
            "pit-stop",
            "exits,",
            "and",
            "race",
            "starts),",
            "how",
            "many",
            "times",
            "has",
            "each",
            "type",
            "of",
            "overtake",
            "occurred",
            "in",
            "Formula",
            "1?"
        ],
        "query": "",
        "db_id": "f1",
        "No. of candidate columns": 228,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local336",
        "question": "In the first five laps of the race, how many overtakes occurred in each category—retirements, pit stops, start-related overtakes, and standard on-track passes?",
        "external_knowledge": "f1_overtake.md",
        "question_toks": [
            "In",
            "the",
            "first",
            "five",
            "laps",
            "of",
            "the",
            "race,",
            "how",
            "many",
            "overtakes",
            "occurred",
            "in",
            "each",
            "category—retirements,",
            "pit",
            "stops,",
            "start-related",
            "overtakes,",
            "and",
            "standard",
            "on-track",
            "passes?"
        ],
        "query": "",
        "db_id": "f1",
        "No. of candidate columns": 228,
        "No. of gold tables": 0
    },
    {
        "instance_id": "local354",
        "question": "Among Formula 1 drivers who raced during the 1950s, which drivers completed a season in that decade with the same constructor in both the first and the last race they participated in, while also taking part in at least two distinct race rounds during that season?",
        "external_knowledge": null,
        "question_toks": [
            "Among",
            "Formula",
            "1",
            "drivers",
            "who",
            "raced",
            "during",
            "the",
            "1950s,",
            "which",
            "drivers",
            "completed",
            "a",
            "season",
            "in",
            "that",
            "decade",
            "with",
            "the",
            "same",
            "constructor",
            "in",
            "both",
            "the",
            "first",
            "and",
            "the",
            "last",
            "race",
            "they",
            "participated",
            "in,",
            "while",
            "also",
            "taking",
            "part",
            "in",
            "at",
            "least",
            "two",
            "distinct",
            "race",
            "rounds",
            "during",
            "that",
            "season?"
        ],
        "query": "",
        "db_id": "f1",
        "No. of candidate columns": 228,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf006",
        "question": "For each U.S. state, find how the number of active financial branch entities has changed from March 1, 2020, to December 31, 2021. An entity is considered active on a specific date if its start date is on or before that date and its end date is either null or on or after that date. For each state, calculate the number of entities active on March 1, 2020, the number of entities active on December 31, 2021, and the percentage change in these counts",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "each",
            "U.S.",
            "state,",
            "find",
            "how",
            "the",
            "number",
            "of",
            "active",
            "financial",
            "branch",
            "entities",
            "has",
            "changed",
            "from",
            "March",
            "1,",
            "2020,",
            "to",
            "December",
            "31,",
            "2021.",
            "An",
            "entity",
            "is",
            "considered",
            "active",
            "on",
            "a",
            "specific",
            "date",
            "if",
            "its",
            "start",
            "date",
            "is",
            "on",
            "or",
            "before",
            "that",
            "date",
            "and",
            "its",
            "end",
            "date",
            "is",
            "either",
            "null",
            "or",
            "on",
            "or",
            "after",
            "that",
            "date.",
            "For",
            "each",
            "state,",
            "calculate",
            "the",
            "number",
            "of",
            "entities",
            "active",
            "on",
            "March",
            "1,",
            "2020,",
            "the",
            "number",
            "of",
            "entities",
            "active",
            "on",
            "December",
            "31,",
            "2021,",
            "and",
            "the",
            "percentage",
            "change",
            "in",
            "these",
            "counts"
        ],
        "query": "",
        "db_id": "FINANCE__ECONOMICS",
        "No. of candidate columns": 441,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf037",
        "question": "How can we calculate the shortest straight-line distance in miles between each 'The Home Depot' store, identified by its POI ID, and its nearest 'Lowe's Home Improvement' store using the geographic coordinates and ensuring we only return the minimal distance for each 'The Home Depot' location?",
        "temporal": "Yes",
        "external_knowledge": null,
        "question_toks": [
            "How",
            "can",
            "we",
            "calculate",
            "the",
            "shortest",
            "straight-line",
            "distance",
            "in",
            "miles",
            "between",
            "each",
            "'The",
            "Home",
            "Depot'",
            "store,",
            "identified",
            "by",
            "its",
            "POI",
            "ID,",
            "and",
            "its",
            "nearest",
            "'Lowe's",
            "Home",
            "Improvement'",
            "store",
            "using",
            "the",
            "geographic",
            "coordinates",
            "and",
            "ensuring",
            "we",
            "only",
            "return",
            "the",
            "minimal",
            "distance",
            "for",
            "each",
            "'The",
            "Home",
            "Depot'",
            "location?"
        ],
        "query": "",
        "db_id": "US_REAL_ESTATE",
        "No. of candidate columns": 243,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf012",
        "question": "For each year from 2010 through 2019, what were the total building damage amounts and total contents damage amounts reported under the National Flood Insurance Program for the NFIP community named 'City Of New York,' grouped by each year of loss?",
        "external_knowledge": null,
        "question_toks": [
            "For",
            "each",
            "year",
            "from",
            "2010",
            "through",
            "2019,",
            "what",
            "were",
            "the",
            "total",
            "building",
            "damage",
            "amounts",
            "and",
            "total",
            "contents",
            "damage",
            "amounts",
            "reported",
            "under",
            "the",
            "National",
            "Flood",
            "Insurance",
            "Program",
            "for",
            "the",
            "NFIP",
            "community",
            "named",
            "'City",
            "Of",
            "New",
            "York,'",
            "grouped",
            "by",
            "each",
            "year",
            "of",
            "loss?"
        ],
        "query": "SELECT \n    YEAR(claims.date_of_loss)               AS year_of_loss,\n    claims.nfip_community_name,\n    SUM(claims.building_damage_amount) AS total_building_damage_amount,\n    SUM(claims.contents_damage_amount) AS total_contents_damage_amount\nFROM WEATHER__ENVIRONMENT.CYBERSYN.fema_national_flood_insurance_program_claim_index claims\nWHERE \n    claims.nfip_community_name = 'City Of New York' \n    AND year_of_loss >=2010 AND year_of_loss <=2019\nGROUP BY year_of_loss, claims.nfip_community_name\nORDER BY year_of_loss, claims.nfip_community_name;",
        "db_id": "WEATHER__ENVIRONMENT",
        "No. of candidate columns": 313,
        "No. of gold tables": 0
    },
    {
        "instance_id": "sf029",
        "question": "Generate a daily detailed sales report for each product under the 'Manufacturing' distributor view, covering the 30 days leading up to February 6, 2022, by joining the sales, traffic, inventory, and net PPM data on date, ASIN, program, period, and distributor_view. The report must include total ordered units, ordered revenue, average selling price, glance views, conversion rate, shipped units, shipped revenue, average net PPM, average procurable product OOS, total on-hand units and value, net received units and value, open purchase order quantities, unfilled customer ordered units, and average vendor confirmation rate, receive fill rate, sell-through rate, and vendor lead time.",
        "external_knowledge": null,
        "question_toks": [
            "Generate",
            "a",
            "daily",
            "detailed",
            "sales",
            "report",
            "for",
            "each",
            "product",
            "under",
            "the",
            "'Manufacturing'",
            "distributor",
            "view,",
            "covering",
            "the",
            "30",
            "days",
            "leading",
            "up",
            "to",
            "February",
            "6,",
            "2022,",
            "by",
            "joining",
            "the",
            "sales,",
            "traffic,",
            "inventory,",
            "and",
            "net",
            "PPM",
            "data",
            "on",
            "date,",
            "ASIN,",
            "program,",
            "period,",
            "and",
            "distributor_view.",
            "The",
            "report",
            "must",
            "include",
            "total",
            "ordered",
            "units,",
            "ordered",
            "revenue,",
            "average",
            "selling",
            "price,",
            "glance",
            "views,",
            "conversion",
            "rate,",
            "shipped",
            "units,",
            "shipped",
            "revenue,",
            "average",
            "net",
            "PPM,",
            "average",
            "procurable",
            "product",
            "OOS,",
            "total",
            "on-hand",
            "units",
            "and",
            "value,",
            "net",
            "received",
            "units",
            "and",
            "value,",
            "open",
            "purchase",
            "order",
            "quantities,",
            "unfilled",
            "customer",
            "ordered",
            "units,",
            "and",
            "average",
            "vendor",
            "confirmation",
            "rate,",
            "receive",
            "fill",
            "rate,",
            "sell-through",
            "rate,",
            "and",
            "vendor",
            "lead",
            "time."
        ],
        "query": "",
        "db_id": "AMAZON_VENDOR_ANALYTICS__SAMPLE_DATASET",
        "No. of candidate columns": 1237,
        "No. of gold tables": 0
    }
]